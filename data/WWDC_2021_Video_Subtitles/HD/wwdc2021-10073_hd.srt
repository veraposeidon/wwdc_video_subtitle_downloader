2
00:00:02,069 --> 00:00:07,074 line:-1
[music]


3
00:00:09.042 --> 00:00:10.177 line:-2 align:center
[David]
Hello.


4
00:00:10.210 --> 00:00:13.046 line:-2 align:center
I’m David,
an engineer from the ARKit team.


5
00:00:13,080 --> 00:00:15,682 line:-2
Today Christopher and I will be
sharing a broad range


6
00:00:15,716 --> 00:00:17,618 line:-1
of improvements to ARKit 5.


7
00:00:17,651 --> 00:00:21,321 line:-2
We’re excited to discuss
the changes coming to iOS 15.


8
00:00:21,355 --> 00:00:24,191 line:-2
This year, we’ve made many
upgrades across the board,


9
00:00:24,224 --> 00:00:27,661 line:-2
and we’ll be discussing
multiple features.


10
00:00:27,694 --> 00:00:29,696 line:-2
Before we do that,
we want to showcase


11
00:00:29.730 --> 00:00:32.432 line:-2 align:center
the experiences you all have
been building with LiDAR.


12
00:00:32,466 --> 00:00:35,169 line:-2
We’ve seen a variety
of LiDAR-enabled apps using


13
00:00:35,202 --> 00:00:38,772 line:-2
the scene reconstruction
and depth APIs: productivity,


14
00:00:38,805 --> 00:00:41,308 line:-2
photo filter effects,
entertainment,


15
00:00:41,341 --> 00:00:43,777 line:-2
and even games that you can play
in your living room.


16
00:00:43.810 --> 00:00:45.746 line:-2 align:center
We’re really happy
to see the creativity


17
00:00:45.779 --> 00:00:48.782 line:-2 align:center
and resourcefulness shown
by the ARKit community.


18
00:00:48.815 --> 00:00:51.852 line:-2 align:center
While you’re creating
these apps, we’re working hard


19
00:00:51,885 --> 00:00:54,388 line:-2
on bringing you
the world’s best AR framework


20
00:00:54,421 --> 00:00:56,924 line:-2
and pushing the boundaries
of what’s possible.


21
00:00:56,957 --> 00:01:00,694 line:-2
Let’s go over the changes
coming in ARKit 5.


22
00:01:00,727 --> 00:01:03,864 line:-2
First, we’ll share some updates
and best practices


23
00:01:03,897 --> 00:01:07,267 line:-2
for location anchors,
which enable AR experiences


24
00:01:07,301 --> 00:01:10,237 line:-1
in real-world outdoor locations.


25
00:01:10.270 --> 00:01:12.573 line:-1 align:center
Next we’ll cover App Clip Codes,


26
00:01:12.606 --> 00:01:14.775 line:-2 align:center
which are a great way
to discover app clips


27
00:01:14.808 --> 00:01:18.779 line:-2 align:center
and also allow you
to position your content in AR.


28
00:01:18,812 --> 00:01:21,248 line:-2
We’ll highlight some
improvements to face tracking


29
00:01:21.281 --> 00:01:23.817 line:-2 align:center
using the ultra-wide
front-facing camera


30
00:01:23,851 --> 00:01:26,620 line:-1
on the new iPad Pro.


31
00:01:26.653 --> 00:01:28.689 line:-2 align:center
And we’ll finish
with some enhancements


32
00:01:28.722 --> 00:01:31.091 line:-1 align:center
to ARKit motion capture.


33
00:01:31,124 --> 00:01:33,227 line:-2
We’ll begin
with location anchors,


34
00:01:33,260 --> 00:01:35,662 line:-2
where we’ve worked
to expand region support


35
00:01:35.696 --> 00:01:38.198 line:-2 align:center
and provide some quality
of life improvements.


36
00:01:38,232 --> 00:01:40,501 line:-2
We’ll also recommend
some best practices


37
00:01:40,534 --> 00:01:42,769 line:-1
for creating applications.


38
00:01:42.803 --> 00:01:46.507 line:-2 align:center
Location anchors were introduced
last year to allow placement


39
00:01:46,540 --> 00:01:50,077 line:-2
of AR content at a specific
latitude and longitude.


40
00:01:50.110 --> 00:01:52.145 line:-2 align:center
Their purpose is
to allow creation


41
00:01:52.179 --> 00:01:56.049 line:-2 align:center
of AR experiences tied
to geographic locations.


42
00:01:56,083 --> 00:01:58,252 line:-1
Let’s take a look at an example.


43
00:01:58.285 --> 00:02:00.287 line:-2 align:center
This is
the New Nature experience


44
00:02:00.320 --> 00:02:02.122 line:-1 align:center
from the ScavengAR application,


45
00:02:02,155 --> 00:02:05,259 line:-2
built using
the location anchors API.


46
00:02:05,292 --> 00:02:08,929 line:-2
ScavengAR hosts AR content
at real-world locations


47
00:02:08,962 --> 00:02:10,330 line:-1
and enables the creation


48
00:02:10.364 --> 00:02:13.400 line:-2 align:center
of virtual public art
installations and activities.


49
00:02:13,433 --> 00:02:15,936 line:-2
It’s a good example
of how location anchors can


50
00:02:15,969 --> 00:02:19,306 line:-2
power outdoor experiences
as the world reopens.


51
00:02:19.339 --> 00:02:22.342 line:-2 align:center
The Maps app is also
introducing a new AR feature


52
00:02:22.376 --> 00:02:24.778 line:-1 align:center
that uses the API in iOS 15.


53
00:02:24.811 --> 00:02:26.480 line:-1 align:center
Let’s take a look.


54
00:02:26.513 --> 00:02:29.616 line:-2 align:center
This year Maps is adding
turn-by-turn walking directions


55
00:02:29,650 --> 00:02:32,819 line:-2
shown in AR,
using the location anchors API.


56
00:02:32.853 --> 00:02:35.656 line:-2 align:center
They incorporate several
practices we recommend.


57
00:02:35.689 --> 00:02:37.024 line:-1 align:center
We’ll cover these later on


58
00:02:37.057 --> 00:02:39.626 line:-2 align:center
to show how you can
build great applications.


59
00:02:39,660 --> 00:02:42,529 line:-2
Now that we’ve seen a few
samples, let’s recap how


60
00:02:42,563 --> 00:02:45,332 line:-2
location anchors can
be used to create them, starting


61
00:02:45.365 --> 00:02:48.969 line:-2 align:center
with the steps required to set
up a GeoTrackingConfiguration.


62
00:02:49,002 --> 00:02:52,973 line:-2
First, verify that the feature
is supported on the device.


63
00:02:53,006 --> 00:02:56,009 line:-2
Location anchors require
an A12 chip or newer


64
00:02:56,043 --> 00:02:58,979 line:-1
and cellular and GPS support.


65
00:02:59,012 --> 00:03:01,515 line:-2
Next, check
that the feature is available


66
00:03:01,548 --> 00:03:04,451 line:-2
at the location
before launching.


67
00:03:04.484 --> 00:03:07.254 line:-2 align:center
Camera and location permissions
must be approved


68
00:03:07.287 --> 00:03:08.555 line:-1 align:center
by the device owner.


69
00:03:08.589 --> 00:03:11.558 line:-2 align:center
ARKit will prompt
for permissions if needed.


70
00:03:11.592 --> 00:03:14.995 line:-2 align:center
Last year’s presentation
introducing ARKit 4


71
00:03:15.028 --> 00:03:18.498 line:-2 align:center
and the sample project,
“Tracking Geographic Locations


72
00:03:18,532 --> 00:03:23,036 line:-2
in AR,” cover all these topics
and API usage in greater depth.


73
00:03:23.070 --> 00:03:25.706 line:-2 align:center
We highly recommend
familiarizing yourself


74
00:03:25,739 --> 00:03:28,041 line:-1
with both of these sources.


75
00:03:28,075 --> 00:03:30,677 line:-2
This code sample shows how
to perform the checks


76
00:03:30.711 --> 00:03:32.246 line:-1 align:center
from the previous slide.


77
00:03:32.279 --> 00:03:35.516 line:-2 align:center
It queries for device support
and then verifies


78
00:03:35.549 --> 00:03:38.285 line:-2 align:center
if the feature is available
at the current location


79
00:03:38,318 --> 00:03:42,623 line:-2
before attempting to run
a GeoTrackingConfiguration.


80
00:03:42,656 --> 00:03:45,526 line:-2
GeoAnchors can then be
added to the ARSession


81
00:03:45.559 --> 00:03:47.094 line:-1 align:center
like other types of anchors.


82
00:03:47.127 --> 00:03:49.997 line:-2 align:center
They’re specified with
latitude-longitude coordinates


83
00:03:50.030 --> 00:03:52.633 line:-1 align:center
and, optionally, altitude.


84
00:03:52,666 --> 00:03:55,903 line:-2
It’s important to monitor
the GeoTrackingConfiguration’s


85
00:03:55.936 --> 00:03:58.872 line:-2 align:center
status to see if the feature has
localized


86
00:03:58,906 --> 00:04:01,608 line:-2
and what issues may
remain to be resolved.


87
00:04:01,642 --> 00:04:03,911 line:-2
The developer sample
contains an example


88
00:04:03,944 --> 00:04:07,347 line:-2
of how to implement a method
to receive status updates.


89
00:04:07,381 --> 00:04:10,517 line:-2
Checking availability near
the device location is important


90
00:04:10,551 --> 00:04:13,554 line:-2
for starting an application
with geo tracking.


91
00:04:13.587 --> 00:04:16.223 line:-2 align:center
We’re constantly working
to support more regions.


92
00:04:16.256 --> 00:04:19.092 line:-2 align:center
Location anchors were
limited to five metro areas


93
00:04:19.126 --> 00:04:21.662 line:-2 align:center
for their initial release
and, since then,


94
00:04:21,695 --> 00:04:27,301 line:-2
support has expanded to more
than 25 cities across the U.S.


95
00:04:27.334 --> 00:04:29.903 line:-2 align:center
We’re also working hard
to bring location anchors


96
00:04:29.937 --> 00:04:31.305 line:-1 align:center
to cities around the globe.


97
00:04:31.338 --> 00:04:33.674 line:-2 align:center
For the first time,
we’re excited to announce


98
00:04:33,707 --> 00:04:36,176 line:-2
a market
outside the United States.


99
00:04:36,210 --> 00:04:39,746 line:-2
Location anchors are
coming to London.


100
00:04:39.780 --> 00:04:43.016 line:-2 align:center
We’ll continue working
to add new regions over time.


101
00:04:43,050 --> 00:04:45,819 line:-2
If you don’t live
in a supported metro area,


102
00:04:45,853 --> 00:04:48,755 line:-2
you can also begin to experiment
with location anchors


103
00:04:48.789 --> 00:04:50.591 line:-2 align:center
through the use
of recording and replay,


104
00:04:50,624 --> 00:04:52,492 line:-2
which we’ll cover later
on in this session.


105
00:04:52,526 --> 00:04:54,494 line:-2
For the list
of supported regions,


106
00:04:54.528 --> 00:04:56.463 line:-2 align:center
refer
to the online documentation


107
00:04:56.496 --> 00:04:59.132 line:-2 align:center
for ARGeoTrackingConfiguration
at any time.


108
00:04:59.166 --> 00:05:02.336 line:-2 align:center
As location anchors become
available in more regions,


109
00:05:02.369 --> 00:05:05.072 line:-2 align:center
we recognize the need
to have a common visual language


110
00:05:05.105 --> 00:05:06.740 line:-1 align:center
to guide people.


111
00:05:06,773 --> 00:05:10,110 line:-2
To assist with a consistent
onboarding process, we’re adding


112
00:05:10,143 --> 00:05:14,314 line:-2
a new .geoTracking goal to use
with the ARCoachingOverlayView.


113
00:05:14.348 --> 00:05:18.285 line:-2 align:center
Similar to the existing overlay
for world tracking, it displays


114
00:05:18,318 --> 00:05:21,688 line:-2
an animation to help people
achieve a good experience.


115
00:05:21,722 --> 00:05:25,158 line:-2
Since coaching overlays are used
across many different AR apps,


116
00:05:25.192 --> 00:05:27.661 line:-2 align:center
including Maps,
people will already have


117
00:05:27.694 --> 00:05:30.531 line:-2 align:center
some familiarity with them
and know how to respond.


118
00:05:30.564 --> 00:05:33.066 line:-2 align:center
We encourage you
to include the coaching overlay


119
00:05:33,100 --> 00:05:35,869 line:-2
to ease the learning curve
for this feature.


120
00:05:35.903 --> 00:05:39.673 line:-2 align:center
Even while using the coaching
overlays, it’s still recommended


121
00:05:39.706 --> 00:05:42.176 line:-2 align:center
to monitor
the .geoTracking status updates,


122
00:05:42.209 --> 00:05:45.612 line:-2 align:center
which contain more detailed
information on tracking state.


123
00:05:45.646 --> 00:05:48.682 line:-2 align:center
Here’s what the .geoTracking
coaching overlay looks like.


124
00:05:48,715 --> 00:05:51,451 line:-2
The UI shows an instruction
to point the device away


125
00:05:51.485 --> 00:05:55.155 line:-2 align:center
from the ground and then
towards building facades.


126
00:05:55,189 --> 00:05:57,691 line:-2
After a few seconds,
tracking succeeds,


127
00:05:57.724 --> 00:06:01.028 line:-2 align:center
and your app can place
geo-tracked content.


128
00:06:01,061 --> 00:06:03,764 line:-2
The code for displaying
this animation is very similar


129
00:06:03,797 --> 00:06:06,600 line:-2
to that used
for other coaching overlays.


130
00:06:06,633 --> 00:06:08,468 line:-2
What’s unique
is the introduction


131
00:06:08,502 --> 00:06:10,637 line:-2
of the .geoTracking
goal for the overlay.


132
00:06:10.671 --> 00:06:14.141 line:-2 align:center
Make sure to set this goal
to display the correct guide.


133
00:06:14,174 --> 00:06:16,243 line:-2
We’ve seen
how the coaching overlay can


134
00:06:16.276 --> 00:06:18.412 line:-2 align:center
create a uniform onboarding
process.


135
00:06:18,445 --> 00:06:20,781 line:-2
Now we’ll go over some
other best practices


136
00:06:20,814 --> 00:06:24,418 line:-2
that will help you create
geo-tracked AR experiences.


137
00:06:24,451 --> 00:06:27,187 line:-2
Our first recommendation
is to use recording


138
00:06:27.221 --> 00:06:29.289 line:-2 align:center
and replay
for faster development.


139
00:06:29,323 --> 00:06:32,292 line:-2
ARKit sessions can be recorded
on devices using


140
00:06:32.326 --> 00:06:36.230 line:-2 align:center
Reality Composer, which is
available on the App Store.


141
00:06:36,263 --> 00:06:39,233 line:-2
This is especially useful
for location anchors


142
00:06:39,266 --> 00:06:42,069 line:-2
so you don’t have
to go outside as often to test.


143
00:06:42,102 --> 00:06:46,106 line:-2
It also allows collaboration
with remotely located creators.


144
00:06:46.139 --> 00:06:49.776 line:-2 align:center
The recordings can be replayed
on a device using Xcode.


145
00:06:49.810 --> 00:06:52.880 line:-2 align:center
To avoid incompatibility issues,
it’s recommended


146
00:06:52.913 --> 00:06:56.049 line:-2 align:center
to use the same device
and iOS version.


147
00:06:56,083 --> 00:06:59,620 line:-2
This also works for other types
of ARKit applications.


148
00:06:59,653 --> 00:07:03,156 line:-2
Replay is not specific
to location anchors.


149
00:07:03,190 --> 00:07:07,694 line:-2
Let’s walk through the process
for capturing a recording.


150
00:07:07.728 --> 00:07:10.731 line:-1 align:center
To record, open Reality Composer


151
00:07:10.764 --> 00:07:13.367 line:-2 align:center
and tap for more options
in the upper right.


152
00:07:13.400 --> 00:07:17.437 line:-2 align:center
Then open the Developer pane
and select Record AR Session.


153
00:07:17.471 --> 00:07:20.007 line:-2 align:center
Make sure location services
are enabled.


154
00:07:20,040 --> 00:07:25,112 line:-2
Tap the red button to start
and stop the recording.


155
00:07:25.145 --> 00:07:28.015 line:-2 align:center
To replay the recording,
connect the device


156
00:07:28,048 --> 00:07:29,950 line:-1
to a computer running Xcode.


157
00:07:29,983 --> 00:07:33,787 line:-2
Click Edit Scheme and set
the ARKit Replay data option


158
00:07:33.820 --> 00:07:35.355 line:-1 align:center
for the run configuration.


159
00:07:35.389 --> 00:07:37.758 line:-1 align:center
Then run the application.


160
00:07:37,791 --> 00:07:40,661 line:-2
While recording and replay can
help speed up development,


161
00:07:40.694 --> 00:07:43.964 line:-2 align:center
there are other practices we
recommend for content placement.


162
00:07:43,997 --> 00:07:46,834 line:-2
Here’s a video
demonstrating these.


163
00:07:46,867 --> 00:07:50,504 line:-2
Notice how the AR content is
large and clearly visible,


164
00:07:50.537 --> 00:07:53.807 line:-2 align:center
and information is conveyed
without needing to be overlaid


165
00:07:53.841 --> 00:07:55.843 line:-2 align:center
with a structure
in the environment.


166
00:07:55.876 --> 00:07:57.778 line:-2 align:center
As a trade-off
between development time


167
00:07:57.811 --> 00:07:59.112 line:-1 align:center
and placement precision,


168
00:07:59,146 --> 00:08:01,849 line:-2
consider creating content
that floats in the air


169
00:08:01.882 --> 00:08:05.953 line:-2 align:center
rather than trying to closely
overlap real-world objects.


170
00:08:05.986 --> 00:08:07.888 line:-2 align:center
We have a few
other recommendations


171
00:08:07.921 --> 00:08:09.823 line:-1 align:center
for placing content.


172
00:08:09.857 --> 00:08:13.727 line:-2 align:center
To obtain latitude and longitude
coordinates to place objects,


173
00:08:13.760 --> 00:08:16.196 line:-2 align:center
use the Apple Maps app
and copy coordinates


174
00:08:16,230 --> 00:08:18,599 line:-2
with at least six digits
of precision.


175
00:08:18.632 --> 00:08:22.169 line:-2 align:center
The steps for this were shown in
the video introducing ARKit 4,


176
00:08:22.202 --> 00:08:25.072 line:-2 align:center
so please refer there
for more details.


177
00:08:25,105 --> 00:08:28,308 line:-2
When creating an application,
it’s also important


178
00:08:28,342 --> 00:08:30,511 line:-2
to adjust the altitude
of the content relative


179
00:08:30,544 --> 00:08:35,649 line:-2
to the location anchor as needed
to produce a good experience.


180
00:08:35.682 --> 00:08:38.919 line:-2 align:center
If the app requires more precise
content placement,


181
00:08:38.952 --> 00:08:40.954 line:-2 align:center
add the geo anchor
when the device is


182
00:08:40.988 --> 00:08:44.157 line:-2 align:center
within 50 meters
of its location.


183
00:08:44,191 --> 00:08:47,427 line:-2
If ARKit places the anchor
with precise altitude,


184
00:08:47,461 --> 00:08:50,063 line:-2
it will update the anchor’s
altitude source field


185
00:08:50,097 --> 00:08:52,199 line:-1
to indicate this.


186
00:08:52.232 --> 00:08:55.068 line:-2 align:center
The CLLocation class has
a method that can be used


187
00:08:55.102 --> 00:08:58.272 line:-2 align:center
to compute the distances
in meters between two points.


188
00:08:58.305 --> 00:09:00.274 line:-2 align:center
This can
be used to verify that someone


189
00:09:00.307 --> 00:09:03.477 line:-2 align:center
is close to a location
before adding an anchor.


190
00:09:03.510 --> 00:09:06.280 line:-2 align:center
This concludes our session
on location anchors.


191
00:09:06,313 --> 00:09:08,348 line:-2
There are more ways
to place AR content


192
00:09:08,382 --> 00:09:10,184 line:-1
in your apps using ARKit 5.


193
00:09:10,217 --> 00:09:11,952 line:-2
So let me hand it off
to Christopher,


194
00:09:11,985 --> 00:09:13,320 line:-1
who will tell you more.


195
00:09:13.353 --> 00:09:14.488 line:-2 align:center
[Christopher]
Thank you, David.


196
00:09:14.521 --> 00:09:15.556 line:-1 align:center
Hi, my name is Christopher,


197
00:09:15,589 --> 00:09:17,457 line:-2
and I’m an engineer
on the ARKit team.


198
00:09:17.491 --> 00:09:18.559 line:-1 align:center
I'm excited to tell you more


199
00:09:18.592 --> 00:09:20.761 line:-2 align:center
about the other great new
features in ARKit 5.


200
00:09:20.794 --> 00:09:23.063 line:-2 align:center
Let me start with App Clip Codes
in ARKit.


201
00:09:23.096 --> 00:09:25.098 line:-2 align:center
You probably remember
that we introduced App Clips


202
00:09:25.132 --> 00:09:26.834 line:-1 align:center
at WWDC last year.


203
00:09:26,867 --> 00:09:29,570 line:-2
An app clip is a small slice
of an app which takes people


204
00:09:29.603 --> 00:09:31.405 line:-2 align:center
through one contextual workflow
of your app


205
00:09:31,438 --> 00:09:33,340 line:-2
without having
to install the whole app.


206
00:09:33,373 --> 00:09:36,510 line:-2
Owing to its small file size,
an app clip saves download time


207
00:09:36.543 --> 00:09:38.145 line:-2 align:center
and instantly
takes people directly


208
00:09:38.178 --> 00:09:40.514 line:-2 align:center
to a specific part of the app
that’s highly relevant


209
00:09:40.547 --> 00:09:42.149 line:-1 align:center
to their context at the moment.


210
00:09:42.182 --> 00:09:44.218 line:-2 align:center
We also
introduced App Clip Codes,


211
00:09:44,251 --> 00:09:46,620 line:-2
which are a great way
for people to visually discover


212
00:09:46,653 --> 00:09:47,888 line:-1
and launch your app clips.


213
00:09:47.921 --> 00:09:50.057 line:-2 align:center
No trips
to the App Store necessary.


214
00:09:50.090 --> 00:09:51.925 line:-2 align:center
This is what App Clip Codes
look like.


215
00:09:51.959 --> 00:09:54.161 line:-2 align:center
They can come in a variety
of shapes and colors.


216
00:09:54,194 --> 00:09:56,296 line:-2
As the developer,
you can create a look


217
00:09:56,330 --> 00:09:57,998 line:-2
which works
best for your scenario.


218
00:09:58,031 --> 00:10:01,735 line:-2
You also decide what data
to encode in the App Clip Code


219
00:10:01.768 --> 00:10:04.972 line:-2 align:center
and which app clip is
associated with which code.


220
00:10:05.005 --> 00:10:07.975 line:-2 align:center
All App Clip Codes contain
a visual scannable pattern


221
00:10:08,008 --> 00:10:11,245 line:-2
and some, like the red, blue
and orange codes shown here,


222
00:10:11.278 --> 00:10:14.982 line:-2 align:center
also contain an NFC tag
for the user’s convenience.


223
00:10:15.015 --> 00:10:17.351 line:-2 align:center
People can scan the code
with their camera


224
00:10:17,384 --> 00:10:19,820 line:-2
or hold the phone
to the embedded NFC tag


225
00:10:19,853 --> 00:10:21,889 line:-2
to launch your associated
app clip.


226
00:10:21.922 --> 00:10:24.057 line:-1 align:center
And now, you can also recognize


227
00:10:24,091 --> 00:10:26,860 line:-2
and track App Clip Codes
in your AR experiences.


228
00:10:26.894 --> 00:10:29.463 line:-2 align:center
We’ll take a look at how that’s
done later in this session.


229
00:10:29,496 --> 00:10:32,065 line:-2
But first, let’s take
a look at this app clip


230
00:10:32,099 --> 00:10:34,568 line:-2
developed by Primer,
where they use an App Clip Code


231
00:10:34,601 --> 00:10:36,470 line:-1
to launch an AR experience.


232
00:10:36,503 --> 00:10:38,372 line:-1
Primer partnered with Cle Tile


233
00:10:38.405 --> 00:10:39.973 line:-2 align:center
to show
people what their samples


234
00:10:40,007 --> 00:10:43,010 line:-2
will look like in AR
with the help of App Clip Codes.


235
00:10:43,043 --> 00:10:44,845 line:-2
Simply place your iPhone
and iPad


236
00:10:44,878 --> 00:10:47,948 line:-2
over the App Clip Code
to invoke an AR experience.


237
00:10:47,981 --> 00:10:50,851 line:-2
Now people can preview
the tile swatch on their wall,


238
00:10:50,884 --> 00:10:53,253 line:-1
all without downloading an app.


239
00:10:53,287 --> 00:10:54,788 line:-1
That’s pretty cool, right?


240
00:10:54,821 --> 00:10:58,091 line:-2
So, starting with iOS
and iPad 14.3, you can detect


241
00:10:58.125 --> 00:11:00.627 line:-2 align:center
and track App Clip Codes
in AR experiences.


242
00:11:00,661 --> 00:11:03,230 line:-2
Note that App Clip Code tracking
requires devices


243
00:11:03.263 --> 00:11:07.334 line:-2 align:center
with an A12 Bionic processor
or later, like the iPhone XS.


244
00:11:07.367 --> 00:11:10.504 line:-2 align:center
Let’s take a closer look at how
to use App Clip Codes in ARKit.


245
00:11:10,537 --> 00:11:13,073 line:-2
In iOS 14.3,
we introduced a new type


246
00:11:13,106 --> 00:11:16,243 line:-2
of ARAnchor,
an ARAppClipCodeAnchor.


247
00:11:16.276 --> 00:11:19.813 line:-2 align:center
This anchor has three
new properties: the URL embedded


248
00:11:19.847 --> 00:11:23.483 line:-2 align:center
in the App Clip Code,
a URL decoding state,


249
00:11:23.517 --> 00:11:26.887 line:-2 align:center
and the radius
of the App Clip Code in meters.


250
00:11:26.920 --> 00:11:29.089 line:-1 align:center
Let me explain.


251
00:11:29.122 --> 00:11:31.291 line:-2 align:center
Each App Clip Code
contains a URL


252
00:11:31.325 --> 00:11:33.894 line:-2 align:center
that is decoded
to display the correct content.


253
00:11:33,927 --> 00:11:36,330 line:-1
Decoding the URL is not instant.


254
00:11:36.363 --> 00:11:39.666 line:-2 align:center
ARKit can detect the presence
of an App Clip Code quickly.


255
00:11:39.700 --> 00:11:42.402 line:-2 align:center
But it can take
a little bit longer for ARKit


256
00:11:42,436 --> 00:11:45,539 line:-2
to decode the URL,
depending on the user’s distance


257
00:11:45.572 --> 00:11:48.675 line:-2 align:center
to the code
and other factors like lighting.


258
00:11:48,709 --> 00:11:50,511 line:-2
This is why
the App Clip Code anchor


259
00:11:50,544 --> 00:11:52,279 line:-2
contains
a .decoding state property,


260
00:11:52.312 --> 00:11:56.416 line:-2 align:center
and it can be
in one of three states.


261
00:11:56.450 --> 00:11:58.485 line:-2 align:center
The initial state .decoding
indicates


262
00:11:58.519 --> 00:12:00.554 line:-2 align:center
that ARKit is still
decoding the URL.


263
00:12:00,587 --> 00:12:03,390 line:-2
As soon as ARKit has
successfully decoded the URL,


264
00:12:03.423 --> 00:12:05.759 line:-2 align:center
the state will then switch
to .decoded.


265
00:12:05.792 --> 00:12:07.861 line:-2 align:center
When decoding the URL is not
possible,


266
00:12:07.895 --> 00:12:10.497 line:-2 align:center
the state will switch
to .failed instead.


267
00:12:10,531 --> 00:12:13,233 line:-2
This can, for example,
occur when someone scans


268
00:12:13.267 --> 00:12:16.603 line:-2 align:center
an App Clip Code which is not
associated with the app clip.


269
00:12:16,637 --> 00:12:19,273 line:-2
To use App Clip Code tracking,
you should first check


270
00:12:19,306 --> 00:12:21,308 line:-2
if it is supported
on the device.


271
00:12:21.341 --> 00:12:23.644 line:-2 align:center
Remember the App Clip Code
tracking is only supported


272
00:12:23.677 --> 00:12:26.880 line:-2 align:center
on devices with an A12 Bionic
processor or later.


273
00:12:26.914 --> 00:12:29.483 line:-2 align:center
Then set
the appClipCodeTrackingEnabled property


274
00:12:29.516 --> 00:12:33.987 line:-2 align:center
on your configuration
to true and run the session.


275
00:12:34,021 --> 00:12:36,323 line:-2
To read the URL
of an App Clip Code,


276
00:12:36,356 --> 00:12:39,393 line:-2
monitor the AR sessions
did update Anchors callback


277
00:12:39.426 --> 00:12:40.794 line:-1 align:center
and check the decoding state


278
00:12:40.827 --> 00:12:44.264 line:-2 align:center
of any detected
App Clip Code anchors.


279
00:12:44,298 --> 00:12:46,633 line:-2
While ARKit is decoding
the App Clip Code,


280
00:12:46.667 --> 00:12:49.136 line:-2 align:center
you might want to display
a placeholder visualization


281
00:12:49,169 --> 00:12:51,038 line:-2
on top of the App Clip Code
to give


282
00:12:51,071 --> 00:12:53,307 line:-2
the user instant feedback
that the App Clip Code


283
00:12:53.340 --> 00:12:57.578 line:-2 align:center
was detected
but still needs to be decoded.


284
00:12:57.611 --> 00:13:00.314 line:-2 align:center
As mentioned before,
decoding App Clip Codes can


285
00:13:00.347 --> 00:13:03.617 line:-2 align:center
also fail. For example,
when someone points the phone


286
00:13:03.650 --> 00:13:06.854 line:-2 align:center
at the App Clip Code which does
not belong to your app clip.


287
00:13:06.887 --> 00:13:10.357 line:-2 align:center
We recommend that you also
give feedback in that case.


288
00:13:10,390 --> 00:13:12,526 line:-2
Once the App Clip Code
has been decoded,


289
00:13:12.559 --> 00:13:15.262 line:-2 align:center
you can finally access its URL
and start displaying


290
00:13:15.295 --> 00:13:17.297 line:-2 align:center
the right content
for this App Clip Code.


291
00:13:17,331 --> 00:13:20,434 line:-2
For example,
in case of the Primer app clip


292
00:13:20.467 --> 00:13:23.237 line:-2 align:center
which you saw earlier,
the URL contains information


293
00:13:23.270 --> 00:13:25.272 line:-2 align:center
about which tile swatch
to display.


294
00:13:25.305 --> 00:13:28.575 line:-2 align:center
Once an App Clip Code has been
decoded, the question is, where


295
00:13:28,609 --> 00:13:31,345 line:-2
should you display the content
associated with this code?


296
00:13:31,378 --> 00:13:33,814 line:-2
One option is to display it
directly on top


297
00:13:33.847 --> 00:13:34.948 line:-1 align:center
of the App Clip Code anchor.


298
00:13:34.982 --> 00:13:37.985 line:-2 align:center
However, depending on your use
case, the App Clip Code itself


299
00:13:38,018 --> 00:13:40,320 line:-2
might not be the best place
to display the content.


300
00:13:40,354 --> 00:13:42,890 line:-2
So, for example,
you could position the content


301
00:13:42,923 --> 00:13:46,793 line:-2
nearby the App Clip Code
with a fixed relative position.


302
00:13:46.827 --> 00:13:48.562 line:-2 align:center
This works well
when the App Clip Code


303
00:13:48,595 --> 00:13:50,931 line:-2
is printed on an object,
say, a coffeemaker,


304
00:13:50.964 --> 00:13:53.100 line:-2 align:center
and you want to display
the virtual instructions


305
00:13:53.133 --> 00:13:57.137 line:-2 align:center
on how to operate it on top
of the machine’s buttons.


306
00:13:57.171 --> 00:13:59.673 line:-2 align:center
Or you could combine
the App Clip Code tracking


307
00:13:59.706 --> 00:14:02.776 line:-2 align:center
with other tracking technologies
supported by ARKit.


308
00:14:02.809 --> 00:14:04.745 line:-1 align:center
For example, image tracking.


309
00:14:04.778 --> 00:14:07.681 line:-2 align:center
Let’s take a look
at an implementation of that.


310
00:14:07,714 --> 00:14:10,517 line:-2
The videos and code
which you see next are based


311
00:14:10.551 --> 00:14:12.753 line:-2 align:center
on the “Interacting
with App Clip Codes in AR”


312
00:14:12,786 --> 00:14:16,290 line:-2
sample code which you can
download on developer.apple.com.


313
00:14:16,323 --> 00:14:20,060 line:-2
What you see now is a recording
of the sample’s AR experience.


314
00:14:20,093 --> 00:14:22,329 line:-2
First, I’m starting
in the Camera app,


315
00:14:22.362 --> 00:14:24.198 line:-2 align:center
scanning
a sunflower seed package.


316
00:14:24,231 --> 00:14:26,366 line:-2
Maybe I’m shopping
in the gardening store,


317
00:14:26.400 --> 00:14:28.702 line:-2 align:center
trying to decide
what plant seeds to buy.


318
00:14:28.735 --> 00:14:31.271 line:-2 align:center
iOS recognizes the App Clip Code
on the package


319
00:14:31.305 --> 00:14:34.308 line:-2 align:center
and launches the associated
Seed Shop app clip.


320
00:14:34.341 --> 00:14:36.877 line:-2 align:center
Here, I’m scanning
the App Clip Code a second time,


321
00:14:36,910 --> 00:14:40,214 line:-2
and then the grown sunflower
appears on the seed package.


322
00:14:40.247 --> 00:14:42.716 line:-2 align:center
Note that the app clip
uses image tracking


323
00:14:42,749 --> 00:14:45,786 line:-2
of the entire seed package
and places the sunflower on it.


324
00:14:45.819 --> 00:14:47.955 line:-2 align:center
This approach makes
sense in this use case,


325
00:14:47.988 --> 00:14:49.923 line:-2 align:center
as the person’s attention is
most likely


326
00:14:49,957 --> 00:14:51,658 line:-2
on the entire seed package
and not


327
00:14:51,692 --> 00:14:54,294 line:-2
on the smaller App Clip Code
in the top right.


328
00:14:54.328 --> 00:14:56.230 line:-2 align:center
But what if someone wanted
to see the plant grow


329
00:14:56.263 --> 00:14:57.297 line:-1 align:center
in their garden?


330
00:14:57,331 --> 00:14:58,999 line:-2
Here is
what that could look like.


331
00:14:59.032 --> 00:15:00.834 line:-2 align:center
Here we see
that when the code is scanned


332
00:15:00.868 --> 00:15:04.137 line:-2 align:center
for the first time,
it invokes an app clip download.


333
00:15:04.171 --> 00:15:06.240 line:-2 align:center
Then when the same code is
scanned again


334
00:15:06.273 --> 00:15:08.408 line:-2 align:center
from within the app clip,
it associates the code


335
00:15:08.442 --> 00:15:11.178 line:-2 align:center
with a sunflower seed box
and then tapping on the lawn


336
00:15:11.211 --> 00:15:13.046 line:-1 align:center
makes a sunflower appear there.


337
00:15:13.080 --> 00:15:15.983 line:-2 align:center
If instead, the app clip saw
the code on the rose seed box,


338
00:15:16,016 --> 00:15:18,151 line:-2
it would have spawned
a rose plant on the lawn.


339
00:15:18.185 --> 00:15:22.422 line:-2 align:center
Note that app clips are supposed
to contain only one workflow.


340
00:15:22,456 --> 00:15:24,825 line:-2
But the app clip can
offer a button to download


341
00:15:24.858 --> 00:15:27.227 line:-2 align:center
the full Seed Shop app
to experience other plants


342
00:15:27.261 --> 00:15:28.829 line:-2 align:center
they could preview
in their space.


343
00:15:28,862 --> 00:15:30,764 line:-2
Remember,
App Clip Code tracking also


344
00:15:30.797 --> 00:15:32.833 line:-1 align:center
works in App Clip’s parent app.


345
00:15:32.866 --> 00:15:35.035 line:-2 align:center
Let’s take a look
at the code which we need


346
00:15:35,068 --> 00:15:37,171 line:-1
to place sunflowers on the lawn.


347
00:15:37,204 --> 00:15:39,873 line:-2
First, you add
a tapGestureRecognizer to


348
00:15:39,907 --> 00:15:42,943 line:-2
the view to detect taps
on the screen.


349
00:15:42.976 --> 00:15:44.578 line:-2 align:center
When the person taps
on the screen


350
00:15:44,611 --> 00:15:46,280 line:-2
you can cast a ray
into the world


351
00:15:46,313 --> 00:15:48,148 line:-2
and get back
a resulting location


352
00:15:48,182 --> 00:15:51,218 line:-2
on the horizontal plane
in front of their device.


353
00:15:51,251 --> 00:15:55,889 line:-2
In our scenario,
this would be the person’s lawn.


354
00:15:55,923 --> 00:16:00,727 line:-2
You then grab the last App Clip
Code URL that was decoded


355
00:16:00,761 --> 00:16:04,264 line:-2
and add a new ARAnchor
on the lawn.


356
00:16:04,298 --> 00:16:07,100 line:-2
Lastly, you download
the sunflower 3D model


357
00:16:07.134 --> 00:16:09.002 line:-1 align:center
and display it on the lawn.


358
00:16:09.036 --> 00:16:11.772 line:-2 align:center
Now, let’s talk
about some best practices


359
00:16:11.805 --> 00:16:14.141 line:-1 align:center
for App Clip Codes in ARKit.


360
00:16:14.174 --> 00:16:16.510 line:-2 align:center
App clips can be used
in different environments


361
00:16:16.543 --> 00:16:18.245 line:-1 align:center
and for different use cases.


362
00:16:18.278 --> 00:16:20.147 line:-2 align:center
Consider whether it’s an option
for you


363
00:16:20.180 --> 00:16:22.549 line:-1 align:center
to create NFC App Clip Codes.


364
00:16:22.583 --> 00:16:24.885 line:-2 align:center
We recommend NFC App Clip Codes
for environments


365
00:16:24,918 --> 00:16:27,621 line:-2
where people can physically
access the code.


366
00:16:27.654 --> 00:16:29.756 line:-1 align:center
When using an NFC App Clip Code,


367
00:16:29,790 --> 00:16:32,726 line:-2
use appropriate call to action
text that guides people


368
00:16:32.759 --> 00:16:35.696 line:-2 align:center
to tap onto the tag
or, alternatively,


369
00:16:35,729 --> 00:16:39,132 line:-2
offers an explicit affordance
to scan the code.


370
00:16:39.166 --> 00:16:41.335 line:-2 align:center
Last but not least,
you need to make sure


371
00:16:41,368 --> 00:16:43,070 line:-2
that your App Clip Codes
are printed


372
00:16:43,103 --> 00:16:46,106 line:-2
on the appropriate size
for the user’s environment.


373
00:16:46,139 --> 00:16:50,043 line:-2
For example, a restaurant menu
might be printed on A4 paper,


374
00:16:50.077 --> 00:16:51.445 line:-1 align:center
and people will be comfortable


375
00:16:51.478 --> 00:16:54.615 line:-2 align:center
scanning a 2.5-centimeter
App Clip Code on that menu


376
00:16:54,648 --> 00:16:56,984 line:-2
from a distance of up
to 50 centimeters.


377
00:16:57.017 --> 00:16:59.920 line:-2 align:center
A movie poster, however,
is usually much larger


378
00:16:59,953 --> 00:17:01,288 line:-1
and might have enough space for


379
00:17:01.321 --> 00:17:03.857 line:-2 align:center
a 12-centimeter App Clip Code
which people would be able


380
00:17:03,891 --> 00:17:07,494 line:-2
to scan with their phone
from up to 2.5 meters away.


381
00:17:07,528 --> 00:17:09,830 line:-2
Please check out
our Human Interface Guidelines


382
00:17:09,863 --> 00:17:11,565 line:-2
on App Clip Codes
for more information


383
00:17:11.598 --> 00:17:13.967 line:-1 align:center
on recommended code sizes.


384
00:17:14.001 --> 00:17:17.171 line:-2 align:center
So that’s how you use
App Clip Codes in ARKit.


385
00:17:17,204 --> 00:17:21,008 line:-2
If you want to dive deeper into
app clips and App Clip Codes,


386
00:17:21,041 --> 00:17:23,243 line:-2
be sure to check out
“What’s new in App Clips”


387
00:17:23,277 --> 00:17:26,847 line:-2
and “Build light and fast
App Clips” sessions.


388
00:17:26,880 --> 00:17:29,082 line:-2
Now let’s jump over
to face tracking.


389
00:17:29,116 --> 00:17:31,051 line:-2
Face tracking allows
you to detect faces


390
00:17:31,084 --> 00:17:33,720 line:-2
in the front-facing camera,
overlay virtual content,


391
00:17:33,754 --> 00:17:36,356 line:-2
and animate facial
expressions in real time.


392
00:17:36,390 --> 00:17:39,326 line:-2
Since the launch of iPhone X,
ARKit has seen a ton


393
00:17:39.359 --> 00:17:41.862 line:-2 align:center
of great apps that take
advantage of face tracking.


394
00:17:41.895 --> 00:17:44.498 line:-2 align:center
From tracking multiple faces
to running face tracking


395
00:17:44,531 --> 00:17:47,267 line:-2
in simultaneous front
and back camera use case,


396
00:17:47,301 --> 00:17:50,470 line:-2
this API has received a number
of advancements over the years.


397
00:17:50.504 --> 00:17:53.140 line:-2 align:center
Last year, we introduced
face tracking on devices


398
00:17:53.173 --> 00:17:55.375 line:-2 align:center
without a TrueDepth sensor,
as long as they have


399
00:17:55,409 --> 00:17:57,544 line:-2
an A12 Bionic processor
or later.


400
00:17:57.578 --> 00:17:58.745 line:-1 align:center
And earlier this year,


401
00:17:58.779 --> 00:18:00.647 line:-2 align:center
we launched the new iPad Pro
that provides you


402
00:18:00.681 --> 00:18:03.317 line:-2 align:center
with an ultra wide field
of view front-facing camera


403
00:18:03,350 --> 00:18:05,853 line:-2
for your AR face tracking
experiences.


404
00:18:05.886 --> 00:18:07.788 line:-1 align:center
Let’s take a look.


405
00:18:07,821 --> 00:18:09,323 line:-1
Here you see the regular


406
00:18:09.356 --> 00:18:12.326 line:-2 align:center
front-facing camera’s field
of view.


407
00:18:12.359 --> 00:18:14.461 line:-2 align:center
And this is the new
ultra-wide field of view


408
00:18:14.494 --> 00:18:15.729 line:-1 align:center
on the new iPad Pro.


409
00:18:15.762 --> 00:18:18.098 line:-2 align:center
It really makes a difference,
doesn’t it?


410
00:18:18,131 --> 00:18:20,501 line:-2
Be aware that your existing apps
will keep using


411
00:18:20.534 --> 00:18:22.369 line:-2 align:center
the normal camera
for face tracking.


412
00:18:22,402 --> 00:18:24,838 line:-2
If you want to upgrade
your user’s experience


413
00:18:24,872 --> 00:18:27,374 line:-2
to the ultra-wide field of view
on the new iPad Pro,


414
00:18:27,407 --> 00:18:28,909 line:-2
you have to check
which video formats


415
00:18:28,942 --> 00:18:32,179 line:-2
are available and opt-in
for the new ultra-wide format.


416
00:18:32,212 --> 00:18:35,649 line:-2
You can do this by iterating
over all supported video formats


417
00:18:35,682 --> 00:18:39,453 line:-2
and checking for the
builtInUltraWideCamera option.


418
00:18:39.486 --> 00:18:42.055 line:-2 align:center
You then set this format
on your AR configuration


419
00:18:42,089 --> 00:18:44,992 line:-1
and run the session.


420
00:18:45,025 --> 00:18:47,361 line:-2
One thing to note is
that the new iPad Pro’s


421
00:18:47.394 --> 00:18:49.663 line:-2 align:center
ultra-wide camera has
a much larger field of view


422
00:18:49.696 --> 00:18:51.231 line:-1 align:center
than the TrueDepth sensor.


423
00:18:51.265 --> 00:18:54.067 line:-2 align:center
Therefore you will not get
a capturedDepthData buffer


424
00:18:54,101 --> 00:18:56,970 line:-2
on the ARFrame when using
the ultra-wide video format.


425
00:18:57,004 --> 00:18:59,740 line:-2
Last but not least,
let’s talk about motion capture.


426
00:18:59,773 --> 00:19:02,809 line:-2
Since its launch in 2019,
motion capture has enabled


427
00:19:02.843 --> 00:19:05.212 line:-2 align:center
robust integration
of real people in AR scenes,


428
00:19:05,245 --> 00:19:07,281 line:-2
such as animating virtual
characters


429
00:19:07,314 --> 00:19:10,083 line:-2
along with being used
in 2D and 3D simulation.


430
00:19:10,117 --> 00:19:13,420 line:-2
In iOS 15, motion capture is
getting even better.


431
00:19:13.453 --> 00:19:16.423 line:-2 align:center
On devices with
an Apple A14 Bionic processor


432
00:19:16,456 --> 00:19:17,724 line:-1
like the iPhone 12,


433
00:19:17,758 --> 00:19:20,794 line:-2
motion capture now supports
a wider range of body poses.


434
00:19:20.827 --> 00:19:23.197 line:-2 align:center
And this requires no
code changes at all.


435
00:19:23.230 --> 00:19:27.267 line:-2 align:center
All motion capture apps on
iOS 15 will benefit from this.


436
00:19:27.301 --> 00:19:29.837 line:-2 align:center
Most notably, rotations
are more accurate than ever,


437
00:19:29,870 --> 00:19:33,073 line:-2
helping you track sports actions
with much more precision.


438
00:19:33,106 --> 00:19:35,609 line:-2
Another big improvement is
that your device camera can


439
00:19:35.642 --> 00:19:38.378 line:-2 align:center
now track body joints
from a much further distance.


440
00:19:38,412 --> 00:19:41,081 line:-2
Also there has been
a significant increase


441
00:19:41.114 --> 00:19:42.983 line:-2 align:center
in tracking the range
of limb movement.


442
00:19:43,016 --> 00:19:45,352 line:-1
Let’s take a look at an example.


443
00:19:45.385 --> 00:19:47.354 line:-2 align:center
Here is one
of my coworkers, Ejler,


444
00:19:47.387 --> 00:19:50.457 line:-2 align:center
tracking his workouts
with the app Driven2win.


445
00:19:50,490 --> 00:19:54,228 line:-2
The results on iOS 15
are more precise than ever.


446
00:19:54.261 --> 00:19:56.163 line:-1 align:center
To recap, ARKit 5 brings lots


447
00:19:56.196 --> 00:19:57.564 line:-2 align:center
of new features
and improvements.


448
00:19:57,598 --> 00:19:59,633 line:-2
Location anchors
are available in new cities


449
00:19:59,666 --> 00:20:01,668 line:-2
and feature
a new coaching overlay.


450
00:20:01.702 --> 00:20:04.171 line:-2 align:center
App Clip Code tracking assists
in the easy discovery


451
00:20:04.204 --> 00:20:05.672 line:-1 align:center
and use of AR in your app clip,


452
00:20:05.706 --> 00:20:08.709 line:-2 align:center
as well as precise positioning
of your virtual content.


453
00:20:08,742 --> 00:20:11,278 line:-2
Face tracking works with the new
ultra-wide field of view


454
00:20:11.311 --> 00:20:13.914 line:-2 align:center
on the new iPad Pro,
and motion capture


455
00:20:13,947 --> 00:20:16,750 line:-2
adds better accuracy
and larger range of motion.


456
00:20:16.783 --> 00:20:19.286 line:-2 align:center
I’m so excited to see
all the amazing experiences


457
00:20:19,319 --> 00:20:21,321 line:-1
you will create with ARKit 5.


458
00:20:21.355 --> 00:20:23.957 line:-1 align:center
[music]

