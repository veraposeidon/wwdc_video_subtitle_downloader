2
00:00:00.033 --> 00:00:01.935 line:-1 position:50%
[MAC STARTUP CHIME]


3
00:00:01.935 --> 00:00:05.439 line:-1 position:50%
♪ Bass music playing ♪


4
00:00:05,439 --> 00:00:07,074 line:-1
[KEYSTROKES]


5
00:00:07,074 --> 00:00:09,243 position:90% align:right line:0
♪


6
00:00:09.243 --> 00:00:10.244 line:-1 position:50%
Michael Patrick Johnson: Hi!


7
00:00:10,244 --> 00:00:12,045 line:-1
My name is
Michael Patrick Johnson,


8
00:00:12,045 --> 00:00:14,781 line:-1
and I am an engineer
on the Object Capture team.


9
00:00:14,781 --> 00:00:16,850 line:-1
Today, my colleague
Dave McKinnon and I


10
00:00:16,850 --> 00:00:19,486 line:-1
will be showing you
how to turn real-world objects


11
00:00:19.486 --> 00:00:24.791 line:-1 position:50%
into 3D models using our new
photogrammetry API on macOS.


12
00:00:24,791 --> 00:00:27,895 line:-1
You may already be familiar with
creating augmented reality apps


13
00:00:27,895 --> 00:00:31,298 line:-1
using our ARKit
and RealityKit frameworks.


14
00:00:31.298 --> 00:00:33.300 line:-1 position:50%
You may have also used
Reality Composer


15
00:00:33,300 --> 00:00:38,038 line:-1
and Reality Converter
to produce 3D models for AR.


16
00:00:38,038 --> 00:00:40,674 line:-1
And now,
with the Object Capture API,


17
00:00:40,674 --> 00:00:43,510 line:-1
you can easily turn images
of real-world objects


18
00:00:43.510 --> 00:00:46.280 line:-1 position:50%
into detailed 3D models.


19
00:00:46,280 --> 00:00:48,882 line:-1
Let's say you have some freshly
baked pizza in front of you


20
00:00:48,882 --> 00:00:50,584 line:-1
on the kitchen table.


21
00:00:50.584 --> 00:00:52.786 line:-1 position:50%
Looks delicious, right?


22
00:00:52.786 --> 00:00:55.222 line:-1 position:50%
Suppose we want to capture
the pizza in the foreground


23
00:00:55,222 --> 00:00:57,224 line:-1
as a 3D model.


24
00:00:57,224 --> 00:00:59,726 line:-1
Normally, you'd need to hire
a professional artist


25
00:00:59,726 --> 00:01:03,330 line:-1
for many hours to model
the shape and texture.


26
00:01:03,330 --> 00:01:05,232 line:-1
But, wait, it took you
only minutes to bake


27
00:01:05.232 --> 00:01:07.701 line:-1 position:50%
in your own oven!


28
00:01:07.701 --> 00:01:11.038 line:-1 position:50%
With Object Capture, you start
by taking photos of your object


29
00:01:11.038 --> 00:01:12.873 line:-1 position:50%
from every angle.


30
00:01:12,873 --> 00:01:15,075 line:-1
Next, you copy the images
to a Mac


31
00:01:15.075 --> 00:01:18.011 line:-1 position:50%
which supports the new
Object Capture API.


32
00:01:18.011 --> 00:01:19.880 line:-1 position:50%
Using a computer vision
technique


33
00:01:19.880 --> 00:01:21.381 line:-1 position:50%
called "photogrammetry",


34
00:01:21.381 --> 00:01:24.284 line:-1 position:50%
the stack of 2D images
is turned into a 3D model


35
00:01:24,284 --> 00:01:26,086 line:-1
in just minutes.


36
00:01:26.086 --> 00:01:28.889 line:-1 position:50%
The output model includes
both a geometric mesh


37
00:01:28.889 --> 00:01:30.991 line:-1 position:50%
as well as various
material maps,


38
00:01:30,991 --> 00:01:33,460 line:-1
and is ready to be dropped
right into your app


39
00:01:33,460 --> 00:01:35,696 line:-1
or viewed in AR Quick Look.


40
00:01:35,696 --> 00:01:39,066 line:-1
Now let's look at each of these
steps in slightly more detail.


41
00:01:39.066 --> 00:01:43.203 line:-1 position:50%
First, you capture photos
of your object from all sides.


42
00:01:43.203 --> 00:01:46.340 line:-1 position:50%
Images can be taken
on your iPhone or iPad,


43
00:01:46,340 --> 00:01:49,209 line:-1
DSLR, or even a drone.


44
00:01:49,209 --> 00:01:51,845 line:-1
You just need to make sure
you get clear photos


45
00:01:51.845 --> 00:01:54.514 line:-1 position:50%
from all angles
around the object.


46
00:01:54,514 --> 00:01:56,883 line:-1
We will provide
best practices for capture


47
00:01:56.883 --> 00:01:58.952 line:-1 position:50%
later in the session.


48
00:01:58,952 --> 00:02:01,288 line:-1
If you capture
on iPhone or iPad,


49
00:02:01,288 --> 00:02:04,624 line:-1
we can use stereo depth data
from supported devices


50
00:02:04,624 --> 00:02:08,161 line:-1
to allow the recovery
of the actual object size,


51
00:02:08,161 --> 00:02:09,763 line:-1
as well as the gravity vector


52
00:02:09.763 --> 00:02:13.033 line:-1 position:50%
so your model is automatically
created right-side up.


53
00:02:13,033 --> 00:02:15,168 line:-1
Once you have captured
a folder of images,


54
00:02:15,168 --> 00:02:17,070 line:-1
you need to copy them
to your Mac


55
00:02:17,070 --> 00:02:19,306 line:-1
where you can use
the Object Capture API


56
00:02:19,306 --> 00:02:22,576 line:-1
to turn them into a 3D model
in just minutes.


57
00:02:22.576 --> 00:02:25.746 line:-1 position:50%
The API is supported
on recent Intel-based Macs,


58
00:02:25,746 --> 00:02:29,416 line:-1
but will run fastest on all
the newest Apple silicon Macs


59
00:02:29.416 --> 00:02:31.585 line:-1 position:50%
since we can utilize
the Apple Neural Engine


60
00:02:31,585 --> 00:02:34,554 line:-1
to speed up our
computer vision algorithms.


61
00:02:34,554 --> 00:02:37,157 line:-1
We also provide
HelloPhotogrammetry,


62
00:02:37,157 --> 00:02:40,694 line:-1
a sample command-line app
to help you get started.


63
00:02:40,694 --> 00:02:43,463 line:-1
You can also use it directly
on your folder of images


64
00:02:43,463 --> 00:02:45,132 line:-1
to try building a model
for yourself


65
00:02:45,132 --> 00:02:47,801 line:-1
before writing any code.


66
00:02:47.801 --> 00:02:51.004 line:-1 position:50%
Finally, you can preview
the USDZ output models


67
00:02:51,004 --> 00:02:52,572 line:-1
right on your Mac.


68
00:02:52,572 --> 00:02:55,275 line:-1
We can provide models
at four detail levels


69
00:02:55.275 --> 00:02:57.811 line:-1 position:50%
optimized for your
different use cases,


70
00:02:57.811 --> 00:03:00.647 line:-1 position:50%
which we discuss
in more detail later.


71
00:03:00,647 --> 00:03:03,917 line:-1
Reduced, Medium, and Full
details are ready to use


72
00:03:03.917 --> 00:03:07.654 line:-1 position:50%
right out of the box,
like the pizza shown here.


73
00:03:07.654 --> 00:03:11.725 line:-1 position:50%
Raw is intended
for custom workflows.


74
00:03:11.725 --> 00:03:15.695 line:-1 position:50%
By selecting USDZ output
at the Medium detail level,


75
00:03:15.695 --> 00:03:18.031 line:-1 position:50%
you can view the new model
in AR Quick Look


76
00:03:18,031 --> 00:03:20,667 line:-1
right on your iPhone or iPad.


77
00:03:20.667 --> 00:03:22.702 line:-1 position:50%
And that's all there is
to getting lifelike objects


78
00:03:22.702 --> 00:03:25.005 line:-1 position:50%
that are optimized for AR!


79
00:03:25,005 --> 00:03:28,041 line:-1
Oh wait, remember the pizzas
from before?


80
00:03:28.041 --> 00:03:29.376 line:-1 position:50%
We have to come clean.


81
00:03:29,376 --> 00:03:31,445 line:-1
This image wasn't
really a photo,


82
00:03:31.445 --> 00:03:33.880 line:-1 position:50%
but was actually created
using Object Capture


83
00:03:33.880 --> 00:03:35.749 line:-1 position:50%
on several pizzas.


84
00:03:35,749 --> 00:03:38,318 line:-1
These models were then combined
into this scene


85
00:03:38.318 --> 00:03:41.421 line:-1 position:50%
in a post-production tool
and rendered using a ray tracer


86
00:03:41,421 --> 00:03:43,924 line:-1
with the advanced material maps.


87
00:03:43,924 --> 00:03:46,059 line:-1
So you see,
Object Capture can support


88
00:03:46.059 --> 00:03:48.261 line:-1 position:50%
a variety of target use cases,


89
00:03:48,261 --> 00:03:50,964 line:-1
from AR apps
on an iPhone or iPad


90
00:03:50.964 --> 00:03:53.333 line:-1 position:50%
to film-ready production assets.


91
00:03:53.333 --> 00:03:55.168 line:-1 position:50%
In the remainder
of this session,


92
00:03:55.168 --> 00:03:56.636 line:-1 position:50%
we'll show you
how to get started


93
00:03:56,636 --> 00:03:58,705 line:-1
using the Object Capture API


94
00:03:58,705 --> 00:04:00,740 line:-1
and then offer
our best practices


95
00:04:00,740 --> 00:04:03,877 line:-1
to achieve
the highest-quality results.


96
00:04:03,877 --> 00:04:05,545 line:-1
In the getting started section,


97
00:04:05,545 --> 00:04:08,915 line:-1
we'll go into more details
about the Object Capture API


98
00:04:08.915 --> 00:04:11.585 line:-1 position:50%
and introduce
the essential code concepts


99
00:04:11,585 --> 00:04:14,454 line:-1
for creating an app.


100
00:04:14,454 --> 00:04:17,924 line:-1
Next we will discuss best
practices for image capture,


101
00:04:17,924 --> 00:04:22,996 line:-1
object selection,
and detail-level selection.


102
00:04:22.996 --> 00:04:25.532 line:-1 position:50%
Let's begin by working through
the essential steps


103
00:04:25.532 --> 00:04:28.368 line:-1 position:50%
in using the API on macOS.


104
00:04:28,368 --> 00:04:31,004 line:-1
In this section, you will learn
the basic components


105
00:04:31.004 --> 00:04:35.408 line:-1 position:50%
of the Object Capture API
and how to put them together.


106
00:04:35,408 --> 00:04:37,410 line:-1
Let's say we have
this cool new sneaker


107
00:04:37,410 --> 00:04:40,947 line:-1
we want to turn into
a 3D model to view in AR.


108
00:04:40,947 --> 00:04:42,782 line:-1
Here we see a graphical diagram


109
00:04:42,782 --> 00:04:46,586 line:-1
of the basic workflow
we will explore in this section.


110
00:04:46,586 --> 00:04:48,955 line:-1
There are two main steps
in the process:


111
00:04:48.955 --> 00:04:52.459 line:-1 position:50%
Setup, where we point to our set
of images of an object;


112
00:04:52,459 --> 00:04:55,462 line:-1
and then Process,
where we request generation


113
00:04:55,462 --> 00:04:58,865 line:-1
of the models we want
to be constructed.


114
00:04:58,865 --> 00:05:01,768 line:-1
First, we will focus
on the Setup block,


115
00:05:01.768 --> 00:05:05.305 line:-1 position:50%
which consists of two substeps:
creating a session


116
00:05:05.305 --> 00:05:08.909 line:-1 position:50%
and then connecting up
its associated output stream.


117
00:05:08.909 --> 00:05:10.710 line:-1 position:50%
Once we have a valid session,


118
00:05:10,710 --> 00:05:13,346 line:-1
we can use it
to generate our models.


119
00:05:13,346 --> 00:05:14,648 line:-1
The first thing we need to do


120
00:05:14.648 --> 00:05:17.217 line:-1 position:50%
is to create
a PhotogrammetrySession.


121
00:05:17,217 --> 00:05:18,552 line:-1
To create a session,


122
00:05:18,552 --> 00:05:22,022 line:-1
we will assume you already have
a folder of images of an object.


123
00:05:22,022 --> 00:05:24,724 line:-1
We have provided some
sample image capture folders


124
00:05:24.724 --> 00:05:29.062 line:-1 position:50%
in the API documentation
for you to get started quickly.


125
00:05:29,062 --> 00:05:32,299 line:-1
A PhotogrammetrySession
is the primary top-level class


126
00:05:32.299 --> 00:05:35.902 line:-1 position:50%
in the API and is the main
point of control.


127
00:05:35,902 --> 00:05:38,104 line:-1
A session can be thought of
as a container


128
00:05:38,104 --> 00:05:41,541 line:-1
for a fixed set of images to
which photogrammetry algorithms


129
00:05:41.541 --> 00:05:45.779 line:-1 position:50%
will be applied to produce
the resulting 3D model.


130
00:05:45.779 --> 00:05:49.616 line:-1 position:50%
Here we have 123 HEIC images
of the sneaker


131
00:05:49,616 --> 00:05:54,321 line:-1
taken using
an iPhone 12 Pro Max.


132
00:05:54,321 --> 00:05:55,755 line:-1
Currently there are several ways


133
00:05:55,755 --> 00:05:58,725 line:-1
to specify the set of images
to use.


134
00:05:58.725 --> 00:06:03.296 line:-1 position:50%
The simplest is just a file URL
to a directory of images.


135
00:06:03,296 --> 00:06:05,699 line:-1
The session will ingest these
one by one


136
00:06:05,699 --> 00:06:08,435 line:-1
and report on any problems
encountered.


137
00:06:08,435 --> 00:06:11,504 line:-1
If there is embedded depth data
in HEIC images,


138
00:06:11.504 --> 00:06:13.039 line:-1 position:50%
it will automatically be used


139
00:06:13,039 --> 00:06:16,710 line:-1
to recover the actual scale
of the object.


140
00:06:16.710 --> 00:06:20.146 line:-1 position:50%
Although we expect most people
will prefer folder inputs,


141
00:06:20,146 --> 00:06:22,849 line:-1
we also offer an interface
for advanced workflows


142
00:06:22.849 --> 00:06:26.152 line:-1 position:50%
to provide a sequence
of custom samples.


143
00:06:26,152 --> 00:06:28,989 line:-1
A PhotogrammetrySample
includes the image


144
00:06:28.989 --> 00:06:32.025 line:-1 position:50%
plus other optional data
such as a depth map,


145
00:06:32.025 --> 00:06:36.630 line:-1 position:50%
gravity vector,
or custom segmentation mask.


146
00:06:36,630 --> 00:06:39,499 line:-1
Once you have created a session
from an input source,


147
00:06:39.499 --> 00:06:42.802 line:-1 position:50%
you will make requests on it
for model reconstruction.


148
00:06:42,802 --> 00:06:45,205 line:0
The session will output
the resulting models


149
00:06:45,205 --> 00:06:49,843 line:0
as well as status messages
on its output message stream.


150
00:06:49,843 --> 00:06:52,012 line:-1
Now that we've seen
what a session is,


151
00:06:52,012 --> 00:06:54,981 line:-1
let's see how to create one
using the API.


152
00:06:54,981 --> 00:06:58,285 line:-1
Here we see the code to perform
the initial setup of a session


153
00:06:58,285 --> 00:07:00,954 line:-1
from a folder of images.


154
00:07:00.954 --> 00:07:02.756 line:-1 position:50%
The PhotogrammetrySession


155
00:07:02.756 --> 00:07:05.825 line:-1 position:50%
lives within
the RealityKit framework.


156
00:07:05,825 --> 00:07:10,363 line:-1
First, we specify the input
folder as a file URL.


157
00:07:10,363 --> 00:07:13,867 line:-1
Here, we assume that we already
have a folder on the local disk


158
00:07:13,867 --> 00:07:16,770 line:-1
containing the images
of our sneaker.


159
00:07:16,770 --> 00:07:19,806 line:-1
Finally, we create the session
by passing the URL


160
00:07:19,806 --> 00:07:21,775 line:-1
as our input source.


161
00:07:21.775 --> 00:07:23.343 line:-1 position:50%
The initializer
will throw an error


162
00:07:23,343 --> 00:07:26,513 line:-1
if the path doesn't exist
or can't be read.


163
00:07:26.513 --> 00:07:27.881 line:-1 position:50%
You can optionally provide


164
00:07:27,881 --> 00:07:30,350 line:-1
advanced configuration
parameters,


165
00:07:30.350 --> 00:07:33.353 line:-1 position:50%
but here we'll just use
the defaults.


166
00:07:33,353 --> 00:07:36,022 line:-1
That's all it takes
to create a session!


167
00:07:36.022 --> 00:07:39.125 line:-1 position:50%
Now that we've successfully
created a session object,


168
00:07:39.125 --> 00:07:41.761 line:-1 position:50%
we need to connect
the session's output stream


169
00:07:41,761 --> 00:07:44,798 line:-1
so that we can handle messages
as they arrive.


170
00:07:44,798 --> 00:07:46,933 line:-1
After the message stream
is connected,


171
00:07:46.933 --> 00:07:49.002 line:-1 position:50%
we will see
how to request models


172
00:07:49.002 --> 00:07:52.305 line:-1 position:50%
that will then arrive
on that stream.


173
00:07:52,305 --> 00:07:56,376 line:-1
We use an AsyncSequence --
a new Swift feature this year --


174
00:07:56,376 --> 00:07:59,045 line:-1
to provide the stream
of outputs.


175
00:07:59,045 --> 00:08:02,148 line:-1
Output messages include
the results of requests,


176
00:08:02,148 --> 00:08:06,319 line:-1
as well as status messages
such as progress updates.


177
00:08:06.319 --> 00:08:08.555 line:-1 position:50%
Once we make
the first process call,


178
00:08:08,555 --> 00:08:12,292 line:-1
messages will begin to flow
on the output message stream.


179
00:08:12,292 --> 00:08:14,661 line:-1
The output message sequence
will not end


180
00:08:14.661 --> 00:08:16.363 line:-1 position:50%
while the session is alive.


181
00:08:16.363 --> 00:08:17.864 line:-1 position:50%
It will keep producing messages


182
00:08:17,864 --> 00:08:20,400 line:-1
until either the session
is deinitialized


183
00:08:20,400 --> 00:08:23,470 line:-1
or in the case of a fatal error.


184
00:08:23.470 --> 00:08:25.205 line:-1 position:50%
Now, let's take a closer look


185
00:08:25,205 --> 00:08:28,074 line:-1
at the types of messages
we will receive.


186
00:08:28.074 --> 00:08:29.943 line:-1 position:50%
After a request is made,


187
00:08:29.943 --> 00:08:33.680 line:-1 position:50%
we expect to receive periodic
requestProgress messages


188
00:08:33,680 --> 00:08:37,384 line:-1
with the fraction completed
estimate for each request.


189
00:08:37,384 --> 00:08:40,520 line:-1
If you're building an app that
calls the Object Capture API,


190
00:08:40.520 --> 00:08:43.890 line:-1 position:50%
you can use these to drive
a progress bar for each request


191
00:08:43,890 --> 00:08:46,459 line:-1
to indicate status.


192
00:08:46.459 --> 00:08:48.862 line:-1 position:50%
Once the request
is done processing,


193
00:08:48,862 --> 00:08:51,598 line:-1
we receive
a requestComplete message


194
00:08:51,598 --> 00:08:53,299 line:-1
containing the resulting
payload,


195
00:08:53,299 --> 00:08:55,869 line:-1
such as a model
or a bounding box.


196
00:08:55,869 --> 00:08:58,171 line:-1
If something went wrong
during processing,


197
00:08:58.171 --> 00:09:03.376 line:-1 position:50%
a requestError will be output
for that request instead.


198
00:09:03,376 --> 00:09:05,845 line:0
For convenience,
a processingComplete message


199
00:09:05,845 --> 00:09:08,081 position:50%
is output when all queued
requests


200
00:09:08,081 --> 00:09:10,016 position:50%
have finished processing.


201
00:09:10.016 --> 00:09:11.317 line:-1 position:50%
Now that we've been introduced


202
00:09:11.317 --> 00:09:13.720 line:-1 position:50%
to the concept
of the session output stream


203
00:09:13.720 --> 00:09:16.322 line:-1 position:50%
and seen the primary
output messages,


204
00:09:16.322 --> 00:09:18.057 line:-1 position:50%
let's take a look
at some example code


205
00:09:18,057 --> 00:09:20,727 line:-1
that processes
the message stream.


206
00:09:20,727 --> 00:09:24,764 line:-1
Once we have this, we'll see
how to request a model.


207
00:09:24,764 --> 00:09:27,634 line:-1
Here is some code
that creates an async task


208
00:09:27.634 --> 00:09:30.470 line:-1 position:50%
that handles messages
as they arrive.


209
00:09:30.470 --> 00:09:32.372 line:-1 position:50%
It may seem like a lot of code,


210
00:09:32,372 --> 00:09:37,377 line:-1
but most of it is simply message
dispatching as we will see.


211
00:09:37.377 --> 00:09:41.981 line:-1 position:50%
We use a "for try await" loop
to asynchronously iterate


212
00:09:41.981 --> 00:09:47.120 line:-1 position:50%
over the messages in
session.outputs as they arrive.


213
00:09:47,120 --> 00:09:49,989 line:-1
The bulk of the code
is a message dispatcher


214
00:09:49,989 --> 00:09:52,859 line:-1
which switches on
the output message.


215
00:09:52.859 --> 00:09:57.263 line:-1 position:50%
Output is an enum with different
message types and payloads.


216
00:09:57,263 --> 00:10:00,366 line:-1
Each case statement
will handle a different message.


217
00:10:00.366 --> 00:10:02.335 line:-1 position:50%
Let's walk through them.


218
00:10:02.335 --> 00:10:04.871 line:-1 position:50%
First, if we get
a progress message,


219
00:10:04,871 --> 00:10:07,140 line:-1
we'll just print out the value.


220
00:10:07,140 --> 00:10:11,411 line:-1
Notice that we get progress
messages for each request.


221
00:10:11,411 --> 00:10:14,647 line:-1
For our example,
when the request is complete,


222
00:10:14,647 --> 00:10:17,584 line:-1
we expect the result payload
to be a modelFile


223
00:10:17,584 --> 00:10:21,488 line:-1
with the URL to where
the model was saved.


224
00:10:21,488 --> 00:10:24,858 line:-1
We will see how to make
such a request momentarily.


225
00:10:24.858 --> 00:10:27.894 line:-1 position:50%
If the request failed
due to a photogrammetry error,


226
00:10:27.894 --> 00:10:31.197 line:-1 position:50%
we will instead get
an error message for it.


227
00:10:31,197 --> 00:10:32,932 line:-1
After the entire set of requests


228
00:10:32.932 --> 00:10:35.235 line:-1 position:50%
from a process call
has finished,


229
00:10:35,235 --> 00:10:38,271 line:-1
a processingComplete message
is generated.


230
00:10:38,271 --> 00:10:41,908 line:-1
For a command-line app,
you might exit the app here.


231
00:10:41,908 --> 00:10:44,911 line:-1
Finally there are other status
messages that you can read about


232
00:10:44.911 --> 00:10:46.346 line:-1 position:50%
in the documentation,


233
00:10:46.346 --> 00:10:48.781 line:-1 position:50%
such as warnings
about images in a folder


234
00:10:48,781 --> 00:10:50,783 line:-1
that couldn't be loaded.


235
00:10:50,783 --> 00:10:52,619 line:-1
And that's it
for the message handling!


236
00:10:52,619 --> 00:10:55,388 line:-1
This message-handling task
will keep iterating


237
00:10:55,388 --> 00:10:57,790 line:-1
and handling messages
asynchronously


238
00:10:57,790 --> 00:11:00,894 line:-1
for as long as
the session is alive.


239
00:11:00.894 --> 00:11:04.130 line:-1 position:50%
OK, let's see where we are
in our workflow.


240
00:11:04.130 --> 00:11:06.232 line:-1 position:50%
We've fully completed
the Setup phase


241
00:11:06.232 --> 00:11:08.601 line:-1 position:50%
and have a session ready to go.


242
00:11:08,601 --> 00:11:12,639 line:-1
We're now ready to make requests
to process the models.


243
00:11:12.639 --> 00:11:15.408 line:-1 position:50%
Before we jump into the code,
let's take a closer look


244
00:11:15.408 --> 00:11:18.244 line:-1 position:50%
at the various types of requests
we can make.


245
00:11:18,244 --> 00:11:20,580 line:-1
There are three different
data types you can receive


246
00:11:20.580 --> 00:11:24.450 line:-1 position:50%
from a session:
a ModelFile, a ModelEntity,


247
00:11:24.450 --> 00:11:26.419 line:-1 position:50%
and a BoundingBox.


248
00:11:26,419 --> 00:11:30,390 line:-1
These types have an associated
case in the Request enum:


249
00:11:30,390 --> 00:11:33,593 line:-1
modelFile, modelEntity,
and bounds;


250
00:11:33.593 --> 00:11:36.195 line:-1 position:50%
each with different parameters.


251
00:11:36,195 --> 00:11:38,731 line:-1
The modelFile request
is the most common


252
00:11:38.731 --> 00:11:41.768 line:-1 position:50%
and the one we will use
in our basic workflow.


253
00:11:41,768 --> 00:11:44,737 line:-1
You simply create
a modelFile request


254
00:11:44,737 --> 00:11:49,309 line:-1
specifying a file URL
with a USDZ extension,


255
00:11:49,309 --> 00:11:51,578 line:-1
as well as a detail level.


256
00:11:51,578 --> 00:11:54,213 line:-1
There is an optional
geometry parameter for use


257
00:11:54.213 --> 00:11:58.184 line:-1 position:50%
in the interactive workflow,
but we won't use that here.


258
00:11:58,184 --> 00:12:01,120 line:-1
For more involved
postprocessing pipelines


259
00:12:01,120 --> 00:12:05,091 line:-1
where you may need USDA
or OBJ output formats,


260
00:12:05,091 --> 00:12:08,695 line:-1
you can provide an output
directory URL instead,


261
00:12:08,695 --> 00:12:11,164 line:-1
along with a detail level.


262
00:12:11.164 --> 00:12:16.135 line:-1 position:50%
The session will then write USDA
and OBJ files into that folder,


263
00:12:16.135 --> 00:12:18.137 line:-1 position:50%
along with all
the referenced assets


264
00:12:18.137 --> 00:12:21.441 line:-1 position:50%
such as textures and materials.


265
00:12:21.441 --> 00:12:24.410 line:-1 position:50%
A GUI app is also able
to request a RealityKit


266
00:12:24.410 --> 00:12:26.512 line:-1 position:50%
ModelEntity and BoundingBox


267
00:12:26.512 --> 00:12:29.716 line:-1 position:50%
for interactive preview
and refinement.


268
00:12:29.716 --> 00:12:32.552 line:-1 position:50%
A modelEntity request
also takes a detail level


269
00:12:32,552 --> 00:12:35,154 line:-1
and optional geometry.


270
00:12:35.154 --> 00:12:36.956 line:-1 position:50%
A bounds request will return


271
00:12:36,956 --> 00:12:41,160 line:-1
an estimated capture volume
BoundingBox for the object.


272
00:12:41,160 --> 00:12:43,429 line:-1
This box can be
adjusted in a UI


273
00:12:43,429 --> 00:12:47,567 line:-1
and then passed in the geometry
argument of a subsequent request


274
00:12:47,567 --> 00:12:50,403 line:-1
to adjust
the reconstruction volume.


275
00:12:50,403 --> 00:12:54,374 line:-1
We'll see how this works
a bit later in the session.


276
00:12:54,374 --> 00:12:57,644 line:-1
Most requests also take
a detail level.


277
00:12:57.644 --> 00:13:01.514 line:-1 position:50%
The preview level is intended
only for interactive workflows.


278
00:13:01,514 --> 00:13:06,152 line:-1
It is very low visual quality
but is created the fastest.


279
00:13:06.152 --> 00:13:07.720 line:-1 position:50%
The primary detail levels


280
00:13:07,720 --> 00:13:10,690 line:-1
in order of increasing
quality and size


281
00:13:10,690 --> 00:13:14,827 line:-1
are Reduced, Medium, and Full.


282
00:13:14,827 --> 00:13:18,998 line:-1
These levels are all
ready to use out of the box.


283
00:13:18,998 --> 00:13:22,702 position:50%
Additionally, the Raw level
is provided for professional use


284
00:13:22,702 --> 00:13:26,372 line:0
and will need a post-production
workflow to be used properly.


285
00:13:26,372 --> 00:13:28,107 line:0
We will discuss these
in more detail


286
00:13:28,107 --> 00:13:30,510 line:0
in the best practices section.


287
00:13:30,510 --> 00:13:34,013 line:-1
OK, now that we've seen what
kinds of requests we can make,


288
00:13:34,013 --> 00:13:36,449 line:-1
let's see how to do this
in code.


289
00:13:36,449 --> 00:13:39,719 line:-1
We will now see how to generate
two models simultaneously


290
00:13:39,719 --> 00:13:41,187 line:-1
in one call,


291
00:13:41.187 --> 00:13:44.991 line:-1 position:50%
each with a different output
filename and detail level.


292
00:13:44,991 --> 00:13:48,594 line:-1
Here we see the first call
to process on the session.


293
00:13:48,594 --> 00:13:51,964 line:-1
Notice that it takes
an array of requests.


294
00:13:51,964 --> 00:13:55,968 line:-1
This is how we can request
two models at once.


295
00:13:55.968 --> 00:13:59.272 line:-1 position:50%
We will request one model
at Reduced detail level


296
00:13:59.272 --> 00:14:04.711 line:-1 position:50%
and one at Medium, each saving
to a different USDZ file.


297
00:14:04,711 --> 00:14:07,146 line:-1
Requesting all desired
detail levels


298
00:14:07,146 --> 00:14:10,383 line:-1
for an object capture
simultaneously in one call


299
00:14:10.383 --> 00:14:12.819 line:-1 position:50%
allows the engine
to share computation


300
00:14:12,819 --> 00:14:14,721 line:-1
and will produce
all the models faster


301
00:14:14.721 --> 00:14:17.290 line:-1 position:50%
than requesting
them sequentially.


302
00:14:17.290 --> 00:14:20.526 line:-1 position:50%
You can even ask
for all details levels at once.


303
00:14:20.526 --> 00:14:24.197 line:-1 position:50%
Process may immediately throw an
error if a request is invalid,


304
00:14:24,197 --> 00:14:27,400 line:-1
such as if the output location
can't be written.


305
00:14:27.400 --> 00:14:28.868 line:-1 position:50%
This call returns immediately


306
00:14:28.868 --> 00:14:34.707 line:-1 position:50%
and soon messages will begin
to appear on the output stream.


307
00:14:34,707 --> 00:14:37,376 line:-1
And that's the end
of the basic workflow!


308
00:14:37.376 --> 00:14:39.746 line:-1 position:50%
You create the session
with your images,


309
00:14:39,746 --> 00:14:43,483 line:-1
connect the output stream,
and then request models.


310
00:14:43.483 --> 00:14:45.785 line:-1 position:50%
The processing time
for each of your models


311
00:14:45,785 --> 00:14:49,355 line:-1
will depend on the number
of images and quality level.


312
00:14:49,355 --> 00:14:51,257 line:-1
Once the processing is complete,


313
00:14:51.257 --> 00:14:53.092 line:-1 position:50%
you will receive
the output message


314
00:14:53,092 --> 00:14:55,428 line:-1
that the model is available.


315
00:14:55,428 --> 00:14:59,031 line:-1
You can open the resulting USDZ
file of the sneaker you created


316
00:14:59.031 --> 00:15:02.902 line:-1 position:50%
right on your Mac
and inspect the results in 3D


317
00:15:02,902 --> 00:15:06,606 line:-1
from any angle,
including the bottom.


318
00:15:06,606 --> 00:15:07,640 line:-1
Later in this session,


319
00:15:07,640 --> 00:15:09,408 line:-1
we'll show you
how to achieve coverage


320
00:15:09.408 --> 00:15:13.112 line:-1 position:50%
for all sides of your object
in one capture session,


321
00:15:13.112 --> 00:15:16.649 line:-1 position:50%
avoiding the need to combine
multiple captures together.


322
00:15:16,649 --> 00:15:18,785 line:-1
It's looking great!


323
00:15:18.785 --> 00:15:21.020 line:-1 position:50%
Now that you've seen
the basic workflow,


324
00:15:21,020 --> 00:15:22,655 line:-1
we will give
a high-level overview


325
00:15:22.655 --> 00:15:25.057 line:-1 position:50%
of a more advanced
interactive workflow


326
00:15:25,057 --> 00:15:28,561 line:-1
that the Object Capture API
also supports.


327
00:15:28.561 --> 00:15:30.863 line:-1 position:50%
The interactive workflow
is designed to allow


328
00:15:30,863 --> 00:15:33,833 line:-1
several adjustments to be made
on a preview model


329
00:15:33.833 --> 00:15:36.102 line:-1 position:50%
before the final reconstruction,


330
00:15:36,102 --> 00:15:39,205 line:-1
which can eliminate the need
for post-production model edits


331
00:15:39,205 --> 00:15:42,074 line:-1
and optimize the use of memory.


332
00:15:42,074 --> 00:15:45,411 line:-1
First, note that the Setup step
and the Process step


333
00:15:45.411 --> 00:15:49.048 line:-1 position:50%
on both ends of this workflow
are the same as before.


334
00:15:49,048 --> 00:15:52,685 line:-1
You will still create a session
and connect the output stream.


335
00:15:52.685 --> 00:15:55.721 line:-1 position:50%
You will also request
final models as before.


336
00:15:55,721 --> 00:15:59,725 line:-1
However, notice that we've added
a block in the middle


337
00:15:59.725 --> 00:16:01.561 line:-1 position:50%
where a 3D UI is presented


338
00:16:01,561 --> 00:16:04,931 line:-1
for interactive editing
of a preview model.


339
00:16:04,931 --> 00:16:09,202 line:-1
This process is iterated until
you are happy with the preview.


340
00:16:09,202 --> 00:16:11,804 line:-1
You can then continue to make
the final model requests


341
00:16:11,804 --> 00:16:13,573 line:-1
as before.


342
00:16:13.573 --> 00:16:15.508 line:-1 position:50%
You first request
a preview model


343
00:16:15.508 --> 00:16:20.313 line:-1 position:50%
by specifying a model request
with detail level of preview.


344
00:16:20.313 --> 00:16:22.748 line:-1 position:50%
A preview model
is of low visual quality


345
00:16:22.748 --> 00:16:25.952 line:-1 position:50%
and is generated
as quickly as possible.


346
00:16:25.952 --> 00:16:28.321 line:-1 position:50%
You can ask for a model file
and load it yourself


347
00:16:28,321 --> 00:16:32,892 line:-1
or directly request a RealityKit
ModelEntity to display.


348
00:16:32.892 --> 00:16:35.928 line:-1 position:50%
Typically, a bounds request
is also made at the same time


349
00:16:35.928 --> 00:16:39.565 line:-1 position:50%
to preview and edit
the capture volume as well.


350
00:16:39,565 --> 00:16:41,234 line:-1
You can adjust
the capture volume


351
00:16:41,234 --> 00:16:44,570 line:-1
to remove any unwanted
geometry in the capture,


352
00:16:44,570 --> 00:16:47,006 line:-1
such as a pedestal needed
to hold the object upright


353
00:16:47.006 --> 00:16:49.108 line:-1 position:50%
during capture.


354
00:16:49.108 --> 00:16:52.011 line:-1 position:50%
You can also adjust
the root transform to scale,


355
00:16:52,011 --> 00:16:55,381 line:-1
translate, and rotate the model.


356
00:16:55,381 --> 00:16:58,517 line:-1
The geometry property of
the request we saw earlier


357
00:16:58,517 --> 00:17:01,420 line:-1
allows a capture volume
and relative root transform


358
00:17:01,420 --> 00:17:05,024 line:-1
to be provided before the model
is generated.


359
00:17:05,024 --> 00:17:08,661 line:-1
This outputs a 3D model
that's ready to use.


360
00:17:08.661 --> 00:17:10.596 line:-1 position:50%
Let's look at this process
in action.


361
00:17:10.596 --> 00:17:13.933 line:-1 position:50%
Here we see an example
interactive Object Capture app


362
00:17:13.933 --> 00:17:15.935 line:-1 position:50%
we created using the API


363
00:17:15,935 --> 00:17:18,571 line:-1
to demonstrate
this interactive workflow.


364
00:17:18,571 --> 00:17:21,040 line:-1
First, we select
the Images folder


365
00:17:21,040 --> 00:17:23,209 line:-1
containing images
of a decorative rock,


366
00:17:23.209 --> 00:17:25.244 line:-1 position:50%
as well as an output folder


367
00:17:25.244 --> 00:17:29.482 line:-1 position:50%
where the final USDZ
will be written.


368
00:17:29.482 --> 00:17:32.752 line:-1 position:50%
Then we hit Preview
to request the preview model


369
00:17:32.752 --> 00:17:35.354 line:-1 position:50%
and estimated capture volume.


370
00:17:35,354 --> 00:17:37,123 line:-1
After some time has passed,


371
00:17:37.123 --> 00:17:41.394 line:-1 position:50%
the preview model of our rock
and its capture volume appear.


372
00:17:41,394 --> 00:17:42,828 line:-1
But let's say that we only want


373
00:17:42,828 --> 00:17:44,730 line:-1
the top part of the rock
in the output


374
00:17:44,730 --> 00:17:47,066 line:-1
as if the bottom
were underground.


375
00:17:47,066 --> 00:17:48,501 line:-1
We can adjust the bounding box


376
00:17:48,501 --> 00:17:51,570 line:-1
to avoid reconstructing
the bottom of the model.


377
00:17:51,570 --> 00:17:52,805 line:-1
Once we are happy,


378
00:17:52,805 --> 00:17:55,675 line:-1
we hit Refine Model
to produce a new preview


379
00:17:55.675 --> 00:17:59.178 line:-1 position:50%
restricted to this
modified capture volume.


380
00:17:59.178 --> 00:18:03.516 line:-1 position:50%
This also optimizes the output
model for just this portion.


381
00:18:03.516 --> 00:18:08.054 line:-1 position:50%
Once the refined model is ready,
the new preview appears.


382
00:18:08,054 --> 00:18:11,057 line:-1
You can see the new model's
geometry has been clipped


383
00:18:11,057 --> 00:18:13,326 line:-1
to stay inside the box.


384
00:18:13.326 --> 00:18:16.462 line:-1 position:50%
This is useful for removing
unwanted items in a capture


385
00:18:16,462 --> 00:18:19,598 line:-1
such as a pedestal
holding up an object.


386
00:18:19.598 --> 00:18:21.500 line:-1 position:50%
Once we are happy
with the cropped preview,


387
00:18:21.500 --> 00:18:23.836 line:-1 position:50%
we can select
a Full detail final render


388
00:18:23.836 --> 00:18:26.839 line:-1 position:50%
which starts
the creation process.


389
00:18:26,839 --> 00:18:30,209 line:-1
After some time, the Full detail
model is complete


390
00:18:30.209 --> 00:18:32.611 line:-1 position:50%
and replaces the preview model.


391
00:18:32.611 --> 00:18:35.848 line:-1 position:50%
Now we can see the Full detail
of the actual model,


392
00:18:35,848 --> 00:18:37,850 line:-1
which looks great.


393
00:18:37.850 --> 00:18:39.819 line:-1 position:50%
The model is saved
in the output directory


394
00:18:39.819 --> 00:18:41.754 line:-1 position:50%
and ready to use
without the need


395
00:18:41.754 --> 00:18:43.823 line:-1 position:50%
for any additional
post-processing.


396
00:18:43.823 --> 00:18:45.491 line:-1 position:50%
And that's all there is
to getting started


397
00:18:45,491 --> 00:18:48,294 line:-1
with the new Object Capture API.


398
00:18:48,294 --> 00:18:50,930 line:-1
We saw how to create a session
from an input source


399
00:18:50,930 --> 00:18:53,232 line:-1
such as a folder of images.


400
00:18:53,232 --> 00:18:55,501 line:-1
We saw how to connect
the async output stream


401
00:18:55.501 --> 00:18:57.803 line:-1 position:50%
to dispatch messages.


402
00:18:57,803 --> 00:18:59,372 line:-1
We then saw how to request


403
00:18:59.372 --> 00:19:03.009 line:-1 position:50%
two different level of detail
models simultaneously.


404
00:19:03,009 --> 00:19:06,045 line:-1
Finally, we described
the interactive workflow


405
00:19:06.045 --> 00:19:10.916 line:-1 position:50%
with an example RealityKit
GUI app for ObjectCapture.


406
00:19:10,916 --> 00:19:13,753 line:-1
Now I will hand it off
to my colleague Dave McKinnon,


407
00:19:13,753 --> 00:19:17,823 line:-1
who will discuss best practices
with Object Capture.


408
00:19:17.823 --> 00:19:19.091 line:-1 position:50%
Dave McKinnon: Thanks, Michael.


409
00:19:19.091 --> 00:19:21.394 line:-1 position:50%
Hi, I'm Dave McKinnon,
and I am an engineer


410
00:19:21.394 --> 00:19:23.696 line:-1 position:50%
working on the Object Capture
team.


411
00:19:23,696 --> 00:19:26,365 line:-1
In the next section we’ll
be covering best practices


412
00:19:26,365 --> 00:19:30,069 line:-1
to help you achieve
the highest-quality results.


413
00:19:30,069 --> 00:19:32,204 line:-1
First, we'll look into
tips and tricks


414
00:19:32.204 --> 00:19:35.674 line:-1 position:50%
for selecting an object that has
the right characteristics.


415
00:19:35,674 --> 00:19:37,943 line:-1
Followed by a discussion
of how to control


416
00:19:37.943 --> 00:19:40.179 line:-1 position:50%
the environmental conditions
and camera


417
00:19:40.179 --> 00:19:42.214 line:-1 position:50%
to get the best results.


418
00:19:42,214 --> 00:19:45,885 line:-1
Next, we'll walk through how
to use the CaptureSample App.


419
00:19:45,885 --> 00:19:47,853 line:-1
This app allows you
to capture images


420
00:19:47.853 --> 00:19:50.556 line:-1 position:50%
in addition to depth data
and gravity information


421
00:19:50.556 --> 00:19:54.860 line:-1 position:50%
to recover true scale
and orientation of your object.


422
00:19:54,860 --> 00:19:57,329 line:-1
We illustrate the use of
this app for both in-hand


423
00:19:57,329 --> 00:20:00,066 line:-1
as well as turntable capture.


424
00:20:00.066 --> 00:20:02.101 line:-1 position:50%
Finally, we will discuss
how to select


425
00:20:02.101 --> 00:20:04.904 line:-1 position:50%
the right output detail level
for your use case


426
00:20:04,904 --> 00:20:08,441 line:-1
as well as providing some links
for further reading.


427
00:20:08.441 --> 00:20:10.376 line:-1 position:50%
The first thing to consider
when doing a scan


428
00:20:10,376 --> 00:20:13,646 line:-1
is picking an object that has
the right characteristics.


429
00:20:13,646 --> 00:20:14,847 line:-1
For the best results,


430
00:20:14,847 --> 00:20:17,883 line:-1
pick an object that has
adequate texture detail.


431
00:20:17,883 --> 00:20:19,752 line:-1
If the object
contains textureless


432
00:20:19.752 --> 00:20:21.120 line:-1 position:50%
or transparent regions,


433
00:20:21.120 --> 00:20:24.190 line:-1 position:50%
the resulting scan
may lack detail.


434
00:20:24,190 --> 00:20:26,559 line:-1
Additionally, try to avoid
objects that contain


435
00:20:26,559 --> 00:20:28,727 line:-1
highly reflective regions.


436
00:20:28.727 --> 00:20:31.464 line:-1 position:50%
If the object is reflective,
you will get the best results


437
00:20:31,464 --> 00:20:34,300 line:-1
by diffusing the lighting
when you scan.


438
00:20:34.300 --> 00:20:36.969 line:-1 position:50%
If you plan to flip the object
throughout the capture,


439
00:20:36.969 --> 00:20:40.539 line:-1 position:50%
make sure it is rigid
so that it doesn't change shape.


440
00:20:40,539 --> 00:20:42,308 line:-1
Lastly, if you want
to scan an object


441
00:20:42,308 --> 00:20:44,610 line:-1
that contains
fine surface detail,


442
00:20:44,610 --> 00:20:47,012 line:-1
you'll need to use
a high-resolution camera


443
00:20:47.012 --> 00:20:49.148 line:-1 position:50%
in addition to having
many close-up photos


444
00:20:49.148 --> 00:20:52.751 line:-1 position:50%
of the surface
to recover the detail.


445
00:20:52.751 --> 00:20:56.021 line:-1 position:50%
We will now demonstrate
the typical scanning process.


446
00:20:56,021 --> 00:20:58,224 line:-1
Firstly, for best results,


447
00:20:58.224 --> 00:21:00.593 line:-1 position:50%
place your object
on an uncluttered background


448
00:21:00,593 --> 00:21:03,362 line:-1
so the object
clearly stands out.


449
00:21:03.362 --> 00:21:06.799 line:-1 position:50%
The basic process involves
moving slowly around the object


450
00:21:06.799 --> 00:21:10.503 line:-1 position:50%
being sure to capture it
uniformly from all sides.


451
00:21:10,503 --> 00:21:13,139 line:-1
If you would like to reconstruct
the bottom of the object,


452
00:21:13,139 --> 00:21:16,108 line:-1
flip it and continue
to capture images.


453
00:21:16,108 --> 00:21:17,443 line:-1
When taking the images,


454
00:21:17,443 --> 00:21:19,912 line:-1
try to maximize the portion
of the field of view


455
00:21:19.912 --> 00:21:21.914 line:-1 position:50%
capturing the object.


456
00:21:21,914 --> 00:21:26,452 line:-1
This helps the API to recover
as much detail as possible.


457
00:21:26,452 --> 00:21:29,889 line:-1
One way to do this is to use
portrait or landscape mode


458
00:21:29.889 --> 00:21:33.792 line:-1 position:50%
depending on the object's
dimensions and orientation.


459
00:21:33.792 --> 00:21:36.328 line:-1 position:50%
Also, try to maintain
a high degree of overlap


460
00:21:36,328 --> 00:21:38,531 line:-1
between the images.


461
00:21:38.531 --> 00:21:42.034 line:-1 position:50%
Depending on the object,
20 to 200 close-up images


462
00:21:42,034 --> 00:21:44,737 line:-1
should be enough
to get good results.


463
00:21:44.737 --> 00:21:47.273 line:-1 position:50%
To help you get started
capturing high-quality photos


464
00:21:47.273 --> 00:21:49.275 line:-1 position:50%
with depth and gravity on iOS,


465
00:21:49.275 --> 00:21:51.377 line:-1 position:50%
we provide
the CaptureSample App.


466
00:21:51,377 --> 00:21:54,113 line:-1
This can be used as a starting
point for your own apps.


467
00:21:54.113 --> 00:21:55.781 line:-1 position:50%
It is written in SwiftUI


468
00:21:55.781 --> 00:21:59.018 line:-1 position:50%
and is part of
the developer documentation.


469
00:21:59.018 --> 00:22:01.754 line:-1 position:50%
This app demonstrates
how to take high-quality photos


470
00:22:01.754 --> 00:22:03.822 line:-1 position:50%
for Object Capture.


471
00:22:03,822 --> 00:22:06,659 line:-1
It has a manual
and timed shutter mode.


472
00:22:06,659 --> 00:22:09,895 line:-1
You could also modify the app
to sync with your turntable.


473
00:22:09.895 --> 00:22:12.865 line:-1 position:50%
It demonstrates how to use
the iPhone and iPads


474
00:22:12,865 --> 00:22:15,868 line:-1
with dual camera to capture
depth data and embed it


475
00:22:15,868 --> 00:22:18,470 line:-1
right into the output
HEIC files.


476
00:22:18,470 --> 00:22:22,141 line:-1
The app also shows you
how to save gravity data.


477
00:22:22,141 --> 00:22:24,443 line:-1
You can view your gallery
to quickly verify


478
00:22:24.443 --> 00:22:27.880 line:-1 position:50%
that you have all good-quality
photos with depth and gravity


479
00:22:27.880 --> 00:22:29.815 line:-1 position:50%
and delete bad shots.


480
00:22:29.815 --> 00:22:32.885 line:-1 position:50%
Capture folders are saved
in the app's Documents folder


481
00:22:32.885 --> 00:22:37.923 line:-1 position:50%
where it is easy to copy to your
Mac using iCloud or AirDrop.


482
00:22:37.923 --> 00:22:39.158 line:-1 position:50%
There are also help screens


483
00:22:39.158 --> 00:22:41.493 line:-1 position:50%
that summarize some of
the best practice guidelines


484
00:22:41,493 --> 00:22:45,264 line:-1
to get a good capture
that we discuss in this section.


485
00:22:45.264 --> 00:22:47.032 line:-1 position:50%
You can also find
this information


486
00:22:47.032 --> 00:22:49.401 line:-1 position:50%
in developer documentation.


487
00:22:49.401 --> 00:22:51.237 line:-1 position:50%
We recommend turntable capture


488
00:22:51.237 --> 00:22:53.539 line:-1 position:50%
to get the best
results possible.


489
00:22:53.539 --> 00:22:54.940 line:-1 position:50%
In order to get started,


490
00:22:54,940 --> 00:22:57,576 line:-1
you'll need a setup
like we have here.


491
00:22:57.576 --> 00:23:00.679 line:-1 position:50%
This contains
an iOS device for capture,


492
00:23:00.679 --> 00:23:03.549 line:-1 position:50%
but you can also use
a digital SLR;


493
00:23:03,549 --> 00:23:06,685 line:-1
mechanical turntable
to rotate the object;


494
00:23:06.685 --> 00:23:10.122 line:-1 position:50%
some lighting panels
in addition to a light tent.


495
00:23:10,122 --> 00:23:12,057 line:-1
The goal is to have
uniform lighting


496
00:23:12.057 --> 00:23:14.260 line:-1 position:50%
and avoid any hard shadows.


497
00:23:14,260 --> 00:23:17,730 line:-1
A light tent is a good way
to achieve this.


498
00:23:17.730 --> 00:23:19.431 line:-1 position:50%
In this case,
the CaptureSample App


499
00:23:19.431 --> 00:23:22.201 line:-1 position:50%
captures images using
the timed shutter mode


500
00:23:22,201 --> 00:23:24,903 line:-1
synced with the motion
of the turntable.


501
00:23:24.903 --> 00:23:28.641 line:-1 position:50%
We can also flip the object
and do multiple turntable passes


502
00:23:28,641 --> 00:23:31,243 line:-1
to capture the object
from all sides.


503
00:23:31.243 --> 00:23:34.913 line:-1 position:50%
Here is the resulting USDZ file
from the turntable capture


504
00:23:34.913 --> 00:23:37.449 line:-1 position:50%
shown in Preview on macOS.


505
00:23:37.449 --> 00:23:40.986 line:-1 position:50%
Now that we've covered tips
and tricks for capturing images,


506
00:23:40,986 --> 00:23:42,621 line:-1
let's move to our last section


507
00:23:42,621 --> 00:23:45,591 line:-1
on how to select
the right output.


508
00:23:45.591 --> 00:23:48.193 line:-1 position:50%
There's a variety of different
output detail settings


509
00:23:48,193 --> 00:23:49,928 line:-1
available for a scan.


510
00:23:49.928 --> 00:23:51.630 line:-1 position:50%
Let's take a look.


511
00:23:51,630 --> 00:23:54,566 line:0
Here is the table showing
the detail levels.


512
00:23:54,566 --> 00:23:58,070 position:50%
The supported levels are shown
along the leftd side.


513
00:23:58,070 --> 00:24:00,439 position:50%
Reduced and Medium
are optimized for use


514
00:24:00,439 --> 00:24:03,375 line:0
in web-based
and mobile experiences,


515
00:24:03,375 --> 00:24:06,912 position:50%
such as viewing 3D content
in AR Quick Look.


516
00:24:06,912 --> 00:24:09,315 line:0
They have fewer triangles
and material channels


517
00:24:09,315 --> 00:24:12,484 line:0
and consequently
consume less memory.


518
00:24:12,484 --> 00:24:16,655 position:50%
The Full and Raw are intended
for high-end interactive use


519
00:24:16,655 --> 00:24:20,793 position:50%
such as computer games
or post-production workflows.


520
00:24:20,793 --> 00:24:23,028 line:0
They contain the highest
geometric detail


521
00:24:23,028 --> 00:24:24,430 line:0
and give you the flexibility


522
00:24:24,430 --> 00:24:28,167 line:0
to choose between baked
and unbaked materials.


523
00:24:28,167 --> 00:24:31,170 line:-1
Reduced and Medium detail levels
are best for content


524
00:24:31.170 --> 00:24:35.541 line:-1 position:50%
that you wish to display on
the internet or mobile device.


525
00:24:35.541 --> 00:24:38.110 line:-1 position:50%
In this instance,
Object Capture will compress


526
00:24:38,110 --> 00:24:42,114 line:-1
the geometric and material
information from the Raw result


527
00:24:42.114 --> 00:24:45.150 line:-1 position:50%
down to a level that will be
appropriate for display


528
00:24:45,150 --> 00:24:48,354 line:-1
in AR apps
or through AR Quick Look.


529
00:24:48,354 --> 00:24:51,156 line:-1
Both detail levels,
Reduced and Medium,


530
00:24:51,156 --> 00:24:53,525 line:-1
contain the diffuse, normal,


531
00:24:53,525 --> 00:24:56,895 line:-1
and ambient occlusion PBR
material channels.


532
00:24:56.895 --> 00:25:00.132 line:-1 position:50%
If you would like to display
a single scan in high detail,


533
00:25:00,132 --> 00:25:03,535 line:-1
Medium will maximize the quality
against the file size


534
00:25:03,535 --> 00:25:08,140 line:-1
to give you both more geometric
and material detail.


535
00:25:08,140 --> 00:25:11,143 line:-1
However, if you would like
to display multiple scans


536
00:25:11,143 --> 00:25:12,411 line:-1
in the same scene,


537
00:25:12,411 --> 00:25:15,347 line:-1
you should use
the Reduced detail setting.


538
00:25:15,347 --> 00:25:18,083 line:-1
If you want to learn more about
how to use Object Capture


539
00:25:18,083 --> 00:25:21,153 line:-1
to create mobile
or web AR experiences,


540
00:25:21.153 --> 00:25:25.858 line:-1 position:50%
please see the "AR Quick Look,
meet Object Capture" session.


541
00:25:25,858 --> 00:25:27,559 line:-1
Exporting with Full output level


542
00:25:27.559 --> 00:25:30.462 line:-1 position:50%
is a great choice
for pro workflows.


543
00:25:30,462 --> 00:25:32,998 line:-1
In this instance, you are
getting the maximum detail


544
00:25:32,998 --> 00:25:35,534 line:-1
available for your scan.


545
00:25:35.534 --> 00:25:37.836 line:-1 position:50%
Full will optimize
the geometry of the scan


546
00:25:37,836 --> 00:25:40,606 line:-1
and bake the detail
into a PBR material


547
00:25:40.606 --> 00:25:45.144 line:-1 position:50%
containing Diffuse, Normal,
Ambient Occlusion, Roughness,


548
00:25:45,144 --> 00:25:47,513 line:-1
and Displacement information.


549
00:25:47,513 --> 00:25:50,616 line:-1
We think that this output level will
give you everything you need


550
00:25:50,616 --> 00:25:53,719 line:-1
for the most challenging
renders.


551
00:25:53,719 --> 00:25:56,188 line:-1
Lastly, if you don't need
material baking


552
00:25:56,188 --> 00:25:58,357 line:-1
or you have your own
pipeline for this,


553
00:25:58.357 --> 00:26:01.326 line:-1 position:50%
the Raw level will return
the maximum poly count


554
00:26:01,326 --> 00:26:03,962 line:-1
along with the maximum
diffuse texture detail


555
00:26:03,962 --> 00:26:06,298 line:-1
for further processing.


556
00:26:06.298 --> 00:26:08.901 line:-1 position:50%
If you want to learn more about
how to use Object Capture


557
00:26:08.901 --> 00:26:11.069 line:-1 position:50%
for pro workflows on macOS,


558
00:26:11,069 --> 00:26:15,574 line:-1
please see the "Create 3D
Workflows with USD" session.


559
00:26:15.574 --> 00:26:17.309 line:-1 position:50%
Finally, and most importantly,


560
00:26:17,309 --> 00:26:21,447 line:-1
if you plan to use your scan
on both iOS, as well as macOS,


561
00:26:21.447 --> 00:26:24.116 line:-1 position:50%
you can select multiple
detail levels to make sure


562
00:26:24,116 --> 00:26:25,884 line:-1
you have all the right outputs


563
00:26:25,884 --> 00:26:29,588 line:-1
for current and future
use cases.


564
00:26:29,588 --> 00:26:30,589 line:-1
And that's a wrap.


565
00:26:30,589 --> 00:26:32,925 line:-1
Let's recap
what have we have learned.


566
00:26:32,925 --> 00:26:36,161 line:-1
First, we covered, through
example, the main concepts


567
00:26:36.161 --> 00:26:38.697 line:-1 position:50%
behind the Object Capture API.


568
00:26:38,697 --> 00:26:41,366 line:-1
We showed you how to create
an Object Capture session


569
00:26:41,366 --> 00:26:42,935 line:-1
and to use this session


570
00:26:42,935 --> 00:26:47,372 line:-1
to process your collection of
images to produce a 3D model.


571
00:26:47,372 --> 00:26:50,142 line:-1
We showed you an example
of how the API can support


572
00:26:50,142 --> 00:26:52,478 line:-1
an interactive
preview application


573
00:26:52,478 --> 00:26:56,815 line:-1
to let you adjust the capture
volume and model transform.


574
00:26:56.815 --> 00:26:59.685 line:-1 position:50%
Next, we covered best practices
for scanning.


575
00:26:59.685 --> 00:27:01.854 line:-1 position:50%
We discussed
what type of objects to use


576
00:27:01,854 --> 00:27:04,423 line:-1
as well the environment,
lighting, and camera settings


577
00:27:04.423 --> 00:27:06.325 line:-1 position:50%
that give best results.


578
00:27:06.325 --> 00:27:07.960 line:-1 position:50%
Lastly, we discussed
how to choose


579
00:27:07.960 --> 00:27:11.330 line:-1 position:50%
the right output detail settings
for your application.


580
00:27:11,330 --> 00:27:13,499 line:-1
If you want to learn
how to bring Object Capture


581
00:27:13.499 --> 00:27:14.633 line:-1 position:50%
to your own app,


582
00:27:14,633 --> 00:27:18,670 line:-1
check out both the iOS capture
and macOS CLI processing apps


583
00:27:18,670 --> 00:27:20,405 line:-1
to get started.


584
00:27:20,405 --> 00:27:23,342 line:-1
Along with these apps comes
a variety of sample data


585
00:27:23,342 --> 00:27:25,010 line:-1
that embodies best practice


586
00:27:25,010 --> 00:27:29,414 line:-1
and can help when planning on
how to capture your own scans.


587
00:27:29,414 --> 00:27:32,518 position:50%
Additionally, please check out
the detailed documentation


588
00:27:32,518 --> 00:27:36,855 line:0
on best practice online
at developer.apple.com,


589
00:27:36,855 --> 00:27:41,026 position:50%
as well these related
WWDC sessions.


590
00:27:41,026 --> 00:27:43,395 line:-1
The only thing that remains
is for you to go out


591
00:27:43.395 --> 00:27:45.898 line:-1 position:50%
and use Object Capture
for your own scans.


592
00:27:45,898 --> 00:27:49,635 line:-1
We are excited to see what
objects you will scan and share.


593
00:27:49,635 --> 00:27:52,671 align:right line:0 position:90%
♪

