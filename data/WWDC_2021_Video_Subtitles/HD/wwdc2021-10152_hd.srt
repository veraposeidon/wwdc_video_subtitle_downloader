2
00:00:00,567 --> 00:00:07,574 line:-1
[upbeat music]


3
00:00:09,042 --> 00:00:11,311 line:-2
[Saharsh] Hi.
I'm Saharsh Oza.


4
00:00:11,345 --> 00:00:14,548 line:-2
I'm with the GPU Software
Engineering team at Apple.


5
00:00:14,581 --> 00:00:17,184 line:-2
Today my colleague,
Yuliya Pylypiv, and I


6
00:00:17,217 --> 00:00:20,521 line:-2
will talk about what's new in
Metal Performance Shaders Graph.


7
00:00:20.554 --> 00:00:22.956 line:-1 align:center
Let us begin.


8
00:00:22,990 --> 00:00:26,260 line:-2
MPS is a library of metal-based,
high-performance,


9
00:00:26,293 --> 00:00:29,830 line:-2
GPU-accelerated primitives
for varied fields


10
00:00:29.863 --> 00:00:33.000 line:-2 align:center
like image processing,
linear algebra,


11
00:00:33,033 --> 00:00:35,869 line:-2
ray tracing,
and machine learning.


12
00:00:35,903 --> 00:00:38,472 line:-1
MPS team optimizes Metal kernels


13
00:00:38,505 --> 00:00:40,641 line:-2
to give the best performance
on each hardware


14
00:00:40.674 --> 00:00:44.144 line:-2 align:center
across Apple's various
platforms.


15
00:00:44,178 --> 00:00:48,115 line:-2
Last year, we introduced
the MPSGraph framework,


16
00:00:48.148 --> 00:00:51.585 line:-2 align:center
a general purpose compute
graph for the GPU.


17
00:00:51,618 --> 00:00:54,755 line:-1
It is supported on macOS, iOS,


18
00:00:54.788 --> 00:00:57.658 line:-1 align:center
iPadOS and tvOS,


19
00:00:57,691 --> 00:01:00,260 line:-1
same as the MPS framework.


20
00:01:00,294 --> 00:01:02,095 line:-2
Please watch our last year's
session


21
00:01:02,129 --> 00:01:05,499 line:-2
to get more introductory details
on the MPSGraph.


22
00:01:05.532 --> 00:01:07.768 line:-1 align:center
Let's take a look at the agenda.


23
00:01:07.801 --> 00:01:09.336 line:-1 align:center
We have a lot to cover.


24
00:01:09,369 --> 00:01:12,439 line:-2
We will discuss ML inference
and training acceleration


25
00:01:12.472 --> 00:01:14.608 line:-1 align:center
through MPSGraph.


26
00:01:14,641 --> 00:01:18,579 line:-2
We will introduce some exciting
new MPSGraph operations.


27
00:01:18,612 --> 00:01:20,447 line:-1
We will introduce new ways


28
00:01:20,480 --> 00:01:23,784 line:-2
for you to control compilation
in MPSGraph.


29
00:01:23.817 --> 00:01:25.752 line:-1 align:center
And finally, we will look


30
00:01:25,786 --> 00:01:29,723 line:-2
at the all new control-flow
capabilities of MPSGraph.


31
00:01:29.756 --> 00:01:31.925 line:-2 align:center
I'd like to introduce
my colleague, Yuliya,


32
00:01:31,959 --> 00:01:33,861 line:-2
who will share
some exciting updates


33
00:01:33.894 --> 00:01:36.530 line:-2 align:center
for inference
and training acceleration.


34
00:01:36,563 --> 00:01:37,564 line:-1
[Yuliya] Thanks, Saharsh.


35
00:01:37,598 --> 00:01:39,399 line:-2
Hi.
I'm Yuliya Pylypiv.


36
00:01:39.433 --> 00:01:42.269 line:-2 align:center
I am a part
of GPU Software team at Apple.


37
00:01:42,302 --> 00:01:44,605 line:-2
Today, I want to share
the improvements we've made


38
00:01:44,638 --> 00:01:47,708 line:-2
to boost training and
inference performance on GPU.


39
00:01:47.741 --> 00:01:50.878 line:-1 align:center
Let's get right into it.


40
00:01:50,911 --> 00:01:53,380 line:-2
The MPSGraph framework
has been adopted


41
00:01:53,413 --> 00:01:56,884 line:-2
by higher level machine learning
frameworks like Core ML


42
00:01:56,917 --> 00:01:59,820 line:-2
and TensorFlow for GPU
acceleration.


43
00:01:59,853 --> 00:02:03,557 line:-2
This year, we have optimized
MPSGraph even further


44
00:02:03.590 --> 00:02:06.093 line:-2 align:center
with a combination of kernel
improvements


45
00:02:06,126 --> 00:02:07,928 line:-1
and stitching adoption.


46
00:02:07.961 --> 00:02:10.831 line:-2 align:center
This has translated
to large performance gains


47
00:02:10,864 --> 00:02:14,768 line:-2
to the machine learning
frameworks that use MPS.


48
00:02:14,801 --> 00:02:16,336 line:-1
Let's take a closer look


49
00:02:16.370 --> 00:02:19.239 line:-2 align:center
at the new Metal Plugin
for TensorFlow.


50
00:02:19.273 --> 00:02:22.342 line:-2 align:center
TensorFlow is a popular machine
learning training platform,


51
00:02:22.376 --> 00:02:25.812 line:-2 align:center
and GPUs are the
predominant accelerator device.


52
00:02:25,846 --> 00:02:28,916 line:-2
This year, we have
developed a new Metal Plugin


53
00:02:28,949 --> 00:02:31,418 line:-2
using TensorFlow PluggableDevice
Interface


54
00:02:31,451 --> 00:02:34,488 line:-1
released in TensorFlow 2.5.


55
00:02:34,521 --> 00:02:37,224 line:-2
This brings the power
of Metal to TensorFlow


56
00:02:37.257 --> 00:02:39.860 line:-1 align:center
using MPS and MPSGraph.


57
00:02:39.893 --> 00:02:42.796 line:-2 align:center
This allows us to train
any machine learning model


58
00:02:42.829 --> 00:02:46.667 line:-2 align:center
on Mac platform GPUs
without modifications.


59
00:02:46,700 --> 00:02:48,869 line:-2
Now, let's see one of these in
action.


60
00:02:48.902 --> 00:02:52.706 line:-2 align:center
For this demo, I am going to
use a Jupyter environment.


61
00:02:52,739 --> 00:02:54,875 line:-1
On my M1 system,


62
00:02:54,908 --> 00:02:58,712 line:-2
I have the latest available
TensorFlow installed.


63
00:02:58.745 --> 00:03:00.914 line:-1 align:center
When we list physical devices,


64
00:03:00.948 --> 00:03:04.318 line:-2 align:center
you can see there is only
a CPU device registered.


65
00:03:06,086 --> 00:03:08,989 line:-2
Here I am defining a popular
machine learning model,


66
00:03:09.022 --> 00:03:12.559 line:-2 align:center
ResNet50, which is widely used
for image classification,


67
00:03:12,593 --> 00:03:14,895 line:-1
transfer learning, and more.


68
00:03:16,897 --> 00:03:19,933 line:-2
Current model uses
a standard ImageNet dataset


69
00:03:19,967 --> 00:03:23,237 line:-1
with 224 by 224 image sizes.


70
00:03:25.038 --> 00:03:28.475 line:-2 align:center
As you can see, the current
ETA for the first epoch


71
00:03:28.509 --> 00:03:32.379 line:-2 align:center
running on CPU is
around 20 minutes.


72
00:03:32.412 --> 00:03:34.214 line:-2 align:center
Let me install the TensorFlow
Metal Plugin


73
00:03:34.248 --> 00:03:35.782 line:-1 align:center
which we introduced earlier


74
00:03:35.816 --> 00:03:39.186 line:-2 align:center
and see if we can add some
speedup to the current network.


75
00:03:39,219 --> 00:03:40,721 line:-1
To do so,


76
00:03:40,754 --> 00:03:44,424 line:-2
I'm gonna use
pip install tensorflow-metal...


77
00:03:49,162 --> 00:03:52,866 line:-2
going back to the same
ResNet50 model we used before.


78
00:03:54.635 --> 00:03:56.203 line:-2 align:center
Only this time,
you can see


79
00:03:56,236 --> 00:03:58,405 line:-2
there is a new GPU device
registered.


80
00:03:58.438 --> 00:04:00.674 line:-2 align:center
This is the GPU device we
introduced


81
00:04:00,707 --> 00:04:04,178 line:-2
as a part of the TensorFlow
platform using Metal Plugin.


82
00:04:06.880 --> 00:04:09.283 line:-2 align:center
All callbacks and network
definition


83
00:04:09.316 --> 00:04:11.218 line:-1 align:center
remain unchanged.


84
00:04:11,251 --> 00:04:15,189 line:-2
Kicking off the network again
so we can compare ETAs.


85
00:04:15,222 --> 00:04:18,692 line:-2
You can see that the GPU version
of the same network


86
00:04:18,725 --> 00:04:20,827 line:-2
is training around
four times faster


87
00:04:20,861 --> 00:04:22,663 line:-1
using TensorFlow Metal Plugin.


88
00:04:24,064 --> 00:04:27,467 line:-2
Now let's take a closer look
at the other networks.


89
00:04:27,501 --> 00:04:29,169 line:-1
Here we show the performance


90
00:04:29,203 --> 00:04:33,006 line:-2
on key machine learning training
benchmarks relative to the CPU.


91
00:04:33,040 --> 00:04:36,877 line:-2
As you can see, we have a good
speedup across all benchmarks,


92
00:04:36,910 --> 00:04:40,881 line:-2
going up to eight times faster
on the M1 MacBook Pro.


93
00:04:42,349 --> 00:04:46,253 line:-2
Installing the new Metal Plugin
for TensorFlow is easy.


94
00:04:46,286 --> 00:04:48,422 line:-2
After installing the base
TensorFlow


95
00:04:48,455 --> 00:04:50,791 line:-2
using pip install
tensorflow-macos,


96
00:04:50,824 --> 00:04:52,593 line:-1
you can install Metal Plugin


97
00:04:52,626 --> 00:04:55,162 line:-2
using pip install
tensorflow-metal.


98
00:04:55.195 --> 00:04:56.897 line:-2 align:center
The Metal Plugin
will be available


99
00:04:56.930 --> 00:05:00.734 line:-2 align:center
on the official Python package
repo, pypi.org.


100
00:05:00,767 --> 00:05:04,238 line:-2
For details on environment setup
and installation,


101
00:05:04,271 --> 00:05:06,907 line:-2
please refer to Metal Developer
Resource.


102
00:05:06,940 --> 00:05:08,308 line:-1
That's it for TensorFlow.


103
00:05:08.342 --> 00:05:12.012 line:-2 align:center
Next, let's talk about Inference
acceleration in Core ML.


104
00:05:13,213 --> 00:05:16,683 line:-2
Core ML is Apple's machine
learning inference framework.


105
00:05:16,717 --> 00:05:19,920 line:-2
We also saw significant
performance improvements


106
00:05:19.953 --> 00:05:23.190 line:-1 align:center
on Core ML with MPSGraph.


107
00:05:23,223 --> 00:05:25,926 line:-2
We show here inference speedup
of key classes


108
00:05:25,959 --> 00:05:28,629 line:-2
of machine learning networks
on M1.


109
00:05:28,662 --> 00:05:31,298 line:-1
We get a 2x speedup on BERT,


110
00:05:31.331 --> 00:05:33.333 line:-2 align:center
which is a canonical
transformer network


111
00:05:33,367 --> 00:05:35,869 line:-1
used for NLP applications.


112
00:05:35.903 --> 00:05:39.840 line:-2 align:center
ResNet50, which is central
to computer vision applications,


113
00:05:39,873 --> 00:05:43,677 line:-2
has been tuned for texture
paths in previous releases.


114
00:05:43.710 --> 00:05:47.781 line:-2 align:center
This is an additional
performance improvement of 16%


115
00:05:47,814 --> 00:05:51,218 line:-2
with our new buffer backend
through MPSGraph.


116
00:05:51.251 --> 00:05:54.555 line:-2 align:center
These performance improvements
in Core ML and TensorFlow


117
00:05:54,588 --> 00:05:56,590 line:-2
are due to performance
improvements


118
00:05:56,623 --> 00:05:59,893 line:-2
in MPS primitives like
Convolution2D.


119
00:05:59,927 --> 00:06:02,896 line:-2
Here, we show the speedup of
Convolution2D


120
00:06:02,930 --> 00:06:06,366 line:-1
on NHWC and NCHW data layouts


121
00:06:06,400 --> 00:06:10,103 line:-2
which are used for training
and inference respectively.


122
00:06:10.137 --> 00:06:13.106 line:-2 align:center
That's it for the improvements
in inference and training.


123
00:06:13,140 --> 00:06:15,809 line:-2
Next, let's go back to Saharsh
to learn more


124
00:06:15.843 --> 00:06:18.378 line:-2 align:center
about the new operations
in MPSGraph.


125
00:06:18.412 --> 00:06:20.280 line:-1 align:center
[Saharsh] Thanks, Yuliya.


126
00:06:20.314 --> 00:06:22.249 line:-2 align:center
Now we will take a look
at the new set


127
00:06:22,282 --> 00:06:24,551 line:-2
of operations supported
by MPSGraph.


128
00:06:25,919 --> 00:06:29,456 line:-2
We support a plethora
of operations on the MPSGraph,


129
00:06:29.489 --> 00:06:32.826 line:-2 align:center
from multiple variants
of convolutions and reductions


130
00:06:32.860 --> 00:06:36.797 line:-2 align:center
to all the basic math ops you
may need in your compute graphs.


131
00:06:36,830 --> 00:06:39,366 line:-2
This year,
we added special operations


132
00:06:39,399 --> 00:06:42,636 line:-2
to enable you to do even more
with MPSGraph.


133
00:06:42.669 --> 00:06:45.305 line:-2 align:center
We will introduce three new
primitives:


134
00:06:45,339 --> 00:06:48,408 line:-2
control dependency,
stencil operator,


135
00:06:48,442 --> 00:06:50,477 line:-1
and gather operator.


136
00:06:50.511 --> 00:06:53.780 line:-2 align:center
First, we'll look at control
dependency.


137
00:06:53.814 --> 00:06:55.816 line:-1 align:center
Control dependency is needed


138
00:06:55,849 --> 00:06:58,752 line:-2
to explicitly order operations
in the graph.


139
00:06:58,785 --> 00:07:00,053 line:-1
To understand this,


140
00:07:00.087 --> 00:07:02.956 line:-2 align:center
let's formally define a graph
operation.


141
00:07:02.990 --> 00:07:05.692 line:-2 align:center
Operations in the graph connect
with each other


142
00:07:05,726 --> 00:07:07,794 line:-1
via three kinds of edges:


143
00:07:07.828 --> 00:07:10.497 line:-2 align:center
input tensors,
which represent which tensors


144
00:07:10.531 --> 00:07:12.699 line:-1 align:center
act as data inputs to the op,


145
00:07:12.733 --> 00:07:15.903 line:-2 align:center
output tensors, which are
created by the op itself,


146
00:07:15,936 --> 00:07:18,505 line:-2
and finally,
a special kind of edge


147
00:07:18,539 --> 00:07:20,307 line:-1
called control dependency.


148
00:07:20.340 --> 00:07:23.010 line:-2 align:center
They must execute
before the current operation,


149
00:07:23,043 --> 00:07:26,747 line:-2
even if the current operation
itself does not depend on it.


150
00:07:26.780 --> 00:07:28.448 line:-1 align:center
This API also offers


151
00:07:28.482 --> 00:07:30.851 line:-2 align:center
a convenient way to prevent
operations


152
00:07:30,884 --> 00:07:33,754 line:-2
from being optimized away by
MPSGraph.


153
00:07:33,787 --> 00:07:35,222 line:-1
This is needed to implement


154
00:07:35.255 --> 00:07:38.091 line:-2 align:center
machine learning layers
like batch normalization.


155
00:07:38.125 --> 00:07:41.028 line:-1 align:center
Let's see this in practice.


156
00:07:41,061 --> 00:07:43,430 line:-2
Batch normalization is a
standard layer


157
00:07:43,463 --> 00:07:44,598 line:-1
used in ML training


158
00:07:44,631 --> 00:07:48,368 line:-2
to make the network
more stable and converge faster.


159
00:07:48,402 --> 00:07:51,004 line:-2
Here we see the computational
graph for batch normalization


160
00:07:51.038 --> 00:07:52.673 line:-1 align:center
that is used for training.


161
00:07:52.706 --> 00:07:56.343 line:-2 align:center
The first step is to compute
the mean and variance.


162
00:07:56,376 --> 00:07:59,279 line:-2
These are, in turn,
used to update the running mean


163
00:07:59,313 --> 00:08:01,982 line:-2
and running variance
which are needed for inference.


164
00:08:02.015 --> 00:08:04.551 line:-2 align:center
However,
the training graph result


165
00:08:04,585 --> 00:08:06,353 line:-2
does not require these
variables,


166
00:08:06,386 --> 00:08:10,090 line:-2
so the MPSGraph might
optimize them away.


167
00:08:10.123 --> 00:08:12.893 line:-2 align:center
We can solve this
by explicitly ordering them


168
00:08:12.926 --> 00:08:15.229 line:-2 align:center
before the final normalization
operator


169
00:08:15.262 --> 00:08:18.065 line:-1 align:center
using control dependencies.


170
00:08:18.098 --> 00:08:20.133 line:-2 align:center
Let's look at a simple example
with some code


171
00:08:20.167 --> 00:08:22.402 line:-2 align:center
that shows how you can
use this API.


172
00:08:23,170 --> 00:08:26,540 line:0
This graph shows an exponent
and assign operator.


173
00:08:26,573 --> 00:08:30,043 line:0
The assign operator is not used
by anything else in the graph.


174
00:08:30,077 --> 00:08:32,513 align:center
So it may be optimized away.


175
00:08:32,546 --> 00:08:35,682 align:center
One way to solve this is
to explicitly set the assign


176
00:08:35,716 --> 00:08:37,684 line:0
as a targetOperation.


177
00:08:37,718 --> 00:08:40,487 line:0
However,
this requires the developer


178
00:08:40,521 --> 00:08:43,957 align:center
to track dependencies globally
across the graph.


179
00:08:43,991 --> 00:08:47,227 line:0
Instead, with the new
control dependency API,


180
00:08:47,261 --> 00:08:49,263 line:0
you can make the exponent
operation


181
00:08:49,296 --> 00:08:51,164 line:0
depend on the assignment.


182
00:08:51,198 --> 00:08:54,067 align:center
This removes the need
to have a targetOperation


183
00:08:54,101 --> 00:08:58,005 line:0
and also ensures that the graph
does not optimize it away.


184
00:08:58.038 --> 00:09:00.440 line:-2 align:center
Next,
we will see this in code.


185
00:09:01.875 --> 00:09:03.610 line:-1 align:center
We first define the operator


186
00:09:03,644 --> 00:09:06,013 line:-2
that the exponent is
dependent on.


187
00:09:06,046 --> 00:09:08,482 line:-1
Next, we create a dependentBlock


188
00:09:08.515 --> 00:09:11.285 line:-2 align:center
which defines the exponent
operator.


189
00:09:11.318 --> 00:09:15.155 line:-2 align:center
Finally, we call the run API
on this graph.


190
00:09:15.189 --> 00:09:19.059 line:-2 align:center
Note that no targetOperations
need to be tracked globally.


191
00:09:19,092 --> 00:09:21,461 line:-2
That's it for control
dependency.


192
00:09:21,495 --> 00:09:23,997 line:-2
Now let's talk about stencil
operators.


193
00:09:25,299 --> 00:09:27,868 line:-2
A stencil operation
is a generalization


194
00:09:27.901 --> 00:09:31.104 line:-2 align:center
of sliding window operators
like image convolution.


195
00:09:31,138 --> 00:09:34,474 line:-2
These operators are essential
in finite element methods,


196
00:09:34.508 --> 00:09:35.676 line:-1 align:center
machine learning,


197
00:09:35.709 --> 00:09:38.812 line:-2 align:center
and image processing
applications.


198
00:09:38.846 --> 00:09:41.315 line:-2 align:center
Here,
we see a five-point 2D stencil


199
00:09:41,348 --> 00:09:44,918 line:-2
commonly used to
implement Laplacian operations.


200
00:09:44,952 --> 00:09:46,854 line:-1
The stencil operator shown here


201
00:09:46,887 --> 00:09:48,755 line:-2
can be applied
to higher dimensions too,


202
00:09:48,789 --> 00:09:52,159 line:-2
as shown with this seven-point
3D stencil diagram.


203
00:09:52,192 --> 00:09:55,762 line:-2
Let's take a closer look at the
operator.


204
00:09:55,796 --> 00:09:58,899 line:-2
For each output value,
it computes a weighted reduction


205
00:09:58.932 --> 00:10:02.703 line:-2 align:center
over the stencil window
on the input tensor, as shown.


206
00:10:02.736 --> 00:10:05.239 line:-2 align:center
The operator supports
various reduction modes


207
00:10:05.272 --> 00:10:08.542 line:-2 align:center
including argmin/argmax,
and various padding modes,


208
00:10:08,575 --> 00:10:11,645 line:-2
including reflection
and clampToZero.


209
00:10:11,678 --> 00:10:15,182 line:-2
MPSGraph enables stitching
across MPS kernels


210
00:10:15.215 --> 00:10:17.284 line:-1 align:center
for optimal performance.


211
00:10:17,317 --> 00:10:20,120 line:-2
With stitching support,
the stencil operator allows you


212
00:10:20.153 --> 00:10:22.523 line:-2 align:center
to express complex mathematical
operations


213
00:10:22.556 --> 00:10:25.158 line:-1 align:center
in a single kernel launch.


214
00:10:25.192 --> 00:10:28.228 line:-2 align:center
Let us see one such example
in action.


215
00:10:28,262 --> 00:10:31,365 line:-2
Local response normalization
is a pytorch op


216
00:10:31,398 --> 00:10:34,234 line:-2
used for normalizing
in the channel dimension.


217
00:10:34,268 --> 00:10:36,203 line:-2
It's very straightforward
to implement this


218
00:10:36.236 --> 00:10:38.839 line:-1 align:center
with the new stencil operation.


219
00:10:38,872 --> 00:10:42,042 line:0
Here, we see the graph for
this normalization technique.


220
00:10:42,075 --> 00:10:44,077 align:center
We see that it's just element
wise ops


221
00:10:44,111 --> 00:10:46,113 align:center
around the stencil operation.


222
00:10:46,146 --> 00:10:47,748 align:center
Without the new operation,


223
00:10:47,781 --> 00:10:50,417 line:0
multiple dispatches
will be needed.


224
00:10:50,450 --> 00:10:53,654 line:0
Now, since the stencil op
supports stitching,


225
00:10:53,687 --> 00:10:57,591 line:0
this entire graph can be
launched in a single dispatch.


226
00:10:57,624 --> 00:11:00,060 line:-2
So that's it for the stencil
operator.


227
00:11:00.093 --> 00:11:02.229 line:-2 align:center
Next, let's take a look at
improvements


228
00:11:02,262 --> 00:11:03,997 line:-1
in gather operations.


229
00:11:05.098 --> 00:11:07.201 line:-2 align:center
This year,
new gather operations


230
00:11:07,234 --> 00:11:09,603 line:-1
have been added to MPSGraph.


231
00:11:09.636 --> 00:11:11.438 line:-2 align:center
These allow for efficient
copying


232
00:11:11,471 --> 00:11:13,073 line:-1
of arbitrary sized slices


233
00:11:13,106 --> 00:11:16,443 line:-2
in noncontiguous memory
locations.


234
00:11:16,476 --> 00:11:19,213 line:-2
Conceptually,
we are gathering the values


235
00:11:19.246 --> 00:11:22.616 line:-2 align:center
from locations marked in blue
from a chunk of memory.


236
00:11:22.649 --> 00:11:25.652 line:-2 align:center
These gather layers allow
for efficient implementation


237
00:11:25,686 --> 00:11:29,323 line:-2
of embedding lookup
and dynamic matrix copy.


238
00:11:29,356 --> 00:11:32,860 line:-2
GatherND is a powerful extension
of the gather operation.


239
00:11:32,893 --> 00:11:35,863 line:-2
While the normal gather
supports linear indexing,


240
00:11:35,896 --> 00:11:40,067 line:-2
the gatherND operation enables
N-dimensional indexing.


241
00:11:40.100 --> 00:11:42.469 line:-2 align:center
This allows for seamless
copying of data


242
00:11:42.503 --> 00:11:45.706 line:-2 align:center
from anywhere in an
N-dimensional input.


243
00:11:45,739 --> 00:11:48,775 line:-2
The input to this operation
is a vector of coordinates,


244
00:11:48.809 --> 00:11:50.544 line:-1 align:center
and each coordinate can be up


245
00:11:50,577 --> 00:11:53,447 line:-1
to the rank of the input tensor.


246
00:11:53,480 --> 00:11:56,149 line:-2
Any dimensions not specified
in the coordinates


247
00:11:56.183 --> 00:11:59.052 line:-1 align:center
result in slice copies.


248
00:11:59,086 --> 00:12:00,754 line:-1
We can step through an example


249
00:12:00,787 --> 00:12:04,157 line:-2
of a gather of row slices
from a 3D tensor.


250
00:12:04,191 --> 00:12:07,895 line:-2
In this example, the indices
specify two coordinates


251
00:12:07,928 --> 00:12:09,530 line:-1
corresponding to the matrix


252
00:12:09.563 --> 00:12:12.299 line:-1 align:center
and row coordinates.


253
00:12:12,332 --> 00:12:14,701 line:-2
With no third coordinate
to column index,


254
00:12:14,735 --> 00:12:18,539 line:-2
this gatherND will copy
entire rows.


255
00:12:18.572 --> 00:12:22.176 line:-2 align:center
The result tensor is a 2D matrix
of the rows gathered


256
00:12:22,209 --> 00:12:24,278 line:-1
from the input matrix.


257
00:12:24.311 --> 00:12:27.281 line:-2 align:center
GatherND can represent nearly
any form of gather operation


258
00:12:27.314 --> 00:12:29.449 line:-1 align:center
and give great performance.


259
00:12:29,483 --> 00:12:32,152 line:-2
For example,
let's see how we can implement


260
00:12:32.186 --> 00:12:34.488 line:-2 align:center
embedding lookup using gather
operations.


261
00:12:36,123 --> 00:12:38,358 line:-2
Embedding lookup
is a common operation


262
00:12:38,392 --> 00:12:40,127 line:-1
used to find embedding vectors


263
00:12:40.160 --> 00:12:43.430 line:-2 align:center
for a provided set of input
objects.


264
00:12:43,463 --> 00:12:47,401 line:-2
Commonly, this layer is used
in language processing networks,


265
00:12:47,434 --> 00:12:49,870 line:-2
where an embedding matrix
is generated


266
00:12:49,903 --> 00:12:52,339 line:-2
associating each word
in the vocabulary


267
00:12:52.372 --> 00:12:54.575 line:-1 align:center
to an embedding vector.


268
00:12:54,608 --> 00:12:56,877 line:-2
The ID of the words
in the vocabulary


269
00:12:56.910 --> 00:12:59.913 line:-2 align:center
can be used as the indices
to a gather operation,


270
00:12:59.947 --> 00:13:03.650 line:-2 align:center
and the embedding matrix
is our input tensor.


271
00:13:03,684 --> 00:13:05,853 line:-2
We would like to
get the corresponding rows


272
00:13:05.886 --> 00:13:07.087 line:-1 align:center
for each word ID,


273
00:13:07,487 --> 00:13:10,591 line:-2
which we can do easily
using a gather layer.


274
00:13:10.624 --> 00:13:12.860 line:-1 align:center
We only specify one coordinate,


275
00:13:12,893 --> 00:13:16,630 line:-2
so the entire row will be copied
for each input word.


276
00:13:16,663 --> 00:13:19,266 line:-2
The resulting tensor
is a 2D matrix


277
00:13:19.299 --> 00:13:23.237 line:-2 align:center
of each input word's embedding
vector along the rows.


278
00:13:23,270 --> 00:13:26,006 line:-2
That's it for the new MPSGraph
operations


279
00:13:26.039 --> 00:13:27.641 line:-1 align:center
we have introduced this year.


280
00:13:27,674 --> 00:13:30,310 line:-2
Now let's talk about the
compilation APIs.


281
00:13:30,344 --> 00:13:32,079 line:-1
This year, we are introducing


282
00:13:32,112 --> 00:13:35,349 line:-1
the new MPSGraphExecutable API.


283
00:13:35,382 --> 00:13:37,017 line:-1
This compilation API


284
00:13:37,050 --> 00:13:39,586 line:-2
improves performance
in two ways.


285
00:13:39,620 --> 00:13:42,289 line:-2
First,
it gives the developer control


286
00:13:42.322 --> 00:13:44.658 line:-1 align:center
on when to compile the graph.


287
00:13:44.691 --> 00:13:48.228 line:-2 align:center
Second, it allows you to reduce
the number of compilation calls


288
00:13:48,262 --> 00:13:50,597 line:-1
through deferred type inference.


289
00:13:50,631 --> 00:13:53,433 line:-2
Now let's take a closer look at
each.


290
00:13:53.467 --> 00:13:56.904 line:-2 align:center
Last year, we provided
a really convenient API


291
00:13:56.937 --> 00:14:00.674 line:-2 align:center
to define and execute an
MPSGraph.


292
00:14:00.707 --> 00:14:04.545 line:-2 align:center
Under the hood, the first time
an evaluation was requested,


293
00:14:04,578 --> 00:14:07,748 line:-2
MPSGraph invoked compilation
for the input types


294
00:14:07.781 --> 00:14:09.950 line:-2 align:center
and internally created
an executable.


295
00:14:09.983 --> 00:14:12.252 line:-1 align:center
For any subsequent executions,


296
00:14:12.286 --> 00:14:14.955 line:-2 align:center
MPSGraph seamlessly cached
this executable


297
00:14:14,988 --> 00:14:18,358 line:-2
to ensure compilation cost
is not paid again.


298
00:14:18,392 --> 00:14:20,060 line:-1
Users now have the ability


299
00:14:20.093 --> 00:14:22.329 line:-2 align:center
to invoke
compilation ahead of time


300
00:14:22,362 --> 00:14:25,332 line:-2
so you can choose
the timeline for compilation.


301
00:14:25.365 --> 00:14:28.635 line:-2 align:center
With the compiled executable,
you can call run directly


302
00:14:28.669 --> 00:14:31.138 line:-1 align:center
on the MPSGraphExecutable.


303
00:14:31.171 --> 00:14:33.941 line:-2 align:center
This gives the user control
on when the graph is compiled


304
00:14:33.974 --> 00:14:37.110 line:-2 align:center
and also the ability
to cache the compiled executable


305
00:14:37.144 --> 00:14:39.479 line:-2 align:center
so you can gain even more
performance.


306
00:14:39.513 --> 00:14:42.182 line:-1 align:center
Let's see this in code.


307
00:14:42,216 --> 00:14:45,285 line:-2
Here, we have a simple graph
to add two tensors.


308
00:14:45.319 --> 00:14:48.522 line:-2 align:center
Now to compile, we provide
the types for the feeds


309
00:14:48,555 --> 00:14:51,191 line:-2
and target tensors
along with the operations.


310
00:14:51,225 --> 00:14:55,028 line:-2
What we get is a compiled graph
and an executable.


311
00:14:55,062 --> 00:14:58,165 line:-2
And the evaluation method
is just as simple.


312
00:14:58.198 --> 00:14:59.933 line:-1 align:center
We provide a Metal command queue


313
00:14:59,967 --> 00:15:02,436 line:-1
and our input tensor data.


314
00:15:02,469 --> 00:15:05,506 line:-2
So those are the basics
of compiling an MPS graph.


315
00:15:05.539 --> 00:15:07.908 line:-2 align:center
Next, let's talk about how we
reduce


316
00:15:07,941 --> 00:15:11,078 line:-2
the number of compilation calls
through deferred type inference.


317
00:15:11,111 --> 00:15:13,847 line:-2
Type inference
is a compilation pass


318
00:15:13,881 --> 00:15:16,683 line:-2
where MPSGraph must determine
tensor shapes


319
00:15:16.717 --> 00:15:19.386 line:-2 align:center
where they are not specified
by the user.


320
00:15:19.419 --> 00:15:21.522 line:-2 align:center
In this graph,
we are performing


321
00:15:21.555 --> 00:15:25.058 line:-2 align:center
a matrix multiplication
of two 2D tensors.


322
00:15:25.092 --> 00:15:27.794 line:-2 align:center
The shapes of the input tensors
are shown.


323
00:15:27.828 --> 00:15:31.164 line:-2 align:center
However, the output tensor
is of an unknown shape.


324
00:15:32,099 --> 00:15:34,668 line:-2
Once the type inference pass
is complete,


325
00:15:34.701 --> 00:15:36.570 line:-2 align:center
the output tensor shape
is determined


326
00:15:36.603 --> 00:15:39.673 line:-2 align:center
based on the inputs
and operation type.


327
00:15:39,706 --> 00:15:42,743 line:-2
In standard neural networks,
the inputs to the network


328
00:15:42.776 --> 00:15:45.546 line:-1 align:center
are not always the same size.


329
00:15:45.579 --> 00:15:49.216 line:-2 align:center
For natural language processing,
the sentences or sequences


330
00:15:49,249 --> 00:15:51,018 line:-1
can be of different lengths.


331
00:15:51.051 --> 00:15:53.921 line:-2 align:center
For CNNs,
we see different-sized images


332
00:15:53,954 --> 00:15:56,390 line:-1
coming in to be evaluated.


333
00:15:56,423 --> 00:15:58,825 line:-2
Before the compilation upgrades
of this year,


334
00:15:58,859 --> 00:16:00,427 line:-1
for every new sized image,


335
00:16:00,460 --> 00:16:03,297 line:-2
a compilation would be invoked
to do type inference


336
00:16:03,330 --> 00:16:05,332 line:-1
for the whole graph.


337
00:16:05.365 --> 00:16:09.102 line:-2 align:center
Now with control over
compilation, you, the developer,


338
00:16:09,136 --> 00:16:10,704 line:-1
can invoke compilation


339
00:16:10.737 --> 00:16:13.407 line:-2 align:center
with type inference pass
turned off.


340
00:16:13.440 --> 00:16:16.176 line:-2 align:center
This can save tens or hundreds
of many seconds


341
00:16:16.210 --> 00:16:17.377 line:-1 align:center
of compilation time


342
00:16:17.411 --> 00:16:20.681 line:-2 align:center
on each iteration
and get the best performance.


343
00:16:21,849 --> 00:16:23,784 line:-2
MPSGraph runtime
will infer types


344
00:16:23.817 --> 00:16:28.622 line:-2 align:center
just in time during encoding
and seamlessly make things work.


345
00:16:28,655 --> 00:16:31,225 line:-2
It is a tradeoff between
saving compilation time


346
00:16:31,258 --> 00:16:34,361 line:-2
versus getting the most
optimal graph.


347
00:16:34,394 --> 00:16:36,897 line:-2
Let's see how this can be used
in the code example


348
00:16:36.930 --> 00:16:37.965 line:-1 align:center
shared before.


349
00:16:39.566 --> 00:16:41.902 line:-2 align:center
Disabling the type inference
pass can be achieved


350
00:16:41,935 --> 00:16:45,172 line:-2
by setting the compilation
descriptor as shown.


351
00:16:45.205 --> 00:16:48.108 line:-1 align:center
That's it for compilation APIs.


352
00:16:48.141 --> 00:16:50.544 line:-2 align:center
Finally, let's talk about the
new


353
00:16:50,577 --> 00:16:53,080 line:-1
control flow APIs of MPSGraph.


354
00:16:53,113 --> 00:16:56,783 line:-2
These APIs let you
dynamically dispatch operations


355
00:16:56.817 --> 00:17:00.787 line:-2 align:center
based on tensors previously
evaluated by the graph.


356
00:17:00,821 --> 00:17:04,024 line:-2
This is common in applications
like batch normalization


357
00:17:04.057 --> 00:17:07.461 line:-1 align:center
and recurrent neural networks.


358
00:17:07,494 --> 00:17:10,330 line:-2
Let's take a look at how a
“while loop” can be implemented


359
00:17:10,364 --> 00:17:13,300 line:-2
with MPSGraph today without
the new API.


360
00:17:14.935 --> 00:17:16.770 line:-1 align:center
First, we create a graph


361
00:17:16,803 --> 00:17:18,972 line:-1
that computes the predicate.


362
00:17:19.006 --> 00:17:22.242 line:-2 align:center
Next, the predicate is evaluated
on the CPU


363
00:17:22,276 --> 00:17:25,846 line:-2
through an explicit
memory synchronization.


364
00:17:25,879 --> 00:17:29,049 line:-2
If the predicate is true,
the previously created graph


365
00:17:29.082 --> 00:17:32.519 line:-2 align:center
is re-executed with the new
inputs.


366
00:17:32.553 --> 00:17:35.055 line:-2 align:center
Otherwise,
if the predicate is false,


367
00:17:35.088 --> 00:17:38.058 line:-2 align:center
the loop ends
and a second MPSGraph is created


368
00:17:38.091 --> 00:17:41.461 line:-2 align:center
and executed to consume
the result.


369
00:17:41.495 --> 00:17:44.932 line:-2 align:center
With the new control flow API,
all these steps can be launched


370
00:17:44.965 --> 00:17:47.935 line:-2 align:center
as part of a single
MPSGraph execution.


371
00:17:48.936 --> 00:17:50.504 line:-2 align:center
This is more convenient
to implement


372
00:17:50,537 --> 00:17:52,072 line:-2
because you don't have to
introduce


373
00:17:52,105 --> 00:17:55,576 line:-2
explicit memory
synchronization primitives.


374
00:17:55,609 --> 00:17:57,144 line:-1
Now let's take a look


375
00:17:57,177 --> 00:17:59,546 line:-2
at how this can be
potentially more efficient.


376
00:17:59.580 --> 00:18:02.049 line:-2 align:center
Here we see the control flow
timeline


377
00:18:02,082 --> 00:18:04,117 line:-1
without the new API.


378
00:18:04,151 --> 00:18:07,487 line:-2
We encode
the first kernel on the CPU.


379
00:18:07.521 --> 00:18:09.356 line:-1 align:center
Once the kernel is complete,


380
00:18:09,389 --> 00:18:13,227 line:-2
we have to synchronize memory
to read the result.


381
00:18:13.260 --> 00:18:15.195 line:-1 align:center
This is potentially inefficient,


382
00:18:15,229 --> 00:18:19,066 line:-2
as the CPU has to wait
for the GPU to finish executing.


383
00:18:19.099 --> 00:18:21.802 line:-2 align:center
Similarly,
the GPU also has to wait


384
00:18:21.835 --> 00:18:23.637 line:-1 align:center
for the CPU synchronization


385
00:18:23.670 --> 00:18:26.573 line:-2 align:center
and subsequent encoding
to complete.


386
00:18:26.607 --> 00:18:29.543 line:-1 align:center
This happens in each iteration.


387
00:18:29.576 --> 00:18:30.978 line:-1 align:center
Now let's see the benefits


388
00:18:31.011 --> 00:18:33.580 line:-1 align:center
of using the new MPSGraph API.


389
00:18:33,614 --> 00:18:37,017 line:-2
We have to perform
only one CPU encode call.


390
00:18:37,050 --> 00:18:40,254 line:-2
Since the predicate is evaluated
on the GPU timeline,


391
00:18:40.287 --> 00:18:42.923 line:-2 align:center
no synchronization overhead
is incurred,


392
00:18:42,956 --> 00:18:45,826 line:-2
and the kernels can be launched
without any bubbles.


393
00:18:46,927 --> 00:18:49,429 line:-2
Now let's see what the new APIs
are.


394
00:18:52.065 --> 00:18:55.102 line:-2 align:center
We added three new
control flow APIs:


395
00:18:55,135 --> 00:18:57,571 line:-1
if/else, for loops,


396
00:18:57.604 --> 00:18:59.473 line:-1 align:center
and while loops.


397
00:18:59,506 --> 00:19:02,543 line:-2
Let's start with the if/else
primitive.


398
00:19:02,576 --> 00:19:04,945 line:-1
We are all familiar with this.


399
00:19:04,978 --> 00:19:06,380 line:-1
Based on a predicate,


400
00:19:06.413 --> 00:19:08.849 line:-2 align:center
different code paths
are executed.


401
00:19:08.882 --> 00:19:10.651 line:-2 align:center
We are provided a Boolean
predicate


402
00:19:10.684 --> 00:19:14.655 line:-2 align:center
along with a code block for
the “if” and “else” conditions.


403
00:19:14.688 --> 00:19:16.290 line:-1 align:center
If this predicate is true,


404
00:19:16,323 --> 00:19:18,458 line:-2
we execute the then
block of code.


405
00:19:18,492 --> 00:19:20,527 line:-1
Otherwise, if it's false,


406
00:19:20,561 --> 00:19:23,630 line:-1
the else branch is executed.


407
00:19:23,664 --> 00:19:25,432 line:-1
Having the if/else operation


408
00:19:25.465 --> 00:19:28.135 line:-2 align:center
is very useful in neural
networks.


409
00:19:28,168 --> 00:19:31,705 line:-2
One canonical usage is
in batchNormalization operation,


410
00:19:31,738 --> 00:19:35,642 line:-2
which has different behavior
in training and inference.


411
00:19:35.676 --> 00:19:38.679 line:-2 align:center
With the isTraining Boolean,
we can have a single graph


412
00:19:38,712 --> 00:19:42,049 line:-2
to represent both variants
of the normalizer.


413
00:19:42.082 --> 00:19:44.985 line:-2 align:center
Let's look at how to set up
an if/else branch in code.


414
00:19:45.986 --> 00:19:47.821 line:-1 align:center
Let's take a very simple example


415
00:19:47,855 --> 00:19:50,524 line:-1
of two input scalar tensors.


416
00:19:50.557 --> 00:19:52.926 line:-2 align:center
If the first tensor is smaller
than the second,


417
00:19:52.960 --> 00:19:55.295 line:-2 align:center
we return the sum of the
operations.


418
00:19:55.329 --> 00:19:58.732 line:-1 align:center
Else, we return the difference.


419
00:19:58,765 --> 00:20:00,567 line:-1
First, we compute the predicate


420
00:20:00.601 --> 00:20:03.403 line:-1 align:center
and pass that to the API.


421
00:20:03.437 --> 00:20:05.772 line:-2 align:center
Next,
when the predicate is true,


422
00:20:05.806 --> 00:20:09.409 line:-2 align:center
we compute the then block
and add the tensors.


423
00:20:09,443 --> 00:20:12,079 line:-2
Finally,
when the predicate is false,


424
00:20:12,112 --> 00:20:15,916 line:-2
we compute the else block
and subtract the tensors.


425
00:20:15.949 --> 00:20:18.685 line:-2 align:center
Next, let's see how to implement
a for loop.


426
00:20:19,753 --> 00:20:22,623 line:-2
The for loop primitive loops
over a set of operations


427
00:20:22,656 --> 00:20:24,491 line:-1
a fixed number of times.


428
00:20:24.525 --> 00:20:26.793 line:-2 align:center
This is common
in recurrent neural networks


429
00:20:26.827 --> 00:20:28.795 line:-2 align:center
where we have to loop over
sequences


430
00:20:28,829 --> 00:20:31,532 line:-2
of different lengths
during training.


431
00:20:31.565 --> 00:20:33.867 line:-2 align:center
We need to provide the
numberOfIterations


432
00:20:33,901 --> 00:20:34,902 line:-1
of the for loop.


433
00:20:34.935 --> 00:20:37.004 line:-1 align:center
The index is initialized to 0


434
00:20:37.037 --> 00:20:39.139 line:-2 align:center
and compared against
the numberOfIterations


435
00:20:39.173 --> 00:20:42.142 line:-1 align:center
each loop iteration.


436
00:20:42,176 --> 00:20:44,444 line:-2
If it's less than the
numberOfIterations,


437
00:20:44,478 --> 00:20:46,513 line:-2
we execute the body
of the for loop


438
00:20:46,547 --> 00:20:48,282 line:-1
and increment the index by 1.


439
00:20:50.050 --> 00:20:51.318 line:-1 align:center
When the index is equal to


440
00:20:51,351 --> 00:20:53,187 line:-2
or greater than the
numberOfIterations,


441
00:20:53,220 --> 00:20:55,088 line:-1
we end the loop.


442
00:20:55.122 --> 00:20:57.024 line:-2 align:center
Let's see how to implement this
in code.


443
00:20:58.792 --> 00:21:02.296 line:-2 align:center
Let's say we wanted to implement
a really simple example.


444
00:21:02,329 --> 00:21:06,166 line:-2
We'll initialize the result
variable to some input value.


445
00:21:06.200 --> 00:21:09.303 line:-2 align:center
Then we loop four times,
multiplying the result


446
00:21:09,336 --> 00:21:13,040 line:-2
by another input value
each time.


447
00:21:13.073 --> 00:21:15.876 line:-2 align:center
First, we create two graph
tensors.


448
00:21:15,909 --> 00:21:19,713 line:-2
The output tensor
will be initialized to input0.


449
00:21:19.746 --> 00:21:21.181 line:-1 align:center
In each iteration,


450
00:21:21.215 --> 00:21:24.151 line:-2 align:center
this tensor will be multiplied
by input1.


451
00:21:24.184 --> 00:21:27.287 line:-2 align:center
Next, we set
the numberOfIterations to 4


452
00:21:27,321 --> 00:21:30,023 line:-2
so that we can execute
the loop four times,


453
00:21:30.057 --> 00:21:33.293 line:-1 align:center
from index 0 to index 3.


454
00:21:33,327 --> 00:21:35,729 line:-2
Next, we create the body
of the for loop.


455
00:21:35.762 --> 00:21:37.598 line:-2 align:center
This is done by creating
a closure


456
00:21:37,631 --> 00:21:40,501 line:-2
which represents a single
iteration.


457
00:21:40,534 --> 00:21:43,570 line:-2
Each iteration is passed the
index of the current iteration,


458
00:21:43.604 --> 00:21:47.107 line:-2 align:center
as well as the output
of the previous iteration.


459
00:21:47.140 --> 00:21:49.610 line:-2 align:center
Then, we'll update the result
and return it,


460
00:21:49.643 --> 00:21:52.646 line:-2 align:center
to be passed to the next
iteration.


461
00:21:52.679 --> 00:21:55.082 line:-2 align:center
Finally,
we pass all these arguments


462
00:21:55.115 --> 00:21:57.951 line:-2 align:center
to the for loop API in
the graph.


463
00:21:57,985 --> 00:22:00,654 line:-2
Note that the iterationArguments
of the body


464
00:22:00.687 --> 00:22:04.491 line:-2 align:center
are initialized to input0
tensor.


465
00:22:04,525 --> 00:22:06,460 line:-1
That's it for the for loop.


466
00:22:06.493 --> 00:22:08.829 line:-2 align:center
Now let's look at the while loop
API.


467
00:22:09,997 --> 00:22:12,666 line:-2
This primitive executes
a set of operations


468
00:22:12,699 --> 00:22:14,501 line:-1
while a condition is met.


469
00:22:14,535 --> 00:22:16,537 line:-2
We need to provide two blocks
of code


470
00:22:16,570 --> 00:22:18,739 line:-1
to use this API.


471
00:22:18,772 --> 00:22:19,973 line:-1
In the first block,


472
00:22:20.007 --> 00:22:22.709 line:-2 align:center
the condition
is checked with a predicate.


473
00:22:22.743 --> 00:22:25.879 line:-2 align:center
When the predicate is true,
the body of the while loop


474
00:22:25.913 --> 00:22:27.915 line:-1 align:center
in the after block is executed.


475
00:22:27,948 --> 00:22:30,384 line:-1
This recomputes the predicate.


476
00:22:30,417 --> 00:22:32,486 line:-2
MPSGraph then uses this
predicate


477
00:22:32,519 --> 00:22:36,123 line:-2
in the next iteration of
the before block.


478
00:22:36,156 --> 00:22:38,325 align:center
If the condition evaluated
is false,


479
00:22:38,358 --> 00:22:40,527 align:center
it exits the loop.


480
00:22:40,561 --> 00:22:43,864 line:0
The API also allows for
implementing the do-while loop


481
00:22:43,897 --> 00:22:45,132 align:center
by swapping the body


482
00:22:45,165 --> 00:22:48,101 align:center
and condition evaluation
code blocks.


483
00:22:48.135 --> 00:22:51.538 line:-2 align:center
Let's say we wanted to implement
a really simple example.


484
00:22:51.572 --> 00:22:55.509 line:-2 align:center
We'll initialize the result
variable to some input value.


485
00:22:55,542 --> 00:22:58,512 line:-2
Then we'll multiply the result
by a multiplier each time


486
00:22:58.545 --> 00:23:01.248 line:-2 align:center
in a loop till we exceed
a threshold.


487
00:23:01,281 --> 00:23:05,152 line:-2
First, we define a block of code
that will evaluate the predicate


488
00:23:05,185 --> 00:23:08,188 line:-2
using the result
of the previous iteration.


489
00:23:08,222 --> 00:23:10,991 line:-2
It also stores the results
of the previous iteration


490
00:23:11,024 --> 00:23:13,227 line:-1
in a returnTensors NSArray.


491
00:23:13.260 --> 00:23:15.495 line:-2 align:center
This array will be used
as the input


492
00:23:15,529 --> 00:23:17,931 line:-2
to the next iteration
when the predicate is true


493
00:23:17.965 --> 00:23:19.733 line:-1 align:center
and used as the final result


494
00:23:19.766 --> 00:23:22.336 line:-1 align:center
if the predicate is false.


495
00:23:22,369 --> 00:23:24,705 line:-2
Next, we define the body
of the while loop


496
00:23:24,738 --> 00:23:27,374 line:-2
where the tensors are
multiplied.


497
00:23:27,407 --> 00:23:30,444 line:-2
The product is returned
for the condition block to read.


498
00:23:31,812 --> 00:23:34,314 line:-2
Finally, we'll pass all these
arguments


499
00:23:34,348 --> 00:23:36,917 line:-1
to the while loop API as shown.


500
00:23:36,950 --> 00:23:39,052 line:-1
Note the initialInputs argument


501
00:23:39,086 --> 00:23:42,089 line:-2
is used in the first iteration
of the before block.


502
00:23:43,090 --> 00:23:45,025 line:-1
That's it for while loops.


503
00:23:45,058 --> 00:23:48,896 line:-2
Next, we'll see how this can be
used in a real application.


504
00:23:48,929 --> 00:23:52,566 line:-2
Image composition is a
common image editing utility.


505
00:23:52.599 --> 00:23:56.170 line:-2 align:center
Here, an object is implanted
into a target image.


506
00:23:56,203 --> 00:23:57,838 line:-1
We start with a source image


507
00:23:57.871 --> 00:24:00.240 line:-2 align:center
and a background image,
as shown.


508
00:24:00.274 --> 00:24:03.944 line:-2 align:center
Next, we create a mask
on the source image.


509
00:24:03.977 --> 00:24:06.280 line:-2 align:center
Let's place this mask of the
source image


510
00:24:06,313 --> 00:24:08,582 line:-1
directly against the background.


511
00:24:08.615 --> 00:24:10.050 line:-1 align:center
That does not look great,


512
00:24:10,083 --> 00:24:13,554 line:-2
as we can clearly see the edges
of the source image.


513
00:24:13,587 --> 00:24:14,988 line:-1
Through image composition,


514
00:24:15.022 --> 00:24:17.691 line:-1 align:center
we want to smoothen these edges.


515
00:24:17.724 --> 00:24:20.961 line:-2 align:center
Pairing a Laplacian edge filter
with an iterative linear solver


516
00:24:20,994 --> 00:24:23,564 line:-1
is a common way to achieve this.


517
00:24:23.597 --> 00:24:25.566 line:-1 align:center
Now let's look at the details.


518
00:24:25,599 --> 00:24:27,801 line:-1
Here, we see the pipeline needed


519
00:24:27.835 --> 00:24:30.938 line:-2 align:center
to perform image composition
with MPSGraph.


520
00:24:30.971 --> 00:24:34.675 line:-2 align:center
We start with our input tensors,
the background image,


521
00:24:34,708 --> 00:24:38,545 line:-2
source image,
and a mask of the object.


522
00:24:38,579 --> 00:24:41,014 line:-2
Next we use an iterative
linear solver


523
00:24:41,048 --> 00:24:44,017 line:-2
coupled with a Laplacian
edge detector.


524
00:24:44.051 --> 00:24:46.420 line:-2 align:center
The output of this set of
operations is


525
00:24:46,453 --> 00:24:49,623 line:-2
a composite image
with smooth edges.


526
00:24:49,656 --> 00:24:53,493 line:-2
Let's take a look
at the Laplacian edge filter.


527
00:24:53,527 --> 00:24:55,796 line:-2
Implementing the Laplacian
edge filter


528
00:24:55,829 --> 00:24:57,197 line:-1
involves a windowed reduction


529
00:24:57.231 --> 00:25:00.234 line:-2 align:center
over the source image
with a set of weights.


530
00:25:00,267 --> 00:25:01,802 line:-1
The stencil operator is used


531
00:25:01,835 --> 00:25:04,204 line:-1
to implement this as shown.


532
00:25:04.238 --> 00:25:06.240 line:-2 align:center
Using this operator,
we are able


533
00:25:06,273 --> 00:25:08,876 line:-2
to see the edges of the
source object.


534
00:25:08.909 --> 00:25:10.878 line:-2 align:center
The edges computed here
will be used


535
00:25:10,911 --> 00:25:13,547 line:-2
as the input to the linear
solver.


536
00:25:13,580 --> 00:25:16,383 line:-2
Next, let's take a look
at the linear solver.


537
00:25:17.484 --> 00:25:19.286 line:-2 align:center
We start with the background
image


538
00:25:19.319 --> 00:25:22.089 line:-2 align:center
and feed it into the linear
solver.


539
00:25:22,122 --> 00:25:24,024 line:-1
The solver updates this image,


540
00:25:24,057 --> 00:25:27,494 line:-2
and the result is
subsequently read back in.


541
00:25:27,528 --> 00:25:31,398 line:-2
As we can see,
this is an iterative process.


542
00:25:31.431 --> 00:25:33.467 line:-1 align:center
As the iterations progress,


543
00:25:33,500 --> 00:25:35,802 line:-2
the solution image improves
till we arrive


544
00:25:35.836 --> 00:25:38.071 line:-2 align:center
at the perfect blend
at the edges.


545
00:25:38.105 --> 00:25:39.907 line:-2 align:center
The loop terminates
when the error


546
00:25:39,940 --> 00:25:42,042 line:-2
is below a user defined
tolerance.


547
00:25:42,075 --> 00:25:44,044 line:-1
This requires a while loop.


548
00:25:44,077 --> 00:25:46,980 line:-2
You can now use
the MPSGraph Control Flow API


549
00:25:47,014 --> 00:25:48,682 line:-1
to implement this.


550
00:25:48.715 --> 00:25:50.984 line:-1 align:center
Now, let's look at the demo.


551
00:25:51,018 --> 00:25:53,253 line:-2
We have implemented
an image composition utility


552
00:25:53,287 --> 00:25:56,390 line:-2
using the MPSGraph
as an iPad Pro application.


553
00:25:58,192 --> 00:26:00,194 line:-2
We start with a source image
on the top


554
00:26:00,227 --> 00:26:02,429 line:-1
and a target image below.


555
00:26:02.462 --> 00:26:03.997 line:-1 align:center
We will be cloning objects


556
00:26:04.031 --> 00:26:06.533 line:-1 align:center
from the source to the target.


557
00:26:06.567 --> 00:26:08.569 line:-2 align:center
The first thing we need to do
is to draw a mask


558
00:26:08.569 --> 00:26:10.504 line:-2 align:center
around the cow
that we want to move.


559
00:26:11,905 --> 00:26:14,141 line:-2
Let's see how this looks
with a naive clone.


560
00:26:15.375 --> 00:26:18.745 line:-2 align:center
That does not look very good,
as we can see the rough edges.


561
00:26:18,779 --> 00:26:20,547 line:-2
Now let's try the image
composition technique


562
00:26:20.581 --> 00:26:22.282 line:-1 align:center
we just described.


563
00:26:22.316 --> 00:26:23.884 line:-1 align:center
We will start by setting


564
00:26:23.917 --> 00:26:26.386 line:-2 align:center
the initial solution
to the background image.


565
00:26:26.420 --> 00:26:29.323 line:-2 align:center
Let's run this for about 50
iterations.


566
00:26:31,959 --> 00:26:34,461 line:-2
Clearly, the solution image
has not yet converged.


567
00:26:34.494 --> 00:26:37.231 line:-2 align:center
Let's run it for about 50 more
iterations.


568
00:26:39.533 --> 00:26:42.469 line:-2 align:center
This looks way more natural
as the edges smoothen out.


569
00:26:42,503 --> 00:26:45,005 line:-2
The ease of programming with
MPSGraph


570
00:26:45.005 --> 00:26:46.540 line:-2 align:center
makes experimenting with
different techniques


571
00:26:46.573 --> 00:26:48.041 line:-1 align:center
straightforward.


572
00:26:48.075 --> 00:26:50.344 line:-2 align:center
Initializing the solver
with the cloned image


573
00:26:50.377 --> 00:26:52.012 line:-1 align:center
instead of the background image


574
00:26:52,045 --> 00:26:53,413 line:-2
can result in faster
convergence.


575
00:26:53.447 --> 00:26:56.416 line:-2 align:center
We can enable this
initialization mode


576
00:26:56.450 --> 00:26:58.352 line:-1 align:center
by toggling this switch.


577
00:26:58.385 --> 00:27:00.821 line:-2 align:center
Let's see this in action by
setting the iteration count


578
00:27:00.854 --> 00:27:03.323 line:-2 align:center
to 50 again and
resetting to the naive clone.


579
00:27:04,925 --> 00:27:07,461 line:-1
Now let's rerun the solver.


580
00:27:07.494 --> 00:27:08.996 line:-1 align:center
We can see the solution image


581
00:27:09,029 --> 00:27:11,365 line:-2
after 50 iterations
looks pretty good.


582
00:27:11,365 --> 00:27:13,700 line:-2
Since we already start
with the source object,


583
00:27:13.700 --> 00:27:16.303 line:-2 align:center
we also observe less bleeding
at the edges.


584
00:27:16,336 --> 00:27:17,337 line:-1
This is great.


585
00:27:17,371 --> 00:27:20,140 line:-2
But what we really want is
to automate convergence


586
00:27:20,174 --> 00:27:21,508 line:-1
based on an error tolerance.


587
00:27:21,542 --> 00:27:23,810 line:-1
This will require a while loop


588
00:27:23,844 --> 00:27:26,713 line:-2
which we will enable by
using this switch.


589
00:27:26,747 --> 00:27:30,050 line:-2
We have implemented this
with the new MPSGraph API.


590
00:27:30,083 --> 00:27:32,986 line:-2
The error tolerance can be
controlled with this slider.


591
00:27:33,020 --> 00:27:35,055 line:-1
We have set it to 0.1, as shown.


592
00:27:35.088 --> 00:27:37.291 line:-2 align:center
Let's reset this back to the
naive clone.


593
00:27:37.858 --> 00:27:40.394 line:-1 align:center
Now we start the solver.


594
00:27:40.427 --> 00:27:43.130 line:-2 align:center
With this while loop, we
converge to the solution image


595
00:27:43,163 --> 00:27:44,831 line:-1
in about 80 iterations


596
00:27:44.865 --> 00:27:48.268 line:-2 align:center
without me having
to specify any iteration count.


597
00:27:48.302 --> 00:27:49.536 line:-1 align:center
Now let's have some fun


598
00:27:49,570 --> 00:27:52,072 line:-2
by cloning other animals
onto this background.


599
00:27:52,105 --> 00:27:54,241 line:-1
Let's try this cute puppy.


600
00:27:56,410 --> 00:27:58,478 line:-1
All right, done tracing.


601
00:27:58,512 --> 00:27:59,780 line:-2
I think it would look great
at the bottom right


602
00:27:59.813 --> 00:28:01.415 line:-1 align:center
of this image.


603
00:28:03,584 --> 00:28:06,320 line:-1
Maybe we can try a bird next.


604
00:28:07.554 --> 00:28:11.225 line:-2 align:center
This would look good on the
top right of the background.


605
00:28:11.258 --> 00:28:14.494 line:-2 align:center
The new background with all
these images looks pretty neat.


606
00:28:14,528 --> 00:28:15,896 line:-1
That's it for the demo.


607
00:28:17.564 --> 00:28:20.834 line:-2 align:center
In summary,
we showed how adopting MPSGraph


608
00:28:20.868 --> 00:28:23.036 line:-2 align:center
led to amazing performance
improvements


609
00:28:23,070 --> 00:28:25,672 line:-1
for CoreML and TensorFlow.


610
00:28:25.706 --> 00:28:29.142 line:-2 align:center
Inference
is now up to twice as fast.


611
00:28:29,176 --> 00:28:31,612 line:-2
We introduced
useful new compute primitives,


612
00:28:31,645 --> 00:28:34,348 line:-2
including the stencil operator
that is going to enable


613
00:28:34,381 --> 00:28:36,149 line:-1
a wide range of applications.


614
00:28:37.451 --> 00:28:39.520 line:-2 align:center
We showed new compilation
flexibility


615
00:28:39,553 --> 00:28:41,455 line:-1
that MPSGraph offers.


616
00:28:41,488 --> 00:28:44,358 line:-2
This is going to shave off
latency from inference networks.


617
00:28:45,459 --> 00:28:47,761 line:-1
And finally, we showed all new


618
00:28:47.794 --> 00:28:50.697 line:-2 align:center
control flow capabilities of
MPSGraph.


619
00:28:50.731 --> 00:28:53.367 line:-1 align:center
This API is key to expressing


620
00:28:53,400 --> 00:28:55,269 line:-2
several linear algebra
applications


621
00:28:55,302 --> 00:28:57,404 line:-2
in addition to machine
learning networks.


622
00:28:58.505 --> 00:29:00.307 line:-1 align:center
We are excited to see how you


623
00:29:00,340 --> 00:29:02,509 line:-2
will take advantage of
these features.


624
00:29:02,543 --> 00:29:06,346 line:-2
Thank you,
and have a great WWDC 2021.


625
00:29:06,380 --> 00:29:08,415 line:-1
[upbeat music]

