2
00:00:02,069 --> 00:00:07,074 line:-1
[music]


3
00:00:09,409 --> 00:00:11,845 line:-2
[John]
Hello, and welcome to WWDC.


4
00:00:11,879 --> 00:00:14,414 line:-2
My name’s John,
and I work on Core ML,


5
00:00:14,448 --> 00:00:16,416 line:-2
Apple’s machine learning
framework.


6
00:00:16,450 --> 00:00:17,985 line:-2
Together
with my colleague Brian,


7
00:00:18,018 --> 00:00:19,820 line:-2
we're excited to show you
how to tune up your models


8
00:00:19,853 --> 00:00:21,355 line:-2
as you bring the magic
of machine learning


9
00:00:21,388 --> 00:00:22,689 line:-1
to your apps.


10
00:00:22.723 --> 00:00:24.658 line:-2 align:center
To start things off,
I’m going to show you


11
00:00:24,691 --> 00:00:27,194 line:-2
some enhancements
to our machine learning APIs.


12
00:00:27.227 --> 00:00:29.663 line:-2 align:center
After that, we’ll dive
into file format improvements


13
00:00:29.696 --> 00:00:32.432 line:-2 align:center
that open up a range
of new possibilities.


14
00:00:32,466 --> 00:00:35,035 line:-2
Later on,
Brian will show us ML Programs


15
00:00:35,068 --> 00:00:36,870 line:-2
and take us under
the hood and walk us


16
00:00:36.904 --> 00:00:39.039 line:-2 align:center
through typed execution
and how you can use it


17
00:00:39,072 --> 00:00:42,776 line:-2
to fine-tune the accuracy
and performance of your models.


18
00:00:42,809 --> 00:00:45,145 line:-2
You can use these improvements
to streamline your workflow


19
00:00:45,179 --> 00:00:48,315 line:-2
and push your ML-powered
experiences even further.


20
00:00:48.348 --> 00:00:52.019 line:-2 align:center
Let’s start
with the API improvements.


21
00:00:52,052 --> 00:00:54,188 line:-2
Core ML provides you
with a simple API


22
00:00:54.221 --> 00:00:56.523 line:-2 align:center
to work with models
on your user’s device.


23
00:00:56.557 --> 00:00:58.625 line:-2 align:center
These models can be designed
to work with a variety


24
00:00:58.659 --> 00:01:01.962 line:-2 align:center
of inputs and outputs, such
as strings or primitive values


25
00:01:01.995 --> 00:01:05.666 line:-2 align:center
or more complex inputs
like images and MultiArrays.


26
00:01:05.699 --> 00:01:09.736 line:-2 align:center
Let’s talk more about
this last type, MultiArray.


27
00:01:09.770 --> 00:01:11.672 line:-1 align:center
Core ML makes it easy to work


28
00:01:11.705 --> 00:01:14.608 line:-2 align:center
with multidimensional
data using MLMultiArray.


29
00:01:14,641 --> 00:01:17,110 line:-2
While it’s a simple API,
the code you have to write


30
00:01:17,144 --> 00:01:19,580 line:-2
to manipulate data with it
doesn't always feel natural


31
00:01:19,613 --> 00:01:20,681 line:-1
in Swift.


32
00:01:20,714 --> 00:01:23,217 line:-2
For example, to initialize
a MultiArray with a bunch


33
00:01:23.250 --> 00:01:26.486 line:-2 align:center
of integers, you have to pass
in the type at runtime.


34
00:01:26,520 --> 00:01:29,756 line:-2
Plus you have to use NSNumber
instead of regular integers,


35
00:01:29,790 --> 00:01:31,058 line:-1
and that’s not type-safe


36
00:01:31,091 --> 00:01:34,294 line:-2
and doesn’t really look
like elegant Swift.


37
00:01:34.328 --> 00:01:37.464 line:-2 align:center
Core ML is introducing
MLShapedArray to make it easier


38
00:01:37.497 --> 00:01:39.666 line:-2 align:center
for you to work
with multidimensional data.


39
00:01:39,700 --> 00:01:42,803 line:-2
MLShapedArray is a pure
Swift type that’s similar


40
00:01:42,836 --> 00:01:45,839 line:-2
to a normal array but supports
multiple dimensions.


41
00:01:45,873 --> 00:01:49,543 line:-2
Like array, it’s a value type,
with copy-on-write semantics


42
00:01:49,576 --> 00:01:52,145 line:-2
and a rich slicing syntax
that works easily


43
00:01:52.179 --> 00:01:55.849 line:-2 align:center
with your existing
MLMultiArray code.


44
00:01:55.883 --> 00:01:58.418 line:-2 align:center
To initialize a two-dimensional
MLMultiArray,


45
00:01:58.452 --> 00:02:02.489 line:-2 align:center
you typically use two
nested “for” loops.


46
00:02:02,523 --> 00:02:05,292 line:-2
With an MLShapedArray,
you can initialize


47
00:02:05,325 --> 00:02:08,161 line:-2
the same 2D array
with a single line.


48
00:02:08,195 --> 00:02:11,064 line:-2
MLShapedArray fits naturally
in Swift and makes writing


49
00:02:11.098 --> 00:02:14.134 line:-2 align:center
and reviewing your code
that much easier.


50
00:02:14,168 --> 00:02:15,435 line:-1
Here’s another example.


51
00:02:15,469 --> 00:02:17,337 line:-2
To access the second row
as a slice,


52
00:02:17.371 --> 00:02:20.474 line:-2 align:center
you can just index
into it like this.


53
00:02:20,507 --> 00:02:23,310 line:-2
To access multiple rows
and columns as a slice,


54
00:02:23,343 --> 00:02:27,548 line:-2
you can use a range
for each dimension.


55
00:02:27.581 --> 00:02:29.750 line:-1 align:center
MLShapedArray and MLMultiArray


56
00:02:29.783 --> 00:02:31.451 line:-2 align:center
are fully compatible
with each other.


57
00:02:31,485 --> 00:02:34,588 line:-2
You can easily convert one type
into the other by using


58
00:02:34,621 --> 00:02:37,891 line:-2
the initializer that takes
an instance of the other type.


59
00:02:37.925 --> 00:02:39.493 line:-1 align:center
You can also convert data types


60
00:02:39,526 --> 00:02:41,628 line:-2
by using
the converting initializer.


61
00:02:41,662 --> 00:02:44,097 line:-2
For example,
this code converts a MultiArray


62
00:02:44,131 --> 00:02:47,301 line:-2
of doubles to a ShapedArray
of Floats.


63
00:02:47,334 --> 00:02:49,937 line:-2
Shaped arrays come in handy
anytime you need to work


64
00:02:49.970 --> 00:02:51.538 line:-1 align:center
with multidimensional data.


65
00:02:51.572 --> 00:02:55.209 line:-2 align:center
For example, the YOLO object
detection model finds objects


66
00:02:55.242 --> 00:02:58.478 line:-2 align:center
in an image, and then it
outputs a 2-dimensional array.


67
00:02:58.512 --> 00:03:00.948 line:-2 align:center
The table shows the data
from one prediction.


68
00:03:00.981 --> 00:03:03.016 line:-2 align:center
Each row
represents a bounding box,


69
00:03:03.050 --> 00:03:05.686 line:-2 align:center
and the values in each column
range between 0 and 1.


70
00:03:05,719 --> 00:03:08,255 line:-2
Each value represents
how confident the model is


71
00:03:08.288 --> 00:03:10.090 line:-2 align:center
that the bounding box
contains a person,


72
00:03:10.123 --> 00:03:12.459 line:-1 align:center
bicycle, or car, et cetera.


73
00:03:12,492 --> 00:03:14,995 line:-2
I want to write some code
to pick the most likely label


74
00:03:15.028 --> 00:03:17.197 line:-1 align:center
for each bounding box.


75
00:03:17,231 --> 00:03:19,600 line:-2
Here’s an example of how
to do that.


76
00:03:19,633 --> 00:03:22,002 line:-2
The code starts with the
output’s confidence property,


77
00:03:22,035 --> 00:03:24,438 line:-2
which is
a 2-dimensional MultiArray.


78
00:03:24,471 --> 00:03:26,540 line:-2
This function loops
through each row to find


79
00:03:26.573 --> 00:03:29.243 line:-2 align:center
the highest confidence score
in that row.


80
00:03:29.276 --> 00:03:33.780 line:-2 align:center
Notice it has to frequently cast
integers to NSNumber.


81
00:03:33,814 --> 00:03:37,050 line:-2
This code uses MLShapedArray
instead and does the same job


82
00:03:37.084 --> 00:03:39.353 line:-2 align:center
in fewer lines
that are easier to read.


83
00:03:39,386 --> 00:03:41,455 line:-2
Notice the model’s prediction
result gives us


84
00:03:41,488 --> 00:03:44,958 line:-2
a ShapedArray property that
contains the confidence values.


85
00:03:44,992 --> 00:03:48,095 line:-2
This code is simpler because
MLShapedArray and its scalars


86
00:03:48,128 --> 00:03:50,731 line:-2
conform to the standard
Swift collection protocols.


87
00:03:50,764 --> 00:03:53,200 line:-2
This provides a nice
strongly typed experience


88
00:03:53,233 --> 00:03:56,470 line:-2
that’s more readable
and a joy to work with in Swift.


89
00:03:56,503 --> 00:03:58,739 line:-2
Next up,
let’s talk about Core ML models


90
00:03:58.772 --> 00:04:01.341 line:-2 align:center
and how they’re represented
in the file system.


91
00:04:01,375 --> 00:04:03,277 line:-2
Core ML makes it easy
to build rich


92
00:04:03,310 --> 00:04:06,013 line:-2
machine learning-powered
experiences for your user.


93
00:04:06.046 --> 00:04:08.482 line:-2 align:center
An ML model is the engine
that brings these experiences


94
00:04:08,515 --> 00:04:09,683 line:-1
to life.


95
00:04:09.716 --> 00:04:11.952 line:-1 align:center
The .mlmodel file format encodes


96
00:04:11.985 --> 00:04:13.587 line:-2 align:center
and abstracts
the model’s functionality


97
00:04:13.620 --> 00:04:15.122 line:-2 align:center
so you don’t need to worry
about it.


98
00:04:15,155 --> 00:04:17,591 line:-2
The format stores all
the implementation details


99
00:04:17.624 --> 00:04:19.426 line:-1 align:center
and complexities of a model.


100
00:04:19,459 --> 00:04:21,361 line:-2
As a developer,
you don’t need to care


101
00:04:21,395 --> 00:04:23,297 line:-2
about whether it’s a tree
ensemble or a neural network


102
00:04:23,330 --> 00:04:24,631 line:-1
with millions of parameters.


103
00:04:24.665 --> 00:04:27.568 line:-2 align:center
An ML Model is just a single
file that you simply add


104
00:04:27,601 --> 00:04:29,736 line:-2
to an Xcode project
and write code that works


105
00:04:29,770 --> 00:04:32,739 line:-2
with it,
just like any other API.


106
00:04:32.773 --> 00:04:36.410 line:-2 align:center
Each Core ML model file consists
of several components.


107
00:04:36.443 --> 00:04:40.013 line:-2 align:center
The metadata stores information
such as the author, license,


108
00:04:40,047 --> 00:04:42,649 line:-2
version,
and a short description.


109
00:04:42.683 --> 00:04:46.353 line:-2 align:center
The interface defines
the model’s inputs and outputs.


110
00:04:46.386 --> 00:04:49.756 line:-2 align:center
The architecture defines
the model’s internal structure.


111
00:04:49,790 --> 00:04:51,992 line:-2
For example,
with a neural network,


112
00:04:52,025 --> 00:04:54,595 line:-2
the architecture section
describes the model's layers


113
00:04:54,628 --> 00:04:56,930 line:-2
and all the connections
between them.


114
00:04:56.964 --> 00:04:59.399 line:-2 align:center
Finally, the last section
stores the massive array


115
00:04:59,433 --> 00:05:03,437 line:-2
of values that the model learned
during the training phase.


116
00:05:03,470 --> 00:05:05,806 line:-2
An ML Model file encodes
all these sections


117
00:05:05,839 --> 00:05:08,876 line:-2
into a protobuf binary format,
which file systems


118
00:05:08.909 --> 00:05:12.513 line:-2 align:center
and source control software see
as a single binary file.


119
00:05:12,546 --> 00:05:15,282 line:-2
Source control software can’t
tell that the binary model file


120
00:05:15,315 --> 00:05:18,151 line:-2
is actually a combination
of several distinct components.


121
00:05:18.185 --> 00:05:21.221 line:-2 align:center
To solve that, Core ML is
adding a new model format


122
00:05:21.255 --> 00:05:23.657 line:-2 align:center
that breaks these components
into separate files,


123
00:05:23,690 --> 00:05:27,294 line:-2
using macOS’ built-in
package functionality.


124
00:05:27,327 --> 00:05:30,297 line:-2
Which brings us to the new
Core ML Model Package.


125
00:05:30,330 --> 00:05:32,933 line:-2
It’s a container that stores
each of a model’s components


126
00:05:32,966 --> 00:05:35,602 line:-2
in its own file,
separating out its architecture,


127
00:05:35.636 --> 00:05:37.938 line:-1 align:center
weights, and metadata.


128
00:05:37.971 --> 00:05:39.640 line:-1 align:center
By separating these components,


129
00:05:39,673 --> 00:05:42,075 line:-2
model packages allow
you to easily edit metadata


130
00:05:42.109 --> 00:05:44.678 line:-2 align:center
and track changes
with source control.


131
00:05:44.711 --> 00:05:46.446 line:-2 align:center
They also compile
more efficiently


132
00:05:46.480 --> 00:05:48.448 line:-2 align:center
and provide more flexibility
for tools


133
00:05:48,482 --> 00:05:50,617 line:-1
which read and write models.


134
00:05:50,651 --> 00:05:52,953 line:-2
Core ML and Xcode still
fully support


135
00:05:52,986 --> 00:05:55,022 line:-1
the original ML model format.


136
00:05:55,055 --> 00:05:57,090 line:-2
But you can move
to a more extensible format


137
00:05:57,124 --> 00:06:00,661 line:-2
and compile more efficiently
by updating to a model package.


138
00:06:00,694 --> 00:06:02,696 line:-1
Let’s try this out in Xcode.


139
00:06:02.729 --> 00:06:05.232 line:-2 align:center
Here’s a simple app that uses
an object detection model


140
00:06:05,265 --> 00:06:07,734 line:-1
to identify animals in an image.


141
00:06:07.768 --> 00:06:10.337 line:-2 align:center
Notice that some of the metadata
fields are empty.


142
00:06:10,370 --> 00:06:12,105 line:-2
It’s fairly common
to come across models


143
00:06:12.139 --> 00:06:14.141 line:-2 align:center
where the metadata isn’t
filled in.


144
00:06:14,174 --> 00:06:17,077 line:-2
In the past, you couldn’t
edit these fields in Xcode.


145
00:06:17,110 --> 00:06:20,981 line:-2
But now that Xcode supports
model packages, you can.


146
00:06:21.014 --> 00:06:23.717 line:-2 align:center
Right now the model’s
file type is ML Model,


147
00:06:23,750 --> 00:06:26,587 line:-2
but when I click on the Edit
button, Xcode prompts me


148
00:06:26,620 --> 00:06:29,990 line:-2
to update the ML Model file
to an ML Package.


149
00:06:30,023 --> 00:06:32,092 line:-2
Xcode tells me
that it’s about to update any


150
00:06:32.125 --> 00:06:34.895 line:-2 align:center
of my workspace’s references
to the original model file


151
00:06:34.928 --> 00:06:37.264 line:-1 align:center
to point at the new.mlpackage.


152
00:06:37,297 --> 00:06:40,133 line:-2
I’ll go ahead and click Update
and Edit.


153
00:06:42.369 --> 00:06:45.372 line:-2 align:center
Xcode’s UI
now indicates the model is


154
00:06:45,405 --> 00:06:48,408 line:-1
in the ML Package format.


155
00:06:48,442 --> 00:06:51,712 line:-2
Now I can fill in the missing
values directly in Xcode.


156
00:06:51.745 --> 00:06:54.948 line:-2 align:center
I’ll go ahead
and update the description


157
00:06:54.982 --> 00:06:57.451 line:-1 align:center
with the word “animals.”


158
00:06:57,484 --> 00:06:59,586 line:-2
Since this model came
from my coworker, Joseph,


159
00:06:59,620 --> 00:07:01,722 line:-2
I’ll put his name
in the Author field.


160
00:07:01.755 --> 00:07:05.192 line:-2 align:center
I’ll say MIT License
and version 2.0.


161
00:07:07,127 --> 00:07:08,795 line:-1
I can also add, modify,


162
00:07:08,829 --> 00:07:11,431 line:-2
and remove additional
metadata fields as well.


163
00:07:11,465 --> 00:07:13,901 line:-2
I’ll add a new metadata item
that indicates


164
00:07:13.934 --> 00:07:17.204 line:-2 align:center
which year we used
this model at WWDC.


165
00:07:17.237 --> 00:07:19.907 line:-1 align:center
So we’ll say 2021.


166
00:07:19.940 --> 00:07:21.508 line:-2 align:center
Now, in addition
to the UI support,


167
00:07:21,542 --> 00:07:23,644 line:-2
all of this information is
also accessible using


168
00:07:23,677 --> 00:07:27,314 line:-2
Core ML’s MLModelDescription API
at runtime.


169
00:07:27.347 --> 00:07:28.916 line:-2 align:center
I can also modify
the description


170
00:07:28.949 --> 00:07:32.920 line:-2 align:center
of the model's Inputs and
Outputs in the Predictions tab.


171
00:07:32,953 --> 00:07:35,489 line:-2
Here I’ll change the description
of this Input.


172
00:07:35.522 --> 00:07:38.058 line:-1 align:center
We'll add "of an animal."


173
00:07:38,091 --> 00:07:43,330 line:-2
And down here, I’ll fix a typo
by adding a missing hyphen.


174
00:07:43.363 --> 00:07:45.766 line:-2 align:center
Now, a model with good
metadata is a lot like code


175
00:07:45,799 --> 00:07:46,900 line:-1
with good comments.


176
00:07:46,934 --> 00:07:49,102 line:-2
It helps you and your team
understand the model's intent,


177
00:07:49.136 --> 00:07:50.604 line:-2 align:center
and so it’s particularly
important


178
00:07:50.637 --> 00:07:51.772 line:-2 align:center
to make sure
you write good descriptions


179
00:07:51,805 --> 00:07:54,741 line:-2
for your model’s inputs
and outputs.


180
00:07:54,775 --> 00:07:57,845 line:-2
I’ll click Done
to save the changes.


181
00:07:57,878 --> 00:08:01,415 line:-2
Now if I click on Source Control
and then Commit,


182
00:08:01,448 --> 00:08:04,885 line:-2
Xcode shows
the changes in a diff view.


183
00:08:07,354 --> 00:08:09,790 line:-2
The metadata is now
in its own.json file,


184
00:08:09,823 --> 00:08:12,626 line:-2
which makes it easy
to verify my changes.


185
00:08:12.659 --> 00:08:14.561 line:-2 align:center
Similarly,
the Feature Descriptions


186
00:08:14.595 --> 00:08:17.798 line:-2 align:center
have their own
separate.json file.


187
00:08:17,831 --> 00:08:19,333 line:-1
If we had changed a few bytes


188
00:08:19,366 --> 00:08:22,102 line:-2
of a 62-megabyte binary
ML Model file,


189
00:08:22.135 --> 00:08:24.705 line:-2 align:center
we’d have
a 62-megabyte binary diff.


190
00:08:24,738 --> 00:08:27,508 line:-2
Model packages, however,
are much more efficient and easy


191
00:08:27,541 --> 00:08:30,177 line:-2
to work with, especially
for small text changes.


192
00:08:30,210 --> 00:08:32,212 line:-2
Xcode supports
both model packages


193
00:08:32,246 --> 00:08:34,214 line:-1
and model files equally.


194
00:08:34,248 --> 00:08:36,550 line:-2
For example,
I can use the Preview tab


195
00:08:36,583 --> 00:08:39,353 line:-1
to test out my model package.


196
00:08:39,386 --> 00:08:42,789 line:-2
If I bring in an image
of two bears, we’ll see


197
00:08:42,823 --> 00:08:46,627 line:-2
that we get two bounding boxes,
one for each bear.


198
00:08:46,660 --> 00:08:50,430 line:-2
Similarly, I can go
to the Utilities tab,


199
00:08:50,464 --> 00:08:52,099 line:-2
where I can generate
an encryption key


200
00:08:52,132 --> 00:08:54,535 line:-2
or an ML archive
for a model package the same


201
00:08:54.568 --> 00:08:56.970 line:-1 align:center
as I would for an ML model file.


202
00:08:57.004 --> 00:08:59.106 line:-2 align:center
So that’s model packages
in Xcode.


203
00:08:59,139 --> 00:09:01,975 line:-2
Packages can do everything
a model file can and more,


204
00:09:02,009 --> 00:09:04,444 line:-1
such as editing model metadata.


205
00:09:04.478 --> 00:09:06.146 line:-2 align:center
The last thing I want
to show is the code


206
00:09:06,180 --> 00:09:07,648 line:-2
that Xcode
automatically generates


207
00:09:07,681 --> 00:09:10,217 line:-2
for each model you add
to a project.


208
00:09:10.250 --> 00:09:13.987 line:-2 align:center
I’m going to click on this icon
to see the generated code.


209
00:09:14.021 --> 00:09:16.223 line:-2 align:center
Earlier,
we took a look at MLMultiArray


210
00:09:16.256 --> 00:09:19.359 line:-2 align:center
and its new Swift counterpart,
MLShapedArray.


211
00:09:19,393 --> 00:09:21,895 line:-2
Xcode now adds a new
shaped array property


212
00:09:21.929 --> 00:09:25.933 line:-2 align:center
for each MultiArray output
in the wrapper class.


213
00:09:25.966 --> 00:09:28.135 line:-2 align:center
For example,
the generated class now has


214
00:09:28.168 --> 00:09:31.772 line:-2 align:center
a confidenceShapedArray property
for the model’s output.


215
00:09:31,805 --> 00:09:34,608 line:-2
You can still use the original
confidence MLMultiArray property


216
00:09:34.641 --> 00:09:36.977 line:-1 align:center
if you like.


217
00:09:37.010 --> 00:09:39.179 line:-2 align:center
Note that your project’s
deployment target must be one


218
00:09:39.213 --> 00:09:43.116 line:-2 align:center
of these OS versions,
for example, macOS 12 or iOS 15,


219
00:09:43.150 --> 00:09:46.286 line:-2 align:center
to take advantage of the new
shaped array property.


220
00:09:46,320 --> 00:09:47,754 line:-2
Now that we’ve seen
all this in action,


221
00:09:47.788 --> 00:09:51.892 line:-2 align:center
let’s take a look at ML Model
and ML Package side by side.


222
00:09:51,925 --> 00:09:54,661 line:-2
ML Packages support all the same
types that ML Model files


223
00:09:54,695 --> 00:09:58,999 line:-2
support, including trees, SVMs,
neural networks, and so on.


224
00:09:59,032 --> 00:10:02,035 line:-2
In addition to these types,
ML Packages also support


225
00:10:02.069 --> 00:10:05.172 line:-2 align:center
a powerful new model type
called ML Program.


226
00:10:05,205 --> 00:10:08,408 line:-2
ML Program is a model type
that represents neural networks


227
00:10:08,442 --> 00:10:10,644 line:-1
in a more code-oriented format.


228
00:10:10.677 --> 00:10:12.546 line:-2 align:center
To tell you more
about ML Programs


229
00:10:12.579 --> 00:10:13.647 line:-2 align:center
and the new features
they enable,


230
00:10:13,680 --> 00:10:15,115 line:-1
I’ll hand it over to Brian.


231
00:10:15,148 --> 00:10:16,183 line:-2
[Brian]
Thanks, John.


232
00:10:16,216 --> 00:10:18,018 line:-2
My name is Brian Keene,
and I’m excited to talk


233
00:10:18,051 --> 00:10:21,088 line:-2
about ML Programs and how typed
execution gives you more control


234
00:10:21,121 --> 00:10:24,391 line:-2
over accuracy
and better model performance.


235
00:10:24.424 --> 00:10:26.560 line:-2 align:center
There are various ways
a machine learning model


236
00:10:26,593 --> 00:10:28,529 line:-1
may have been presented to you.


237
00:10:28.562 --> 00:10:30.397 line:-2 align:center
If you’re taking
a machine learning course


238
00:10:30.430 --> 00:10:33.433 line:-2 align:center
or reading a paper, you may
encounter a model described


239
00:10:33,467 --> 00:10:36,937 line:-2
with respect to its mathematical
or statistical formulation.


240
00:10:36,970 --> 00:10:40,541 line:-2
However, these mathematical
expressions are often abstracted


241
00:10:40,574 --> 00:10:42,643 line:-2
and alternatively presented
to you in the form


242
00:10:42,676 --> 00:10:45,212 line:-2
of a computation graph
or network.


243
00:10:45,245 --> 00:10:47,781 line:-2
This graphical representation
as depicted


244
00:10:47.814 --> 00:10:49.983 line:-2 align:center
in the middle two figures,
describes how data flows


245
00:10:50.017 --> 00:10:51.318 line:-1 align:center
through a series of layers,


246
00:10:51.351 --> 00:10:54.688 line:-2 align:center
each of which applies
their own specific transform.


247
00:10:54.721 --> 00:10:56.557 line:-2 align:center
In a machine learning
software library,


248
00:10:56,590 --> 00:10:59,893 line:-2
the model is instead expressed
as operations in code.


249
00:10:59.927 --> 00:11:02.329 line:-2 align:center
Machine learning engineers
are increasingly leveraging


250
00:11:02,362 --> 00:11:04,231 line:-2
this more generic program
structure


251
00:11:04.264 --> 00:11:07.401 line:-2 align:center
composed of blocks,
functions, and control flow.


252
00:11:07,434 --> 00:11:11,071 line:-2
The new ML Program model type
in Core ML aligns itself


253
00:11:11,104 --> 00:11:13,607 line:-1
with this last representation.


254
00:11:13.640 --> 00:11:16.276 line:-2 align:center
This is
a representative ML Program.


255
00:11:16.310 --> 00:11:18.779 line:-2 align:center
It’s in a human readable
text format, although


256
00:11:18,812 --> 00:11:21,114 line:-2
the intention is that you don’t
have to write it yourself.


257
00:11:21,148 --> 00:11:23,417 line:-2
The ML Program will be
generated automatically


258
00:11:23.450 --> 00:11:25.319 line:-1 align:center
by Core ML’s converter.


259
00:11:25.352 --> 00:11:28.155 line:-2 align:center
An ML program consists
of a main function.


260
00:11:28.188 --> 00:11:30.524 line:-2 align:center
This main function
consists of a sequence


261
00:11:30,557 --> 00:11:32,726 line:-1
of operations, or ops.


262
00:11:32.759 --> 00:11:34.528 line:-1 align:center
Each op produces a variable,


263
00:11:34.561 --> 00:11:37.464 line:-2 align:center
and this variable is
strongly typed.


264
00:11:37.497 --> 00:11:40.300 line:-2 align:center
For operations that have
weights, such as the linear


265
00:11:40.334 --> 00:11:42.603 line:-2 align:center
or convolution ops,
the weights are typically


266
00:11:42.636 --> 00:11:46.907 line:-2 align:center
serialized
into a separate binary file.


267
00:11:46,940 --> 00:11:49,710 line:-2
This is a brief summary
of how ML Programs


268
00:11:49,743 --> 00:11:52,045 line:-1
compare to Neural Networks.


269
00:11:52,079 --> 00:11:57,251 line:-2
Neural networks have layers,
while ML Programs have ops.


270
00:11:57.284 --> 00:11:59.720 line:-2 align:center
Weights in neural network
models are embedded


271
00:11:59,753 --> 00:12:00,988 line:-1
in their layer descriptions,


272
00:12:01.021 --> 00:12:04.324 line:-2 align:center
while ML Programs serialize
the weights separately.


273
00:12:04,358 --> 00:12:06,426 line:-2
And neural networks don’t
specify


274
00:12:06.460 --> 00:12:07.895 line:-1 align:center
the intermediate tensor types.


275
00:12:07.928 --> 00:12:09.963 line:-2 align:center
Instead,
the compute unit determines


276
00:12:09.997 --> 00:12:11.632 line:-1 align:center
these types at runtime.


277
00:12:11.665 --> 00:12:15.402 line:-2 align:center
ML Programs, on the other hand,
have strongly typed tensors.


278
00:12:15,435 --> 00:12:19,006 line:-2
Today I’ll focus on ML Program’s
strongly typed syntax


279
00:12:19,039 --> 00:12:21,575 line:-2
and the implications that typed
intermediate tensors have


280
00:12:21,608 --> 00:12:24,478 line:-2
for on-device machine
learning with ML Programs.


281
00:12:24.511 --> 00:12:28.081 line:-2 align:center
But first,
how do you get an ML Program?


282
00:12:28,115 --> 00:12:32,286 line:-2
Core ML previously introduced
a unified converter API.


283
00:12:32.319 --> 00:12:35.422 line:-2 align:center
This unified converter API
provides a convenient means


284
00:12:35,455 --> 00:12:37,124 line:-2
to get your model
from Tensorflow


285
00:12:37.157 --> 00:12:39.960 line:-2 align:center
or PyTorch to the Core ML
neural network model


286
00:12:39.993 --> 00:12:42.896 line:-1 align:center
with a single function call.


287
00:12:42,930 --> 00:12:45,399 line:-2
You can now use the same API
to convert


288
00:12:45.432 --> 00:12:48.001 line:-2 align:center
to an ML Program
by selecting iOS 15


289
00:12:48.035 --> 00:12:51.405 line:-2 align:center
as the minimum
deployment target.


290
00:12:51.438 --> 00:12:53.540 line:-2 align:center
Under the hood,
the Core ML converter


291
00:12:53.574 --> 00:12:55.209 line:-2 align:center
selects
an on-disk representation


292
00:12:55,242 --> 00:12:57,344 line:-2
for the model
at conversion time.


293
00:12:57.377 --> 00:13:00.547 line:-2 align:center
For ML Programs, the on-disk
intermediate representation is


294
00:13:00.581 --> 00:13:02.649 line:-2 align:center
provided
by Model Intermediate Language,


295
00:13:02,683 --> 00:13:05,953 line:-2
a feature
introduced at WWDC 2020.


296
00:13:05,986 --> 00:13:08,822 line:-2
The unified converter
API is where you can opt-in


297
00:13:08,856 --> 00:13:12,392 line:-2
to deploy your model
as an ML Program.


298
00:13:12.426 --> 00:13:14.494 line:-2 align:center
Moving forward,
ML Program will be


299
00:13:14.528 --> 00:13:16.763 line:-2 align:center
the favored format
over neural network.


300
00:13:16.797 --> 00:13:18.832 line:-2 align:center
And ML Program is available
beginning


301
00:13:18.866 --> 00:13:21.568 line:-1 align:center
with iOS15 and macOS Monterey.


302
00:13:21,602 --> 00:13:25,038 line:-2
Core ML supports both ML Model
and ML Package formats


303
00:13:25.072 --> 00:13:26.440 line:-1 align:center
for neural networks models,


304
00:13:26.473 --> 00:13:29.343 line:-2 align:center
but ML Program must be
an ML Package to store


305
00:13:29,376 --> 00:13:31,578 line:-2
its weights separately
from the architecture.


306
00:13:31,612 --> 00:13:33,580 line:-2
Core ML
is investing in ML Program


307
00:13:33.614 --> 00:13:35.282 line:-1 align:center
as a foundation for the future.


308
00:13:35.315 --> 00:13:37.484 line:-2 align:center
There will be continued support
for neural networks,


309
00:13:37.518 --> 00:13:40.220 line:-2 align:center
but ML Program will be
central to new features.


310
00:13:40,254 --> 00:13:42,589 line:-1
So if ML Program is the future,


311
00:13:42.623 --> 00:13:45.592 line:-2 align:center
what are the benefits
of adopting ML Program today?


312
00:13:45,626 --> 00:13:47,661 line:-2
This brings us
to typed execution.


313
00:13:47.694 --> 00:13:49.763 line:-2 align:center
To highlight the benefits
of typed execution


314
00:13:49.796 --> 00:13:52.366 line:-2 align:center
with ML Programs,
let’s first discuss what happens


315
00:13:52,399 --> 00:13:54,201 line:-1
with neural networks.


316
00:13:54.234 --> 00:13:56.970 line:-2 align:center
Shown here is an example input
and output


317
00:13:57,004 --> 00:14:01,375 line:-2
to a Core ML Neural Network
model that specifies Float32


318
00:14:01.408 --> 00:14:04.845 line:-2 align:center
for the input
and output tensors.


319
00:14:04,878 --> 00:14:09,049 line:-2
Inputs and outputs can also be
double or 32-bit integer types.


320
00:14:09,082 --> 00:14:11,685 line:-2
So the neural network model
strongly types


321
00:14:11.718 --> 00:14:13.487 line:-1 align:center
these input and output tensors.


322
00:14:13.520 --> 00:14:17.824 line:-2 align:center
What about the types
of the intermediate tensors?


323
00:14:17,858 --> 00:14:19,826 line:-2
A neural network doesn’t
strongly


324
00:14:19,860 --> 00:14:21,428 line:-1
type its intermediate tensors.


325
00:14:21.461 --> 00:14:23.497 line:-2 align:center
There is no information
about the types


326
00:14:23.530 --> 00:14:25.632 line:-2 align:center
of these tensors
in the on-disk model.


327
00:14:25,666 --> 00:14:27,901 line:-2
Instead, the compute unit
that runs the model


328
00:14:27.935 --> 00:14:33.106 line:-2 align:center
infers the tensor’s types
after Core ML loads the model.


329
00:14:33.140 --> 00:14:35.709 line:-2 align:center
When the Core ML runtime
loads a neural network,


330
00:14:35.742 --> 00:14:37.211 line:-1 align:center
it automatically and dynamically


331
00:14:37.244 --> 00:14:39.413 line:-2 align:center
partitions the network graph
into sections:


332
00:14:39,446 --> 00:14:43,617 line:-2
Apple Neural Engine friendly,
GPU friendly, and CPU.


333
00:14:43.650 --> 00:14:45.919 line:-2 align:center
Each compute unit
executes its section


334
00:14:45,953 --> 00:14:48,355 line:-2
of the network using
its native type to maximize


335
00:14:48.388 --> 00:14:51.892 line:-2 align:center
its performance and the model’s
overall performance.


336
00:14:51,925 --> 00:14:54,962 line:-2
The GPU and the Neural Engine
both use Float16,


337
00:14:54,995 --> 00:14:57,431 line:-1
and CPU uses Float32.


338
00:14:57,464 --> 00:14:59,399 line:-2
As the developer,
you have some control


339
00:14:59.433 --> 00:15:02.970 line:-2 align:center
over this execution scheme
by selecting .all, .cpuAndGPU,


340
00:15:03.003 --> 00:15:07.808 line:-2 align:center
or .cpuOnly with the model’s
computeUnits property.


341
00:15:07,841 --> 00:15:10,878 line:-2
This property defaults to .all,
which instructs Core ML


342
00:15:10,911 --> 00:15:12,946 line:-2
to partition the model
across the neural engine,


343
00:15:12.980 --> 00:15:15.015 line:-1 align:center
GPU, and CPU at runtime


344
00:15:15.048 --> 00:15:18.318 line:-2 align:center
to give your app
the best performance possible.


345
00:15:18.352 --> 00:15:20.354 line:-1 align:center
And if you set it to cpuOnly,


346
00:15:20.387 --> 00:15:23.257 line:-2 align:center
Core ML will not use either
the Neural Engine or the GPU,


347
00:15:23,290 --> 00:15:26,460 line:-2
which ensures your model is only
executing the Float32 precision


348
00:15:26,493 --> 00:15:28,862 line:-1
on the CPU.


349
00:15:28,896 --> 00:15:31,832 line:-2
To summarize, neural networks
have intermediate tensors,


350
00:15:31.865 --> 00:15:33.567 line:-2 align:center
which are automatically typed
at runtime


351
00:15:33.600 --> 00:15:36.336 line:-2 align:center
by the compute unit responsible
for producing them.


352
00:15:36,370 --> 00:15:38,539 line:-2
You do have some control
of their precision


353
00:15:38.572 --> 00:15:41.041 line:-2 align:center
by configuring the set
of allowed compute units,


354
00:15:41,074 --> 00:15:43,243 line:-2
but doing so is a global setting
for the model


355
00:15:43.277 --> 00:15:46.847 line:-2 align:center
and may leave some
performance on the table.


356
00:15:46,880 --> 00:15:49,216 line:-1
What about ML Program?


357
00:15:49,249 --> 00:15:50,951 line:-1
In the ML Program depicted here,


358
00:15:50,984 --> 00:15:53,654 line:-2
the input and output
tensors are strongly typed,


359
00:15:53,687 --> 00:15:58,258 line:-2
and so is every intermediate
tensor of the program.


360
00:15:58.292 --> 00:16:00.994 line:-2 align:center
You can even mix
and match precision support


361
00:16:01,028 --> 00:16:04,431 line:-2
within a single compute unit,
say, the CPU or GPU,


362
00:16:04.464 --> 00:16:07.701 line:-2 align:center
and these types are well defined
at the time of model conversion.


363
00:16:07.734 --> 00:16:10.103 line:-2 align:center
That’s long before you would use
Core ML to load


364
00:16:10.137 --> 00:16:13.540 line:-2 align:center
and run the model
in a deployment scenario.


365
00:16:13.574 --> 00:16:16.844 line:-2 align:center
ML Programs use the same
automatic partioning scheme


366
00:16:16,877 --> 00:16:18,645 line:-2
that distributes work
to the Neural Engine,


367
00:16:18,679 --> 00:16:20,280 line:-1
GPU, and CPU.


368
00:16:20,314 --> 00:16:22,516 line:-2
However,
it adds a type constraint.


369
00:16:22,549 --> 00:16:24,985 line:-2
Core ML retains the ability
to promote a tensor


370
00:16:25.018 --> 00:16:27.521 line:-2 align:center
to a higher precision,
but the Core ML runtime


371
00:16:27,554 --> 00:16:30,123 line:-2
never casts intermediate tensors
to a lower precision


372
00:16:30.157 --> 00:16:32.793 line:-2 align:center
than that specified
in the ML Program.


373
00:16:32,826 --> 00:16:35,362 line:-2
This new support
for typed execution


374
00:16:35,395 --> 00:16:37,898 line:-2
has been made possible
via expanded op support


375
00:16:37,931 --> 00:16:40,467 line:-1
on both GPU and CPU,


376
00:16:40.501 --> 00:16:43.270 line:-2 align:center
particularly for Float32 ops
on GPU


377
00:16:43,303 --> 00:16:45,939 line:-2
and selected ops in Float16
on CPU.


378
00:16:45.973 --> 00:16:48.208 line:-2 align:center
With this expanded support,
you can still


379
00:16:48.242 --> 00:16:50.143 line:-2 align:center
see the performance
benefits of the GPU


380
00:16:50.177 --> 00:16:54.715 line:-2 align:center
when your ML Program
specifies Float32 precision.


381
00:16:54.748 --> 00:16:56.850 line:-2 align:center
Let’s try out
the unified converter API


382
00:16:56,884 --> 00:17:00,921 line:-2
to produce ML Programs
with different precisions.


383
00:17:00,954 --> 00:17:03,223 line:-2
OK,
I’m now in a Jupyter notebook,


384
00:17:03.257 --> 00:17:05.826 line:-2 align:center
which is a convenient tool
for executing Python code


385
00:17:05,859 --> 00:17:07,327 line:-1
in an interactive way.


386
00:17:07.361 --> 00:17:09.696 line:-2 align:center
I’ll go over the process
of converting a model


387
00:17:09,730 --> 00:17:11,598 line:-1
to the new ML Program format.


388
00:17:11.632 --> 00:17:14.735 line:-2 align:center
The model I’m going to use today
is a style transfer model.


389
00:17:14.768 --> 00:17:17.237 line:-2 align:center
I’ve already downloaded
a pretrained Tensorflow model


390
00:17:17.271 --> 00:17:18.372 line:-1 align:center
from Open Source.


391
00:17:18.405 --> 00:17:22.009 line:-2 align:center
This model takes in an image
and produces a stylized image.


392
00:17:22,042 --> 00:17:24,378 line:-2
The first thing needed is
a few import statements.


393
00:17:24,411 --> 00:17:27,614 line:-2
I’ll import coremltools,
the Python image library,


394
00:17:27,648 --> 00:17:29,416 line:-2
as well
as a couple helper libraries


395
00:17:29,449 --> 00:17:31,018 line:-2
and simple helper functions
that I’ve written


396
00:17:31,051 --> 00:17:32,920 line:-2
to keep the code
I use here succinct.


397
00:17:38.058 --> 00:17:41.395 line:-2 align:center
Now I’ll specify the path
of the style transfer model


398
00:17:41.428 --> 00:17:43.897 line:-2 align:center
and the path to the image
I’m going to stylize.


399
00:17:43,931 --> 00:17:45,666 line:-2
I’m going to also set up
the input types


400
00:17:45.699 --> 00:17:46.700 line:-1 align:center
for the conversion.


401
00:17:46.733 --> 00:17:49.269 line:-2 align:center
In this case, it’ll be an image
input type which specifies


402
00:17:49,303 --> 00:17:52,072 line:-2
the dimensions of the image
on which the model was trained.


403
00:17:52,105 --> 00:17:53,907 line:-2
Finally,
there’s some additional setup


404
00:17:53.941 --> 00:17:56.009 line:-2 align:center
to prepare the input
dictionary that I can use


405
00:17:56.043 --> 00:18:00.013 line:-2 align:center
to run the Core ML model
post conversion.


406
00:18:00.047 --> 00:18:01.982 line:-1 align:center
So the input has been loaded,


407
00:18:02.015 --> 00:18:03.650 line:-2 align:center
and the source model is
available.


408
00:18:03,684 --> 00:18:06,486 line:-2
At this point, all of the
external resources are ready


409
00:18:06.520 --> 00:18:08.889 line:-1 align:center
for conversion to an ML Program.


410
00:18:11.391 --> 00:18:14.761 line:-2 align:center
For conversion, I’ll use
the Unified Converter API.


411
00:18:14,795 --> 00:18:17,231 line:-2
The first argument is
the source model path.


412
00:18:17,264 --> 00:18:19,499 line:-2
Next, pass the array
of input types.


413
00:18:19,533 --> 00:18:21,235 line:-1
Here, there’s just the one.


414
00:18:21.268 --> 00:18:23.704 line:-2 align:center
Finally, the minimum
deployment target argument


415
00:18:23,737 --> 00:18:26,340 line:-2
will determine if Core ML Tools
produces a neural network


416
00:18:26.373 --> 00:18:28.108 line:-1 align:center
or an ML Program.


417
00:18:28,141 --> 00:18:32,579 line:-2
It defaults to iOS 13
and produces a neural network.


418
00:18:32.613 --> 00:18:34.715 line:-2 align:center
Right now I want
to get an ML Program,


419
00:18:34,748 --> 00:18:37,651 line:-2
so I’ll set the deployment
target to iOS 15.


420
00:18:37,684 --> 00:18:40,954 line:-2
I want to eventually
deploy this model on an iOS app.


421
00:18:40.988 --> 00:18:43.423 line:-2 align:center
I could have alternatively
specified a deployment target


422
00:18:43.457 --> 00:18:47.060 line:-2 align:center
of macOS 12,
if my target device was a Mac.


423
00:18:47,094 --> 00:18:50,797 line:-2
I’ll press Shift-Enter
to convert the model.


424
00:18:50.831 --> 00:18:53.033 line:-1 align:center
And conversion has completed.


425
00:18:53.066 --> 00:18:55.602 line:-2 align:center
There is a graph transform
that happens automatically


426
00:18:55.636 --> 00:18:57.504 line:-2 align:center
for ML Programs
during conversion.


427
00:18:57,538 --> 00:19:02,075 line:-2
It’s called
the FP16ComputePrecision pass.


428
00:19:02,109 --> 00:19:05,179 line:-2
This graph pass
casts every Float32 tensor


429
00:19:05.212 --> 00:19:06.813 line:-1 align:center
in the original Tensorflow graph


430
00:19:06.847 --> 00:19:09.616 line:-2 align:center
to a Float16 tensor
in the ML program.


431
00:19:09,650 --> 00:19:13,220 line:-2
OK, now since the conversion
is done, the next step is


432
00:19:13,253 --> 00:19:15,589 line:-2
to check the correctness
of the ML program.


433
00:19:15.622 --> 00:19:17.424 line:-2 align:center
I can compare
the output numerics


434
00:19:17,457 --> 00:19:19,860 line:-2
with the original Tensorflow
model by calling prediction


435
00:19:19.893 --> 00:19:23.564 line:-2 align:center
with the same image
with both the models.


436
00:19:23.597 --> 00:19:25.532 line:-2 align:center
It’s worth noting
for ML Programs,


437
00:19:25.566 --> 00:19:28.268 line:-2 align:center
I’m using exactly
the same Core ML Tools APIs


438
00:19:28,302 --> 00:19:30,003 line:-2
as in previous
years for prediction,


439
00:19:30.037 --> 00:19:32.172 line:-2 align:center
model saving,
and other utilities.


440
00:19:32,206 --> 00:19:34,241 line:-2
To do the comparison,
I have already written


441
00:19:34,274 --> 00:19:37,511 line:-2
a utility method called
_get_coreml_tensorflow_output.


442
00:19:37.544 --> 00:19:39.913 line:-2 align:center
It will print out multiple
error metrics to evaluate


443
00:19:39.947 --> 00:19:42.749 line:-2 align:center
the output from Tensorflow
and the output from Core ML.


444
00:19:45,419 --> 00:19:47,454 line:-1
So since this is an image,


445
00:19:47,487 --> 00:19:49,289 line:-2
the most appropriate
error metric may be


446
00:19:49,323 --> 00:19:51,291 line:-2
the signal to noise ratio,
or SNR.


447
00:19:51.325 --> 00:19:53.994 line:-2 align:center
In practice,
an SNR above 20 or 30 is


448
00:19:54,027 --> 00:19:55,896 line:-2
usually indicative
of good results.


449
00:19:55,929 --> 00:19:59,700 line:-2
Here I have an SNR of 71,
and that’s pretty great.


450
00:19:59.733 --> 00:20:03.003 line:-2 align:center
There’s a couple other metrics:
max absolute error,


451
00:20:03.036 --> 00:20:04.838 line:-1 align:center
average absolute error.


452
00:20:04,872 --> 00:20:07,007 line:-2
I’m curious, though,
what’s the accuracy cost


453
00:20:07,040 --> 00:20:08,408 line:-1
of using Float16?


454
00:20:08,442 --> 00:20:10,444 line:-1
What have I lost?


455
00:20:10.477 --> 00:20:11.845 line:-1 align:center
To find out,


456
00:20:11,879 --> 00:20:16,016 line:-2
I can disable the Float16
transform and convert again.


457
00:20:16.049 --> 00:20:18.619 line:-2 align:center
I’ll use the same convert
command, but this time


458
00:20:18,652 --> 00:20:22,589 line:-2
I’ll specify a compute_precision
argument and set it to Float32.


459
00:20:22.623 --> 00:20:24.625 line:-2 align:center
This will tell the converter
to not inject


460
00:20:24,658 --> 00:20:27,227 line:-2
those Float16 casts,
and so the Core ML Tools


461
00:20:27,261 --> 00:20:32,032 line:-2
converter will produce
a Float32 ML Program.


462
00:20:32.065 --> 00:20:35.836 line:-2 align:center
OK, now I’ll compare
this Float32 ML Program


463
00:20:35,869 --> 00:20:38,205 line:-1
to the original Tensorflow one.


464
00:20:41,742 --> 00:20:44,244 line:-2
And the SNR has increased
to over 100,


465
00:20:44,278 --> 00:20:46,180 line:-2
and the maximum absolute error
has decreased


466
00:20:46,213 --> 00:20:50,384 line:-1
from about 1 down to 0.02.


467
00:20:50.417 --> 00:20:52.853 line:-2 align:center
I still haven’t answered whether
the error I got earlier


468
00:20:52.886 --> 00:20:55.556 line:-2 align:center
with the Float16 model
had any discernible impact.


469
00:20:55.589 --> 00:20:58.625 line:-2 align:center
This is a style transfer model,
so the verdict could be made


470
00:20:58,659 --> 00:21:01,028 line:-2
based on a simple plot
of the output image.


471
00:21:03.363 --> 00:21:05.432 line:-2 align:center
I’ll plot the source image
and the stylized versions


472
00:21:05,465 --> 00:21:08,769 line:-2
from all three models that
I have: the Float16 ML Program,


473
00:21:08,802 --> 00:21:12,306 line:-2
the Float32 ML program,
and the Tensorflow model.


474
00:21:14,708 --> 00:21:16,210 line:-2
And I really don’t see
any difference


475
00:21:16,243 --> 00:21:17,878 line:-1
between the three model outputs.


476
00:21:17,911 --> 00:21:20,314 line:-2
Of course, this evaluation
of a single image,


477
00:21:20.347 --> 00:21:23.217 line:-2 align:center
once with a couple of metrics
and a visual inspection


478
00:21:23.250 --> 00:21:24.718 line:-1 align:center
is really just a smoke test.


479
00:21:24,751 --> 00:21:26,453 line:-1
Things look OK.


480
00:21:26.486 --> 00:21:29.156 line:-2 align:center
In practice, I’d evaluate
with more error metrics


481
00:21:29.189 --> 00:21:30.524 line:-1 align:center
across a large dataset,


482
00:21:30.557 --> 00:21:33.026 line:-2 align:center
evaluate failure cases
within the pipeline used


483
00:21:33,060 --> 00:21:35,596 line:-2
by the machine learning model,
and triage those.


484
00:21:35.629 --> 00:21:37.030 line:-1 align:center
I have a small dataset handy,


485
00:21:37.064 --> 00:21:39.099 line:-2 align:center
and to go one step further
with this example,


486
00:21:39,132 --> 00:21:40,767 line:-2
I can compare
the two ML Programs


487
00:21:40.801 --> 00:21:44.338 line:-2 align:center
with the Tensorflow model for
each image within the dataset.


488
00:21:44.371 --> 00:21:47.841 line:-2 align:center
The SNR of the Float32 ML
program versus Tensorflow


489
00:21:47.875 --> 00:21:49.977 line:-2 align:center
is depicted as a red line
with Xs,


490
00:21:50,010 --> 00:21:53,113 line:-2
and the Float16 ML Program
is a blue line with circles.


491
00:21:53.146 --> 00:21:56.950 line:-2 align:center
The Float32 ML Program seems
to average an SNR around 100,


492
00:21:56,984 --> 00:22:00,053 line:-2
and the Float16 ML Program stays
around 70.


493
00:22:00.087 --> 00:22:01.788 line:-1 align:center
The Float16 precision does


494
00:22:01.822 --> 00:22:03.056 line:-2 align:center
affect the numerics
a little bit,


495
00:22:03,090 --> 00:22:05,058 line:-2
but it doesn't seem significant
for this use case.


496
00:22:05.092 --> 00:22:08.128 line:-2 align:center
Although, even in this small
dataset of 131 images,


497
00:22:08,161 --> 00:22:09,863 line:-1
there are a few outliers.


498
00:22:09.897 --> 00:22:11.732 line:-2 align:center
Overall,
the model is doing pretty well


499
00:22:11,765 --> 00:22:13,200 line:-1
what it’s expected to do.


500
00:22:13,233 --> 00:22:15,035 line:-2
And this is the case
for a majority


501
00:22:15,068 --> 00:22:16,103 line:-1
of deep learning models.


502
00:22:16,136 --> 00:22:17,738 line:-2
They typically tend
to work just fine,


503
00:22:17,771 --> 00:22:19,806 line:-1
even with Float16 precision.


504
00:22:19.840 --> 00:22:22.342 line:-2 align:center
That’s why we have turned
the Float16 transform on


505
00:22:22,376 --> 00:22:24,811 line:-2
by default
in the Core ML converter.


506
00:22:24,845 --> 00:22:27,848 line:-2
A Float16 typed ML program
will be available to execute


507
00:22:27.881 --> 00:22:30.450 line:-2 align:center
on the neural engine,
which can present a substantial


508
00:22:30.484 --> 00:22:33.387 line:-2 align:center
performance boost and reduction
in power consumption.


509
00:22:33,420 --> 00:22:35,489 line:-2
Since the runtime treats
the types of the tensors


510
00:22:35,522 --> 00:22:39,493 line:-2
as a minimum precision during
execution, a Float32 ML Program


511
00:22:39,526 --> 00:22:43,697 line:-2
will execute on a combination
of only the GPU and the CPU.


512
00:22:43,730 --> 00:22:46,133 line:-2
This demo demonstrated
how easy it is now


513
00:22:46,166 --> 00:22:48,669 line:-2
to control the minimum precision
in which the ML Program


514
00:22:48,702 --> 00:22:51,572 line:-2
will execute right
at conversion time.


515
00:22:51,605 --> 00:22:54,374 line:-2
And unlike neural network
Core ML models, if your model


516
00:22:54.408 --> 00:22:57.511 line:-2 align:center
needs higher precision, you do
not have to change the setting


517
00:22:57.544 --> 00:23:01.048 line:-2 align:center
of the compute unit to cpuOnly
in the app code to achieve that.


518
00:23:01,081 --> 00:23:03,617 line:-2
And as a final note,
this demo notebook will be


519
00:23:03,650 --> 00:23:04,751 line:-1
available as an example


520
00:23:04.785 --> 00:23:07.821 line:-2 align:center
on the Core ML Tools
documentation site.


521
00:23:07,855 --> 00:23:10,190 line:-1
To recap, to get an ML program,


522
00:23:10.224 --> 00:23:12.893 line:-2 align:center
use the convert function
and pass an additional argument


523
00:23:12,926 --> 00:23:14,528 line:-2
to specify
the deployment target,


524
00:23:14,561 --> 00:23:18,398 line:-2
and set it
to at least iOS 15 or macOS 12.


525
00:23:18,432 --> 00:23:20,467 line:-2
By default,
the Core ML converter


526
00:23:20,501 --> 00:23:22,569 line:-2
will produce
an optimized Float16 model


527
00:23:22,603 --> 00:23:25,572 line:-2
that is eligible for execution
on the neural engine.


528
00:23:25.606 --> 00:23:28.075 line:-2 align:center
If, as it might happen
in some cases,


529
00:23:28,108 --> 00:23:30,711 line:-2
the model is sensitive
to Float16 precision,


530
00:23:30,744 --> 00:23:34,381 line:-2
it’s simple to set the precision
to Float32 instead.


531
00:23:34.414 --> 00:23:36.483 line:-2 align:center
There are, in fact,
more advanced options available


532
00:23:36.517 --> 00:23:39.319 line:-2 align:center
in the Core ML Tools API,
using which you can select


533
00:23:39,353 --> 00:23:41,889 line:-2
specific ops to execute
in Float32 while keeping


534
00:23:41.922 --> 00:23:45.592 line:-2 align:center
the rest in Float16 to produce
a mixed type ML Program.


535
00:23:45,626 --> 00:23:47,027 line:-2
Please check
out our documentation


536
00:23:47.060 --> 00:23:48.128 line:-1 align:center
for these examples.


537
00:23:48,161 --> 00:23:51,198 line:-2
In summary, Core ML has
several new enhancements


538
00:23:51,231 --> 00:23:53,967 line:-2
that make it easier to tune
and work with your models.


539
00:23:54,001 --> 00:23:56,803 line:-2
The new MLShapedArray type
makes it easy to work


540
00:23:56.837 --> 00:23:59.006 line:-1 align:center
with multidimensional data.


541
00:23:59.039 --> 00:24:00.974 line:-1 align:center
The ML Package format allows you


542
00:24:01.008 --> 00:24:03.510 line:-2 align:center
to edit metadata directly
in Xcode.


543
00:24:03.544 --> 00:24:06.213 line:-2 align:center
An ML Package with the new
ML Program model type


544
00:24:06.246 --> 00:24:09.716 line:-2 align:center
supports typed execution
with Float32 support on GPU,


545
00:24:09.750 --> 00:24:11.451 line:-2 align:center
giving you more options
to play with


546
00:24:11,485 --> 00:24:14,054 line:-2
as you tune your model’s
performance and accuracy.


547
00:24:14,087 --> 00:24:15,756 line:-2
We encourage you
to upgrade your model


548
00:24:15.789 --> 00:24:18.959 line:-2 align:center
to ML Packages
and use ML Programs.


549
00:24:18,992 --> 00:24:22,829 line:-2
Thanks for watching our session,
and enjoy the rest of WWDC.


550
00:24:22.863 --> 00:24:24.932 line:-1 align:center
[music]

