2
00:00:02.069 --> 00:00:09.009 line:-1 align:center
[music]


3
00:00:09.476 --> 00:00:12.012 line:-2 align:center
[Frank]
Hello, and welcome to WWDC.


4
00:00:12.045 --> 00:00:13.247 line:-1 align:center
My name is Frank Doepke,


5
00:00:13.280 --> 00:00:15.215 line:-2 align:center
and I'm an Engineer
on the Vision team.


6
00:00:16,483 --> 00:00:18,552 line:-2
The Vision framework
has grown over the years,


7
00:00:18.585 --> 00:00:20.921 line:-2 align:center
with its focus
on image analysis.


8
00:00:20.954 --> 00:00:22.256 line:-1 align:center
To get a better grasp,


9
00:00:22,289 --> 00:00:23,991 line:-2
we can look
at Vision's capabilities


10
00:00:24.024 --> 00:00:26.527 line:-1 align:center
in terms of its usage focus.


11
00:00:26.560 --> 00:00:27.861 line:-1 align:center
Sports.


12
00:00:27.895 --> 00:00:30.597 line:-2 align:center
Tracking objects and
the analysis of the human pose


13
00:00:30,631 --> 00:00:32,533 line:-1
are just some of the requests


14
00:00:32.566 --> 00:00:35.669 line:-2 align:center
that can help you
to create a sports application.


15
00:00:36,670 --> 00:00:38,172 line:-1
Accessibility.


16
00:00:38,205 --> 00:00:39,806 line:-1
Visions request like OCR


17
00:00:39.840 --> 00:00:42.476 line:-2 align:center
or image classification
and object detection


18
00:00:42.509 --> 00:00:45.412 line:-2 align:center
are helping
visually-impaired users.


19
00:00:46,413 --> 00:00:47,381 line:-1
People.


20
00:00:47,414 --> 00:00:49,082 line:-1
Vision provides a number of face


21
00:00:49.116 --> 00:00:50.918 line:-1 align:center
and body-related requests


22
00:00:50.951 --> 00:00:52.753 line:-1 align:center
that your app can use.


23
00:00:52.786 --> 00:00:54.521 line:-1 align:center
You can find out more about this


24
00:00:54.555 --> 00:00:59.993 line:-2 align:center
in the "Detect people, faces,
and poses using Vision" session.


25
00:01:00.994 --> 00:01:01.895 line:-1 align:center
Health.


26
00:01:01.929 --> 00:01:04.398 line:-1 align:center
From barcode scanning and OCR


27
00:01:04.431 --> 00:01:06.433 line:-1 align:center
to analysis of the human pose,


28
00:01:06.466 --> 00:01:07.901 line:-1 align:center
Vision provides building blocks


29
00:01:07,935 --> 00:01:09,903 line:-2
to create a smart
Health application.


30
00:01:11.905 --> 00:01:13.841 line:-1 align:center
Computational Photography.


31
00:01:13.874 --> 00:01:15.309 line:-1 align:center
Features like portrait mode


32
00:01:15,342 --> 00:01:17,911 line:-2
rely on face detection and
segmentation.


33
00:01:19,913 --> 00:01:21,081 line:-1
Security.


34
00:01:21.114 --> 00:01:23.383 line:-2 align:center
Requests like face
and human detection


35
00:01:23.417 --> 00:01:25.652 line:-2 align:center
are helpful for applications
like motion detection


36
00:01:25,686 --> 00:01:27,688 line:-1
in security cameras.


37
00:01:29.690 --> 00:01:31.191 line:-1 align:center
And documents.


38
00:01:31,225 --> 00:01:34,394 line:-2
This is what we want
to focus on in this session.


39
00:01:36,530 --> 00:01:38,599 line:-2
Vision offers
a number of requests


40
00:01:38,632 --> 00:01:41,468 line:-2
that help you
with the analysis of documents:


41
00:01:41,502 --> 00:01:43,103 line:-1
barcode detection,


42
00:01:43.136 --> 00:01:46.240 line:-2 align:center
text recognition,
or commonly known as OCR,


43
00:01:46,273 --> 00:01:48,108 line:-1
contour detection,


44
00:01:48,141 --> 00:01:49,676 line:-1
rectangle detection,


45
00:01:49,710 --> 00:01:51,378 line:-1
and new for this year,


46
00:01:51,411 --> 00:01:54,081 line:-1
document segmentation detection.


47
00:01:55.082 --> 00:01:56.650 line:-1 align:center
Here's our agenda.


48
00:01:56,683 --> 00:01:59,119 line:-2
First, we'll talk
about barcode detection.


49
00:01:59.152 --> 00:02:01.455 line:-2 align:center
Then, we'll talk
about text recognition.


50
00:02:01,488 --> 00:02:03,957 line:-2
And last, we'll talk
about document detection.


51
00:02:04,958 --> 00:02:06,860 line:-1
Let's look at barcode detection.


52
00:02:07.327 --> 00:02:09.530 line:-2 align:center
This year, we are introducing
a new revision


53
00:02:09.563 --> 00:02:11.532 line:-2 align:center
of the barcode
detection request.


54
00:02:12,533 --> 00:02:15,002 line:-1
VNDetectBarcodesRequestRevision2


55
00:02:15.035 --> 00:02:18.071 line:-2 align:center
offers support
for new symbologies.


56
00:02:18,105 --> 00:02:19,540 line:-1
Codabar,


57
00:02:19.573 --> 00:02:24.611 line:-2 align:center
GS1Databar, including
Expanded and Limited,


58
00:02:24.645 --> 00:02:28.515 line:-1 align:center
MicroPDF, and MicroQR,


59
00:02:28.549 --> 00:02:30.784 line:-2 align:center
where the latter is particularly
helpful


60
00:02:30.817 --> 00:02:33.453 line:-2 align:center
if you want to make
a QR code for a URL


61
00:02:33.487 --> 00:02:36.290 line:-2 align:center
and need to place it
on a small label or package,


62
00:02:36,323 --> 00:02:38,325 line:-1
as it uses a lot less space.


63
00:02:40,327 --> 00:02:43,330 line:-2
We changed the behavior
for this new revision


64
00:02:43.363 --> 00:02:44.998 line:-2 align:center
to be in line
with the rest of Vision


65
00:02:45.032 --> 00:02:47.668 line:-2 align:center
in respect to how
the resulting bounding boxes


66
00:02:47.701 --> 00:02:51.138 line:-2 align:center
are reported in relation
to the region of interest


67
00:02:51.171 --> 00:02:53.507 line:-1 align:center
that a client has specified.


68
00:02:55.776 --> 00:02:58.145 line:-2 align:center
Let's look at that change
in detail.


69
00:02:58.178 --> 00:03:01.648 line:-2 align:center
Here, we have a document
with a QR code.


70
00:03:01.682 --> 00:03:03.951 line:-2 align:center
When we do not specify
a Region of Interest,


71
00:03:03.984 --> 00:03:05.719 line:-1 align:center
also known as ROI,


72
00:03:05.752 --> 00:03:07.821 line:-1 align:center
the bounding box gets reported


73
00:03:07.855 --> 00:03:10.824 line:-1 align:center
in relation to the full image.


74
00:03:10,858 --> 00:03:12,860 line:-1
Now, let's specify an ROI,


75
00:03:12.893 --> 00:03:15.262 line:-2 align:center
like we want to only focus on
the center part


76
00:03:15,295 --> 00:03:17,297 line:-1
of what the camera sees.


77
00:03:17.331 --> 00:03:19.967 line:-2 align:center
Revision 2
now reports the bounding box


78
00:03:20.000 --> 00:03:24.037 line:-2 align:center
in relation to the ROI,
just like other Vision requests.


79
00:03:25,038 --> 00:03:26,773 line:-1
Unfortunately, Revision 1


80
00:03:26,807 --> 00:03:29,810 line:-2
always reports
in relation to the full image.


81
00:03:29.843 --> 00:03:31.778 line:-2 align:center
But we don't want
to change that behavior,


82
00:03:31.812 --> 00:03:34.815 line:-2 align:center
as it would potentially
break existing clients.


83
00:03:34.848 --> 00:03:36.550 line:-1 align:center
And just as a reminder,


84
00:03:36.583 --> 00:03:38.285 line:-2 align:center
when you compile
your application


85
00:03:38.318 --> 00:03:40.020 line:-1 align:center
against the latest SDK


86
00:03:40,053 --> 00:03:42,656 line:-2
and do not specify
a specific revision,


87
00:03:42.689 --> 00:03:45.859 line:-2 align:center
you will always get the latest
revision on your request.


88
00:03:45,893 --> 00:03:48,896 line:-2
But for applications
that specify Revision 1


89
00:03:48,929 --> 00:03:51,732 line:-2
or do not re-compile
against a new SDK,


90
00:03:51,765 --> 00:03:55,102 line:-2
they will still get
the old Revision 1 behavior.


91
00:03:57.738 --> 00:03:59.640 line:-2 align:center
Let me highlight
a few interesting aspects


92
00:03:59.673 --> 00:04:03.076 line:-2 align:center
of the barcode detection
request in Vision.


93
00:04:03,110 --> 00:04:06,346 line:-2
Vision supports
1D and 2D barcodes.


94
00:04:07,347 --> 00:04:08,949 line:-2
But what makes
it really interesting


95
00:04:08,982 --> 00:04:10,517 line:-1
is that within one image,


96
00:04:10.551 --> 00:04:12.352 line:-1 align:center
it can detect multiple codes,


97
00:04:12,386 --> 00:04:15,822 line:-2
as well as multiple
symbologies, at once.


98
00:04:16,823 --> 00:04:18,425 line:-2
That means
you don't have to scan


99
00:04:18.458 --> 00:04:20.994 line:-2 align:center
again and again
to get multiple codes.


100
00:04:21.028 --> 00:04:24.665 line:-2 align:center
This is a huge advantage over
most handheld scanners.


101
00:04:24,698 --> 00:04:28,302 line:-2
Keep in mind that if you scan
for multiple symbologies,


102
00:04:28,335 --> 00:04:32,639 line:-2
it'll take longer the more
symbologies you have specified.


103
00:04:32,673 --> 00:04:35,475 line:-2
So you want to setup the request
with only the symbologies


104
00:04:35,509 --> 00:04:38,412 line:-2
that are relevant
to your use case.


105
00:04:40,647 --> 00:04:42,816 line:-2
With the expansion
of the new symbologies


106
00:04:42,850 --> 00:04:44,318 line:-1
for barcode scanning,


107
00:04:44,351 --> 00:04:46,720 line:-2
Vision can play a particularly
helpful role


108
00:04:46,753 --> 00:04:47,955 line:-1
in the health sector.


109
00:04:47,988 --> 00:04:49,056 line:-1
With an iPhone,


110
00:04:49.089 --> 00:04:51.792 line:-2 align:center
you can analyze multiple codes
at once,


111
00:04:51.825 --> 00:04:54.595 line:-2 align:center
and thanks to its connectivity
to the internet,


112
00:04:54,628 --> 00:04:57,064 line:-2
pull up the information without
needing a separate scanner.


113
00:04:57,664 --> 00:05:00,701 line:-2
And thanks to the iPhone's
strong low-light capabilities,


114
00:05:00,734 --> 00:05:02,135 line:-1
you can scan codes,


115
00:05:02.169 --> 00:05:04.171 line:-1 align:center
even in dark scenarios,


116
00:05:04.204 --> 00:05:06.006 line:-1 align:center
without shooting off a laser


117
00:05:06,039 --> 00:05:09,576 line:-2
or disturbing the patient
while they are resting.


118
00:05:10.811 --> 00:05:14.548 line:-2 align:center
Now, let's look at how Vision
performs barcode detection.


119
00:05:15.549 --> 00:05:18.785 line:-2 align:center
1D codes
will get scanned as lines.


120
00:05:18.819 --> 00:05:20.220 line:-1 align:center
That means you will likely get


121
00:05:20.254 --> 00:05:23.824 line:-2 align:center
multiple detections
for the same code.


122
00:05:23,857 --> 00:05:25,893 line:-1
It is easy to de-duplicate them


123
00:05:25,926 --> 00:05:27,361 line:-1
by looking at the payload,


124
00:05:27,394 --> 00:05:31,198 line:-2
which is the real data
that is included in the barcode.


125
00:05:33.333 --> 00:05:35.836 line:-2 align:center
2D codes get scanned
as a single unit.


126
00:05:35.869 --> 00:05:38.005 line:-2 align:center
That means you get
one bounding box back


127
00:05:38.038 --> 00:05:39.573 line:-1 align:center
for the whole code.


128
00:05:39.606 --> 00:05:44.178 line:-2 align:center
An example for a 2D code
would be a QR code.


129
00:05:45.646 --> 00:05:49.116 line:-2 align:center
Each barcode gets reported
with its own observation.


130
00:05:49,149 --> 00:05:50,784 line:-1
But as I mentioned before,


131
00:05:50,817 --> 00:05:53,820 line:-2
1D codes can return
multiple observations,


132
00:05:53.854 --> 00:05:57.991 line:-2 align:center
with the same content, but in
different physical locations.


133
00:05:58.025 --> 00:06:00.561 line:-2 align:center
The payload
is the content of the barcode,


134
00:06:00.594 --> 00:06:03.030 line:-2 align:center
that is, the data
that is included


135
00:06:03,063 --> 00:06:05,666 line:-1
in this machine-readable code.


136
00:06:05,699 --> 00:06:08,335 line:-2
In particular
for the payload of QR codes,


137
00:06:08,368 --> 00:06:10,304 line:-2
you might want to use
data detectors


138
00:06:10.337 --> 00:06:13.106 line:-1 align:center
to analyze the encoded URL.


139
00:06:14.107 --> 00:06:16.677 line:-2 align:center
Now, let's look
at this in a little demo.


140
00:06:17,911 --> 00:06:19,913 line:-2
Alright, here we have
an Xcode playground,


141
00:06:19,947 --> 00:06:21,248 line:-2
where you see
that I have an image


142
00:06:21.281 --> 00:06:23.851 line:-1 align:center
with all the barcodes in them.


143
00:06:24.251 --> 00:06:26.787 line:-2 align:center
I use the
VNDetectBarcodesRequest,


144
00:06:26,820 --> 00:06:29,556 line:-1
and I set the Revision to 2.


145
00:06:29,590 --> 00:06:31,291 line:-1
Now, as the symbologies,


146
00:06:31.325 --> 00:06:33.126 line:-1 align:center
I just have codabar,


147
00:06:33.160 --> 00:06:34.661 line:-1 align:center
and when we look at this,


148
00:06:34.695 --> 00:06:37.898 line:-2 align:center
we see the codabar
got highlighted in red.


149
00:06:38.899 --> 00:06:42.870 line:-2 align:center
Now, I can change this
to, let's say, QR.


150
00:06:46,073 --> 00:06:46,907 line:-1
What happens now


151
00:06:46,940 --> 00:06:49,543 line:-2
is that we run
the request again,


152
00:06:49.576 --> 00:06:52.579 line:-2 align:center
and we see that
the QR code gets highlighted.


153
00:06:52.613 --> 00:06:54.815 line:-2 align:center
But it's an array,
so I can also specify


154
00:06:54.848 --> 00:06:58.685 line:-2 align:center
other requests with it,
let's say ean8.


155
00:06:58,719 --> 00:07:00,220 line:-1
And when I do that,


156
00:07:00,254 --> 00:07:02,389 line:-1
we'll now see that we have both,


157
00:07:02,422 --> 00:07:05,993 line:-1
the ean8 and the QR code.


158
00:07:06,026 --> 00:07:08,495 line:-2
But what
if I want to get all of them?


159
00:07:08,529 --> 00:07:10,931 line:-1
I simply pass in an empty array,


160
00:07:10,964 --> 00:07:13,734 line:-2
and in that moment,
all symbologies get read.


161
00:07:13.767 --> 00:07:14.601 line:-1 align:center
And as you see,


162
00:07:14.635 --> 00:07:18.338 line:-2 align:center
all highlighted right now
with the code on the bottom.


163
00:07:18.372 --> 00:07:20.340 line:-1 align:center
Let's go back to our slides.


164
00:07:21,141 --> 00:07:22,943 line:-2
From barcodes,
we are now moving on


165
00:07:22,976 --> 00:07:25,345 line:-1
to look at text recognition.


166
00:07:25,846 --> 00:07:29,016 line:-2
Vision introduced
text recognition in 2019.


167
00:07:29,049 --> 00:07:33,620 line:-2
It operates in two modes:
Fast and Accurate.


168
00:07:33.654 --> 00:07:37.624 line:-2 align:center
Since then, Vision has expanded
its language support.


169
00:07:37,658 --> 00:07:39,993 line:-2
Let's look at how
text recognition works


170
00:07:40,027 --> 00:07:42,896 line:-1
and where language plays a role.


171
00:07:42.930 --> 00:07:44.031 line:-1 align:center
In the Fast path,


172
00:07:44.064 --> 00:07:46.633 line:-2 align:center
we have
a Latin-character recognizer.


173
00:07:46.667 --> 00:07:48.468 line:-2 align:center
The Accurate path, on the other
hand,


174
00:07:48.502 --> 00:07:50.971 line:-2 align:center
uses a machine-learning-based
recognizer


175
00:07:51.004 --> 00:07:53.273 line:-2 align:center
that operates
on words and lines.


176
00:07:54.274 --> 00:07:56.009 line:-1 align:center
After the recognition is done,


177
00:07:56,043 --> 00:07:59,112 line:-2
each path goes through
a language correction stage.


178
00:07:59.146 --> 00:08:02.482 line:-2 align:center
And, in the end,
we get back the recognized text.


179
00:08:02.516 --> 00:08:05.819 line:-2 align:center
The language selection
affects the recognition stage.


180
00:08:05.853 --> 00:08:07.387 line:-1 align:center
In the Fast path,


181
00:08:07.421 --> 00:08:08.889 line:-1 align:center
it would mean that the different


182
00:08:08,922 --> 00:08:11,491 line:-2
Latin character sets
are supported,


183
00:08:11,525 --> 00:08:13,794 line:-1
like the umlaut for German.


184
00:08:13,827 --> 00:08:14,828 line:-1
In the Accurate path,


185
00:08:14.862 --> 00:08:16.797 line:-2 align:center
a completely different model
gets used


186
00:08:16.830 --> 00:08:18.832 line:-2 align:center
when we have
to recognize Chinese,


187
00:08:18,866 --> 00:08:20,701 line:-2
as its structure
is very different


188
00:08:20,734 --> 00:08:23,136 line:-1
to Latin-based languages.


189
00:08:23.170 --> 00:08:25.906 line:-2 align:center
That means if you need
to read Chinese text,


190
00:08:25.939 --> 00:08:27.007 line:-1 align:center
then it is important


191
00:08:27.040 --> 00:08:29.343 line:-2 align:center
that Chinese
is the primary language


192
00:08:29,376 --> 00:08:31,512 line:-1
in the request.


193
00:08:31.545 --> 00:08:35.048 line:-2 align:center
The language selection also
influences language correction,


194
00:08:35,082 --> 00:08:38,385 line:-2
as it picks the correct
dictionary for its work.


195
00:08:40,387 --> 00:08:41,822 line:-1
So, what are the best practices


196
00:08:41,855 --> 00:08:44,591 line:-2
when using languages
in text recognition?


197
00:08:44,625 --> 00:08:46,960 line:-2
Even though it might look
like a fixed set of languages


198
00:08:46,994 --> 00:08:49,563 line:-2
is supported,
it is always better to query


199
00:08:49.596 --> 00:08:51.265 line:-1 align:center
which languages are supported


200
00:08:51,298 --> 00:08:53,700 line:-2
for a given request
configuration using


201
00:08:53.734 --> 00:08:56.737 line:-1 align:center
supportedRecognitionLanguages().


202
00:08:56,770 --> 00:08:58,772 line:-2
You can specify
multiple languages,


203
00:08:58.805 --> 00:09:01.642 line:-2 align:center
and, in that case,
the order matters.


204
00:09:01.675 --> 00:09:03.076 line:-1 align:center
When there is ambiguity,


205
00:09:03.110 --> 00:09:06.446 line:-2 align:center
it gets resolved
in the order of languages.


206
00:09:06,480 --> 00:09:08,482 line:-2
In particular
for the Accurate path,


207
00:09:08,515 --> 00:09:13,387 line:-2
the first language decides which
recognition model gets used.


208
00:09:13.420 --> 00:09:15.689 line:-2 align:center
That means
your use case dictates


209
00:09:15,722 --> 00:09:19,126 line:-2
which languages
you want to use in the request.


210
00:09:22.129 --> 00:09:24.698 line:-2 align:center
Let's look at this
in a little demo.


211
00:09:25.465 --> 00:09:27.568 line:-2 align:center
So, I have here now
a revised version


212
00:09:27.601 --> 00:09:29.336 line:-1 align:center
of our sample code,


213
00:09:29.369 --> 00:09:31.405 line:-2 align:center
and you can see
that I have an image


214
00:09:31,438 --> 00:09:34,708 line:-2
with different languages
of text in it.


215
00:09:35,209 --> 00:09:37,778 line:-1
Now, I specified Revision 2,


216
00:09:37,811 --> 00:09:39,913 line:-2
and I can see
which languages are supported.


217
00:09:39,947 --> 00:09:43,417 line:-2
We have English,
French, and so on.


218
00:09:45,419 --> 00:09:48,755 line:-2
Now, if I switch, for instance,
back to Revision 1,


219
00:09:49.389 --> 00:09:52.659 line:-1 align:center
we can see I only have English.


220
00:09:52,693 --> 00:09:55,128 line:-2
And that is the same
for the Fast


221
00:09:55,162 --> 00:09:57,764 line:-1
as it is for the Accurate path.


222
00:09:57.798 --> 00:09:59.499 line:-2 align:center
Now, let's go back
to Revision 2.


223
00:10:00.767 --> 00:10:02.669 line:-1 align:center
Notice that when I switch now,


224
00:10:02,703 --> 00:10:04,838 line:-1
for instance, to German,


225
00:10:04,872 --> 00:10:06,340 line:-2
I actually
get the umlaut correctly


226
00:10:06,373 --> 00:10:08,842 line:-1
in Grüsse aus Cupertino.


227
00:10:10.210 --> 00:10:11.578 line:-1 align:center
But I don't have support


228
00:10:11,612 --> 00:10:14,281 line:-1
in the Fast path for Chinese.


229
00:10:15,916 --> 00:10:17,618 line:-1
In the Accurate path,


230
00:10:18,752 --> 00:10:21,288 line:-1
I can now pick Chinese.


231
00:10:22.022 --> 00:10:23.557 line:-1 align:center
And now, we finally get


232
00:10:23.590 --> 00:10:26.727 line:-2 align:center
the correct Chinese letters
for "Hello World."


233
00:10:27.728 --> 00:10:29.963 line:-1 align:center
Let's go back to the slides.


234
00:10:30.931 --> 00:10:31.932 line:-1 align:center
Last but not least,


235
00:10:31.965 --> 00:10:33.834 line:-2 align:center
let's look
at Document Detection.


236
00:10:34,434 --> 00:10:36,303 line:-2
Vision introduces
a new request called


237
00:10:36.336 --> 00:10:39.006 line:-1 align:center
VNDocumentSegmentationRequest.


238
00:10:39.039 --> 00:10:40.874 line:-2 align:center
It's a machine-learning-based
detector


239
00:10:40.908 --> 00:10:43.210 line:-2 align:center
that we have trained
on various types of documents,


240
00:10:43,243 --> 00:10:45,279 line:-1
like sheets of paper, signs,


241
00:10:45.312 --> 00:10:48.749 line:-2 align:center
notes, receipts, labels,
et cetera.


242
00:10:49,750 --> 00:10:51,251 line:-1
The result of the request


243
00:10:51.285 --> 00:10:53.820 line:-2 align:center
is a low resolution segmentation
mask,


244
00:10:53.854 --> 00:10:56.290 line:-2 align:center
where each pixel
represents a confidence


245
00:10:56,323 --> 00:11:00,928 line:-2
if that pixel is part
of the detected document or not.


246
00:11:00,961 --> 00:11:03,931 line:-2
In addition it provides
the four corner points


247
00:11:03,964 --> 00:11:05,999 line:-1
of the quadrilateral.


248
00:11:07,601 --> 00:11:09,770 line:-1
On devices with a Neural Engine,


249
00:11:09,803 --> 00:11:14,007 line:-2
the request can run in realtime
on a camera or video feed.


250
00:11:14.041 --> 00:11:16.677 line:-2 align:center
The VNDocumentCamera
in VisionKit


251
00:11:16,710 --> 00:11:20,480 line:-2
is now using the request instead
of the VNDetectRectanglesRequest


252
00:11:20.514 --> 00:11:23.884 line:-2 align:center
on modern devices
with a Neural Engine.


253
00:11:25,752 --> 00:11:28,222 line:-2
Speaking of the
VNDetectRectanglesRequest,


254
00:11:28.255 --> 00:11:29.823 line:-2 align:center
how do these
two requests differ,


255
00:11:29,857 --> 00:11:33,594 line:-2
as they both can be used
to detect a document?


256
00:11:33,627 --> 00:11:36,263 line:-2
The DetectDocumentsRequest
is, as I mentioned,


257
00:11:36.296 --> 00:11:37.497 line:-1 align:center
machine-learning-based


258
00:11:37,531 --> 00:11:40,033 line:-2
and performs fastest
on the Neural Engine.


259
00:11:40.067 --> 00:11:43.971 line:-2 align:center
But it can also be used
on the GPU or CPU,


260
00:11:44,004 --> 00:11:47,140 line:-2
but it is not fast enough there
for realtime performance.


261
00:11:48,141 --> 00:11:49,476 line:-1
The rectangle detector


262
00:11:49.510 --> 00:11:51.578 line:-2 align:center
is a traditional computer vision
algorithm


263
00:11:51,612 --> 00:11:53,881 line:-1
that runs only on the CPU


264
00:11:53,914 --> 00:11:55,883 line:-2
and can keep up
with the realtime performance,


265
00:11:55,916 --> 00:11:59,987 line:-2
as long as the CPU is not
saturated with other tasks.


266
00:12:01,588 --> 00:12:04,992 line:-2
The document request is trained
on a variety of documents,


267
00:12:05.025 --> 00:12:06.860 line:-2 align:center
and they don't have
to be all rectangles,


268
00:12:06,894 --> 00:12:09,863 line:-2
which is one
of its main strengths.


269
00:12:09.897 --> 00:12:11.832 line:-2 align:center
The rectangle detector,
on the other hand,


270
00:12:11,865 --> 00:12:14,501 line:-2
works by finding edges
and intersections


271
00:12:14.535 --> 00:12:16.203 line:-1 align:center
that form a quadrilateral,


272
00:12:16.236 --> 00:12:18.872 line:-2 align:center
which can be a challenge
with obscured corners


273
00:12:18.906 --> 00:12:21.241 line:-1 align:center
or folds in the document.


274
00:12:22,042 --> 00:12:25,312 line:-2
The documents requests
provides a segmentation mask


275
00:12:25.345 --> 00:12:26.680 line:-1 align:center
and the corner points,


276
00:12:26.713 --> 00:12:31.151 line:-2 align:center
while the rectangle detector
only provides corner points.


277
00:12:31,185 --> 00:12:32,519 line:-1
And the document detector


278
00:12:32.553 --> 00:12:35.455 line:-2 align:center
is trained to look
for one document only.


279
00:12:35.489 --> 00:12:39.026 line:-2 align:center
With the rectangle detector
will return multiple rectangles.


280
00:12:39,059 --> 00:12:42,029 line:-2
These rectangles
can even be nested.


281
00:12:42.062 --> 00:12:44.431 line:-2 align:center
Let's look at this
a little bit more.


282
00:12:46.133 --> 00:12:47.534 line:-1 align:center
As I mentioned,


283
00:12:47,568 --> 00:12:50,204 line:-2
the document detector
finds one document,


284
00:12:50.237 --> 00:12:51.438 line:-1 align:center
which we see here


285
00:12:51.471 --> 00:12:55.008 line:-2 align:center
with the quadrilateral
of the detected object.


286
00:12:55,042 --> 00:12:56,510 line:-1
But the rectangle detector


287
00:12:56.543 --> 00:12:59.112 line:-2 align:center
will deliver back
multiple observations


288
00:12:59.146 --> 00:13:02.182 line:-2 align:center
of all the rectangles
it finds in the image,


289
00:13:02,216 --> 00:13:04,084 line:-1
and I highlighted a few here.


290
00:13:04.117 --> 00:13:05.786 line:-1 align:center
It's up to the app to decide


291
00:13:05,819 --> 00:13:08,755 line:-1
which rectangle is the document.


292
00:13:08,789 --> 00:13:11,225 line:-2
How about we try
all this in a demo?


293
00:13:12,559 --> 00:13:14,962 line:-2
All right, we wanted
to create a little survey,


294
00:13:14,995 --> 00:13:16,997 line:-1
how well we are doing at WWDC.


295
00:13:17,030 --> 00:13:18,532 line:-2
Now, unfortunately,
you are not with me,


296
00:13:18,565 --> 00:13:20,300 line:-2
so I had to ask
the camera team here


297
00:13:20,334 --> 00:13:22,736 line:-1
to fill out the survey for you.


298
00:13:22.769 --> 00:13:24.004 line:-1 align:center
So, I created a little app


299
00:13:24,037 --> 00:13:27,040 line:-2
in which I can now
scan our survey cards.


300
00:13:27.774 --> 00:13:28.842 line:-1 align:center
And what do we get?


301
00:13:28.876 --> 00:13:31.211 line:-2 align:center
QuickDraw for beginners
felt outdated.


302
00:13:31,245 --> 00:13:32,880 line:-1
Well, it is bit old by now.


303
00:13:36,650 --> 00:13:38,819 line:-1
Let's go for the next one.


304
00:13:38,852 --> 00:13:43,390 line:-2
Ah, Vision was entertaining
and informative.


305
00:13:45.192 --> 00:13:47.261 line:-1 align:center
And last but not least,


306
00:13:47,294 --> 00:13:49,229 line:-1
Cobol, just what I needed.


307
00:13:49,263 --> 00:13:52,533 line:-2
Somebody is in
the wrong session here.


308
00:13:52.566 --> 00:13:56.637 line:-2 align:center
Okay, now let's look
how we did this in the code.


309
00:13:56,670 --> 00:13:58,772 line:-2
So, I created again
a little playground here


310
00:13:58,805 --> 00:14:01,141 line:-2
because it's easier
to build this stuff up for us.


311
00:14:01,675 --> 00:14:04,912 line:-2
What you can already see
is that I loaded up an image,


312
00:14:04,945 --> 00:14:06,680 line:-1
and I used the CIImage,


313
00:14:06.713 --> 00:14:09.983 line:-2 align:center
because I need to do some
image manipulation on it.


314
00:14:10,017 --> 00:14:12,653 line:-2
I created a requestHandler,
and I used the new


315
00:14:12,686 --> 00:14:15,923 line:-2
VNDetectDocument
SegmentationRequest().


316
00:14:15.956 --> 00:14:18.325 line:-1 align:center
Once I perform the request,


317
00:14:18,358 --> 00:14:19,893 line:-1
I get now the results back,


318
00:14:19.927 --> 00:14:21.795 line:-2 align:center
and I created
a little helper function


319
00:14:21.828 --> 00:14:24.431 line:-2 align:center
that I used core image
to use now


320
00:14:24.464 --> 00:14:27.367 line:-2 align:center
as a perspective
corrected image,


321
00:14:27,401 --> 00:14:30,838 line:-2
and we get back
just a cropped-out card


322
00:14:30.871 --> 00:14:33.540 line:-1 align:center
in a perspective corrected form.


323
00:14:33.574 --> 00:14:35.175 line:-1 align:center
So, that's easy.


324
00:14:35.209 --> 00:14:37.244 line:-1 align:center
So, what do we have to do next?


325
00:14:37,878 --> 00:14:39,746 line:-1
We need to detect the bar codes,


326
00:14:39,780 --> 00:14:41,815 line:-1
detect the rectangles,


327
00:14:41.849 --> 00:14:43.417 line:-1 align:center
and recognize the text.


328
00:14:44,184 --> 00:14:45,953 line:-1
Once we perform this request,


329
00:14:45.986 --> 00:14:47.621 line:-2 align:center
we then have to scan
the check boxes


330
00:14:47,654 --> 00:14:50,224 line:-1
to see which ones were ticked.


331
00:14:50.257 --> 00:14:52.025 line:-2 align:center
All right,
I prepared this a little bit,


332
00:14:52,059 --> 00:14:54,895 line:-2
so let's start
with detecting the bar codes.


333
00:14:58.131 --> 00:14:59.800 line:-2 align:center
And I'm using,
as the symbologies,


334
00:14:59.833 --> 00:15:02.102 line:-1 align:center
just the QR code.


335
00:15:02.135 --> 00:15:03.604 line:-1 align:center
I loaded into the document title


336
00:15:03.637 --> 00:15:04.938 line:-1 align:center
because I know that is--


337
00:15:04,972 --> 00:15:07,140 line:-1
the content of my QR code


338
00:15:07.174 --> 00:15:09.676 line:-2 align:center
will be the title
of what we get out of it.


339
00:15:09,710 --> 00:15:12,613 line:-2
Next, we need
to detect the rectangles.


340
00:15:12,646 --> 00:15:15,682 line:-2
Again, we have a little piece
of code rectangle for that.


341
00:15:18.085 --> 00:15:20.220 line:-1 align:center
So, I create two arrays.


342
00:15:20,254 --> 00:15:22,422 line:-2
I want to get
all the checkBoxImages,


343
00:15:22.456 --> 00:15:25.259 line:-2 align:center
which is data needed
for the analysis.


344
00:15:25,292 --> 00:15:27,394 line:-2
And I get
all the rectangles out.


345
00:15:27.427 --> 00:15:30.531 line:-2 align:center
So, I used
the VNDetectRectanglesRequest.


346
00:15:30,564 --> 00:15:32,733 line:-1
Now, what I do here is


347
00:15:32,766 --> 00:15:34,535 line:-2
I sort them
in the vertical order


348
00:15:34,568 --> 00:15:38,172 line:-2
so that I get the results
in the correct order back.


349
00:15:39.506 --> 00:15:43.010 line:-2 align:center
OK, now we need
to recognize our text.


350
00:15:44,545 --> 00:15:45,379 line:-1
That is simple.


351
00:15:45.412 --> 00:15:48.215 line:-2 align:center
We store
all the resulting textBlocks,


352
00:15:48,248 --> 00:15:51,485 line:-2
and we use
the VNRecognizeTextRequest.


353
00:15:51.518 --> 00:15:54.521 line:-2 align:center
So now, what we have to do
is simply perform the request.


354
00:15:56,623 --> 00:15:59,626 line:-2
And as you can see, I used
the documentRequestHandler,


355
00:15:59.660 --> 00:16:02.229 line:-2 align:center
which is the one that used
the cropped-out image,


356
00:16:02.262 --> 00:16:04.665 line:-2 align:center
and performed
the requests on it.


357
00:16:05,165 --> 00:16:07,267 line:-1
And if I go back up here,


358
00:16:07,301 --> 00:16:11,405 line:-2
I can already see
that I get my correct QR code,


359
00:16:12.372 --> 00:16:14.541 line:-2 align:center
but something is not quite right
with my rectangles.


360
00:16:14,575 --> 00:16:16,543 line:-1
I don't get any rectangles.


361
00:16:16,577 --> 00:16:18,111 line:-1
So, what do I have to do?


362
00:16:18.145 --> 00:16:20.013 line:-1 align:center
Well, by default,


363
00:16:20,047 --> 00:16:22,583 line:-2
the rectangles detector
only looks for rectangles


364
00:16:22.616 --> 00:16:24.985 line:-2 align:center
that are at least 20%
of the image.


365
00:16:25.018 --> 00:16:26.920 line:-1 align:center
So, we need to correct that.


366
00:16:26.954 --> 00:16:28.689 line:-1 align:center
So, I go in


367
00:16:29,690 --> 00:16:31,658 line:-1
and set the minimumSize


368
00:16:33,660 --> 00:16:36,763 line:-2
to, let's say,
something like 10%.


369
00:16:41.635 --> 00:16:44.905 line:-2 align:center
And once we do that,
we get a rectangle.


370
00:16:45,772 --> 00:16:47,975 line:-1
Okay, well, that's only one.


371
00:16:48,008 --> 00:16:51,078 line:-2
Well, the other thing
with the rectangle detector is


372
00:16:51.111 --> 00:16:53.814 line:-2 align:center
that I need to tell it
how many it should return.


373
00:16:53,847 --> 00:16:54,982 line:-1
By default,


374
00:16:55.015 --> 00:16:57.551 line:-2 align:center
the rectangle detection
will only return one,


375
00:16:57.584 --> 00:16:59.286 line:-1 align:center
the most prominent rectangle.


376
00:16:59,319 --> 00:17:00,888 line:-1
But I want to get all of them.


377
00:17:00.921 --> 00:17:05.325 line:-2 align:center
I do this by setting
the maximumObservations to 0.


378
00:17:05,359 --> 00:17:08,595 line:-1
And once I have done that,


379
00:17:08.629 --> 00:17:11.298 line:-1 align:center
I now get


380
00:17:11.331 --> 00:17:13.734 line:-2 align:center
all of our checkboxes and the
bar code,


381
00:17:13,767 --> 00:17:16,737 line:-2
because that looks
like a rectangle.


382
00:17:16,770 --> 00:17:18,872 line:-1
Okay, so we are good.


383
00:17:18,906 --> 00:17:20,340 line:-1
Now comes the last part,


384
00:17:20,374 --> 00:17:23,143 line:-2
and I need to actually
scan the checkboxes.


385
00:17:23,177 --> 00:17:25,212 line:-2
So, for that,
I actually prepared


386
00:17:25.245 --> 00:17:26.813 line:-1 align:center
a little machine-learning demo.


387
00:17:28.015 --> 00:17:28.949 line:-1 align:center
I have a model here


388
00:17:28,982 --> 00:17:31,418 line:-2
that I trained earlier
with Create ML.


389
00:17:31,451 --> 00:17:33,287 line:-1
It's an image classifier,


390
00:17:33.320 --> 00:17:34.154 line:-1 align:center
and all I did was


391
00:17:34,188 --> 00:17:35,989 line:-2
I used some of these
checkbox images,


392
00:17:36,023 --> 00:17:36,890 line:-1
which were marked,


393
00:17:36.924 --> 00:17:38.392 line:-1 align:center
and some of them are not marked,


394
00:17:38,425 --> 00:17:40,260 line:-1
for my "yes" and "no" label.


395
00:17:40.294 --> 00:17:43.163 line:-2 align:center
And I also gathered a few images
that are neither of them.


396
00:17:43.197 --> 00:17:45.132 line:-1 align:center
That's my NotIt.


397
00:17:47.034 --> 00:17:49.002 line:-2 align:center
Again, we can use this
in our code.


398
00:17:56,577 --> 00:17:58,879 line:-1
So, what do we have?


399
00:17:58.912 --> 00:18:00.814 line:-2 align:center
We create our request
by loading the model


400
00:18:00,848 --> 00:18:03,250 line:-2
and create
our Create ML request.


401
00:18:03,283 --> 00:18:06,620 line:-2
And then we iterate,
over all the checkbox images,


402
00:18:06,653 --> 00:18:09,223 line:-2
create an ImageRequestHandler
from it,


403
00:18:09,256 --> 00:18:11,859 line:-1
and perform our classification.


404
00:18:12.759 --> 00:18:14.728 line:-2 align:center
Now, I can look
at my top classification.


405
00:18:14.761 --> 00:18:16.196 line:-1 align:center
If that is "Yes,"


406
00:18:16.230 --> 00:18:18.198 line:-1 align:center
then I just find which text line


407
00:18:18,232 --> 00:18:20,801 line:-2
lines up with the checkbox
that I have,


408
00:18:20.834 --> 00:18:22.536 line:-1 align:center
and what do we get, in the end?


409
00:18:22.569 --> 00:18:26.406 line:-2 align:center
Vision was entertaining
and informative.


410
00:18:26,440 --> 00:18:28,509 line:-1
Let's go back to the slides.


411
00:18:29,977 --> 00:18:31,879 line:-1
Let's recap on what we saw.


412
00:18:31.912 --> 00:18:35.349 line:-2 align:center
Document analysis
is a focus in the Vision API.


413
00:18:35,382 --> 00:18:36,884 line:-1
Barcode detection in Vision


414
00:18:36.917 --> 00:18:39.086 line:-2 align:center
is more versatile
than a scanner,


415
00:18:39.119 --> 00:18:42.956 line:-2 align:center
and we are introducing a new
document segmentation detection.


416
00:18:42.990 --> 00:18:45.626 line:-2 align:center
If you want to learn more
about how to use OCR,


417
00:18:45.659 --> 00:18:49.830 line:-2 align:center
please look at our session
from WWDC 2019.


418
00:18:49,863 --> 00:18:54,668 line:-2
The "Vision and core image"
session from WWDC 2020


419
00:18:54.701 --> 00:18:56.136 line:-1 align:center
gives you additional insights


420
00:18:56,170 --> 00:18:58,639 line:-2
in doing your own custom
document analysis


421
00:18:58,672 --> 00:19:00,340 line:-1
by preprocessing images


422
00:19:00,374 --> 00:19:02,576 line:-1
and detecting contours.


423
00:19:02,609 --> 00:19:05,145 line:-2
Thank you,
and enjoy the rest of WWDC.


424
00:19:05,179 --> 00:19:08,315 line:-1
[music]

