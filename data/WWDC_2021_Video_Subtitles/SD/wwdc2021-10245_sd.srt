2
00:00:00.000 --> 00:00:02.002 line:-1 position:50%
[MAC STARTUP CHIME]


3
00:00:02,002 --> 00:00:05,572 line:-1
♪ Bass music playing ♪


4
00:00:05.572 --> 00:00:07.307 line:-1 position:50%
[KEYSTROKES]


5
00:00:07,307 --> 00:00:09,309 line:0 position:90% size:2%
♪


6
00:00:09,309 --> 00:00:10,277 line:-1
Peter Tsoi: Hello and welcome


7
00:00:10,277 --> 00:00:12,679 line:-1
to "Design for
spatial interaction."


8
00:00:12.679 --> 00:00:13.580 line:-1 position:50%
My name is Peter,


9
00:00:13.580 --> 00:00:16.283 line:-1 position:50%
and I'm a designer
on the Apple Design team.


10
00:00:16,283 --> 00:00:21,388 line:-1
Together with my colleagues
Arian, Taylor, Linus, and Pedro,


11
00:00:21,388 --> 00:00:23,924 line:-1
we're excited to share
some of the considerations


12
00:00:23.924 --> 00:00:28.161 line:-1 position:50%
that guide how we approach
designing spatial interactions.


13
00:00:28,161 --> 00:00:30,764 line:-1
We'll share lessons learned
while creating interactions


14
00:00:30.764 --> 00:00:33.934 line:-1 position:50%
for AirTag, HomePod mini,
and iPhone,


15
00:00:33,934 --> 00:00:36,837 line:-1
and also give you tips
and tricks that will help you


16
00:00:36.837 --> 00:00:38.205 line:-1 position:50%
apply those principles


17
00:00:38.205 --> 00:00:40.908 line:-1 position:50%
while designing interactions
of your own.


18
00:00:40,908 --> 00:00:42,910 line:-1
Let's get started.


19
00:00:42.910 --> 00:00:44.645 line:-1 position:50%
As our devices have evolved,


20
00:00:44.645 --> 00:00:47.948 line:-1 position:50%
so too has the way
that we interact with them.


21
00:00:47.948 --> 00:00:50.951 line:-1 position:50%
Early computers were operated
only using a keyboard


22
00:00:50,951 --> 00:00:54,321 line:-1
and interfaces
were entirely text based.


23
00:00:54,321 --> 00:00:56,390 line:-1
Users memorized
abstract commands


24
00:00:56,390 --> 00:00:58,959 line:-1
and relied on arrow keys
to move around the screen


25
00:00:58,959 --> 00:01:01,194 line:-1
and express their intent.


26
00:01:01.194 --> 00:01:04.531 line:-1 position:50%
Nowadays, most people
use their keyboards together


27
00:01:04.531 --> 00:01:08.135 line:-1 position:50%
with graphical user interfaces
and a mouse.


28
00:01:08,135 --> 00:01:11,138 line:-1
These innovations
removed a layer of abstraction


29
00:01:11.138 --> 00:01:13.006 line:-1 position:50%
and allowed people
to use the mouse


30
00:01:13.006 --> 00:01:15.609 line:-1 position:50%
to point, click, and drag


31
00:01:15,609 --> 00:01:19,246 line:-1
to more directly
express their intent.


32
00:01:19,246 --> 00:01:21,915 line:-1
Later, Multi-Touch
brought the digital world


33
00:01:21.915 --> 00:01:23.450 line:-1 position:50%
to people's fingertips,


34
00:01:23.450 --> 00:01:25.686 line:-1 position:50%
removing yet another
layer of abstraction


35
00:01:25,686 --> 00:01:28,188 line:-1
and allowing people
to touch their music,


36
00:01:28.188 --> 00:01:31.892 line:-1 position:50%
their photos,
and the mobile web.


37
00:01:31,892 --> 00:01:34,361 line:-1
Today we want to talk about
a class of interactions


38
00:01:34,361 --> 00:01:37,130 line:-1
that go beyond the bounds
of a single device


39
00:01:37,130 --> 00:01:40,567 line:-1
and ways to use the capabilities
of the latest Apple devices


40
00:01:40,567 --> 00:01:43,170 line:-1
to help users interact
more directly


41
00:01:43,170 --> 00:01:45,205 line:-1
with their physical
surroundings.


42
00:01:45,205 --> 00:01:48,308 line:-1
Some of these interactions
may already feel familiar,


43
00:01:48,308 --> 00:01:50,010 line:-1
like how you can
pay for a coffee


44
00:01:50.010 --> 00:01:53.847 line:-1 position:50%
by holding your phone or watch
close to a payment terminal.


45
00:01:53,847 --> 00:01:57,117 position:50%
Or how you can quickly check the
battery level on your AirPods


46
00:01:57,117 --> 00:02:00,821 line:0
just by flipping open the case
when it's near your phone.


47
00:02:00,821 --> 00:02:02,990 line:-1
These human-scale
interactions --


48
00:02:02,990 --> 00:02:05,926 line:-1
the ones that happen
between devices nearby --


49
00:02:05,926 --> 00:02:08,929 line:-1
have the ability to remove
layers of abstraction


50
00:02:08,929 --> 00:02:11,398 line:-1
and allow users
to interact more directly


51
00:02:11.398 --> 00:02:13.100 line:-1 position:50%
with their surroundings.


52
00:02:13.100 --> 00:02:14.735 line:-1 position:50%
And with the enhanced
spatial awareness


53
00:02:14.735 --> 00:02:18.338 line:-1 position:50%
enabled by the U1 chip
in the latest Apple products,


54
00:02:18,338 --> 00:02:21,475 line:-1
we've been able to deliver
more capable and responsive


55
00:02:21,475 --> 00:02:26,546 line:-1
experiences for AirTag,
HomePod mini, and iPhone.


56
00:02:26.546 --> 00:02:30.083 line:-1 position:50%
And now, thanks to new APIs
and the ability to interact


57
00:02:30.083 --> 00:02:33.820 line:-1 position:50%
with third-party hardware
that you build in iOS 15,


58
00:02:33.820 --> 00:02:36.023 line:-1 position:50%
you can now bring
these kinds of experiences


59
00:02:36.023 --> 00:02:37.991 line:-1 position:50%
to your own products.


60
00:02:37,991 --> 00:02:40,327 line:-1
In designing these interactions,
we learned that


61
00:02:40.327 --> 00:02:43.096 line:-1 position:50%
it's important to consider
distance and ability,


62
00:02:43.096 --> 00:02:47.200 line:-1 position:50%
provide continuous feedback,
and embrace the physical action.


63
00:02:47,200 --> 00:02:48,668 line:-1
Let's dive right in.


64
00:02:48.668 --> 00:02:51.738 line:-1 position:50%
In iOS 13, we made it
even easier to share content


65
00:02:51.738 --> 00:02:54.641 line:-1 position:50%
by bringing spatial awareness
to the share sheet.


66
00:02:54.641 --> 00:02:56.777 line:-1 position:50%
Using information about
who you are facing


67
00:02:56.777 --> 00:03:00.480 line:-1 position:50%
or physically close to, combined
with on-device knowledge


68
00:03:00,480 --> 00:03:03,784 line:-1
about the frequency and recency
of your communications,


69
00:03:03.784 --> 00:03:06.486 line:-1 position:50%
allows your device
to intelligently predict


70
00:03:06.486 --> 00:03:08.688 line:-1 position:50%
who you are trying
to share with.


71
00:03:08,688 --> 00:03:12,526 line:-1
This is a great example of how
existing features in your apps


72
00:03:12,526 --> 00:03:15,595 line:-1
can be made more intelligent
with spatial awareness.


73
00:03:15.595 --> 00:03:18.331 line:-1 position:50%
You don't have to build
an entirely new experience


74
00:03:18.331 --> 00:03:20.801 line:-1 position:50%
to take advantage
of these new capabilities.


75
00:03:20,801 --> 00:03:22,602 line:-1
When incorporating
spatial awareness


76
00:03:22,602 --> 00:03:24,337 line:-1
into existing features,


77
00:03:24.337 --> 00:03:26.440 line:-1 position:50%
be mindful
that these capabilities


78
00:03:26,440 --> 00:03:29,709 line:-1
are not available on all devices
and your design


79
00:03:29,709 --> 00:03:33,046 line:-1
should accommodate
varying levels of capabilities.


80
00:03:33.046 --> 00:03:35.715 line:-1 position:50%
With the share sheet,
all devices are able


81
00:03:35.715 --> 00:03:38.785 line:-1 position:50%
to look for others
using Bluetooth and Wi-Fi.


82
00:03:38.785 --> 00:03:41.888 line:-1 position:50%
However, iPhones with
the U1 spatial awareness chip


83
00:03:41.888 --> 00:03:44.891 line:-1 position:50%
take this a step further
by prioritizing others


84
00:03:44,891 --> 00:03:47,694 line:-1
that you are facing
or are very close to.


85
00:03:47,694 --> 00:03:50,063 line:-1
Of course, spatial awareness
can be used


86
00:03:50,063 --> 00:03:52,799 line:-1
to not just enhance
existing experiences;


87
00:03:52.799 --> 00:03:55.602 line:-1 position:50%
it can help build
entirely new ones.


88
00:03:55.602 --> 00:03:58.505 line:-1 position:50%
Next, Arian will share
how these same concepts


89
00:03:58.505 --> 00:04:00.307 line:-1 position:50%
apply to AirTag.


90
00:04:00.307 --> 00:04:02.209 line:-1 position:50%
Arian Behzadi: With AirTag,
we will show you


91
00:04:02,209 --> 00:04:03,810 line:-1
how your design can adapt


92
00:04:03.810 --> 00:04:07.147 line:-1 position:50%
to accommodate different
distances and abilities.


93
00:04:07,147 --> 00:04:10,951 line:-1
In this example, imagine I've
misplaced an item I care about.


94
00:04:10.951 --> 00:04:14.254 line:-1 position:50%
I retrace my steps and realize
I'm not sure where it is.


95
00:04:14,254 --> 00:04:16,123 line:-1
I use my iPhone
and feel relieved


96
00:04:16,123 --> 00:04:18,592 line:-1
that I can see
where it is on a map.


97
00:04:18,592 --> 00:04:19,960 line:-1
Previously, I'd only be able


98
00:04:19,960 --> 00:04:22,162 line:-1
to get to the general vicinity
of this item,


99
00:04:22.162 --> 00:04:23.797 line:-1 position:50%
but now my iPhone can guide me


100
00:04:23.797 --> 00:04:26.600 line:-1 position:50%
at a scale
that is much more helpful.


101
00:04:26.600 --> 00:04:28.969 line:-1 position:50%
In fact, the same button
that gave me directions


102
00:04:28,969 --> 00:04:31,171 line:-1
when I was far away
has now become a button


103
00:04:31,171 --> 00:04:34,107 line:-1
that will help me find it
as I'm closer.


104
00:04:34.107 --> 00:04:35.609 line:-1 position:50%
Augmenting elements
of the design


105
00:04:35,609 --> 00:04:38,078 line:-1
when at the appropriate scale
is a great way for people


106
00:04:38,078 --> 00:04:43,083 line:-1
to discover and use
these new abilities.


107
00:04:43,083 --> 00:04:45,085 line:-1
As iPhone is locating my AirTag,


108
00:04:45,085 --> 00:04:49,256 line:-1
I'm invited to move around
and search my surroundings.


109
00:04:49,256 --> 00:04:51,258 line:-1
Once connected,
an arrow forms


110
00:04:51.258 --> 00:04:55.095 line:-1 position:50%
and points directly to where
I need to go. [LOW CHIME]


111
00:04:55,095 --> 00:04:57,430 line:-1
As I align with the direction
of my AirTag,


112
00:04:57.430 --> 00:05:01.101 line:-1 position:50%
the design lights up
to reinforce this.


113
00:05:01.101 --> 00:05:03.236 line:-1 position:50%
We emphasize
this facing direction


114
00:05:03,236 --> 00:05:06,540 line:-1
and provide guidance
when not facing this direction.


115
00:05:06,540 --> 00:05:07,774 line:-1
In a subtle way,


116
00:05:07.774 --> 00:05:10.844 line:-1 position:50%
this distinction also scales
based on distance.


117
00:05:10.844 --> 00:05:13.346 line:-1 position:50%
When further away,
we found that it is really hard


118
00:05:13.346 --> 00:05:16.016 line:-1 position:50%
to remain facing
a specific direction.


119
00:05:16.016 --> 00:05:18.518 line:-1 position:50%
To remedy this, we are actually
more generous


120
00:05:18.518 --> 00:05:21.087 line:-1 position:50%
with the angle that iPhone
considers facing.


121
00:05:21.087 --> 00:05:24.524 line:-1 position:50%
As you get closer, this
forgiveness becomes more narrow


122
00:05:24,524 --> 00:05:26,893 line:-1
to become
more and more specific.


123
00:05:26,893 --> 00:05:28,762 line:-1
This happens
without you noticing [CHIME]


124
00:05:28,762 --> 00:05:31,798 line:-1
as you're gently guided
to your AirTag.


125
00:05:31.798 --> 00:05:34.534 line:-1 position:50%
When you're finally within
arm's reach of your AirTag,


126
00:05:34,534 --> 00:05:36,937 line:-1
the arrow defers
to a form of feedback


127
00:05:36.937 --> 00:05:41.675 line:-1 position:50%
that we find much more effective
at this small scale. [CHIME]


128
00:05:41,675 --> 00:05:44,678 line:-1
The design transforms
to highlight haptic feedback


129
00:05:44.678 --> 00:05:45.946 line:-1 position:50%
as you pass your iPhone over


130
00:05:45,946 --> 00:05:48,148 line:-1
where your AirTag
might be hiding.


131
00:05:48,148 --> 00:05:50,183 line:-1
With this example,
we've shown you


132
00:05:50,183 --> 00:05:53,286 line:-1
how your design can transform
based on distance,


133
00:05:53,286 --> 00:05:56,656 line:-1
whether you're very far away
or within millimeters.


134
00:05:56.656 --> 00:05:58.325 line:-1 position:50%
Think about how
your design can best


135
00:05:58,325 --> 00:06:01,428 line:-1
accommodate varying abilities
we all share as humans.


136
00:06:01.428 --> 00:06:03.697 line:-1 position:50%
Be forgiving with angles
at a distance,


137
00:06:03,697 --> 00:06:05,966 line:-1
and consider changing
the dominant form of feedback


138
00:06:05,966 --> 00:06:08,668 line:-1
to one that works best
at smaller scale.


139
00:06:08.668 --> 00:06:10.804 line:-1 position:50%
Next, I'd like to hand it
over to Taylor


140
00:06:10.804 --> 00:06:13.807 line:-1 position:50%
to show you just how critical
this continuous feedback is


141
00:06:13,807 --> 00:06:16,876 line:-1
when designing these kinds
of interactions.


142
00:06:16.876 --> 00:06:18.211 line:-1 position:50%
Taylor Carrigan: Thanks, Arian.


143
00:06:18.211 --> 00:06:20.847 line:-1 position:50%
We've gone to great lengths
to make onscreen interactions


144
00:06:20,847 --> 00:06:23,617 line:-1
fluidly and dynamically respond
to touch input,


145
00:06:23,617 --> 00:06:25,919 line:-1
but this continuous feedback
is even more critical


146
00:06:25,919 --> 00:06:28,555 line:-1
when interacting in the physical
world where your device


147
00:06:28,555 --> 00:06:31,458 line:-1
becomes a more literal
extension of your body.


148
00:06:31,458 --> 00:06:34,327 line:-1
The right type of feedback
applied and choreographed


149
00:06:34.327 --> 00:06:36.663 line:-1 position:50%
at the right time
throughout these interactions


150
00:06:36.663 --> 00:06:39.599 line:-1 position:50%
can help make the feature
you're designing discoverable,


151
00:06:39.599 --> 00:06:41.167 line:-1 position:50%
provides instruction,


152
00:06:41.167 --> 00:06:44.037 line:-1 position:50%
and can communicate
success or failure.


153
00:06:44.037 --> 00:06:45.505 line:-1 position:50%
It also acknowledges
that our movements


154
00:06:45.505 --> 00:06:49.309 line:-1 position:50%
can start, stop,
and be interrupted at any time.


155
00:06:49.309 --> 00:06:51.278 line:-1 position:50%
We're going to talk about
how you can use feedback


156
00:06:51.278 --> 00:06:54.214 line:-1 position:50%
you can see, [CHIME] hear,
and feel


157
00:06:54.214 --> 00:06:57.083 line:-1 position:50%
to help connect your interaction
to the physical world.


158
00:06:57.083 --> 00:06:58.618 line:-1 position:50%
Though dependent
on the capabilities


159
00:06:58.618 --> 00:07:00.053 line:-1 position:50%
of the devices used,


160
00:07:00.053 --> 00:07:01.421 line:-1 position:50%
there are multiple
types of feedback


161
00:07:01.421 --> 00:07:04.057 line:-1 position:50%
worth considering
and using together.


162
00:07:04.057 --> 00:07:06.059 line:-1 position:50%
These can include
visual feedback --


163
00:07:06.059 --> 00:07:07.661 line:-1 position:50%
such as user interface changes,


164
00:07:07,661 --> 00:07:09,362 line:-1
lights and hardware
interactions,


165
00:07:09,362 --> 00:07:12,465 line:-1
and visual feedback coordinated
across both devices --


166
00:07:12,465 --> 00:07:15,302 line:-1
audio feedback [CHIME],
and haptic feedback.


167
00:07:15.302 --> 00:07:17.337 line:-1 position:50%
We'll also talk about
natural interruption


168
00:07:17.337 --> 00:07:19.639 line:-1 position:50%
and cancellation and
the importance these play


169
00:07:19,639 --> 00:07:23,610 line:-1
in creating a successful
interaction between two devices.


170
00:07:23,610 --> 00:07:25,545 line:-1
Let's look first at how
different types of feedback


171
00:07:25,545 --> 00:07:28,048 line:-1
help make the transfer of music
to HomePod mini


172
00:07:28,048 --> 00:07:30,150 line:-1
intuitive and satisfying.


173
00:07:30,150 --> 00:07:31,751 line:-1
[MUSIC PLAYING QUIETLY]
With HomePod mini,


174
00:07:31,751 --> 00:07:33,753 line:-1
we use multiple types
of feedback to establish


175
00:07:33.753 --> 00:07:35.889 line:-1 position:50%
a physical relationship
with your iPhone,


176
00:07:35.889 --> 00:07:38.224 line:-1 position:50%
provide direction,
and ultimately confirm


177
00:07:38.224 --> 00:07:41.161 line:-1 position:50%
that your music has been
successfully transferred.


178
00:07:41.161 --> 00:07:43.663 line:-1 position:50%
We achieved this by creating
two discrete boundaries


179
00:07:43.663 --> 00:07:44.831 line:-1 position:50%
around the HomePod,


180
00:07:44,831 --> 00:07:48,635 line:-1
and respond to your movement
across and between them.


181
00:07:48,635 --> 00:07:51,671 line:-1
Feedback is provided when your
iPhone reaches the first zone,


182
00:07:51.671 --> 00:07:54.574 line:-1 position:50%
between the first and second
to instruct you to move closer


183
00:07:54.574 --> 00:07:56.443 line:-1 position:50%
or allow you to cancel
the interaction,


184
00:07:56,443 --> 00:07:59,045 line:-1
and finally when your iPhone
reaches the second zone,


185
00:07:59,045 --> 00:08:01,581 line:-1
to confirm and transfer music.


186
00:08:01,581 --> 00:08:03,450 line:-1
Feedback is continuously
provided


187
00:08:03,450 --> 00:08:06,986 line:-1
from the moment iPhone reaches
the first distance threshold.


188
00:08:06,986 --> 00:08:10,323 line:-1
On screen, the banner position,
scale, and modality


189
00:08:10.323 --> 00:08:11.925 line:-1 position:50%
created by the background blur


190
00:08:11,925 --> 00:08:14,194 line:-1
increase fluidly
and in direct response


191
00:08:14.194 --> 00:08:17.030 line:-1 position:50%
to your distance
from the HomePod.


192
00:08:17,030 --> 00:08:18,898 line:-1
When designing
visual feedback,


193
00:08:18,898 --> 00:08:21,735 line:-1
look for opportunities for the
onscreen elements to animate


194
00:08:21.735 --> 00:08:24.437 line:-1 position:50%
in a way that feels related
to your physical movements --


195
00:08:24,437 --> 00:08:26,005 line:-1
like how the movement
of this banner


196
00:08:26.005 --> 00:08:27.807 line:-1 position:50%
is related to the linear
movement of your hand


197
00:08:27.807 --> 00:08:31.277 line:-1 position:50%
towards or away
from the HomePod.


198
00:08:31,277 --> 00:08:34,481 line:-1
Haptic feedback complements this
with a physical acknowledgement


199
00:08:34.481 --> 00:08:36.750 line:-1 position:50%
that the two devices
are aware of each other,


200
00:08:36.750 --> 00:08:38.618 line:-1 position:50%
and increases in strength
to encourage you


201
00:08:38.618 --> 00:08:40.854 line:-1 position:50%
to continue moving closer.


202
00:08:40,854 --> 00:08:43,089 line:-1
In addition to the feedback
on iPhone,


203
00:08:43.089 --> 00:08:45.525 line:-1 position:50%
HomePod mini acknowledges
the proximity of iPhone


204
00:08:45.525 --> 00:08:48.395 line:-1 position:50%
through the animations
on the top of the speaker.


205
00:08:48.395 --> 00:08:51.097 line:-1 position:50%
Great spatial interactions
use natural body movements


206
00:08:51,097 --> 00:08:54,234 line:-1
to not only confirm
but also to cancel actions.


207
00:08:54,234 --> 00:08:55,702 line:-1
[MUSIC PLAYING QUIETLY]
When moving an iPhone


208
00:08:55.702 --> 00:08:58.271 line:-1 position:50%
near a HomePod mini,
clear and continuous feedback


209
00:08:58.271 --> 00:09:00.407 line:-1 position:50%
that tracks your distance
from the HomePod


210
00:09:00.407 --> 00:09:02.208 line:-1 position:50%
makes it clear that
you can simply pull away


211
00:09:02.208 --> 00:09:04.844 line:-1 position:50%
to cancel or interrupt
the gesture.


212
00:09:04,844 --> 00:09:06,913 line:-1
This allowed us to create
an interaction that can be done


213
00:09:06,913 --> 00:09:08,948 line:-1
entirely without
looking at the display


214
00:09:08.948 --> 00:09:11.151 line:-1 position:50%
or requiring additional
onscreen buttons


215
00:09:11.151 --> 00:09:13.820 line:-1 position:50%
to cancel or confirm
user intent.


216
00:09:13,820 --> 00:09:16,523 line:-1
All of these aspects
are driven by and respond to


217
00:09:16.523 --> 00:09:18.625 line:-1 position:50%
the movement of your body
as it brings iPhone


218
00:09:18.625 --> 00:09:21.594 line:-1 position:50%
closer to or farther away
from the HomePod.


219
00:09:21.594 --> 00:09:22.929 line:-1 position:50%
The directness
of the relationship


220
00:09:22,929 --> 00:09:25,031 line:-1
between someone's movements
in the physical world


221
00:09:25,031 --> 00:09:28,401 line:-1
and what they're seeing,
hearing, and feeling


222
00:09:28,401 --> 00:09:30,270 line:-1
on one or both devices
are critical


223
00:09:30.270 --> 00:09:32.439 line:-1 position:50%
when designing
a spatial interaction.


224
00:09:32.439 --> 00:09:35.608 line:-1 position:50%
Next, Linus will talk about
the unique constraints


225
00:09:35.608 --> 00:09:39.078 line:-1 position:50%
of providing feedback
while finding an AirTag.


226
00:09:39,078 --> 00:09:40,547 line:-1
Linus Persson: HomePod mini
is a good example


227
00:09:40.547 --> 00:09:43.450 line:-1 position:50%
of how to choreograph
feedback across two devices,


228
00:09:43,450 --> 00:09:45,752 line:-1
both capable of expressing
rich feedback.


229
00:09:45.752 --> 00:09:48.021 line:-1 position:50%
For designs where
this is not a possibility,


230
00:09:48.021 --> 00:09:51.891 line:-1 position:50%
you might have to rely
more heavily on a single device.


231
00:09:51.891 --> 00:09:54.461 line:-1 position:50%
Since AirTag helps you
find an item when it's lost,


232
00:09:54.461 --> 00:09:55.995 line:-1 position:50%
the experience is designed
for scenarios


233
00:09:55,995 --> 00:09:58,164 line:-1
when it's hidden from view.


234
00:09:58,164 --> 00:10:01,768 line:-1
Let's revisit the finding
experience we saw before,


235
00:10:01,768 --> 00:10:04,771 line:-1
this time with an eye on how
we provide continuous feedback


236
00:10:04.771 --> 00:10:06.806 line:-1 position:50%
across the senses using iPhone's


237
00:10:06.806 --> 00:10:10.610 line:-1 position:50%
rich haptic, visual,
and acoustic capabilities.


238
00:10:10.610 --> 00:10:13.046 line:-1 position:50%
A spatial interaction
feels great when it's responsive


239
00:10:13.046 --> 00:10:14.747 line:-1 position:50%
and follows your motion.


240
00:10:14.747 --> 00:10:17.584 line:-1 position:50%
That means responding
to movements that are big


241
00:10:17.584 --> 00:10:19.352 line:-1 position:50%
as well as ones
that are subtle.


242
00:10:19,352 --> 00:10:21,688 line:-1
Even as iPhone
is connecting to the AirTag,


243
00:10:21,688 --> 00:10:24,524 line:-1
the interface gently rotates
and responds as I turn,


244
00:10:24.524 --> 00:10:26.526 line:-1 position:50%
implying the nature
of the interaction


245
00:10:26,526 --> 00:10:28,094 line:-1
that is about to follow.


246
00:10:28.094 --> 00:10:30.230 line:-1 position:50%
These dots also
provide the building blocks


247
00:10:30.230 --> 00:10:34.033 line:-1 position:50%
for a continuously
adapting experience.


248
00:10:34.033 --> 00:10:36.669 line:-1 position:50%
Once connected, the distance
between me and my AirTag


249
00:10:36.669 --> 00:10:38.037 line:-1 position:50%
also appears.


250
00:10:38,037 --> 00:10:40,139 line:-1
This distance responds
incredibly precisely


251
00:10:40.139 --> 00:10:41.875 line:-1 position:50%
as I walk in any direction.


252
00:10:41,875 --> 00:10:43,576 line:-1
It instantly updates
and tells me


253
00:10:43,576 --> 00:10:47,046 line:-1
if I'm walking toward, or away,
from where I want to go.


254
00:10:47,046 --> 00:10:49,549 line:-1
As I walk around, the same dots
smoothly form an arrow


255
00:10:49.549 --> 00:10:51.484 line:-1 position:50%
pointing me
in the right direction.


256
00:10:51.484 --> 00:10:54.287 line:-1 position:50%
This moment is reinforced
further using a delicate haptic


257
00:10:54.287 --> 00:10:56.356 line:-1 position:50%
and sound to mark
its importance.


258
00:10:56,356 --> 00:10:57,724 line:-1
[LOW TONES]
It feels as though the arrow


259
00:10:57,724 --> 00:11:00,894 line:-1
floats in space as my iPhone
moves around it.


260
00:11:00.894 --> 00:11:01.728 line:-1 position:50%
As you saw earlier,


261
00:11:01.728 --> 00:11:04.364 line:-1 position:50%
the interface reinforces moments
when I am on the right path.


262
00:11:04.364 --> 00:11:07.500 line:-1 position:50%
[LOW TONES] When facing
the direction of my lost AirTag,


263
00:11:07,500 --> 00:11:08,735 line:-1
the screen boldly lights up


264
00:11:08,735 --> 00:11:11,838 line:-1
and I also feel and hear
the arrow snap into place.


265
00:11:11.838 --> 00:11:14.240 line:-1 position:50%
By responding to every step
and subtle turn,


266
00:11:14,240 --> 00:11:17,777 line:-1
the design feels tightly coupled
with me and the space I'm in.


267
00:11:17.777 --> 00:11:19.579 line:-1 position:50%
When designing
your spatial interaction,


268
00:11:19.579 --> 00:11:21.915 line:-1 position:50%
consider how people
will connect their own movement


269
00:11:21.915 --> 00:11:24.083 line:-1 position:50%
with what they experience
on the device.


270
00:11:24.083 --> 00:11:26.953 line:-1 position:50%
Try to make a clear link
between action and feedback


271
00:11:26,953 --> 00:11:30,089 line:-1
in a way that is mindful
of the particular motion.


272
00:11:30.089 --> 00:11:31.157 line:-1 position:50%
Just ahead of the arrow,


273
00:11:31.157 --> 00:11:33.626 line:-1 position:50%
there's a dot that starts
to pulse in my hand.


274
00:11:33,626 --> 00:11:36,262 line:-1
The pace of this pulse
picks up as I get closer,


275
00:11:36,262 --> 00:11:37,931 line:-1
and the haptics become
tighter and crisper


276
00:11:37,931 --> 00:11:39,032 line:-1
[CHIME]
along with it.


277
00:11:39,032 --> 00:11:40,466 line:-1
If I break away
from this direction,


278
00:11:40.466 --> 00:11:43.236 line:-1 position:50%
the pulse stops and
the interface guides me back.


279
00:11:43.236 --> 00:11:45.238 line:-1 position:50%
If I walk far enough away
from my AirTag,


280
00:11:45,238 --> 00:11:48,007 line:-1
the arrow disassembles
to mark the loss of signal.


281
00:11:48,007 --> 00:11:49,676 line:-1
Nuance in moments like these


282
00:11:49,676 --> 00:11:52,712 line:-1
also provide important
and very helpful guidance.


283
00:11:52.712 --> 00:11:56.382 line:-1 position:50%
Be mindful of how feedback
can complement human motions


284
00:11:56,382 --> 00:11:58,484 line:-1
that are varied
and unpredictable,


285
00:11:58,484 --> 00:12:00,453 line:-1
and build a design
that is resilient


286
00:12:00,453 --> 00:12:03,623 line:-1
and can adaptively change
to accommodate the way we move.


287
00:12:03,623 --> 00:12:07,293 line:-1
When within arm's reach,
we visually zoom in on this dot,


288
00:12:07,293 --> 00:12:09,796 line:-1
and the pulse changes
to continuous haptic feedback


289
00:12:09.796 --> 00:12:13.533 line:-1 position:50%
that shifts with my movement.


290
00:12:13,533 --> 00:12:16,603 line:-1
This haptic response changes
in character as I move closer


291
00:12:16.603 --> 00:12:18.171 line:-1 position:50%
and further away.


292
00:12:18.171 --> 00:12:20.506 line:-1 position:50%
I can move my iPhone over
where AirTag might be


293
00:12:20.506 --> 00:12:23.977 line:-1 position:50%
and sense through my hand more
precisely where it's hiding.


294
00:12:23,977 --> 00:12:26,779 line:-1
Note that we do not use sound
for this part of the experience,


295
00:12:26.779 --> 00:12:30.149 line:-1 position:50%
as haptic feedback does
a much more effective job.


296
00:12:30,149 --> 00:12:31,684 line:-1
As with any continuous
feedback,


297
00:12:31,684 --> 00:12:34,354 line:-1
your design should be mindful
of how haptics, sound,


298
00:12:34.354 --> 00:12:37.657 line:-1 position:50%
and visuals work together
in concert across the senses.


299
00:12:37.657 --> 00:12:40.193 line:-1 position:50%
Similarly to the way
we perceive what we see,


300
00:12:40.193 --> 00:12:45.832 line:-1 position:50%
hear and feel in the world
as one holistic experience.


301
00:12:45,832 --> 00:12:48,334 line:-1
When designing your interaction,
it is important to consider


302
00:12:48.334 --> 00:12:50.670 line:-1 position:50%
the different strengths
of each form of feedback


303
00:12:50,670 --> 00:12:53,573 line:-1
and how they can
be used together.


304
00:12:53.573 --> 00:12:56.075 line:-1 position:50%
Seek to provide a visual layer
of continuous feedback


305
00:12:56.075 --> 00:12:59.445 line:-1 position:50%
tied to physical motion
and use additional feedback


306
00:12:59,445 --> 00:13:02,882 line:-1
to emphasize important moments
in your interaction.


307
00:13:02.882 --> 00:13:05.184 line:-1 position:50%
Use haptics and sound
judiciously


308
00:13:05,184 --> 00:13:06,753 line:-1
and at the right levels,


309
00:13:06.753 --> 00:13:08.488 line:-1 position:50%
with a repeatable
cause and effect


310
00:13:08.488 --> 00:13:11.424 line:-1 position:50%
so it is clear what is being
communicated.


311
00:13:11.424 --> 00:13:13.459 line:-1 position:50%
In addition to working
with feedback in this way,


312
00:13:13.459 --> 00:13:15.161 line:-1 position:50%
keep in mind that your design
will complement


313
00:13:15.161 --> 00:13:16.763 line:-1 position:50%
a physical action.


314
00:13:16.763 --> 00:13:20.199 line:-1 position:50%
And to speak about this
is my colleague Pedro.


315
00:13:20,199 --> 00:13:21,801 line:-1
Pedro Mari: In the case
of HomePods,


316
00:13:21,801 --> 00:13:23,436 line:-1
we use spatial awareness
to make the task


317
00:13:23.436 --> 00:13:25.805 line:-1 position:50%
of selecting a speaker
more natural.


318
00:13:25,805 --> 00:13:28,574 line:-1
Oftentimes, I'll be listening
to some music,


319
00:13:28.574 --> 00:13:30.143 line:-1 position:50%
and I'll want to move it
from my iPhone


320
00:13:30,143 --> 00:13:32,278 line:-1
to a better speaker near me.


321
00:13:32,278 --> 00:13:34,013 line:-1
Previously, if I wanted
to play this song


322
00:13:34.013 --> 00:13:37.450 line:-1 position:50%
on a different speaker, I'd have
to go into the AirPlay list.


323
00:13:37,450 --> 00:13:40,153 line:-1
In this list, all of the other
devices in my space


324
00:13:40,153 --> 00:13:43,923 line:-1
are presented equally,
whether they are near me or not.


325
00:13:43.923 --> 00:13:46.159 line:-1 position:50%
What I am really
interested in, though,


326
00:13:46,159 --> 00:13:48,795 line:-1
is this particular HomePod.


327
00:13:48,795 --> 00:13:50,563 line:-1
With this new human-scale
interaction,


328
00:13:50.563 --> 00:13:52.532 line:-1 position:50%
I can finally transfer a song
to this HomePod


329
00:13:52.532 --> 00:13:54.400 line:-1 position:50%
without navigating
an onscreen UI,


330
00:13:54,400 --> 00:13:57,603 line:-1
or having to interact with the
screen at all, for that matter.


331
00:13:57,603 --> 00:13:59,706 line:-1
We provide visual feedback
on the HomePod itself


332
00:13:59.706 --> 00:14:02.375 line:-1 position:50%
to show that the music
is about to be transferred.


333
00:14:02,375 --> 00:14:04,477 line:-1
[MUSIC PLAYING QUIETLY]
The light modulates precisely


334
00:14:04.477 --> 00:14:07.980 line:-1 position:50%
with my movement, growing in
intensity as I approach,


335
00:14:07.980 --> 00:14:10.083 line:-1 position:50%
and shrinking as I move away.


336
00:14:10,083 --> 00:14:12,051 line:-1
[MUSIC PLAYS ON IPHONE]


337
00:14:12.051 --> 00:14:17.623 line:-1 position:50%
[MUSIC PLAYS ON HOMEPOD]


338
00:14:17.623 --> 00:14:18.524 line:-1 position:50%
[MUSIC STOPS]


339
00:14:18,524 --> 00:14:19,092 line:-1
And of course,


340
00:14:19,092 --> 00:14:20,960 line:-1
the ultimate confirmation
of the transfer


341
00:14:20.960 --> 00:14:23.529 line:-1 position:50%
is the music playing
from the speaker itself.


342
00:14:23.529 --> 00:14:25.732 line:-1 position:50%
By embracing
the physical action,


343
00:14:25,732 --> 00:14:27,633 line:-1
a previously intangible
experience


344
00:14:27,633 --> 00:14:32,772 line:-1
now feels completely tangible,
visceral, and instinctive.


345
00:14:32,772 --> 00:14:34,574 line:-1
Think of ways
that your own interfaces


346
00:14:34,574 --> 00:14:36,976 line:-1
can support
a natural physical motion,


347
00:14:36,976 --> 00:14:39,812 line:-1
rather than an abstracted
list of options.


348
00:14:39.812 --> 00:14:42.115 line:-1 position:50%
Try to make your experiences
and designs


349
00:14:42,115 --> 00:14:44,784 line:-1
defer to the physical task
at hand.


350
00:14:44,784 --> 00:14:48,387 line:-1
Also, consider how the concepts
of "this" and "that"


351
00:14:48,387 --> 00:14:51,023 line:-1
can be finally used to create
a more natural experience


352
00:14:51.023 --> 00:14:53.659 line:-1 position:50%
that aligns with how we think.


353
00:14:53,659 --> 00:14:56,095 line:-1
Make sure to provide
instant and continuous feedback


354
00:14:56,095 --> 00:14:57,663 line:-1
on both devices.


355
00:14:57,663 --> 00:14:59,966 line:-1
Specifically, be very clear
on the target device


356
00:14:59.966 --> 00:15:01.567 line:-1 position:50%
that an action is happening,


357
00:15:01.567 --> 00:15:04.704 line:-1 position:50%
as this is where your attention
will be naturally drawn to.


358
00:15:04,704 --> 00:15:07,206 line:-1
Similarly,
when finding a lost item,


359
00:15:07,206 --> 00:15:09,408 line:-1
my attention is meant to be
directed at the world around me


360
00:15:09.408 --> 00:15:12.779 line:-1 position:50%
and where it might be hiding.


361
00:15:12.779 --> 00:15:15.248 line:-1 position:50%
Playing sound from the AirTag
gives me an immediate sense


362
00:15:15,248 --> 00:15:16,749 line:-1
of its place in space,


363
00:15:16.749 --> 00:15:19.619 line:-1 position:50%
drawing my attention
to my surroundings.


364
00:15:19,619 --> 00:15:23,656 line:-1
[CHIMES, BEEPING]


365
00:15:23.656 --> 00:15:26.526 line:-1 position:50%
When it comes to the visual
feedback on iPhone itself,


366
00:15:26,526 --> 00:15:28,427 line:-1
make sure it can be read
when performing a task


367
00:15:28,427 --> 00:15:31,297 line:-1
that extends beyond the bounds
of the display.


368
00:15:31.297 --> 00:15:33.766 line:-1 position:50%
We often design our interfaces
to work in this manner


369
00:15:33.766 --> 00:15:36.969 line:-1 position:50%
when we anticipate it will
be viewed in the periphery.


370
00:15:36,969 --> 00:15:39,872 line:-1
For instance, when using
turn-by-turn navigation,


371
00:15:39.872 --> 00:15:42.775 line:-1 position:50%
the typography of when and where
I need to take my next turn


372
00:15:42.775 --> 00:15:44.811 line:-1 position:50%
is bigger and bolder
than other notifications


373
00:15:44.811 --> 00:15:47.847 line:-1 position:50%
that might occupy
the same space.


374
00:15:47.847 --> 00:15:51.818 line:-1 position:50%
The buttons and active area
of TV Remote are extra large


375
00:15:51.818 --> 00:15:55.221 line:-1 position:50%
and are designed for your eyes
to be directed to the TV itself,


376
00:15:55.221 --> 00:15:58.391 line:-1 position:50%
rather than the control for it.


377
00:15:58.391 --> 00:16:01.027 line:-1 position:50%
The digits and operation buttons
in Calculator


378
00:16:01.027 --> 00:16:02.695 line:-1 position:50%
are large and bold,
as we anticipate


379
00:16:02.695 --> 00:16:05.198 line:-1 position:50%
you might be referencing numbers
on a restaurant bill


380
00:16:05,198 --> 00:16:08,301 line:-1
to calculate a tip,
for instance.


381
00:16:08.301 --> 00:16:09.669 line:-1 position:50%
As in the previous examples,


382
00:16:09.669 --> 00:16:11.437 line:-1 position:50%
the type size we use
for the distance


383
00:16:11.437 --> 00:16:13.940 line:-1 position:50%
when finding an AirTag
is set much larger


384
00:16:13.940 --> 00:16:15.875 line:-1 position:50%
than in other parts
of the system,


385
00:16:15.875 --> 00:16:17.743 line:-1 position:50%
and the entire UI
revolves around


386
00:16:17,743 --> 00:16:21,914 line:-1
the central element
of a giant arrow.


387
00:16:21,914 --> 00:16:23,482 line:-1
[LOW TONE]


388
00:16:23.482 --> 00:16:26.419 line:-1 position:50%
Bold color changes
can be read in my periphery.


389
00:16:26,419 --> 00:16:28,688 line:-1
Sound reinforces
key moments and states --


390
00:16:28.688 --> 00:16:31.023 line:-1 position:50%
I can actually feel the distance
getting smaller as I walk


391
00:16:31.023 --> 00:16:34.427 line:-1 position:50%
without ever having
to look at the screen.


392
00:16:34.427 --> 00:16:37.997 line:-1 position:50%
This ultimately supports
a more natural pose as I use it.


393
00:16:37.997 --> 00:16:43.536 line:-1 position:50%
[LOW TONES]
[CHIME]


394
00:16:43.536 --> 00:16:44.971 line:-1 position:50%
When in arm's reach,


395
00:16:44,971 --> 00:16:46,439 line:-1
haptic feedback
can guide me closer


396
00:16:46.439 --> 00:16:49.342 line:-1 position:50%
even if the screen
is not in my periphery.


397
00:16:49.342 --> 00:16:51.978 line:-1 position:50%
[CHIME]


398
00:16:54.647 --> 00:16:56.415 line:-1 position:50%
These large and bold UI choices


399
00:16:56.415 --> 00:16:57.917 line:-1 position:50%
enable those
with varying abilities


400
00:16:57,917 --> 00:17:00,086 line:-1
to access the experience
as well.


401
00:17:00.086 --> 00:17:02.788 line:-1 position:50%
Make sure your design uses
more than one mode of feedback,


402
00:17:02.788 --> 00:17:06.158 line:-1 position:50%
and that each one is salient
enough to be clearly understood.


403
00:17:06,158 --> 00:17:08,194 line:-1
Your design shouldn't
demand too much attention


404
00:17:08,194 --> 00:17:09,996 line:-1
to communicate its information


405
00:17:09.996 --> 00:17:12.665 line:-1 position:50%
or compete with
the primary task.


406
00:17:12.665 --> 00:17:14.867 line:-1 position:50%
Lastly, try to reinforce
good states


407
00:17:14,867 --> 00:17:16,335 line:-1
and celebrate positive progress


408
00:17:16,335 --> 00:17:19,672 line:-1
along the way to completing
a spatial interaction.


409
00:17:19.672 --> 00:17:21.274 line:-1 position:50%
Always consider
the physical action


410
00:17:21,274 --> 00:17:23,876 line:-1
your experience
is complementing.


411
00:17:23.876 --> 00:17:26.712 line:-1 position:50%
And now, back to Peter!


412
00:17:26.712 --> 00:17:28.447 line:-1 position:50%
Peter: We've covered
a lot today.


413
00:17:28,447 --> 00:17:30,950 line:-1
We've seen how new
and existing experiences


414
00:17:30,950 --> 00:17:33,419 line:-1
become more intelligent
and relevant


415
00:17:33.419 --> 00:17:37.390 line:-1 position:50%
when they consider the device's
context and surroundings.


416
00:17:37.390 --> 00:17:39.759 line:-1 position:50%
You learned how responsive
and continuous feedback


417
00:17:39.759 --> 00:17:43.863 line:-1 position:50%
can help users discover
and use these new experiences.


418
00:17:43.863 --> 00:17:46.165 line:-1 position:50%
And finally, we took a look
at techniques


419
00:17:46.165 --> 00:17:47.466 line:-1 position:50%
that allow your design


420
00:17:47.466 --> 00:17:50.303 line:-1 position:50%
to be effectively experienced
peripherally


421
00:17:50.303 --> 00:17:53.406 line:-1 position:50%
while keeping attention
on the physical surroundings.


422
00:17:53,406 --> 00:17:56,375 line:-1
We hope that you are
just as excited as we are


423
00:17:56.375 --> 00:17:58.678 line:-1 position:50%
about how spatial awareness
can simplify


424
00:17:58.678 --> 00:18:02.114 line:-1 position:50%
and bring more directness to
interactions between our devices


425
00:18:02.114 --> 00:18:04.417 line:-1 position:50%
and our users'
physical surroundings.


426
00:18:04,417 --> 00:18:08,654 line:0
For more information, be sure
to visit developer.apple.com


427
00:18:08,654 --> 00:18:10,690 position:50%
where you'll find
the Human Interface Guidelines


428
00:18:10,690 --> 00:18:13,993 position:50%
for spatial interactions,
as well as technical information


429
00:18:13,993 --> 00:18:17,129 position:50%
about how to implement
these types of interactions.


430
00:18:17,129 --> 00:18:19,465 position:50%
We can't wait to see
what you'll build next.


431
00:18:19,465 --> 00:18:22,802 align:right line:0 size:2%
♪

