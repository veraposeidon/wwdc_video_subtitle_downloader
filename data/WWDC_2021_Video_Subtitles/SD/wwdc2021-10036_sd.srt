2
00:00:00,334 --> 00:00:03,303 line:-1
[upbeat music]


3
00:00:03.337 --> 00:00:09.776 line:-1 align:center
♪ ♪


4
00:00:09,810 --> 00:00:11,078 line:-1
[Jon] Hi.


5
00:00:11.111 --> 00:00:13.947 line:-2 align:center
Welcome to the Sound Analysis
session at WWDC.


6
00:00:13.981 --> 00:00:15.415 line:-1 align:center
My name is Jon Huang.


7
00:00:15,449 --> 00:00:17,150 line:-2
I'm a researcher
on the audio team.


8
00:00:17,184 --> 00:00:19,119 line:-2
Today, my colleague,
Kevin, and I


9
00:00:19,152 --> 00:00:21,955 line:-2
will introduce enhancements
to sound classification


10
00:00:21.989 --> 00:00:24.491 line:-2 align:center
made available through
the SoundAnalysis framework


11
00:00:24.525 --> 00:00:25.959 line:-1 align:center
and CreateML.


12
00:00:25.993 --> 00:00:28.795 line:-1 align:center
In 2019, we made it possible


13
00:00:28.829 --> 00:00:31.765 line:-2 align:center
to train sound classification
models using CreateML.


14
00:00:31,798 --> 00:00:34,801 line:-2
We showed it was easy to create
sound classification models


15
00:00:34.835 --> 00:00:37.638 line:-2 align:center
and to deploy them
in Apple devices.


16
00:00:37,671 --> 00:00:39,640 line:-1
When you use this framework,


17
00:00:39.673 --> 00:00:41.108 line:-1 align:center
all of the computations


18
00:00:41,141 --> 00:00:42,910 line:-2
are optimized
for hardware acceleration


19
00:00:42,943 --> 00:00:45,245 line:-1
and are done locally on-device.


20
00:00:45,279 --> 00:00:47,581 line:-2
This helps preserve
your user's privacy


21
00:00:47,614 --> 00:00:50,250 line:-2
because audio is never sent
to the Cloud.


22
00:00:50,284 --> 00:00:53,220 line:-2
We leveraged the Sound Analysis
framework to introduce


23
00:00:53.253 --> 00:00:56.690 line:-2 align:center
the Accessibility Feature
called Sound Recognition.


24
00:00:56,723 --> 00:00:59,493 line:-2
This feature can provide
notifications to the user


25
00:00:59,526 --> 00:01:01,662 line:-2
when certain sounds are
heard in the environment


26
00:01:01.695 --> 00:01:03.463 line:-1 align:center
like alarms, pets,


27
00:01:03,497 --> 00:01:06,166 line:-1
and other household sounds.


28
00:01:06,200 --> 00:01:09,469 line:-2
This is just one application
of sound classification.


29
00:01:09,503 --> 00:01:12,372 line:-2
Let's see what else
we can do with it.


30
00:01:12.406 --> 00:01:15.142 line:-2 align:center
The demo app is using
my Mac's built-in microphone


31
00:01:15.175 --> 00:01:17.911 line:-2 align:center
to listen to sounds
in the environment.


32
00:01:17,945 --> 00:01:20,514 line:-2
It's passing audio
through a sound classifier


33
00:01:20,547 --> 00:01:22,649 line:-2
and displaying
the classification results


34
00:01:22.683 --> 00:01:24.017 line:-1 align:center
in the UI.


35
00:01:24,051 --> 00:01:27,754 line:-2
So as I'm chatting to you,
speech is detected.


36
00:01:27.788 --> 00:01:30.390 line:-2 align:center
Please sit back with me
for a bit and see what happens.


37
00:01:30,424 --> 00:01:32,125 line:-1
Make yourself comfortable.


38
00:01:32,159 --> 00:01:34,528 line:-1
Let's start with some music.


39
00:01:34.561 --> 00:01:37.965 line:-2 align:center
Hey Siri, play "Catch a Vibe"
by Karun and Mombru.


40
00:01:38.699 --> 00:01:41.802 line:-2 align:center
[Siri] Now playing "Catch
a Vibe" by Karun and Mombru.


41
00:01:41,835 --> 00:01:44,805 line:-2
[Karun and Mombru's
"Catch a Vibe"]


42
00:01:44.838 --> 00:01:46.106 line:-1 align:center
♪ ♪


43
00:01:46.139 --> 00:01:48.976 line:-2 align:center
[Karun and Mombru]
♪ Oh, oh, oh ♪


44
00:01:49.009 --> 00:01:51.411 line:-2 align:center
[Jon] Notice the classifier
is picking up


45
00:01:51.445 --> 00:01:53.113 line:-1 align:center
both music and singing sounds.


46
00:01:53,146 --> 00:01:56,016 line:-2
[Karun and Mombru]
♪ I don't know anyone ♪


47
00:01:56.049 --> 00:01:59.353 line:-1 align:center
♪ Who feels so right ♪


48
00:01:59,386 --> 00:02:01,321 line:-2
♪ Don't know anyone
who makes me ♪


49
00:02:01.355 --> 00:02:03.290 line:-2 align:center
♪ Catch a vibe,
feel the frequency...♪


50
00:02:03,323 --> 00:02:05,559 line:-2
[Jon] Now please join me
for some tea.


51
00:02:05,592 --> 00:02:07,327 line:-2
[Karun and Mombru]
♪ Feel all right, baby ♪


52
00:02:07.361 --> 00:02:08.795 line:-1 align:center
♪ We could see ♪


53
00:02:08,829 --> 00:02:13,967 line:-1
♪ If we could be right ♪


54
00:02:14.001 --> 00:02:18.438 line:-2 align:center
♪ See if it's something
about the way you smile ♪


55
00:02:18,472 --> 00:02:20,641 line:-2
♪ Hold your breath
and, baby, we could ♪


56
00:02:20.674 --> 00:02:23.043 line:-2 align:center
♪ Catch a vibe,
feel the frequency ♪


57
00:02:23.076 --> 00:02:25.379 line:-2 align:center
♪ Catch a vibe,
only you and me ♪


58
00:02:25,412 --> 00:02:27,614 line:-2
♪ Feel all right, baby,
we could see ♪


59
00:02:27,648 --> 00:02:29,816 line:-1
♪ If we could be ♪


60
00:02:29,850 --> 00:02:33,187 line:-1
♪ I've said, I've said ♪


61
00:02:33.220 --> 00:02:35.155 line:-1 align:center
♪ It's part of me ♪


62
00:02:35,189 --> 00:02:37,124 line:-1
♪ All the part you see ♪


63
00:02:37.157 --> 00:02:38.892 line:-1 align:center
♪ You should be proud of...♪


64
00:02:38,926 --> 00:02:41,295 line:-1
[Jon sighs]


65
00:02:41,328 --> 00:02:42,729 line:-2
[Jon whispering]
This is good tea.


66
00:02:42,763 --> 00:02:45,132 line:-2
[Karun and Mombru]
♪ You're my baby, gee ♪


67
00:02:45,165 --> 00:02:47,367 line:-1
♪ You a cart, I see... ♪


68
00:02:47,401 --> 00:02:48,869 line:-1
[phone ringing]


69
00:02:48.902 --> 00:02:50.771 line:-2 align:center
[Karun and Mombru]
♪ How could this be? ♪


70
00:02:50,804 --> 00:02:51,839 line:-1
♪ How could this be?... ♪


71
00:02:51,872 --> 00:02:53,974 line:-1
[Jon] Hey, Siri. Stop.


72
00:02:54,007 --> 00:02:55,275 line:-1
[music ends]


73
00:02:55.309 --> 00:02:57.444 line:-1 align:center
Now it's reasonable to assume


74
00:02:57.477 --> 00:03:00.581 line:-2 align:center
that I collected some data for
each of these sound categories


75
00:03:00.614 --> 00:03:03.584 line:-2 align:center
and trained a custom model
using CreateML.


76
00:03:03.617 --> 00:03:06.286 line:-1 align:center
Yes, I could have done that,


77
00:03:06.320 --> 00:03:09.623 line:-2 align:center
but actually,
the classifier used is built-in.


78
00:03:09,656 --> 00:03:12,793 line:-2
New to this year,
we have a sound classifier


79
00:03:12.826 --> 00:03:15.629 line:-2 align:center
built right into the Sound
Analysis framework.


80
00:03:15.662 --> 00:03:17.531 line:-1 align:center
It's never been easier to enable


81
00:03:17,564 --> 00:03:19,633 line:-2
sound classification
in your app.


82
00:03:19,666 --> 00:03:22,002 line:-1
It's supported on all platforms.


83
00:03:24,605 --> 00:03:27,007 line:-2
The built-in classifier
is all about simplifying


84
00:03:27.040 --> 00:03:28.575 line:-1 align:center
the developer experience.


85
00:03:28,609 --> 00:03:31,111 line:0
It removes the need
for collecting and labeling


86
00:03:31,144 --> 00:03:32,980 align:center
massive amount of data,


87
00:03:33,013 --> 00:03:36,283 line:0
specialized machine learning
and audio expertise,


88
00:03:36,316 --> 00:03:37,918 align:center
and lots of compute power


89
00:03:37,951 --> 00:03:40,721 align:center
in order to develop
a high-accuracy model.


90
00:03:40,754 --> 00:03:43,624 line:0
The less time you have to worry
about these details,


91
00:03:43,657 --> 00:03:45,158 line:0
the more time you can spend


92
00:03:45,192 --> 00:03:47,995 line:0
enriching the user experience
in your app.


93
00:03:48.028 --> 00:03:49.963 line:-2 align:center
It only takes
a few lines of code


94
00:03:49,997 --> 00:03:52,499 line:-1
to enable sound classification.


95
00:03:52,533 --> 00:03:54,801 line:-2
I'll show you what
this classifier can do.


96
00:03:54.835 --> 00:03:58.405 line:-2 align:center
There's over 300 categories
for you to use.


97
00:03:58.438 --> 00:03:59.940 line:-1 align:center
Let's take a closer look.


98
00:04:00.807 --> 00:04:03.210 line:-2 align:center
We can classify sounds
of domestic animals,


99
00:04:03.243 --> 00:04:06.246 line:-2 align:center
livestock animals,
and wild animals.


100
00:04:09,750 --> 00:04:13,053 line:-2
For music, many instruments
can be recognized:


101
00:04:13,086 --> 00:04:15,189 line:-2
keyboard instruments,
percussion,


102
00:04:15.222 --> 00:04:18.625 line:-2 align:center
string instruments,
wind instruments.


103
00:04:18,659 --> 00:04:21,028 line:-2
We can detect
various human sounds:


104
00:04:21.061 --> 00:04:22.329 line:-1 align:center
group activities,


105
00:04:22,362 --> 00:04:25,265 line:-2
respiratory sounds,
vocalizations.


106
00:04:27,634 --> 00:04:30,003 line:-2
Then there's sounds
of things like vehicles,


107
00:04:30,037 --> 00:04:32,139 line:-1
alarms, tools, liquids,


108
00:04:32,172 --> 00:04:33,874 line:-1
and so much more.


109
00:04:33,907 --> 00:04:37,678 line:-2
These ready-to-use categories
are available for you to try.


110
00:04:37,711 --> 00:04:39,513 line:-2
I'm going to turn it over
to Kevin


111
00:04:39.546 --> 00:04:42.950 line:-2 align:center
to walk you through how to use
this sound classifier.


112
00:04:42,983 --> 00:04:44,318 line:-1
[Kevin] Thanks, Jon.


113
00:04:44,351 --> 00:04:46,520 line:-1
Hi, I'm Kevin,


114
00:04:46,553 --> 00:04:49,556 line:-2
a software engineer
on the Audio team.


115
00:04:49,590 --> 00:04:51,024 line:-1
I'd like to show you how to use


116
00:04:51.058 --> 00:04:53.360 line:-2 align:center
the new built-in
sound classifier


117
00:04:53,393 --> 00:04:56,430 line:-2
by taking a look
at a small application I built.


118
00:04:56,463 --> 00:04:57,931 line:-1
I was hoping Jon would show


119
00:04:57,965 --> 00:05:00,267 line:-2
how well the classifier works
with cowbell,


120
00:05:00.300 --> 00:05:02.369 line:-2 align:center
but since it didn't fit
in his demo,


121
00:05:02,402 --> 00:05:04,671 line:-1
I came up with another idea.


122
00:05:04,705 --> 00:05:07,574 line:-2
I have some media on my Mac
that I collected


123
00:05:07,608 --> 00:05:09,343 line:-2
while preparing
for this session,


124
00:05:09,376 --> 00:05:10,978 line:-1
and I'm pretty sure that I have


125
00:05:11,011 --> 00:05:13,614 line:-2
some old footage
containing cowbell.


126
00:05:13.647 --> 00:05:15.349 line:-1 align:center
I'd love to show it to you,


127
00:05:15.382 --> 00:05:18.952 line:-1 align:center
but first I have to find it.


128
00:05:18.986 --> 00:05:21.989 line:-2 align:center
This means I'll have to find
the right file,


129
00:05:22,022 --> 00:05:23,824 line:-1
and I'll have to look inside


130
00:05:23,857 --> 00:05:26,560 line:-1
to find just the right part.


131
00:05:26.593 --> 00:05:29.429 line:-1 align:center
So how will I do this?


132
00:05:29,463 --> 00:05:30,831 line:0
I'll write a simple program


133
00:05:30,864 --> 00:05:33,200 line:0
that uses the built-in
sound classifier


134
00:05:33,233 --> 00:05:35,369 align:center
to read a file and tell me


135
00:05:35,402 --> 00:05:38,138 line:0
whether a certain sound
is inside.


136
00:05:38,172 --> 00:05:39,806 align:center
If the sound is found,


137
00:05:39,840 --> 00:05:42,142 line:0
the program can use
the classifier


138
00:05:42,176 --> 00:05:45,179 line:0
to tell me the time
at which it occurred.


139
00:05:47,648 --> 00:05:49,683 align:center
I can then use Shortcuts,


140
00:05:49,716 --> 00:05:52,052 align:center
now available on macOS,


141
00:05:52,085 --> 00:05:53,587 line:0
to create a workflow


142
00:05:53,620 --> 00:05:57,357 align:center
that runs my program
over lots of files.


143
00:05:57,391 --> 00:05:59,526 line:0
When my program finds a sound,


144
00:05:59,560 --> 00:06:01,495 align:center
the workflow can automatically


145
00:06:01,528 --> 00:06:03,630 line:0
use the reported detection time


146
00:06:03,664 --> 00:06:07,234 line:0
to extract a video clip
containing the sound.


147
00:06:07,267 --> 00:06:10,237 line:0
This will work great
for finding a cowbell clip.


148
00:06:11.705 --> 00:06:13.640 line:-1 align:center
So let's see it in action.


149
00:06:15.075 --> 00:06:18.145 line:-2 align:center
Here, I have a folder
full of videos.


150
00:06:19,146 --> 00:06:20,747 line:-1
I'll select all the files


151
00:06:20.781 --> 00:06:24.284 line:-2 align:center
and kick off my shortcut
using the Quick Actions menu.


152
00:06:27,988 --> 00:06:30,757 line:-2
I'm asked to select the sound
that I'd like to find,


153
00:06:30,791 --> 00:06:34,595 line:-2
so from the list of options,
I'll choose Cowbell.


154
00:06:35,963 --> 00:06:38,398 line:-1
Now, my shortcut is running,


155
00:06:38,432 --> 00:06:40,567 line:-1
and after just a few moments,


156
00:06:40,601 --> 00:06:42,636 line:-2
it finds the sound
I'm looking for


157
00:06:42,669 --> 00:06:45,706 line:-2
and shows it to me
in a Finder window.


158
00:06:45,739 --> 00:06:47,708 line:-1
Let's take a look.


159
00:06:47,741 --> 00:06:52,779 line:-1
[cowbell jangling]


160
00:06:52,813 --> 00:06:54,581 line:-1
Looking good, Jon.


161
00:06:54.615 --> 00:06:57.784 line:-2 align:center
Let's take a closer look
at the shortcut that I used.


162
00:06:59.119 --> 00:07:00.854 line:-1 align:center
When my shortcut starts,


163
00:07:00,888 --> 00:07:02,856 line:-2
it collects a list
of all the sounds


164
00:07:02,890 --> 00:07:04,625 line:-1
that it can recognize,


165
00:07:04.658 --> 00:07:06.927 line:-1 align:center
and it asks me to pick one.


166
00:07:06,960 --> 00:07:10,030 line:-2
Using my choice,
it visits each of the files


167
00:07:10,063 --> 00:07:11,932 line:-1
that I selected in Finder


168
00:07:11,965 --> 00:07:15,068 line:-1
and looks for the sound inside.


169
00:07:15,102 --> 00:07:17,070 line:-1
When my sound is detected,


170
00:07:17,104 --> 00:07:19,806 line:0
it extracts a few seconds
from the video


171
00:07:19,840 --> 00:07:22,075 line:0
around the time
that the sound occurred


172
00:07:22,109 --> 00:07:25,312 align:center
and shows me the resulting clip.


173
00:07:25,345 --> 00:07:28,382 line:0
Of these steps,
two of them make use


174
00:07:28,415 --> 00:07:31,952 align:center
of the built-in classifier.


175
00:07:31,985 --> 00:07:34,054 align:center
These are the steps
that I implemented


176
00:07:34,087 --> 00:07:36,657 align:center
in my own custom application


177
00:07:36,690 --> 00:07:39,526 line:0
for Shortcuts to use on demand.


178
00:07:41,728 --> 00:07:44,698 align:center
Though I won't talk
about Shortcuts in more detail,


179
00:07:44,731 --> 00:07:46,767 align:center
if you're curious to learn more,


180
00:07:46,800 --> 00:07:49,670 line:0
please refer to the WWDC session


181
00:07:49,703 --> 00:07:52,873 line:0
entitled
"Meet Shortcuts for macOS."


182
00:07:53,874 --> 00:07:56,510 line:-2
Now let's look
at the implementation


183
00:07:56,543 --> 00:07:59,446 line:-1
for my app's two custom actions.


184
00:07:59,479 --> 00:08:02,416 line:-2
The first action reports
all of the sounds


185
00:08:02,449 --> 00:08:04,518 line:-1
that the app can recognize.


186
00:08:04,551 --> 00:08:07,654 line:-2
Since the app is using
the built-in sound classifier,


187
00:08:07.688 --> 00:08:11.525 line:-2 align:center
it can recognize
a few hundred sounds.


188
00:08:11,558 --> 00:08:14,995 line:-2
Here's a function I wrote
to get these sounds.


189
00:08:15.028 --> 00:08:18.198 line:-2 align:center
I create
an SNClassifySoundRequest


190
00:08:18,232 --> 00:08:21,435 line:-2
using a new initializer
that allows me to select


191
00:08:21.468 --> 00:08:24.104 line:-1 align:center
the built-in classifier.


192
00:08:24,137 --> 00:08:26,106 line:-1
Once I have this request,


193
00:08:26.139 --> 00:08:28.475 line:-2 align:center
I can use it to query
the list of sounds


194
00:08:28,509 --> 00:08:31,645 line:-1
that the classifier supports.


195
00:08:31.678 --> 00:08:34.348 line:-2 align:center
The app's second action
tells Shortcuts


196
00:08:34.381 --> 00:08:37.117 line:-2 align:center
when a sound is heard
within a file.


197
00:08:37,150 --> 00:08:40,420 line:-2
To implement this, I'll perform
sound classification


198
00:08:40,454 --> 00:08:42,789 line:-1
and report back the first time


199
00:08:42.823 --> 00:08:46.226 line:-2 align:center
that the sound is detected,
if it's detected at all.


200
00:08:46,260 --> 00:08:48,428 line:-1
To perform sound classification,


201
00:08:48,462 --> 00:08:51,765 line:-2
I'll need to prepare
three objects.


202
00:08:51,798 --> 00:08:55,569 line:-2
First, I'll need
an SNClassifySoundRequest,


203
00:08:55,602 --> 00:08:59,072 line:-2
which I can use to configure
sound classification.


204
00:08:59,106 --> 00:09:03,043 line:-2
Second, I'll need
an SNAudioFileAnalyzer,


205
00:09:03,076 --> 00:09:05,212 line:-2
which will let me
target classification


206
00:09:05,245 --> 00:09:07,981 line:-1
toward a particular file.


207
00:09:08,015 --> 00:09:10,184 line:-1
The third object will require


208
00:09:10,217 --> 00:09:12,252 line:-1
a little extra attention.


209
00:09:12,286 --> 00:09:15,189 line:-2
I'll need to define
my own Observer type,


210
00:09:15,222 --> 00:09:18,225 line:-2
which will handle the results
of classification.


211
00:09:18.258 --> 00:09:20.360 line:-1 align:center
Skipping the Observer for now,


212
00:09:20,394 --> 00:09:24,131 line:-2
here's some code for preparing
the first two of these objects.


213
00:09:25.465 --> 00:09:28.902 line:-2 align:center
I can create
the SNClassifySoundRequest


214
00:09:28.936 --> 00:09:31.538 line:-1 align:center
using the built-in classifier,


215
00:09:31,572 --> 00:09:34,875 line:-2
and I can create
an SNAudioFileAnalyzer


216
00:09:34.908 --> 00:09:38.245 line:-2 align:center
using a URL to the file
I want to classify.


217
00:09:38,946 --> 00:09:42,783 line:-2
If, at this point,
I had an Observer ready to go,


218
00:09:42,816 --> 00:09:46,253 line:-2
it would be easy to start
sound classification,


219
00:09:46.286 --> 00:09:50.157 line:-2 align:center
but defining that Observer
is the missing piece.


220
00:09:50.190 --> 00:09:52.125 line:-1 align:center
So let's do that.


221
00:09:52.159 --> 00:09:54.928 line:-2 align:center
I'm starting here
with a bare Observer


222
00:09:54,962 --> 00:09:56,964 line:-1
that inherits from NSObject


223
00:09:56,997 --> 00:10:00,367 line:-2
and conforms to the
SNResultsObserving protocol.


224
00:10:01,235 --> 00:10:03,203 line:-1
I'll initialize instances


225
00:10:03,237 --> 00:10:05,606 line:-2
with the sound label
I want to search for,


226
00:10:05,639 --> 00:10:08,408 line:-2
and I'll add
a CMTime member variable


227
00:10:08.442 --> 00:10:11.778 line:-2 align:center
to store the time
at which I detect the sound.


228
00:10:11.812 --> 00:10:14.681 line:-2 align:center
I just need
to implement the request:


229
00:10:14.715 --> 00:10:18.318 line:-1 align:center
didProduce result method.


230
00:10:18,352 --> 00:10:21,655 line:-2
This method will be called
when results are produced


231
00:10:21,688 --> 00:10:23,457 line:-1
by sound classification,


232
00:10:23,490 --> 00:10:25,692 line:-1
so I expect to receive instances


233
00:10:25,726 --> 00:10:29,162 line:-1
of SNClassificationResult.


234
00:10:29,196 --> 00:10:32,299 line:-2
I can use
the classificationForIdentifier


235
00:10:32,332 --> 00:10:35,636 line:-2
method of the result
to extract information


236
00:10:35,669 --> 00:10:39,339 line:-2
about the label
that I'm searching for.


237
00:10:39,373 --> 00:10:42,976 line:-2
I'll query the confidence score
associated with the label,


238
00:10:43,010 --> 00:10:45,913 line:-2
and if that score exceeds
a certain threshold,


239
00:10:45.946 --> 00:10:49.616 line:-2 align:center
I'll consider the sound
to be detected.


240
00:10:49,650 --> 00:10:52,486 line:-2
When I notice the detection
for the first time,


241
00:10:52,519 --> 00:10:55,255 line:-2
I'll save the time
at which the sound occurred


242
00:10:55,289 --> 00:10:58,292 line:-2
so that I can provide it
to Shortcuts later.


243
00:10:59,393 --> 00:11:02,029 line:-2
With that,
my Observer is complete,


244
00:11:02.062 --> 00:11:03.964 line:-1 align:center
and I have all the pieces needed


245
00:11:03.997 --> 00:11:07.568 line:-2 align:center
to determine when a sound occurs
within a file.


246
00:11:07.601 --> 00:11:10.437 line:-2 align:center
This example touches
on two important topics


247
00:11:10,470 --> 00:11:12,472 line:-2
that I'd like
to discuss further.


248
00:11:12.506 --> 00:11:15.642 line:-2 align:center
First, I'll talk
about time of detection,


249
00:11:15,676 --> 00:11:19,179 line:-2
and then I'll talk
about detection thresholds.


250
00:11:20,747 --> 00:11:24,251 line:-2
Let's start
with time of detection.


251
00:11:24.284 --> 00:11:26.220 line:-1 align:center
When you classify audio,


252
00:11:26.253 --> 00:11:29.790 line:-2 align:center
the signal gets broken up
into overlapping windows.


253
00:11:30,657 --> 00:11:32,526 line:-1
For each of these windows,


254
00:11:32,559 --> 00:11:33,861 line:-1
you'll get a result


255
00:11:33.894 --> 00:11:36.163 line:-2 align:center
that tells you
what sounds were detected


256
00:11:36,196 --> 00:11:38,432 line:-1
and how confidently.


257
00:11:38.465 --> 00:11:40.934 line:-1 align:center
You'll also get a time range,


258
00:11:40,968 --> 00:11:42,636 line:-1
which tells you what part


259
00:11:42.669 --> 00:11:45.205 line:-1 align:center
of the audio was classified.


260
00:11:45.239 --> 00:11:48.041 line:-2 align:center
In my app,
when I detect a sound,


261
00:11:48.075 --> 00:11:50.210 line:-1 align:center
I use the result's time range


262
00:11:50.244 --> 00:11:52.312 line:-2 align:center
to determine
when the sound occurred.


263
00:11:52.346 --> 00:11:54.381 line:-2 align:center
But the time range
can be impacted


264
00:11:54,414 --> 00:11:56,984 line:-2
when the duration
of a window changes.


265
00:11:57,017 --> 00:11:59,319 line:-2
You can customize
the window duration


266
00:11:59.353 --> 00:12:02.022 line:-1 align:center
to make it big or small


267
00:12:02,055 --> 00:12:04,057 line:-1
based on your use case.


268
00:12:06.260 --> 00:12:09.897 line:-2 align:center
Short windows work well
when working with short sounds,


269
00:12:09.930 --> 00:12:12.332 line:-1 align:center
like a drum tap.


270
00:12:12.366 --> 00:12:14.468 line:-1 align:center
This is because you can capture


271
00:12:14.501 --> 00:12:16.770 line:-2 align:center
all the important features
of that sound


272
00:12:16,803 --> 00:12:19,373 line:-1
within a small window of time.


273
00:12:19.406 --> 00:12:21.608 line:-1 align:center
The small window doesn't cut out


274
00:12:21.642 --> 00:12:23.477 line:-1 align:center
any important information.


275
00:12:23.510 --> 00:12:26.413 line:-2 align:center
The advantage of using
a small window duration


276
00:12:26.446 --> 00:12:28.916 line:-2 align:center
is that it allows you
to more closely pinpoint


277
00:12:28.949 --> 00:12:31.652 line:-2 align:center
the moment at which
a sound occurred.


278
00:12:33.020 --> 00:12:35.989 line:-2 align:center
But small window durations
may not be appropriate


279
00:12:36.023 --> 00:12:38.559 line:-1 align:center
when working with longer sounds.


280
00:12:38,592 --> 00:12:40,627 line:-1
A siren, for example,


281
00:12:40.661 --> 00:12:43.997 line:-2 align:center
may contain both rising
and falling pitches


282
00:12:44.031 --> 00:12:46.433 line:-1 align:center
over a longer period of time.


283
00:12:46.466 --> 00:12:50.070 line:-2 align:center
Capturing all of these pitches
together in a single window


284
00:12:50.103 --> 00:12:52.105 line:-1 align:center
can help sound classification


285
00:12:52.139 --> 00:12:54.474 line:-1 align:center
correctly detect the sound.


286
00:12:54,508 --> 00:12:57,477 line:-2
In general, it's good
to use a window duration


287
00:12:57.511 --> 00:13:00.480 line:-2 align:center
long enough to capture
all the important parts


288
00:13:00.514 --> 00:13:02.583 line:-2 align:center
of the sounds
that you're interested in.


289
00:13:02.616 --> 00:13:05.419 line:-2 align:center
If you'd like to edit
the window duration,


290
00:13:05,452 --> 00:13:07,688 line:-2
you can set
the windowDuration property


291
00:13:07.721 --> 00:13:10.691 line:-1 align:center
of SNClassifySoundRequest.


292
00:13:10.724 --> 00:13:12.059 line:-1 align:center
Note, though,


293
00:13:12.092 --> 00:13:15.028 line:-2 align:center
that not all window durations
are supported.


294
00:13:16,230 --> 00:13:18,398 line:-2
Different classifiers
might support


295
00:13:18,432 --> 00:13:20,467 line:-1
different window durations.


296
00:13:20.501 --> 00:13:22.970 line:-2 align:center
You can check what
window durations are supported


297
00:13:23,003 --> 00:13:25,405 line:-2
by reading
the windowDurationConstraint


298
00:13:25.439 --> 00:13:28.442 line:-2 align:center
property
of SNClassifySoundRequest.


299
00:13:28.475 --> 00:13:31.612 line:-2 align:center
The built-in classifier
supports window durations


300
00:13:31.645 --> 00:13:34.882 line:-2 align:center
between 1/2 second long
and 15 seconds long.


301
00:13:34,915 --> 00:13:37,784 line:-2
A duration of one second
or longer


302
00:13:37.818 --> 00:13:39.353 line:-1 align:center
is a great starting point


303
00:13:39.386 --> 00:13:42.189 line:-2 align:center
when adopting the classifier
in your app.


304
00:13:43,857 --> 00:13:47,628 line:-2
Let's talk next
about confidence thresholds.


305
00:13:47.661 --> 00:13:51.398 line:-2 align:center
In my app, I considered
a sound to be detected


306
00:13:51,431 --> 00:13:54,168 line:0
any time the confidence
for that sound rose


307
00:13:54,201 --> 00:13:56,570 align:center
above a fixed threshold.


308
00:13:56,603 --> 00:14:00,474 align:center
I chose a value of 0.5
for my threshold,


309
00:14:00,507 --> 00:14:02,276 line:0
but there are some things
to consider


310
00:14:02,309 --> 00:14:05,712 align:center
when choosing a threshold
for your own app.


311
00:14:05,746 --> 00:14:07,548 line:0
The classifier can detect


312
00:14:07,581 --> 00:14:10,150 align:center
multiple sounds
at the same time.


313
00:14:10,184 --> 00:14:12,786 line:0
When this happens,
you may notice


314
00:14:12,819 --> 00:14:16,256 align:center
that several labels score
with high confidence.


315
00:14:17,858 --> 00:14:21,795 align:center
Unlike when using a custom model
trained using CreateML,


316
00:14:21,828 --> 00:14:24,231 line:0
label scores do not add up


317
00:14:24,264 --> 00:14:26,200 align:center
to a value of one.


318
00:14:26,233 --> 00:14:28,335 line:0
The confidences are independent


319
00:14:28,368 --> 00:14:31,205 line:0
and shouldn't be compared
against one another.


320
00:14:32.973 --> 00:14:35.442 line:-2 align:center
Because confidence scores
are independent,


321
00:14:35,475 --> 00:14:37,644 line:-1
you may find it useful to choose


322
00:14:37.678 --> 00:14:41.481 line:-2 align:center
different confidence thresholds
for different sounds.


323
00:14:42,082 --> 00:14:44,918 align:center
Choosing a threshold
involves a tradeoff.


324
00:14:44,952 --> 00:14:48,388 align:center
A higher confidence threshold
reduces the probability


325
00:14:48,422 --> 00:14:50,991 align:center
that a sound will be
falsely detected,


326
00:14:51,024 --> 00:14:53,527 line:0
but it also increases
the probability


327
00:14:53,560 --> 00:14:55,696 line:0
that a true detection
will be missed


328
00:14:55,729 --> 00:14:58,098 line:0
because it wasn't strong enough.


329
00:14:58.131 --> 00:15:01.101 line:-2 align:center
When you select a threshold
for your application,


330
00:15:01.134 --> 00:15:03.237 line:-2 align:center
you'll need to find
a value that achieves


331
00:15:03.270 --> 00:15:06.673 line:-2 align:center
the right balance of these
factors for your use case.


332
00:15:06.707 --> 00:15:09.009 line:-2 align:center
Note that confidence scores
may change


333
00:15:09,042 --> 00:15:11,445 line:-2
when you set
a custom window duration,


334
00:15:11,478 --> 00:15:15,048 line:-2
so this can impact
your thresholds as well.


335
00:15:15,082 --> 00:15:17,518 line:-1
One final thing to keep in mind


336
00:15:17.551 --> 00:15:19.419 line:-2 align:center
when using
the built-in classifier


337
00:15:19,453 --> 00:15:21,955 line:-1
is that some sounds are similar.


338
00:15:21,989 --> 00:15:25,659 align:center
Among the large number of sounds
that the classifier can identify


339
00:15:25,692 --> 00:15:28,161 line:0
are several groups of sounds
that can be difficult


340
00:15:28,195 --> 00:15:30,464 align:center
to differentiate
using audio alone,


341
00:15:30,497 --> 00:15:32,232 line:0
even for a human.


342
00:15:32,266 --> 00:15:35,269 line:0
Where possible,
it's best to be selective


343
00:15:35.302 --> 00:15:38.805 line:-2 align:center
about the sounds
that you pay attention to.


344
00:15:38.839 --> 00:15:41.275 line:-2 align:center
You should try to watch
only for sounds


345
00:15:41.308 --> 00:15:43.844 line:-2 align:center
that are likely to occur
in the contexts


346
00:15:43.877 --> 00:15:45.979 line:-1 align:center
where your app will be used.


347
00:15:46.013 --> 00:15:48.582 line:-2 align:center
With that,
let's turn back to Jon


348
00:15:48,615 --> 00:15:51,151 line:-2
to learn about
what's new in CreateML


349
00:15:51.185 --> 00:15:53.287 line:-1 align:center
regarding sound classification.


350
00:15:53.320 --> 00:15:55.656 line:-2 align:center
[Jon] Thanks, Kevin,
for that great example.


351
00:15:55,689 --> 00:15:58,425 line:-2
I'm glad you had fun
with that cowbell video.


352
00:15:58,458 --> 00:16:01,094 line:-2
Now let me show you
what's new in CreateML


353
00:16:01.128 --> 00:16:02.629 line:-1 align:center
or, specifically,


354
00:16:02,663 --> 00:16:05,132 line:-2
how you can improve
your custom models


355
00:16:05,165 --> 00:16:08,335 line:-2
by leveraging the power
of the built-in classifier.


356
00:16:08,368 --> 00:16:11,305 line:-2
The built-in classifier
was trained with a ton of data


357
00:16:11,338 --> 00:16:13,574 line:-2
across a vast number
of categories.


358
00:16:13.607 --> 00:16:16.643 line:-2 align:center
So the model actually contains
a lot of knowledge


359
00:16:16.677 --> 00:16:18.545 line:-1 align:center
about sound classification.


360
00:16:18,579 --> 00:16:20,714 line:-2
All this knowledge
can be utilized


361
00:16:20,747 --> 00:16:24,318 line:-2
for the training of your
custom model using CreateML.


362
00:16:24.351 --> 00:16:26.386 line:-1 align:center
I'll show you how this works.


363
00:16:26,420 --> 00:16:28,422 line:-2
The sound classifier
can be separated


364
00:16:28,455 --> 00:16:30,324 line:-1
into two different networks.


365
00:16:30.357 --> 00:16:32.759 line:-2 align:center
The first part is
the feature extractor,


366
00:16:32.793 --> 00:16:36.129 line:-2 align:center
and the second part is
the classifier model.


367
00:16:36.163 --> 00:16:37.598 line:-1 align:center
The feature extractor,


368
00:16:37.631 --> 00:16:39.933 line:-2 align:center
sometimes known
as the embedding model,


369
00:16:39.967 --> 00:16:41.768 line:-1 align:center
is the backbone of the network.


370
00:16:41.802 --> 00:16:44.972 line:-2 align:center
It takes an audio waveform
and transforms it


371
00:16:45,005 --> 00:16:47,441 line:-1
into a low-dimensional space.


372
00:16:47,474 --> 00:16:49,243 line:-1
A well-trained feature extractor


373
00:16:49,276 --> 00:16:51,345 line:-2
organizes acoustically
similar sounds


374
00:16:51,378 --> 00:16:54,014 line:-2
into nearby locations
in the space.


375
00:16:55.415 --> 00:16:57.317 line:-1 align:center
For example,


376
00:16:57.351 --> 00:16:59.887 line:-2 align:center
sounds of guitar
would cluster together


377
00:16:59.920 --> 00:17:03.056 line:-2 align:center
but are placed away
from drum and car sounds.


378
00:17:04.124 --> 00:17:06.126 line:-2 align:center
Now, the second part
of this pipeline


379
00:17:06.159 --> 00:17:07.861 line:-1 align:center
is the classifier model.


380
00:17:07.895 --> 00:17:10.631 line:-2 align:center
It takes the output
of the feature extractor


381
00:17:10.664 --> 00:17:13.500 line:-2 align:center
and computes
the class probabilities.


382
00:17:13.534 --> 00:17:15.736 line:-2 align:center
The classifier benefits
from being paired


383
00:17:15.769 --> 00:17:17.538 line:-1 align:center
with a good feature extractor,


384
00:17:17.571 --> 00:17:21.074 line:-2 align:center
like the one we have embedded
into the built-in classifier.


385
00:17:22.109 --> 00:17:23.710 line:-2 align:center
We're making
the built-in classifier's


386
00:17:23,744 --> 00:17:26,146 line:-2
feature extractor
available to you.


387
00:17:26.180 --> 00:17:28.749 line:-2 align:center
It is called
Audio Feature Print.


388
00:17:28,782 --> 00:17:31,919 line:-2
When you train your own
custom model in CreateML,


389
00:17:31.952 --> 00:17:35.088 line:-2 align:center
your model will be paired
with Audio Feature Print.


390
00:17:35.122 --> 00:17:37.357 line:-1 align:center
With this, your model benefits


391
00:17:37.391 --> 00:17:40.761 line:-2 align:center
from all the knowledge contained
in the built-in classifier.


392
00:17:40,794 --> 00:17:43,797 line:-2
Compared to the previous
generation feature extractor,


393
00:17:43,830 --> 00:17:47,601 line:-2
Audio Feature Print has
improvements across the board.


394
00:17:47.634 --> 00:17:50.537 line:-2 align:center
Even though this network
is smaller and faster,


395
00:17:50,571 --> 00:17:52,739 line:-1
it achieves higher accuracy


396
00:17:52,773 --> 00:17:56,109 line:-2
on all benchmark data sets
we compared against.


397
00:17:56.143 --> 00:17:58.378 line:-2 align:center
And like
the built-in classifier,


398
00:17:58,412 --> 00:18:01,014 line:-2
models using
Audio Feature Print support


399
00:18:01,048 --> 00:18:02,883 line:-1
a flexible window duration.


400
00:18:02,916 --> 00:18:05,552 line:-2
You can select a long
window duration to optimize


401
00:18:05.586 --> 00:18:07.187 line:-1 align:center
for sounds like sirens


402
00:18:07,221 --> 00:18:10,991 line:-2
or a short window duration
for sounds like drum taps.


403
00:18:11.024 --> 00:18:14.494 line:-2 align:center
Audio Feature Print is the new
default feature extractor


404
00:18:14,528 --> 00:18:17,364 line:-2
when you train a custom model
using CreateML.


405
00:18:18.599 --> 00:18:20.968 line:-2 align:center
The Window duration is
the length of audio used


406
00:18:21,001 --> 00:18:24,404 line:-2
to generate a single
feature while training.


407
00:18:24.438 --> 00:18:26.273 line:-1 align:center
It defaults to three seconds,


408
00:18:26.306 --> 00:18:29.142 line:-2 align:center
but you can adjust it
to suit your needs.


409
00:18:29,176 --> 00:18:31,845 line:-2
CreateML gives you
the option to select


410
00:18:31,879 --> 00:18:35,816 line:-2
a window duration between
1/2 second to 15 seconds.


411
00:18:35,849 --> 00:18:39,086 line:-2
For a more detailed example
of training a custom model,


412
00:18:39,119 --> 00:18:41,488 align:center
you can check out
the 2019 session


413
00:18:41,522 --> 00:18:43,357 line:0
on "Training Sound
Classification Models


414
00:18:43,390 --> 00:18:44,925 line:0
in CreateML."


415
00:18:44,958 --> 00:18:47,828 line:0
It also shows you how to use
the Sound Analysis Framework


416
00:18:47,861 --> 00:18:49,196 align:center
to run the custom model.


417
00:18:49,196 --> 00:18:50,364 line:0
Thanks for joining us


418
00:18:50.397 --> 00:18:52.299 line:-2 align:center
in the session
on Sound Analysis.


419
00:18:52.332 --> 00:18:55.435 line:-2 align:center
Today, we introduced
a powerful new sound classifier


420
00:18:55,469 --> 00:18:56,937 line:-1
built into the OS.


421
00:18:56.970 --> 00:18:58.705 line:-1 align:center
Along with it,


422
00:18:58.739 --> 00:19:01.742 line:-2 align:center
we've upgraded the feature
extractor in CreateML.


423
00:19:01.775 --> 00:19:04.011 line:-2 align:center
These will unlock
new possibilities,


424
00:19:04,044 --> 00:19:07,347 line:-2
and we can't wait to see what
you'll do with them in your app.


425
00:19:07.381 --> 00:19:10.117 line:-1 align:center
Enjoy the rest of WWDC.


426
00:19:10,150 --> 00:19:13,020 align:center
[upbeat music]

