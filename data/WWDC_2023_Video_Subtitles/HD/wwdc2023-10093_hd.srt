2
00:00:00.033 --> 00:00:03.003 line:-1 position:50%
♪ Mellow instrumental hip-hop ♪


3
00:00:03,003 --> 00:00:10,444 line:0 position:90% align:right
♪


4
00:00:10.444 --> 00:00:12.212 line:-1 position:50%
Christopher Figueroa:
Hello, I'm Christopher Figueroa


5
00:00:12.212 --> 00:00:14.047 line:-1 position:50%
from the ARKit team at Apple.


6
00:00:14,047 --> 00:00:16,683 line:-1
Peter Kuhn:
And I'm Peter Kuhn from Unity.


7
00:00:16.683 --> 00:00:19.019 line:-1 position:50%
Christopher: Unity has brought
their engine and XR ecosystem


8
00:00:19,019 --> 00:00:20,454 line:-1
to this new platform,


9
00:00:20.454 --> 00:00:23.123 line:-1 position:50%
making it simple for a Unity
developer like yourself


10
00:00:23,123 --> 00:00:25,826 line:-1
to easily bring
your project over.


11
00:00:25,826 --> 00:00:27,427 line:0
Peter and I will show you
how to build


12
00:00:27,427 --> 00:00:30,597 line:0
a fully immersive experience,
like Rec Room here,


13
00:00:30,597 --> 00:00:33,500 line:0
using Unity workflows
you're already familiar with.


14
00:00:33,500 --> 00:00:35,602 line:0
You'll start by creating
an Immersive Space


15
00:00:35,602 --> 00:00:37,838 line:0
with a Full Immersive style.


16
00:00:37,838 --> 00:00:39,606 line:0
This allows your app
to hide passthrough


17
00:00:39,606 --> 00:00:42,943 position:50%
and transport someone
to another world.


18
00:00:42.943 --> 00:00:44.678 line:-1 position:50%
In a fully immersive experience,


19
00:00:44,678 --> 00:00:47,014 line:-1
Unity utilizes
Compositor Services,


20
00:00:47,014 --> 00:00:50,384 line:-1
and gives your app the power
of Metal rendering capabilities.


21
00:00:50.384 --> 00:00:52.452 line:-1 position:50%
Unity also takes
advantage of ARKit


22
00:00:52,452 --> 00:00:55,122 line:-1
to recognize your body position
and the surroundings,


23
00:00:55,122 --> 00:00:58,392 line:-1
including skeletal
hand tracking.


24
00:00:58.392 --> 00:01:00.327 line:-1 position:50%
Unity builds upon
these technologies


25
00:01:00,327 --> 00:01:04,131 line:-1
to provide the same services
in the Unity Engine.


26
00:01:04,131 --> 00:01:05,332 line:-1
There are two main approaches


27
00:01:05,332 --> 00:01:06,733 line:-1
for creating immersive
experiences


28
00:01:06,733 --> 00:01:08,702 line:-1
on this platform with Unity.


29
00:01:08,702 --> 00:01:10,537 line:-1
You can bring a fully
immersive Unity experience


30
00:01:10.537 --> 00:01:12.239 line:-1 position:50%
to this platform,
replacing the player's


31
00:01:12.239 --> 00:01:14.341 line:-1 position:50%
surroundings with
your own environments.


32
00:01:14.341 --> 00:01:17.044 line:-1 position:50%
Or you can mix your content
with passthrough


33
00:01:17,044 --> 00:01:19,279 line:-1
to create immersive experiences
that blend in


34
00:01:19,279 --> 00:01:21,315 line:-1
with their surroundings.


35
00:01:21,315 --> 00:01:23,216 position:50%
If you're interested
in the second approach,


36
00:01:23,216 --> 00:01:27,754 line:0
I recommend you check out
"Create immersive Unity apps."


37
00:01:27,754 --> 00:01:30,657 line:-1
Now, Peter will go over how
these new Apple technologies


38
00:01:30,657 --> 00:01:33,427 line:-1
help Unity developers bring
fully immersive VR games


39
00:01:33,427 --> 00:01:35,195 line:-1
to this platform.


40
00:01:35,195 --> 00:01:37,164 line:-1
Peter: Thanks, Christopher.


41
00:01:37.164 --> 00:01:39.266 line:-1 position:50%
First, I wanted to start off
by showing you Rec Room


42
00:01:39,266 --> 00:01:40,867 line:-1
from Against Gravity.


43
00:01:40,867 --> 00:01:43,303 line:-1
It's a popular VR social
platform that allows users


44
00:01:43.303 --> 00:01:45.539 line:-1 position:50%
to create and play games
and experiences with others


45
00:01:45,539 --> 00:01:47,240 line:-1
from around the world.


46
00:01:47,240 --> 00:01:48,909 line:-1
It's built on the Unity
game engine,


47
00:01:48.909 --> 00:01:50.944 line:-1 position:50%
which provides a powerful
and flexible platform


48
00:01:50,944 --> 00:01:52,846 line:-1
for game development.


49
00:01:52,846 --> 00:01:55,282 line:-1
I'll introduce you to some
of those tools and technologies


50
00:01:55.282 --> 00:01:57.651 line:-1 position:50%
that will to make it easier
for you to bring your VR content


51
00:01:57,651 --> 00:02:00,854 line:-1
to this new platform,
just like Rec Room.


52
00:02:00,854 --> 00:02:03,357 line:-1
I'll tell you about some things
to keep in mind when planning


53
00:02:03,357 --> 00:02:06,626 line:-1
to bring your Unity content
to this new platform.


54
00:02:06,626 --> 00:02:09,262 line:-1
First I'll cover the workflow
you'll use to deploy content


55
00:02:09,262 --> 00:02:12,132 line:-1
from Unity to the device.


56
00:02:12,132 --> 00:02:14,034 line:-1
There are a few things
you'll need to keep in mind


57
00:02:14.034 --> 00:02:17.237 line:-1 position:50%
related to graphics
on this platform.


58
00:02:17.237 --> 00:02:20.073 line:-1 position:50%
And finally, I'll talk about how
to adapt controller inputs


59
00:02:20,073 --> 00:02:22,109 line:-1
to hand input,
and some of the tools


60
00:02:22.109 --> 00:02:25.545 line:-1 position:50%
that Unity provides to help
with this transition.


61
00:02:25,545 --> 00:02:27,814 line:-1
To start, there's a build
and run workflow


62
00:02:27.814 --> 00:02:31.451 line:-1 position:50%
that you should already
be familiar with.


63
00:02:31,451 --> 00:02:33,820 line:-1
We've built full support
for this platform into Unity,


64
00:02:33,820 --> 00:02:35,989 line:-1
so you can see your projects
running on this device


65
00:02:35,989 --> 00:02:37,758 line:-1
in just a few steps.


66
00:02:37,758 --> 00:02:40,994 line:-1
The first is to select the build
target for this platform.


67
00:02:40.994 --> 00:02:43.697 line:-1 position:50%
Then, like you would
for any other VR platform,


68
00:02:43,697 --> 00:02:46,400 line:-1
enable the XR Plug-in.


69
00:02:46,400 --> 00:02:48,335 line:-1
If your app relies
on native plug-ins,


70
00:02:48.335 --> 00:02:50.670 line:-1 position:50%
they'll need to be recompiled
for this platform.


71
00:02:50,670 --> 00:02:52,139 line:-1
On the other hand,
if you are using


72
00:02:52,139 --> 00:02:57,110 line:-1
raw source code or .mm files,
you're already good to go.


73
00:02:57.110 --> 00:03:00.347 line:-1 position:50%
Building from Unity will now
generate an Xcode project,


74
00:03:00,347 --> 00:03:04,951 line:-1
just like it does for an iOS,
Mac, or Apple TV target.


75
00:03:04.951 --> 00:03:07.120 line:-1 position:50%
Then, from within Xcode,
you can build and run


76
00:03:07.120 --> 00:03:09.456 line:-1 position:50%
to either the device
or the device simulator


77
00:03:09,456 --> 00:03:12,926 line:-1
for faster iteration.


78
00:03:12.926 --> 00:03:14.761 line:-1 position:50%
The graphics pipeline
you'll use to transform


79
00:03:14,761 --> 00:03:17,764 line:-1
someone's surroundings into
a fully immersive experience


80
00:03:17,764 --> 00:03:20,734 line:-1
is likely to be familiar
to you as well.


81
00:03:20,734 --> 00:03:22,536 line:-1
But there are a few new concepts
that are important


82
00:03:22,536 --> 00:03:24,738 line:-1
to understand.


83
00:03:24.738 --> 00:03:26.973 line:-1 position:50%
One choice every project
makes right in the beginning


84
00:03:26.973 --> 00:03:29.409 line:-1 position:50%
is which rendering pipeline
to use.


85
00:03:29,409 --> 00:03:32,579 line:-1
The Universal Render Pipeline
is an ideal choice.


86
00:03:32,579 --> 00:03:35,415 line:-1
It enables a special feature
unique to this platform


87
00:03:35.415 --> 00:03:37.751 line:-1 position:50%
called Foveated Rendering.


88
00:03:41,388 --> 00:03:42,789 position:50%
Foveated Rendering
is a technique


89
00:03:42,789 --> 00:03:45,225 line:0
that concentrates more pixel
density in the center


90
00:03:45,225 --> 00:03:48,628 position:50%
of each lens where the eyes
are likely to be focused,


91
00:03:48,628 --> 00:03:50,997 position:50%
and less detail on
the peripherals of the screen


92
00:03:50,997 --> 00:03:53,400 line:0
where the eyes are
less sensitive to detail.


93
00:03:53,400 --> 00:03:55,435 position:50%
This results in a much
higher-quality experience


94
00:03:55,435 --> 00:03:58,672 line:0
for the person
using the device.


95
00:03:58,672 --> 00:04:00,874 line:-1
When you use
the Universal Render Pipeline,


96
00:04:00,874 --> 00:04:02,409 line:-1
Static Foveated Rendering
is applied


97
00:04:02,409 --> 00:04:04,544 line:-1
throughout the entire pipeline.


98
00:04:04.544 --> 00:04:06.413 line:-1 position:50%
And it works with
all URP features,


99
00:04:06.413 --> 00:04:11.151 line:-1 position:50%
including post-processing,
camera stacking, HDR, and more.


100
00:04:11,151 --> 00:04:13,053 line:-1
If you have custom render passes
that would benefit


101
00:04:13,053 --> 00:04:16,890 line:-1
from Foveated Rendering,
there are new APIs in Unity 2022


102
00:04:16,890 --> 00:04:19,392 line:-1
that can take advantage
of this technology.


103
00:04:19.392 --> 00:04:22.195 line:-1 position:50%
Since rendering now happens
in a nonlinear space,


104
00:04:22,195 --> 00:04:26,333 line:-1
there are also shader macros
to handle that remapping.


105
00:04:26.333 --> 00:04:28.335 line:-1 position:50%
Taking advantage
of Static Foveated Rendering


106
00:04:28,335 --> 00:04:30,470 line:-1
means you'll spend resources
on the pixels that matter


107
00:04:30.470 --> 00:04:34.941 line:-1 position:50%
and produce a higher-quality
visual experience.


108
00:04:34,941 --> 00:04:37,244 line:-1
Another way to optimize
your graphics on this platform


109
00:04:37,244 --> 00:04:40,180 line:-1
is by using Single-Pass
Instanced Rendering.


110
00:04:40,180 --> 00:04:42,449 line:-1
In Unity, Single-Pass
Instanced Rendering


111
00:04:42.449 --> 00:04:44.518 line:-1 position:50%
now supports
the Metal graphics API,


112
00:04:44,518 --> 00:04:47,787 line:-1
and it will be enabled
by default.


113
00:04:47.787 --> 00:04:49.856 line:-1 position:50%
With Single-Pass
Instanced Rendering,


114
00:04:49,856 --> 00:04:52,626 line:-1
the engine submits only
one draw call for both eyes,


115
00:04:52,626 --> 00:04:54,261 line:-1
and reduces the overhead
of certain parts


116
00:04:54.261 --> 00:04:56.930 line:-1 position:50%
of the rendering pipeline
like culling and shadows.


117
00:04:56.930 --> 00:05:01.501 line:-1 position:50%
This reduces the CPU overhead of
rendering your scenes in stereo.


118
00:05:01,501 --> 00:05:04,004 line:-1
The good news is, if your app
already renders correctly


119
00:05:04,004 --> 00:05:08,074 line:-1
on other VR platforms using
Single-Pass Instanced Rendering,


120
00:05:08.074 --> 00:05:12.379 line:-1 position:50%
shader macros ensure
it should work here as well.


121
00:05:12,379 --> 00:05:14,414 line:-1
There's one last thing
to consider.


122
00:05:14,414 --> 00:05:16,183 line:-1
Make sure your app
is writing to the depth buffer


123
00:05:16.183 --> 00:05:18.218 line:-1 position:50%
for every pixel correctly.


124
00:05:18.218 --> 00:05:21.588 line:-1 position:50%
The system compositor uses the
depth buffer for reprojection.


125
00:05:21,588 --> 00:05:23,356 line:-1
Wherever the depth information
is missing,


126
00:05:23.356 --> 00:05:27.394 line:-1 position:50%
the system will render
an error color as an indication.


127
00:05:27,394 --> 00:05:30,697 line:-1
One example is the skybox which
normally is infinitely far away


128
00:05:30.697 --> 00:05:34.868 line:-1 position:50%
from the user, so it writes
a depth of zero with reverse Z.


129
00:05:34.868 --> 00:05:38.138 line:-1 position:50%
This requires modification
to appear on the device.


130
00:05:38.138 --> 00:05:39.706 line:-1 position:50%
We've fixed all
of Unity's shaders


131
00:05:39.706 --> 00:05:42.776 line:-1 position:50%
to write correct values
to the depth buffer,


132
00:05:42.776 --> 00:05:46.112 line:-1 position:50%
but if you have any custom
effects such as a custom skybox,


133
00:05:46.112 --> 00:05:49.216 line:-1 position:50%
or perhaps a water effect
or transparency effects,


134
00:05:49,216 --> 00:05:53,587 line:-1
ensure that some value is
written to depth for each pixel.


135
00:05:53,587 --> 00:05:55,855 line:-1
Now that you've rendered
your graphics to the device,


136
00:05:55.855 --> 00:05:57.958 line:-1 position:50%
it's time to make them
interactive.


137
00:05:57.958 --> 00:06:00.093 line:-1 position:50%
Interaction on this device
is unique.


138
00:06:00.093 --> 00:06:01.962 line:-1 position:50%
People will use their hands
and their eyes


139
00:06:01.962 --> 00:06:04.064 line:-1 position:50%
to interact with content.


140
00:06:04,064 --> 00:06:05,632 line:-1
There are a few ways
you will be able


141
00:06:05,632 --> 00:06:09,402 line:-1
to add interaction to your Unity
apps on this platform.


142
00:06:09.402 --> 00:06:11.705 line:-1 position:50%
The XR Interaction Toolkit
adds hand tracking


143
00:06:11,705 --> 00:06:15,742 line:-1
to make it easier for you
to adapt existing projects.


144
00:06:15,742 --> 00:06:18,245 line:-1
You can also react
to the built-in system gestures


145
00:06:18.245 --> 00:06:20.914 line:-1 position:50%
with the Unity Input System.


146
00:06:20.914 --> 00:06:22.949 line:-1 position:50%
And you can access
the raw hand joint data


147
00:06:22.949 --> 00:06:27.120 line:-1 position:50%
for custom interactions
with the Unity Hands Package.


148
00:06:27.120 --> 00:06:30.357 line:-1 position:50%
The XR Interaction Toolkit,
also known as XRI,


149
00:06:30.357 --> 00:06:33.126 line:-1 position:50%
provides a high-level
interaction system.


150
00:06:33,126 --> 00:06:34,861 line:-1
The toolkit is designed
to make it easy


151
00:06:34.861 --> 00:06:37.564 line:-1 position:50%
to translate input
into interactions.


152
00:06:37.564 --> 00:06:41.034 line:-1 position:50%
It works with both 3D
and UI objects.


153
00:06:41.034 --> 00:06:43.403 line:-1 position:50%
XRI abstracts away
the type of input,


154
00:06:43,403 --> 00:06:45,772 line:-1
like hand tracking,
and translates that input


155
00:06:45,772 --> 00:06:48,575 line:-1
into actions that your app
can respond to.


156
00:06:48.575 --> 00:06:51.011 line:-1 position:50%
This means your input code
can work across platforms


157
00:06:51.011 --> 00:06:54.247 line:-1 position:50%
that accept different types
of input.


158
00:06:54.247 --> 00:06:56.983 line:-1 position:50%
XRI makes it easy to respond
to common interactions


159
00:06:56,983 --> 00:07:00,520 line:-1
like hover, grab, and select,
both in 3D space


160
00:07:00.520 --> 00:07:04.124 line:-1 position:50%
and in the UI
for 3D spatial worlds.


161
00:07:04.124 --> 00:07:06.393 line:-1 position:50%
The toolkit also includes
a locomotion system


162
00:07:06,393 --> 00:07:08,795 line:-1
so people can travel
through a fully immersive space


163
00:07:08,795 --> 00:07:11,064 line:-1
more comfortably.


164
00:07:11.064 --> 00:07:12.799 line:-1 position:50%
As people interact
with your world,


165
00:07:12.799 --> 00:07:15.402 line:-1 position:50%
visual feedback is important
for immersion.


166
00:07:15,402 --> 00:07:17,938 line:-1
XRI enables you to define
the visual reactions


167
00:07:17,938 --> 00:07:21,608 line:-1
for each input constraint.


168
00:07:21.608 --> 00:07:24.411 line:-1 position:50%
The core of XRI is a set
of base Interactable


169
00:07:24.411 --> 00:07:26.413 line:-1 position:50%
and Interactor components.


170
00:07:26,413 --> 00:07:28,315 line:-1
Interactables are objects
in your scene


171
00:07:28.315 --> 00:07:29.950 line:-1 position:50%
that can receive input.


172
00:07:29,950 --> 00:07:32,252 line:-1
You define Interactors,
which specify how people


173
00:07:32.252 --> 00:07:34.821 line:-1 position:50%
can interact with
your Interactables.


174
00:07:34,821 --> 00:07:38,692 line:-1
The Interaction Manager ties
these components together.


175
00:07:38,692 --> 00:07:41,394 line:-1
The first step is to decide
which objects in the scene


176
00:07:41.394 --> 00:07:43.563 line:-1 position:50%
can be interacted with,
and how to react


177
00:07:43,563 --> 00:07:46,700 line:-1
when those interactions occur.


178
00:07:46.700 --> 00:07:48.668 line:-1 position:50%
We do this by adding
an Interactable component


179
00:07:48,668 --> 00:07:49,936 line:-1
to the object.


180
00:07:49,936 --> 00:07:52,972 line:-1
There are three built-in types.


181
00:07:52,972 --> 00:07:56,109 line:-1
Simple marks the object
as receiving interactions.


182
00:07:56.109 --> 00:07:58.778 line:-1 position:50%
You can subscribe to events
like SelectEntered


183
00:07:58.778 --> 00:08:02.649 line:-1 position:50%
or SelectExited
with this component.


184
00:08:02,649 --> 00:08:05,819 line:-1
With Grab, when the object
is selected or grabbed,


185
00:08:05.819 --> 00:08:07.620 line:-1 position:50%
it will follow
the Interactor around


186
00:08:07.620 --> 00:08:10.824 line:-1 position:50%
and inherit its velocity
when released.


187
00:08:10,824 --> 00:08:14,694 line:-1
Teleport interactables like
TeleportArea and TeleportAnchor


188
00:08:14.694 --> 00:08:17.497 line:-1 position:50%
enable you to define areas
or points for the player


189
00:08:17.497 --> 00:08:19.532 line:-1 position:50%
to teleport to.


190
00:08:19,532 --> 00:08:24,037 line:-1
And you can create
your own custom Interactables.


191
00:08:24.037 --> 00:08:26.473 line:-1 position:50%
Interactors are responsible
for selecting


192
00:08:26,473 --> 00:08:29,876 line:-1
or interacting with the objects
you've tagged as Interactable.


193
00:08:29,876 --> 00:08:31,544 line:-1
They define a list
of Interactables


194
00:08:31,544 --> 00:08:34,948 line:-1
that they could potentially
hover over or select each frame.


195
00:08:34,948 --> 00:08:37,817 line:-1
There are several types
of Interactors.


196
00:08:37.817 --> 00:08:39.652 line:-1 position:50%
Direct Interactors
select Interactables


197
00:08:39.652 --> 00:08:41.287 line:-1 position:50%
that are touching it.


198
00:08:41.287 --> 00:08:43.223 line:-1 position:50%
You would use one
of these when you want to know


199
00:08:43.223 --> 00:08:45.792 line:-1 position:50%
when a person's hands touch
an interactable object,


200
00:08:45,792 --> 00:08:50,130 line:-1
or when they are close
to interactable objects.


201
00:08:50,130 --> 00:08:53,466 line:-1
Ray Interactors are used
for interacting from far away.


202
00:08:53.466 --> 00:08:55.435 line:-1 position:50%
This Interactor
is highly configurable


203
00:08:55,435 --> 00:08:59,105 line:-1
with curved and straight lines,
and customizable visualizations


204
00:08:59,105 --> 00:09:02,542 line:-1
to help you adapt it to the
visual style of your project.


205
00:09:02,542 --> 00:09:04,577 line:-1
Once the user starts
the interaction,


206
00:09:04,577 --> 00:09:07,480 line:-1
you have options on how
that interaction works.


207
00:09:07.480 --> 00:09:09.983 line:-1 position:50%
For example,
if it's a grab interaction,


208
00:09:09,983 --> 00:09:12,952 line:-1
you may want to move
the object to the user's hand.


209
00:09:12.952 --> 00:09:14.487 line:-1 position:50%
And the Ray Interactor
makes it possible


210
00:09:14,487 --> 00:09:16,556 line:-1
to limit the degrees of freedom
for the grab


211
00:09:16.556 --> 00:09:19.225 line:-1 position:50%
in order to match
your gameplay needs.


212
00:09:19.225 --> 00:09:21.694 line:-1 position:50%
A common interaction
in a fully immersive experience


213
00:09:21,694 --> 00:09:23,196 line:-1
is grabbing an object
and placing it


214
00:09:23,196 --> 00:09:26,666 line:-1
somewhere contextual
to that object.


215
00:09:26,666 --> 00:09:29,736 line:-1
For example, placing
a battery in a socket.


216
00:09:29.736 --> 00:09:31.471 line:-1 position:50%
The Socket Interactor
shows the player


217
00:09:31,471 --> 00:09:34,040 line:-1
that a certain area
can accept an object.


218
00:09:34,040 --> 00:09:36,309 line:-1
These Interactors are not
attached to the hands.


219
00:09:36.309 --> 00:09:39.446 line:-1 position:50%
Instead they live
somewhere in the world.


220
00:09:39.446 --> 00:09:41.314 line:-1 position:50%
With hand tracking
or even controllers,


221
00:09:41.314 --> 00:09:43.516 line:-1 position:50%
a common type of interaction
that users naturally want


222
00:09:43.516 --> 00:09:45.752 line:-1 position:50%
to perform is
the poke interaction.


223
00:09:45,752 --> 00:09:47,620 line:-1
This is similar
to a direct Interactor,


224
00:09:47,620 --> 00:09:49,756 line:-1
except that it includes
direction filtering


225
00:09:49,756 --> 00:09:51,691 line:-1
so that correct motion
must be performed


226
00:09:51,691 --> 00:09:54,527 line:-1
in order to trigger
an interaction.


227
00:09:54,527 --> 00:09:56,396 line:-1
If you want people
to interact by looking,


228
00:09:56,396 --> 00:09:58,264 line:-1
the Gaze Interactor
provides some extensions


229
00:09:58,264 --> 00:10:03,002 line:-1
to the Ray Interactor to make
gaze a bit easier to deal with.


230
00:10:03.002 --> 00:10:05.538 line:-1 position:50%
For example, Gaze Interactors
can automatically


231
00:10:05,538 --> 00:10:07,807 line:-1
make the colliders larger
for Interactables


232
00:10:07.807 --> 00:10:11.511 line:-1 position:50%
so that they're easier
to select.


233
00:10:11,511 --> 00:10:13,980 line:-1
To bring it all together,
the Interaction Manager serves


234
00:10:13.980 --> 00:10:17.083 line:-1 position:50%
as a middleman between the
Interactors and Interactables,


235
00:10:17.083 --> 00:10:19.719 line:-1 position:50%
facilitating the exchange
of interactions.


236
00:10:19.719 --> 00:10:21.621 line:-1 position:50%
Its primary role
is to initiate changes


237
00:10:21.621 --> 00:10:24.157 line:-1 position:50%
in the interaction state
within a designated group


238
00:10:24.157 --> 00:10:27.093 line:-1 position:50%
of registered Interactors
and Interactables.


239
00:10:27.093 --> 00:10:29.796 line:-1 position:50%
Usually, a single Interaction
Manager is established


240
00:10:29.796 --> 00:10:31.965 line:-1 position:50%
to enable the possibility
of all Interactors


241
00:10:31,965 --> 00:10:35,201 line:-1
affecting all Interactables.


242
00:10:35,201 --> 00:10:37,604 line:-1
Alternatively,
multiple complementary


243
00:10:37,604 --> 00:10:40,006 line:-1
Interaction Managers
can be utilized,


244
00:10:40.006 --> 00:10:41.574 line:-1 position:50%
each with their own
unique assortment


245
00:10:41,574 --> 00:10:43,810 line:-1
of Interactors
and Interactables.


246
00:10:43,810 --> 00:10:46,312 line:-1
These managers can be
activated or deactivated


247
00:10:46.312 --> 00:10:49.482 line:-1 position:50%
to enable or disable
specific sets of interactions.


248
00:10:49,482 --> 00:10:51,551 line:-1
For example,
you may have a different set


249
00:10:51,551 --> 00:10:56,422 line:-1
of Interactables per scene,
or in your menus.


250
00:10:56.422 --> 00:10:59.025 line:-1 position:50%
Finally, the XR Controller
component helps you make sense


251
00:10:59,025 --> 00:11:01,127 line:-1
of the input data
you'll receive.


252
00:11:01.127 --> 00:11:03.997 line:-1 position:50%
It takes input actions from
the hands or a tracked device


253
00:11:03,997 --> 00:11:06,999 line:-1
and passes it to the Interactors
so that they can decide


254
00:11:06,999 --> 00:11:10,270 line:-1
to select or activate something
based on that input.


255
00:11:12,038 --> 00:11:14,207 line:-1
You will need to bind
Input Action References


256
00:11:14,207 --> 00:11:18,311 line:-1
for each of the XR Interaction
States, such as Select.


257
00:11:18,311 --> 00:11:20,647 line:-1
You're not limited to just one
XR Controller component


258
00:11:20,647 --> 00:11:24,050 line:-1
per hand or controller,
which gives us the flexibility


259
00:11:24.050 --> 00:11:27.320 line:-1 position:50%
to support both hands
and controllers independently.


260
00:11:27,320 --> 00:11:29,289 line:-1
Sample code
that is bundled with XRI


261
00:11:29,289 --> 00:11:32,659 line:-1
shows you how you can do this.


262
00:11:32.659 --> 00:11:35.128 line:-1 position:50%
In addition to
the advanced features of XRI,


263
00:11:35.128 --> 00:11:36.296 line:-1 position:50%
you've also got the option


264
00:11:36.296 --> 00:11:38.431 line:-1 position:50%
of simply using
the system gesture inputs


265
00:11:38,431 --> 00:11:41,167 line:-1
directly from
the Unity Input System.


266
00:11:41,167 --> 00:11:43,903 line:-1
You can then map the platform's
built-in interactions,


267
00:11:43.903 --> 00:11:48.575 line:-1 position:50%
like tap gestures,
to your own interaction system.


268
00:11:48.575 --> 00:11:51.010 line:-1 position:50%
You can use the binding paths
from the Unity Input System


269
00:11:51,010 --> 00:11:54,180 line:-1
to access and respond
to these system gestures.


270
00:11:54,180 --> 00:11:56,883 line:-1
The pinch gesture, for example,
comes through as a value


271
00:11:56,883 --> 00:11:59,886 line:-1
when active,
with position and rotation.


272
00:11:59.886 --> 00:12:03.289 line:-1 position:50%
These can be bound
to input actions.


273
00:12:03,289 --> 00:12:05,391 line:-1
Where the person is directing
their focus comes through


274
00:12:05.391 --> 00:12:07.694 line:-1 position:50%
in the same frame
as a pinch gesture,


275
00:12:07,694 --> 00:12:10,763 line:-1
with position and rotation.


276
00:12:10,763 --> 00:12:12,665 line:-1
For even more flexibility,
you can use


277
00:12:12.665 --> 00:12:14.667 line:-1 position:50%
the Unity Hands Subsystem
to access


278
00:12:14.667 --> 00:12:17.437 line:-1 position:50%
all of the raw hand joint data
from the system


279
00:12:17.437 --> 00:12:20.907 line:-1 position:50%
through the Unity
Hands Package.


280
00:12:20.907 --> 00:12:22.675 line:-1 position:50%
The Unity Hands Package
provides access


281
00:12:22.675 --> 00:12:24.277 line:-1 position:50%
to low-level hand joint data


282
00:12:24,277 --> 00:12:26,746 line:-1
that are consistent
across platforms.


283
00:12:26.746 --> 00:12:29.582 line:-1 position:50%
For example, you can write
code to look at each joint


284
00:12:29,582 --> 00:12:32,385 line:-1
and determine how close the pose
is to a certain gesture,


285
00:12:32,385 --> 00:12:35,388 line:-1
like a thumbs up
or a pointing index finger,


286
00:12:35,388 --> 00:12:38,958 line:-1
and translate those
into gameplay actions.


287
00:12:38,958 --> 00:12:41,494 line:-1
This is powerful but can
be challenging to get right


288
00:12:41,494 --> 00:12:43,363 line:-1
since everyone's hands
are different sizes


289
00:12:43,363 --> 00:12:47,667 line:-1
and people have a variety
of range of motions.


290
00:12:47,667 --> 00:12:49,636 line:-1
This code defines a method
which tells you


291
00:12:49,636 --> 00:12:51,738 line:-1
if the index finger is extended.


292
00:12:51,738 --> 00:12:54,674 line:-1
You can call this method from
the OnHandUpdate event


293
00:12:54.674 --> 00:12:57.644 line:-1 position:50%
and pass in one of the hands.


294
00:12:57.644 --> 00:13:00.046 line:-1 position:50%
First, get a few specific joints
to check


295
00:13:00,046 --> 00:13:02,081 line:-1
if the index finger is extended.


296
00:13:02.081 --> 00:13:05.485 line:-1 position:50%
If any of them are invalid,
it will return false.


297
00:13:05,485 --> 00:13:07,287 line:-1
If all joints are valid,
do a simple check


298
00:13:07,287 --> 00:13:09,856 line:-1
to make sure that
the index finger isn't curled.


299
00:13:09,856 --> 00:13:11,591 line:-1
You can extend this logic
to other fingers


300
00:13:11,591 --> 00:13:16,095 line:-1
to start to implement some
basic gesture detections.


301
00:13:16,095 --> 00:13:18,131 line:-1
Another use for
the raw hand joint data


302
00:13:18.131 --> 00:13:20.800 line:-1 position:50%
is mapping it to a custom
hand mesh visual.


303
00:13:20,800 --> 00:13:22,468 line:-1
This can help make
the hands fit more


304
00:13:22,468 --> 00:13:24,504 line:-1
into the art style of your game.


305
00:13:24,504 --> 00:13:27,240 line:-1
For example, Rec Room used
the raw hand joint data


306
00:13:27.240 --> 00:13:30.910 line:-1 position:50%
to show a stylized hand model
that fits their visual style.


307
00:13:30.910 --> 00:13:35.081 line:-1 position:50%
They also show other player
hand models for more immersion.


308
00:13:35,081 --> 00:13:38,151 line:-1
The Unity Hand package has some
sample code to get you started


309
00:13:38,151 --> 00:13:43,189 line:-1
if you want to explore more
about raw hand joint access.


310
00:13:43,189 --> 00:13:44,891 line:-1
I'm excited to see
your VR experiences


311
00:13:44,891 --> 00:13:46,959 line:-1
come to this new platform.


312
00:13:46.959 --> 00:13:48.795 line:-1 position:50%
To get more information
about Unity's support


313
00:13:48.795 --> 00:13:52.165 line:-1 position:50%
for this platform and to sign up
for early beta access,


314
00:13:52.165 --> 00:13:56.569 line:-1 position:50%
please visit unity.com/spatial.


315
00:13:56.569 --> 00:13:58.037 line:-1 position:50%
Christopher: Those are the tools
you can use


316
00:13:58.037 --> 00:14:01.274 line:-1 position:50%
to bring a fully immersive VR
experience to this new platform


317
00:14:01,274 --> 00:14:04,944 line:-1
using Unity workflows
you're already familiar with.


318
00:14:04,944 --> 00:14:07,080 line:-1
Peter: To recap,
this session introduced you


319
00:14:07.080 --> 00:14:08.681 line:-1 position:50%
to some of the tools
and technologies


320
00:14:08.681 --> 00:14:11.150 line:-1 position:50%
that will make it easier for you
to bring your VR content


321
00:14:11,150 --> 00:14:15,021 line:-1
to this new platform,
just like Rec Room.


322
00:14:15.021 --> 00:14:16.622 line:-1 position:50%
If you're starting
a new project,


323
00:14:16.622 --> 00:14:19.392 line:-1 position:50%
use Unity 2022 or later.


324
00:14:19,392 --> 00:14:20,960 line:-1
If you have
an existing project,


325
00:14:20.960 --> 00:14:23.996 line:-1 position:50%
start upgrading to 2022.


326
00:14:23,996 --> 00:14:26,766 line:-1
Consider adopting
the Universal Render Pipeline.


327
00:14:26,766 --> 00:14:29,268 line:-1
While the built-in graphics
pipeline is supported,


328
00:14:29,268 --> 00:14:33,539 line:-1
all future improvements will be
on the Universal Pipeline.


329
00:14:33.539 --> 00:14:35.508 line:-1 position:50%
Start adapting any
controller-based interactions


330
00:14:35,508 --> 00:14:37,076 line:-1
to hands.


331
00:14:37,076 --> 00:14:39,479 line:-1
You can start today
with the XR Interaction Toolkit


332
00:14:39.479 --> 00:14:42.582 line:-1 position:50%
and the Unity Hands package.


333
00:14:42,582 --> 00:14:44,183 line:0
Christopher: And finally,
to learn more about


334
00:14:44,183 --> 00:14:45,685 line:0
how you can use Unity


335
00:14:45,685 --> 00:14:48,054 line:0
to create immersive experiences
with passthrough,


336
00:14:48,054 --> 00:14:51,090 position:50%
I recommend
"Create immersive Unity apps."


337
00:14:51,090 --> 00:14:54,227 line:0
And check out "Build great games
for spatial computing"


338
00:14:54,227 --> 00:14:55,962 position:50%
to get an overview
of what's possible


339
00:14:55,962 --> 00:14:58,464 line:0
for game developers
on this platform.


340
00:14:58,464 --> 00:15:01,033 line:-1
Peter: We're excited to see
what you bring to the platform.


341
00:15:01.033 --> 00:15:03.169 line:-1 position:50%
Christopher:
Thanks for watching.


342
00:15:03,169 --> 00:15:06,739 position:90% line:0 align:right
♪

