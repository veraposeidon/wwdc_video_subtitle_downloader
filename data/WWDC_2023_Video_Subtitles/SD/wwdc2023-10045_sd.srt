2
00:00:00.334 --> 00:00:06.340 line:-1 align:center
♪ ♪


3
00:00:10,644 --> 00:00:12,412 line:-1
Nadia Zouba: Hello, everyone, and welcome.


4
00:00:12.446 --> 00:00:17.317 line:-2 align:center
My name is Nadia Zouba and
I work on the Vision team here at Apple.


5
00:00:17.351 --> 00:00:23.724 line:-2 align:center
Today, I will be talking about a new
amazing API in Vision: Animal Body Pose.


6
00:00:23,757 --> 00:00:28,495 line:-2
I will also go over
some important updates in Vision.


7
00:00:28,529 --> 00:00:31,832 line:-1
Let’s start with Animal Body Pose.


8
00:00:31.865 --> 00:00:36.537 line:-2 align:center
Animal Body Pose can be used in
many possible applications.


9
00:00:36.570 --> 00:00:41.141 line:-2 align:center
For example, imagine you left your cat
and dog at home alone,


10
00:00:41,175 --> 00:00:43,577 line:-1
and you spent the day at work.


11
00:00:43.610 --> 00:00:48.248 line:-2 align:center
When you are back from work,
you find this mess in your house.


12
00:00:48.282 --> 00:00:49.516 line:-1 align:center
Don’t worry.


13
00:00:49,550 --> 00:00:52,686 line:-2
The Vision Framework can help you
figure out what happened,


14
00:00:52.719 --> 00:00:56.890 line:-2 align:center
what your pets were doing the whole day,
and who is making the mess.


15
00:00:56,924 --> 00:01:01,028 line:-2
But before I dig into that,
let’s talk about poses.


16
00:01:01,061 --> 00:01:06,166 line:-2
Three years ago, Vision introduced
Human Body Pose to detect human poses.


17
00:01:06.200 --> 00:01:09.303 line:-2 align:center
The request generates a collection of
human body landmarks


18
00:01:09,336 --> 00:01:13,440 line:-1
by detecting up to 19 body joints.


19
00:01:13.473 --> 00:01:17.177 line:-2 align:center
Developers around the world
used the API to create


20
00:01:17,211 --> 00:01:22,349 line:-2
many useful applications
for health, fitness, et cetera.


21
00:01:22.382 --> 00:01:24.952 line:-2 align:center
And since Vision interacts with
the real world,


22
00:01:24,985 --> 00:01:30,057 line:-2
we don’t only care about humans;
we also care about animals.


23
00:01:30.090 --> 00:01:33.126 line:-2 align:center
Vision has already a request
for animal recognition


24
00:01:33,160 --> 00:01:37,364 line:-1
that detects and recognizes cats and dogs.


25
00:01:37.397 --> 00:01:40.067 line:-1 align:center
The request generates a bounding box


26
00:01:40.100 --> 00:01:45.739 line:-2 align:center
with a label for the recognized animal
and a confidence level.


27
00:01:45,772 --> 00:01:50,644 line:-2
That’s a great API if you are trying to
locate and identify the animal,


28
00:01:50,677 --> 00:01:55,148 line:-2
but how about if you want to know
more about the animal?


29
00:01:55.182 --> 00:02:00.187 line:-2 align:center
It can be challenging to infer
what the animal is doing.


30
00:02:00.220 --> 00:02:03.190 line:-2 align:center
For example,
when I dog-sit for my neighbor,


31
00:02:03,223 --> 00:02:06,527 line:-2
I might like to know the specific pose
of my neighbor’s dog


32
00:02:06,560 --> 00:02:09,563 line:-1
when he wants a snack or needs a walk.


33
00:02:09,596 --> 00:02:13,000 line:-2
Guess what?
Vision expanded the body pose to animals.


34
00:02:13.033 --> 00:02:13.934 line:-1 align:center
That’s awesome.


35
00:02:15.602 --> 00:02:19.406 line:-1 align:center
Animal Body Pose is a new API in Vision.


36
00:02:19,439 --> 00:02:25,445 line:-2
It's offered in Vision via
DetectAnimalBodyPoseRequest.


37
00:02:25.479 --> 00:02:30.751 line:-2 align:center
This request, once processed,
returns an observation for each animal


38
00:02:30.784 --> 00:02:34.955 line:-2 align:center
which contains a collection of
animal body joint locations.


39
00:02:34.988 --> 00:02:37.357 line:-1 align:center
The request supports cats and dogs,


40
00:02:37,391 --> 00:02:43,697 line:-2
and detects 25 animal body landmarks
that includes the tail and the ears.


41
00:02:44.698 --> 00:02:47.634 line:-2 align:center
The Animal Body Pose API is
available in Vision


42
00:02:47,668 --> 00:02:51,572 line:-1
starting in iOS 17, iPadOS 17,


43
00:02:51.605 --> 00:02:56.910 line:-1 align:center
tvOS 17, and macOS Sonoma.


44
00:02:56.944 --> 00:03:02.549 line:-2 align:center
The input to Animal Body Pose can be
an image or a video.


45
00:03:02,583 --> 00:03:06,320 line:-2
After creating and processing the request
in Vision,


46
00:03:06.353 --> 00:03:09.523 line:-2 align:center
the request will produce
a collection of joints


47
00:03:09,556 --> 00:03:14,728 line:-2
which will define
the skeleton of the animal.


48
00:03:14,761 --> 00:03:19,867 line:-2
For Animal Body Pose,
six joint groups have been defined:


49
00:03:19,900 --> 00:03:26,640 line:-2
The Head group contains the ears,
the eyes, and the nose.


50
00:03:27,641 --> 00:03:33,180 line:-2
The Forelegs group includes
the front legs.


51
00:03:33,213 --> 00:03:39,686 line:-2
You guessed it; here comes
the Hindlegs group for the back legs.


52
00:03:39.720 --> 00:03:42.956 line:-1 align:center
Trunk group refers to the neck,


53
00:03:42.990 --> 00:03:47.761 line:-2 align:center
and the Tail group contains
three tail joints.


54
00:03:47,794 --> 00:03:49,997 line:0
Finally, there is the All group,


55
00:03:50,030 --> 00:03:53,233 align:center
which is composed by all the joints.


56
00:03:54,668 --> 00:03:57,838 line:-2
To demonstrate everything
I’ve talked about so far,


57
00:03:57,871 --> 00:04:01,308 line:-2
I have a sample app that draws
the skeleton of the animal


58
00:04:01.341 --> 00:04:04.077 line:-1 align:center
using the location of the landmarks.


59
00:04:04.111 --> 00:04:07.948 line:-2 align:center
I have this cute little chihuahua toy dog
sitting on my desk.


60
00:04:07.981 --> 00:04:12.753 line:-2 align:center
Since this dog can walk, I will use it
to show the results of the sample app.


61
00:04:12.786 --> 00:04:16.890 line:-2 align:center
I take the dog and put it
in front of my phone’s camera


62
00:04:16.924 --> 00:04:19.560 line:-1 align:center
and I start the sample app.


63
00:04:19,593 --> 00:04:23,096 line:-2
The app draws
a skeleton on top of the animal.


64
00:04:23,130 --> 00:04:26,233 line:-1
Let’s turn on the dog so he can walk.


65
00:04:28,902 --> 00:04:33,407 line:-2
The skeleton follows the animal
in his walk.


66
00:04:33,440 --> 00:04:36,844 line:-2
Oops!
The dog is walking away from the camera.


67
00:04:36.877 --> 00:04:40.347 line:-2 align:center
Let’s move it back to keep it
in front of the phone’s camera.


68
00:04:41.582 --> 00:04:45.586 line:-2 align:center
The skeleton is still following the dog.
That’s awesome.


69
00:04:45,619 --> 00:04:51,191 line:-2
Now I will go into the code to show you
how the sample app was done.


70
00:04:52,693 --> 00:04:54,828 align:center
We start with the capture output


71
00:04:54,862 --> 00:04:59,533 align:center
where we are receiving CMSampleBuffers
from the camera stream.


72
00:04:59,566 --> 00:05:01,869 align:center
The first step is to create the request.


73
00:05:01,902 --> 00:05:07,007 align:center
I will use VNDetectAnimalBodyPoseRequest.


74
00:05:09,009 --> 00:05:14,348 line:0
The next step is to create a request
handler using imageRequestHandler.


75
00:05:16,350 --> 00:05:22,523 align:center
Then I provide the request to the handler
via a call to perform.


76
00:05:22,556 --> 00:05:24,491 align:center
If perform request succeed,


77
00:05:24,525 --> 00:05:28,629 align:center
VNAnimalBodyPoseObservations
will be returned


78
00:05:28,662 --> 00:05:32,633 line:0
in the request results property.


79
00:05:32,666 --> 00:05:36,270 line:0
Each will contain
the location of the joints.


80
00:05:36,303 --> 00:05:40,707 line:0
To access these joints from
Animal Pose Observation,


81
00:05:40,741 --> 00:05:45,179 line:0
I will request a dictionary of
recognized points in the group


82
00:05:45,212 --> 00:05:49,082 align:center
by calling .recognizedPoints.


83
00:05:49,116 --> 00:05:52,986 line:0
Since I needed all the joints
to draw the skeleton of the animal,


84
00:05:53,020 --> 00:05:57,925 align:center
I choose to use the All group.


85
00:05:57,958 --> 00:06:03,597 line:0
You can use another group if you need to
only access some of the animal joints.


86
00:06:04,131 --> 00:06:06,900 line:-2
And finally,
to draw the skeleton of the animal,


87
00:06:06.934 --> 00:06:11.405 line:-2 align:center
I iterate over all the recognized points
and connect the joints.


88
00:06:12,239 --> 00:06:15,776 align:center
Here is an example of how
the head joints were connected


89
00:06:15,809 --> 00:06:18,812 align:center
to draw the head skeleton.


90
00:06:23,650 --> 00:06:26,320 line:-2
There are some considerations
to keep in mind.


91
00:06:26.353 --> 00:06:28.589 line:-1 align:center
Using the new Animal Body Pose,


92
00:06:28,622 --> 00:06:33,260 line:-2
you can detect up to two animals
in an image.


93
00:06:33,293 --> 00:06:39,433 line:-2
The input image size should be
at least 64 pixels on each side.


94
00:06:39,466 --> 00:06:45,973 line:-2
And by using the neural engine, the
performance can keep up with live capture.


95
00:06:46.006 --> 00:06:50.511 line:-2 align:center
Let’s go through a few examples of
what can be done with Animal Pose.


96
00:06:50,544 --> 00:06:54,448 line:-2
Using the new
Animal Pose API with still images,


97
00:06:54.481 --> 00:06:57.618 line:-2 align:center
you can develop your own analysis on
the joints


98
00:06:57,651 --> 00:07:01,522 align:center
to recognize interesting poses
of your animal,


99
00:07:01,555 --> 00:07:05,559 align:center
such as, stretching after waking up...


100
00:07:08,061 --> 00:07:12,065 line:0
standing, begging for a treat...


101
00:07:17,971 --> 00:07:20,974 line:0
running away from a dog...


102
00:07:24,344 --> 00:07:27,347 line:0
or, curling up to take a nap.


103
00:07:32,553 --> 00:07:34,221 line:-1
As I mentioned before,


104
00:07:34,254 --> 00:07:38,759 line:-2
Animal Recognition allows you to localize
and recognize the animal,


105
00:07:38,792 --> 00:07:43,897 line:-2
and Animal Body Pose returns
the full body landmarks of the animal.


106
00:07:43.931 --> 00:07:47.401 line:-2 align:center
Combining those two requests will allow
you to know


107
00:07:47,434 --> 00:07:52,372 line:-2
what type of animal was detected,
the location, and the pose.


108
00:07:52,406 --> 00:07:57,444 line:-2
Now you can know who is messing up
with the dining table.


109
00:07:57,477 --> 00:07:59,613 line:-1
This will give you a lot of opportunities


110
00:07:59,646 --> 00:08:04,017 line:-2
to develop interesting applications
for your pets;


111
00:08:04.051 --> 00:08:06.820 line:-1 align:center
maybe something for a dog treat dispenser


112
00:08:06,854 --> 00:08:12,025 line:-2
activated on animal recognition
and animal pose detection.


113
00:08:12.059 --> 00:08:16.830 line:-2 align:center
The Animal Pose API can also be used
with videos.


114
00:08:16,864 --> 00:08:21,368 line:-2
You can bring your own algorithms to
your app to analyze the motion,


115
00:08:21,401 --> 00:08:24,905 line:-2
and determine what type of activity
your animal is doing.


116
00:08:24.938 --> 00:08:28.108 line:-1 align:center
You may even go further with your analysis


117
00:08:28,141 --> 00:08:33,714 line:-2
to understand your animal behavior
by tracking the poses over time.


118
00:08:33,747 --> 00:08:35,349 line:-1
Until Animal Body Pose,


119
00:08:35,382 --> 00:08:39,553 line:-2
I thought all those marks
in the wall were from my kids,


120
00:08:39.586 --> 00:08:43.357 line:-2 align:center
but it was the cat trying to catch
a laser pointer.


121
00:08:45,359 --> 00:08:50,464 line:-2
And whoa,
this dog can skateboard better than me!


122
00:08:50,497 --> 00:08:54,501 line:-2
Another use is to track the animal
with the camera.


123
00:08:54,535 --> 00:08:59,540 align:center
To learn more about that kind of tracking,
please refer to the session


124
00:08:59,573 --> 00:09:04,144 align:center
“Integrate with motorized iPhone stands
with DockKit.”


125
00:09:04,178 --> 00:09:07,581 line:-2
You can also
write funny apps for your pets.


126
00:09:07.614 --> 00:09:13.253 line:-2 align:center
For example,
putting a hat and sunglasses on a dog.


127
00:09:13.287 --> 00:09:17.791 line:-2 align:center
Wouldn’t it be super fun to create
a cute card for your animal’s birthday,


128
00:09:17.824 --> 00:09:20.861 line:-1 align:center
and send it to family and friends?


129
00:09:20.894 --> 00:09:24.231 line:-1 align:center
Happy birthday, Mr. Frenchie!


130
00:09:24.264 --> 00:09:30.604 line:-2 align:center
I do this by placing emojis where I find
relevant Animal Body Pose joints.


131
00:09:30,637 --> 00:09:36,844 line:-2
Let me demonstrate the emoji app
using this cute toy dog I have with me.


132
00:09:36.877 --> 00:09:42.883 line:-2 align:center
I will use the same sample app and switch
from the skeleton view to the emoji view.


133
00:09:44.885 --> 00:09:49.890 line:-1 align:center
[toy chirping]


134
00:09:53.493 --> 00:09:56.196 line:-1 align:center
Since this little dog is walking slowly,


135
00:09:56,230 --> 00:10:00,400 line:-2
I added some skates emojis on top of
his paw joints


136
00:10:00,434 --> 00:10:02,569 line:-1
to speed him up a little bit.


137
00:10:02,603 --> 00:10:04,671 line:-1
Oh, wait, safety first!


138
00:10:04.705 --> 00:10:08.876 line:-2 align:center
Let’s go back to the code
and give him a helmet.


139
00:10:08,909 --> 00:10:14,581 line:0
Here I have already added the skates
emojis on top of the paw joints.


140
00:10:14,615 --> 00:10:18,685 line:0
Let’s add the helmet emoji
on top of the ear joints.


141
00:10:18,719 --> 00:10:23,023 line:0
I choose the size and
the position of the emoji.


142
00:10:23,056 --> 00:10:27,561 align:center
Let’s also add some glasses
to skate in style.


143
00:10:30.597 --> 00:10:34.801 line:-2 align:center
I run the app again
after taking care of the dog's safety.


144
00:10:34.835 --> 00:10:37.671 line:-1 align:center
Better be safe than sorry.


145
00:10:37.704 --> 00:10:40.741 line:-1 align:center
Let’s switch to the emoji view.


146
00:10:40.774 --> 00:10:45.279 line:-2 align:center
The dog now has the gears he needed
to continue skating safely.


147
00:10:45,312 --> 00:10:50,317 line:-2
Looks cool, right?
Go, doggy, go! You nailed it!


148
00:10:50,350 --> 00:10:52,786 line:-1
That was it for Animal Body Pose.


149
00:10:52,819 --> 00:10:56,423 line:-2
I can’t wait for you to bring to your app
all the amazing things


150
00:10:56.456 --> 00:11:00.727 line:-2 align:center
you will create using
the new Animal Pose API.


151
00:11:00.761 --> 00:11:04.464 line:-2 align:center
There are more updates in Vision
that you may find helpful,


152
00:11:04,498 --> 00:11:07,334 line:-1
so let me introduce them to you.


153
00:11:07,367 --> 00:11:10,037 line:-1
There are new Stateful Requests.


154
00:11:10.070 --> 00:11:16.276 line:-2 align:center
VNTargetedImage-based requests are
available as Stateful Requests in Vision.


155
00:11:17,277 --> 00:11:20,581 line:-2
Vision has three new derived
Stateful Requests,


156
00:11:20.614 --> 00:11:24.585 line:-1 align:center
all named with the Track verb.


157
00:11:24.618 --> 00:11:28.689 line:-1 align:center
This makes it easier to use for tracking.


158
00:11:28.722 --> 00:11:34.161 line:-2 align:center
I am thrilled to announce that
Vision supports MLComputeDevice.


159
00:11:34,194 --> 00:11:37,364 line:-2
The new Compute Device API
allows you to query


160
00:11:37,397 --> 00:11:43,237 line:-2
where requests get executed
and specify which device to use.


161
00:11:43.270 --> 00:11:46.707 line:-2 align:center
Core ML and Create ML Multilabel
Classification


162
00:11:46.740 --> 00:11:49.910 line:-1 align:center
is now compatible with Vision.


163
00:11:49,943 --> 00:11:52,946 line:-2
This allows you to train
your own classifier


164
00:11:52,980 --> 00:11:56,450 line:-1
that supports more than one label.


165
00:11:56,483 --> 00:12:00,787 align:center
Please refer to the session “Discover
machine learning enhancements


166
00:12:00,821 --> 00:12:04,458 align:center
in Create ML” for more information.


167
00:12:04.491 --> 00:12:10.931 line:-2 align:center
There are also new revisions in existing
requests that bring great improvements.


168
00:12:10.964 --> 00:12:15.602 line:-2 align:center
For Barcodes, there is a new revision,
Revision 4.


169
00:12:15.636 --> 00:12:19.606 line:-2 align:center
The new revision includes
a new MSIPlessey symbology


170
00:12:19.640 --> 00:12:23.243 line:-1 align:center
and supports color inverted QR codes.


171
00:12:23.277 --> 00:12:26.446 line:-2 align:center
And by the way,
Revision 1 will be deprecated.


172
00:12:26,980 --> 00:12:31,985 align:center
Text Recognition is adding support for
Thai and Vietnamese.


173
00:12:34.922 --> 00:12:41.428 line:-2 align:center
And finally, there is a new revision for
FaceCaptureQuality, Revision 3,


174
00:12:41,461 --> 00:12:45,666 line:-1
to improve the quality and the accuracy.


175
00:12:45.699 --> 00:12:49.937 line:-2 align:center
For additional information about
all those new updates in Vision,


176
00:12:49.970 --> 00:12:52.873 line:-1 align:center
please check the developer documentation.


177
00:12:52,906 --> 00:12:55,943 line:-2
Today, I talked about
the new Animal Body Pose


178
00:12:55.976 --> 00:13:00.881 line:-2 align:center
and all the amazing things that can be
done with this new API.


179
00:13:00,914 --> 00:13:03,784 line:-2
I also presented
some important APIs updates


180
00:13:03,817 --> 00:13:06,286 line:-1
and other enhancements in Vision


181
00:13:06,320 --> 00:13:09,489 line:-2
that I hope will be helpful
in your developments.


182
00:13:09.523 --> 00:13:11.892 line:-1 align:center
But wait, there is more.


183
00:13:11,925 --> 00:13:14,862 line:0
Please check the session
“Explore 3D body pose


184
00:13:14,895 --> 00:13:17,297 align:center
and person segmentation in Vision”


185
00:13:17,331 --> 00:13:23,971 align:center
to learn about the new 3D body pose
and person segmentation APIs in Vision.


186
00:13:24,004 --> 00:13:28,041 align:center
And if you want to segment
any selected foreground object,


187
00:13:28,075 --> 00:13:34,414 align:center
please refer to the session
“Lift subjects from images in your app”.


188
00:13:34.448 --> 00:13:36.049 line:-1 align:center
Thank you for your attention,


189
00:13:36.083 --> 00:13:40.153 line:-2 align:center
and we can’t wait for you to
get your paws on Animal Pose.

