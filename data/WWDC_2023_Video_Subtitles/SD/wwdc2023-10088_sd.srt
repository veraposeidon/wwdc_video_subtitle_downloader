2
00:00:00.033 --> 00:00:03.003 line:-1 position:50%
♪ Mellow instrumental hip-hop ♪


3
00:00:03,003 --> 00:00:10,210 size:2% align:right line:0
♪


4
00:00:10,210 --> 00:00:11,545 line:-1
John Calsbeek: Welcome!


5
00:00:11.545 --> 00:00:13.881 line:-1 position:50%
I'm John, and I work
on RealityKit.


6
00:00:13,881 --> 00:00:15,949 line:-1
Vladimir Vukićević:
And I'm Vlad, from Unity.


7
00:00:15.949 --> 00:00:18.352 line:-1 position:50%
John: I'm thrilled
to introduce Unity support


8
00:00:18,352 --> 00:00:20,220 line:-1
for immersive apps.


9
00:00:20,220 --> 00:00:22,256 line:-1
Unity has worked
with Apple to bring


10
00:00:22.256 --> 00:00:25.459 line:-1 position:50%
the full Unity experience
to this new platform.


11
00:00:25,459 --> 00:00:28,595 line:-1
Unity is used
by tens of thousands of apps,


12
00:00:28,595 --> 00:00:32,232 line:-1
and now you can use Unity
to build immersive apps.


13
00:00:32.232 --> 00:00:35.702 line:-1 position:50%
Triband brought their Apple
Arcade title What The Golf?,


14
00:00:35,702 --> 00:00:38,739 line:-1
which is built in Unity,
to this platform.


15
00:00:38,739 --> 00:00:40,841 line:-1
It's really fun to play
on an iPhone,


16
00:00:40.841 --> 00:00:43.543 line:-1 position:50%
and it feels great
to play it this way.


17
00:00:43,543 --> 00:00:45,812 line:-1
There are two main approaches
for creating


18
00:00:45.812 --> 00:00:49.182 line:-1 position:50%
immersive experiences
on this platform with Unity.


19
00:00:49,182 --> 00:00:51,752 line:-1
You can create experiences
which mix your content


20
00:00:51.752 --> 00:00:54.254 line:-1 position:50%
with real-world objects
using passthrough,


21
00:00:54,254 --> 00:00:56,156 line:-1
either as
an immersive experience


22
00:00:56.156 --> 00:00:59.393 line:-1 position:50%
or in the Shared Space
alongside other apps.


23
00:00:59.393 --> 00:01:02.462 line:-1 position:50%
You can also bring a fully
immersive Unity experience


24
00:01:02,462 --> 00:01:03,830 line:-1
to the platform.


25
00:01:03,830 --> 00:01:05,766 position:50%
If you're interested
in this approach,


26
00:01:05,766 --> 00:01:07,367 line:0
I recommend you check out


27
00:01:07,367 --> 00:01:11,672 line:0
"Bring your Unity VR app
to a fully immersive space."


28
00:01:11.672 --> 00:01:14.875 line:-1 position:50%
Creating experiences
for the shared space with Unity


29
00:01:14,875 --> 00:01:17,978 line:-1
opens up exciting opportunities
for your apps.


30
00:01:17.978 --> 00:01:20.147 line:-1 position:50%
Here's Vlad to tell you more.


31
00:01:20,147 --> 00:01:21,248 line:-1
Vladimir: Thanks, John.


32
00:01:21.248 --> 00:01:22.849 line:-1 position:50%
Unity and Apple have been
working together


33
00:01:22,849 --> 00:01:24,885 line:-1
for the past two years
to make sure


34
00:01:24.885 --> 00:01:27.921 line:-1 position:50%
your Unity content looks great
on the platform.


35
00:01:27,921 --> 00:01:30,390 line:-1
Whether you're starting
with an existing project,


36
00:01:30,390 --> 00:01:32,526 line:-1
or building something
completely new,


37
00:01:32,526 --> 00:01:35,662 line:-1
Unity is a great tool for
creating immersive experiences


38
00:01:35,662 --> 00:01:40,067 line:-1
using familiar tools
and some new capabilities.


39
00:01:40,067 --> 00:01:43,203 line:-1
On this platform, you can
achieve the visual look you want


40
00:01:43,203 --> 00:01:46,039 line:-1
using Unity's
shaders and materials.


41
00:01:46.039 --> 00:01:48.442 line:-1 position:50%
We're introducing the ability
to enter play mode


42
00:01:48,442 --> 00:01:52,346 line:-1
directly to device,
improving your iteration time.


43
00:01:52,346 --> 00:01:55,215 line:-1
There's also a new concept
called the volume camera,


44
00:01:55,215 --> 00:01:57,851 line:-1
which controls how content
from your Unity scene


45
00:01:57,851 --> 00:02:00,387 line:-1
is brought into the real world.


46
00:02:00,387 --> 00:02:01,888 line:-1
Input on this new device


47
00:02:01,888 --> 00:02:04,458 line:-1
can be as simple
as a look-and-tap gesture


48
00:02:04,458 --> 00:02:08,095 line:-1
or involve more
complex interactions.


49
00:02:08,095 --> 00:02:10,263 line:-1
And there are a few things
you can do today


50
00:02:10.263 --> 00:02:14.067 line:-1 position:50%
to prepare your Unity content
for spatial computing.


51
00:02:14.067 --> 00:02:17.571 line:-1 position:50%
Here's an example of some of
these elements working together.


52
00:02:17.571 --> 00:02:21.475 line:-1 position:50%
This scene uses materials built
with Unity's Shader Graph,


53
00:02:21,475 --> 00:02:23,677 line:-1
and it's being displayed
in the shared space


54
00:02:23,677 --> 00:02:26,813 line:-1
in the Simulator
with passthrough.


55
00:02:26,813 --> 00:02:29,349 line:-1
There are fully rigged
and animated characters,


56
00:02:29,349 --> 00:02:32,085 line:-1
like the ogre in the back.


57
00:02:32.085 --> 00:02:35.722 line:-1 position:50%
Physics interactions work
just like you're used to.


58
00:02:35,722 --> 00:02:37,391 line:-1
All of the residents
of this town


59
00:02:37.391 --> 00:02:40.327 line:-1 position:50%
are using character navigation
to move around,


60
00:02:40.327 --> 00:02:42.496 line:-1 position:50%
and custom dynamic
scripted behaviors


61
00:02:42,496 --> 00:02:45,999 line:-1
are used to make
this scene feel alive.


62
00:02:45,999 --> 00:02:47,801 line:-1
We put this together
in two weeks with the help


63
00:02:47,801 --> 00:02:50,203 line:-1
of the Asset Store,
and it looks great


64
00:02:50.203 --> 00:02:53.206 line:-1 position:50%
when viewed in your space,
where you can get up close


65
00:02:53.206 --> 00:02:56.309 line:-1 position:50%
and look at a scene
from any angle.


66
00:02:56.309 --> 00:03:00.547 line:-1 position:50%
All content in the shared space
is rendered using RealityKit.


67
00:03:00.547 --> 00:03:03.316 line:-1 position:50%
Your Unity materials and shaders
need to be translated


68
00:03:03,316 --> 00:03:05,519 line:-1
to this new environment.


69
00:03:05.519 --> 00:03:08.555 line:-1 position:50%
Unity has created PolySpatial,
which takes care


70
00:03:08.555 --> 00:03:11.858 line:-1 position:50%
of this translation for you
and brings many Unity features


71
00:03:11,858 --> 00:03:14,828 line:-1
over to this environment.


72
00:03:14,828 --> 00:03:17,197 line:-1
PolySpatial translates
materials,


73
00:03:17,197 --> 00:03:19,332 line:-1
regular and skinned
mesh rendering,


74
00:03:19.332 --> 00:03:23.236 line:-1 position:50%
as well as particle effects
and sprites.


75
00:03:23,236 --> 00:03:25,839 line:-1
Unity simulation features
are supported,


76
00:03:25.839 --> 00:03:28.241 line:-1 position:50%
and you continue to use
MonoBehaviours,


77
00:03:28,241 --> 00:03:31,912 line:-1
scriptable objects,
and other standard tools.


78
00:03:31.912 --> 00:03:34.681 line:-1 position:50%
Three categories of materials
are translated.


79
00:03:34.681 --> 00:03:38.452 line:-1 position:50%
They are the physically based
materials, custom materials,


80
00:03:38.452 --> 00:03:41.154 line:-1 position:50%
and some special effect
materials.


81
00:03:41,154 --> 00:03:43,957 line:-1
Materials based on Unity's
physically based shaders


82
00:03:43,957 --> 00:03:47,027 line:-1
translate directly
to RealityKit.


83
00:03:47,027 --> 00:03:49,830 line:-1
If you're using the
Universal Render Pipeline,


84
00:03:49,830 --> 00:03:52,399 line:-1
you can use any of the Lit,
Simple Lit,


85
00:03:52,399 --> 00:03:55,769 line:-1
or Complex Lit Shaders
in your materials.


86
00:03:55,769 --> 00:03:59,539 line:-1
With the built-in pipeline,
you can use the Standard Shader.


87
00:03:59,539 --> 00:04:01,208 line:-1
All of these are translated


88
00:04:01.208 --> 00:04:04.845 line:-1 position:50%
to a RealityKit
PhysicallyBasedMaterial.


89
00:04:04.845 --> 00:04:07.180 line:-1 position:50%
Custom shader and material types
are supported


90
00:04:07,180 --> 00:04:09,783 line:-1
through Unity Shader Graph.


91
00:04:09,783 --> 00:04:13,253 line:-1
Unity Shader Graphs
are converted to MaterialX,


92
00:04:13.253 --> 00:04:17.591 line:-1 position:50%
a standard interchange format
for complex materials.


93
00:04:17.591 --> 00:04:20.293 line:-1 position:50%
MaterialX shaders become
a ShaderGraphMaterial


94
00:04:20.293 --> 00:04:22.496 line:-1 position:50%
in RealityKit.


95
00:04:22,496 --> 00:04:25,232 line:-1
Many Unity Shader Graph nodes
are supported,


96
00:04:25.232 --> 00:04:28.902 line:-1 position:50%
so you can create complex
and interesting effects.


97
00:04:28,902 --> 00:04:31,037 line:-1
Handwritten shaders
are not supported


98
00:04:31.037 --> 00:04:33.240 line:-1 position:50%
for rendering
through RealityKit,


99
00:04:33,240 --> 00:04:36,877 line:-1
but you can use them
with RenderTextures in Unity.


100
00:04:36.877 --> 00:04:38.812 line:-1 position:50%
You can then use
that RenderTexture


101
00:04:38.812 --> 00:04:41.081 line:-1 position:50%
as a texture input
to a Shader Graph


102
00:04:41.081 --> 00:04:44.284 line:-1 position:50%
for displaying
through RealityKit.


103
00:04:44,284 --> 00:04:47,621 position:50%
Two additional material
shader types are supported.


104
00:04:47,621 --> 00:04:50,991 line:0
First is the Unlit Shader,
which lets you create objects


105
00:04:50,991 --> 00:04:53,160 position:50%
that take on a solid
color or texture,


106
00:04:53,160 --> 00:04:55,428 position:50%
unaffected by lighting.


107
00:04:55,428 --> 00:04:57,697 position:50%
The second is
the Occlusion Shader,


108
00:04:57,697 --> 00:05:01,134 line:0
which lets passthrough
show through the object.


109
00:05:01,134 --> 00:05:04,137 position:50%
You can use the Occlusion Shader
with world mesh data


110
00:05:04,137 --> 00:05:09,676 line:0
to help your content feel more
integrated with the real world.


111
00:05:09,676 --> 00:05:12,045 line:-1
Unity MeshRenderers
and SkinnedMeshRenderers


112
00:05:12,045 --> 00:05:13,780 line:-1
are supported
and are the primary way


113
00:05:13,780 --> 00:05:16,950 line:-1
of bringing visual content
into real space.


114
00:05:16,950 --> 00:05:20,687 line:-1
Rigged characters
and animation are available.


115
00:05:20,687 --> 00:05:24,391 line:-1
You can use either the Universal
or the Built-in Render Pipeline,


116
00:05:24,391 --> 00:05:26,893 line:-1
and your content will be
translated to RealityKit


117
00:05:26,893 --> 00:05:29,229 line:-1
via Unity PolySpatial.


118
00:05:29.229 --> 00:05:31.865 line:-1 position:50%
Rendering features,
such as postprocessing effects


119
00:05:31,865 --> 00:05:35,202 line:-1
and custom pipeline stages,
are not available,


120
00:05:35.202 --> 00:05:39.606 line:-1 position:50%
as RealityKit performs
the final rendering.


121
00:05:39,606 --> 00:05:42,542 line:-1
Particle effects using
Unity's Shuriken system


122
00:05:42,542 --> 00:05:45,312 line:-1
are either translated
to RealityKit's particle system,


123
00:05:45,312 --> 00:05:46,880 line:-1
if they are compatible,


124
00:05:46,880 --> 00:05:49,950 line:-1
or are translated
to baked meshes.


125
00:05:49.950 --> 00:05:53.053 line:-1 position:50%
Sprites become 3D meshes,
though you should consider


126
00:05:53.053 --> 00:05:56.389 line:-1 position:50%
how you're using them
in a spatial context.


127
00:05:56,389 --> 00:05:59,192 line:-1
PolySpatial works to optimize
and translate rendering


128
00:05:59,192 --> 00:06:01,695 line:-1
between Unity and RealityKit.


129
00:06:01,695 --> 00:06:04,864 line:-1
Simulation features in Unity
work just like you're used to,


130
00:06:04,864 --> 00:06:07,934 line:-1
such as Physics,
Animation and Timeline,


131
00:06:07,934 --> 00:06:11,571 line:-1
Pathfinding and NavMesh,
your custom MonoBehaviours,


132
00:06:11,571 --> 00:06:15,208 line:-1
and other
non-rendering features.


133
00:06:15.208 --> 00:06:18.645 line:-1 position:50%
To help you fine-tune your look
and to speed up iteration,


134
00:06:18,645 --> 00:06:22,082 line:-1
Unity PolySpatial
enables "Play to device."


135
00:06:22,082 --> 00:06:24,184 line:-1
It can take time to go
through the build process


136
00:06:24,184 --> 00:06:27,487 line:-1
to see what your content
looks like on your device.


137
00:06:27,487 --> 00:06:30,457 line:-1
With PolySpatial, you have
access to Play to device


138
00:06:30,457 --> 00:06:32,659 line:-1
for the first time.


139
00:06:32,659 --> 00:06:35,128 line:-1
Play to device lets you see
an instant preview


140
00:06:35.128 --> 00:06:38.231 line:-1 position:50%
of your scene and make
live changes to it.


141
00:06:38,231 --> 00:06:43,870 line:-1
It works in the simulator and
works great on device as well.


142
00:06:43,870 --> 00:06:46,406 line:-1
You can use Play to device
to rapidly explore


143
00:06:46,406 --> 00:06:48,608 line:-1
the placement and size
of your content,


144
00:06:48,608 --> 00:06:51,344 line:-1
including adding
and removing elements.


145
00:06:51,344 --> 00:06:53,513 line:-1
You can change materials,
textures,


146
00:06:53.513 --> 00:06:56.516 line:-1 position:50%
and even Shader Graphs
to fine-tune your look


147
00:06:56.516 --> 00:07:00.287 line:-1 position:50%
while seeing your content
in place with passthrough.


148
00:07:00.287 --> 00:07:02.122 line:-1 position:50%
You can test out interaction


149
00:07:02,122 --> 00:07:05,392 line:-1
because events
are sent back to the editor.


150
00:07:05,392 --> 00:07:07,460 line:-1
Your simulation
continues to run,


151
00:07:07,460 --> 00:07:12,399 line:-1
so it's easy to debug just
by attaching to the editor.


152
00:07:12.399 --> 00:07:15.435 line:-1 position:50%
Here's the same castle scene
you saw earlier.


153
00:07:15,435 --> 00:07:17,704 line:-1
I have it open in Unity
on the left,


154
00:07:17.704 --> 00:07:20.073 line:-1 position:50%
and with Play to device,
I can see it running


155
00:07:20,073 --> 00:07:22,509 line:-1
in the simulator on the right.


156
00:07:22.509 --> 00:07:26.546 line:-1 position:50%
I can add more ogres just
by dragging them into my scene.


157
00:07:26,546 --> 00:07:30,750 line:-1
They're instantly visible
in the simulator or device.


158
00:07:30.750 --> 00:07:35.188 line:-1 position:50%
If I want to see how pink
or neon green ogres look, I can.


159
00:07:35.188 --> 00:07:37.424 line:-1 position:50%
Play to device is a really
efficient workflow


160
00:07:37.424 --> 00:07:39.259 line:-1 position:50%
for iterating on your content,


161
00:07:39,259 --> 00:07:41,461 line:-1
and it's currently available
in Unity


162
00:07:41,461 --> 00:07:45,398 line:-1
only for creating content
in the shared space.


163
00:07:45.398 --> 00:07:48.335 line:-1 position:50%
Because you're using Unity
to create volumetric content


164
00:07:48.335 --> 00:07:50.704 line:-1 position:50%
that participates
in the shared space,


165
00:07:50.704 --> 00:07:54.407 line:-1 position:50%
a new concept called
a volume camera lets you control


166
00:07:54,407 --> 00:07:57,711 line:-1
how your scene is brought
into the real world.


167
00:07:57,711 --> 00:08:00,613 line:-1
A volume camera can create
two types of volumes,


168
00:08:00.613 --> 00:08:05.151 line:-1 position:50%
bounded and unbounded, each with
different characteristics.


169
00:08:05,151 --> 00:08:09,389 line:-1
Your application can switch
between the two at any time.


170
00:08:09.389 --> 00:08:11.591 line:-1 position:50%
Bounded volumes exist
in the shared space


171
00:08:11,591 --> 00:08:14,894 line:-1
as volumes, alongside
other apps and games.


172
00:08:14.894 --> 00:08:17.630 line:-1 position:50%
They have dimensions
and a transform in Unity,


173
00:08:17.630 --> 00:08:20.934 line:-1 position:50%
as well as a specific
real-world size.


174
00:08:20,934 --> 00:08:26,306 line:-1
They can be repositioned,
but people cannot resize them.


175
00:08:26,306 --> 00:08:28,975 position:50%
The dimensions and the transform
of the volume camera


176
00:08:28,975 --> 00:08:31,878 line:0
define the region of your scene
that your app will display


177
00:08:31,878 --> 00:08:33,480 line:0
in a volume.


178
00:08:33,480 --> 00:08:36,416 line:0
They're specified
in scene units.


179
00:08:36,416 --> 00:08:38,485 position:50%
You can see a preview
of the volume in green


180
00:08:38,485 --> 00:08:41,788 position:50%
in Unity's scene view.


181
00:08:41.788 --> 00:08:43.923 line:-1 position:50%
By manipulating the dimensions
and the transform


182
00:08:43.923 --> 00:08:46.760 line:-1 position:50%
of the volume camera,
different parts of the scene


183
00:08:46,760 --> 00:08:49,629 line:-1
can be brought into the volume.


184
00:08:49.629 --> 00:08:53.099 line:-1 position:50%
If I move or rotate the camera,
new objects become visible


185
00:08:53.099 --> 00:08:55.201 line:-1 position:50%
in my space.


186
00:08:55.201 --> 00:09:00.407 line:-1 position:50%
If I scale up its size, more
of the scene comes into view.


187
00:09:00.407 --> 00:09:04.244 line:-1 position:50%
In both cases, the volume
remains the same size.


188
00:09:04,244 --> 00:09:08,882 line:-1
Only the content visible
inside of it changes.


189
00:09:08,882 --> 00:09:11,584 line:-1
Notice that in the initial
placement of the volume camera,


190
00:09:11,584 --> 00:09:14,287 line:-1
the spring intersects
the side of the volume;


191
00:09:14.287 --> 00:09:16.956 line:-1 position:50%
content is clipped
by RealityKit.


192
00:09:16.956 --> 00:09:18.858 line:-1 position:50%
If you will have content
intersecting the edges


193
00:09:18.858 --> 00:09:21.461 line:-1 position:50%
of your volume,
consider placing the same mesh


194
00:09:21.461 --> 00:09:24.697 line:-1 position:50%
in your scene a second time
with a back-facing material


195
00:09:24,697 --> 00:09:28,668 line:-1
to fill in the clipped sections.


196
00:09:28,668 --> 00:09:32,872 line:-1
Your unbounded volume displays
in a full space on this platform


197
00:09:32.872 --> 00:09:35.708 line:-1 position:50%
and allows your content
to fully blend with passthrough


198
00:09:35.708 --> 00:09:38.478 line:-1 position:50%
for a more immersive
experience.


199
00:09:38.478 --> 00:09:42.115 line:-1 position:50%
It has no dimensions because
it selects your entire scene,


200
00:09:42.115 --> 00:09:44.984 line:-1 position:50%
and its transform specifies
how your scene units


201
00:09:44.984 --> 00:09:47.954 line:-1 position:50%
are mapped to real-world units.


202
00:09:47,954 --> 00:09:52,592 line:-1
There can only be one unbounded
volume camera active at a time.


203
00:09:52,592 --> 00:09:54,627 line:-1
You'll see an example
of an unbounded volume


204
00:09:54.627 --> 00:09:57.163 line:-1 position:50%
when we talk about interaction.


205
00:09:57.163 --> 00:10:01.868 line:-1 position:50%
Unity supports multiple input
types for apps on this platform.


206
00:10:01.868 --> 00:10:04.804 line:-1 position:50%
On this platform, people use
their eyes and hands


207
00:10:04.804 --> 00:10:09.075 line:-1 position:50%
to look at content and tap their
fingers together to select it.


208
00:10:09,075 --> 00:10:11,678 line:-1
Full hand tracking
as well as head pose data


209
00:10:11.678 --> 00:10:14.981 line:-1 position:50%
lets you create
realistic interactions.


210
00:10:14,981 --> 00:10:18,218 line:-1
Augmented reality data
from ARKit is available,


211
00:10:18,218 --> 00:10:20,119 line:-1
as are Bluetooth devices


212
00:10:20.119 --> 00:10:23.490 line:-1 position:50%
such as keyboards
and game controllers.


213
00:10:23,490 --> 00:10:25,391 line:-1
The tap gesture
is the most common way


214
00:10:25,391 --> 00:10:29,062 line:-1
of interacting with content
on this platform.


215
00:10:29,062 --> 00:10:31,731 line:-1
In order for your objects
to receive these events,


216
00:10:31,731 --> 00:10:34,567 line:-1
they must have
input colliders configured.


217
00:10:34,567 --> 00:10:37,770 line:-1
You can look and tap to select
an object from a distance,


218
00:10:37.770 --> 00:10:40.173 line:-1 position:50%
or you can reach out
and directly touch an object


219
00:10:40,173 --> 00:10:42,108 line:-1
with a finger.


220
00:10:42.108 --> 00:10:46.746 line:-1 position:50%
Up to two simultaneous tap
actions can be in progress.


221
00:10:46,746 --> 00:10:50,517 line:-1
In Unity, taps are available
as WorldTouch events.


222
00:10:50.517 --> 00:10:52.719 line:-1 position:50%
They are similar
to 2D tap events,


223
00:10:52.719 --> 00:10:56.089 line:-1 position:50%
but have a full 3D position.


224
00:10:56,089 --> 00:10:58,625 line:-1
Hand and head pose tracking
gives your application


225
00:10:58.625 --> 00:11:01.327 line:-1 position:50%
precise information
about each hand joint


226
00:11:01.327 --> 00:11:03.396 line:-1 position:50%
and the viewer's head position


227
00:11:03,396 --> 00:11:06,332 line:-1
relative to the global
tracking origin.


228
00:11:06,332 --> 00:11:10,470 line:-1
Low-level hand data is provided
via Unity's Hands package,


229
00:11:10,470 --> 00:11:14,407 line:-1
and head pose is provided
through the Input System.


230
00:11:14,407 --> 00:11:17,677 line:-1
Both of these are available
in unbounded volumes only,


231
00:11:17,677 --> 00:11:20,413 line:-1
and accessing hand tracking
requires your application


232
00:11:20,413 --> 00:11:23,516 line:-1
to request permission
to receive the data.


233
00:11:23.516 --> 00:11:26.719 line:-1 position:50%
Augmented reality data
such as detected planes,


234
00:11:26,719 --> 00:11:29,188 line:-1
the world mesh,
and image markers


235
00:11:29,188 --> 00:11:33,326 line:-1
are available through ARKit
and Unity's AR Foundation.


236
00:11:33,326 --> 00:11:36,663 line:-1
Like hands and head pose,
AR data is only available


237
00:11:36.663 --> 00:11:41.267 line:-1 position:50%
in unbounded volumes
and requires extra permissions.


238
00:11:41,267 --> 00:11:45,204 line:-1
Finally, Bluetooth devices
such as keyboards, controllers,


239
00:11:45,204 --> 00:11:47,907 line:-1
and other supported devices
are available


240
00:11:47,907 --> 00:11:51,778 line:-1
for you to access through
Unity's Input System.


241
00:11:51,778 --> 00:11:54,380 line:-1
Because some types of input
are only available


242
00:11:54,380 --> 00:11:57,050 line:-1
in unbounded volumes,
you'll need to decide


243
00:11:57,050 --> 00:12:00,687 line:-1
what type of interaction
you would like to build.


244
00:12:00,687 --> 00:12:03,323 line:0
Using look and tap will allow
your content to work


245
00:12:03,323 --> 00:12:05,091 line:0
in a bounded volume
that can live


246
00:12:05,091 --> 00:12:08,261 position:50%
alongside other applications,
but if you need access


247
00:12:08,261 --> 00:12:11,197 line:0
to hand tracking
or augmented reality data,


248
00:12:11,197 --> 00:12:13,032 position:50%
you'll need to use
an unbounded volume


249
00:12:13,032 --> 00:12:15,468 position:50%
and request permissions.


250
00:12:15,468 --> 00:12:18,004 line:0
Each of these is delivered
to your Unity application


251
00:12:18,004 --> 00:12:21,207 position:50%
via an appropriate mechanism.


252
00:12:21,207 --> 00:12:24,110 line:0
This sample uses tapping,
hand tracking,


253
00:12:24,110 --> 00:12:28,548 line:0
and plane detection
in an unbounded volume scene.


254
00:12:28,548 --> 00:12:32,518 line:0
You can look at a surface found
via ARKit plane detection


255
00:12:32,518 --> 00:12:36,656 position:50%
and create flowers by dragging
your finger along it.


256
00:12:36,656 --> 00:12:39,392 line:0
The flowers are painted
using hand tracking,


257
00:12:39,392 --> 00:12:42,528 line:0
and you can tap to grow flowers.


258
00:12:42,528 --> 00:12:44,897 line:-1
Flowers that you grow react
to hand movement


259
00:12:44.897 --> 00:12:47.600 line:-1 position:50%
using Unity's physics system.


260
00:12:47,600 --> 00:12:51,037 line:-1
By incorporating the real world
into your content in this way,


261
00:12:51,037 --> 00:12:54,073 line:-1
you can create a much
deeper sense of immersion.


262
00:12:54,073 --> 00:12:56,442 line:-1
The best way to adapt
your existing interactions


263
00:12:56.442 --> 00:12:58.444 line:-1 position:50%
depends on the type.


264
00:12:58.444 --> 00:13:00.246 line:-1 position:50%
If you are already
working with touch,


265
00:13:00,246 --> 00:13:01,814 line:-1
such as on an iPhone,


266
00:13:01.814 --> 00:13:03.950 line:-1 position:50%
you can add appropriate
input colliders


267
00:13:03.950 --> 00:13:08.054 line:-1 position:50%
and continue to use tap as
your primary input mechanism.


268
00:13:08,054 --> 00:13:11,491 line:-1
If you are using VR controllers,
you will have to redefine


269
00:13:11.491 --> 00:13:15.261 line:-1 position:50%
your interactions in terms of
either tap or hand-based input,


270
00:13:15,261 --> 00:13:18,331 line:-1
depending on how complex
they are.


271
00:13:18,331 --> 00:13:23,202 line:-1
Existing hand-based input
should work without changes.


272
00:13:23,202 --> 00:13:25,338 line:-1
And if you have
existing UI panels


273
00:13:25,338 --> 00:13:27,907 line:-1
using one of Unity's UI systems,


274
00:13:27.907 --> 00:13:30.610 line:-1 position:50%
you can bring them
to this platform.


275
00:13:30.610 --> 00:13:33.379 line:-1 position:50%
User interface elements
built using uGUI,


276
00:13:33.379 --> 00:13:36.382 line:-1 position:50%
as well as UI Toolkit,
are supported.


277
00:13:36.382 --> 00:13:38.351 line:-1 position:50%
If you are using
other UI systems,


278
00:13:38.351 --> 00:13:40.420 line:-1 position:50%
they will work as long
as they use meshes


279
00:13:40,420 --> 00:13:43,523 line:-1
and MeshRenderers
or draw to a RenderTexture,


280
00:13:43,523 --> 00:13:46,025 line:-1
which is then placed
on a mesh.


281
00:13:46,025 --> 00:13:48,628 line:-1
Support for spatial computing
on Apple platforms


282
00:13:48.628 --> 00:13:52.565 line:-1 position:50%
will be coming soon in beta
based on Unity 2022.


283
00:13:52.565 --> 00:13:57.136 line:-1 position:50%
However, you can start getting
your content ready today.


284
00:13:57.136 --> 00:13:58.871 line:-1 position:50%
If you're starting
a new project,


285
00:13:58.871 --> 00:14:02.208 line:-1 position:50%
use Unity 2022 or later.


286
00:14:02.208 --> 00:14:07.380 line:-1 position:50%
If you have an existing project,
start upgrading to 2022.


287
00:14:07.380 --> 00:14:10.049 line:-1 position:50%
If you have handwritten shaders
in your project,


288
00:14:10.049 --> 00:14:13.486 line:-1 position:50%
start converting them
to Shader Graph.


289
00:14:13,486 --> 00:14:16,923 line:-1
Consider adopting
the Universal Render Pipeline.


290
00:14:16,923 --> 00:14:19,559 line:-1
While the built-in graphics
pipeline is supported,


291
00:14:19.559 --> 00:14:24.030 line:-1 position:50%
all future improvements will be
on the Universal pipeline.


292
00:14:24,030 --> 00:14:28,367 line:-1
If you haven't yet, start using
the Input System package.


293
00:14:28,367 --> 00:14:31,370 line:-1
Mixed-mode input is supported,
but platform events


294
00:14:31.370 --> 00:14:34.807 line:-1 position:50%
are only delivered
through the Input System.


295
00:14:34,807 --> 00:14:37,477 line:-1
Finally, start thinking about
how you can bring


296
00:14:37.477 --> 00:14:40.313 line:-1 position:50%
an existing app or game
to spatial computing,


297
00:14:40,313 --> 00:14:43,549 line:-1
or what new experience
you'd like to create.


298
00:14:43,549 --> 00:14:46,185 line:-1
Consider whether your idea
fits in the shared space


299
00:14:46.185 --> 00:14:49.989 line:-1 position:50%
to give people more flexibility,
or if your app needs the power


300
00:14:49,989 --> 00:14:52,191 line:-1
of a full space.


301
00:14:52.191 --> 00:14:54.160 line:-1 position:50%
To get more information
about Unity's support


302
00:14:54.160 --> 00:14:55.762 line:-1 position:50%
for this platform,


303
00:14:55,762 --> 00:14:58,097 line:-1
and to sign up
for early beta access,


304
00:14:58,097 --> 00:15:01,734 line:-1
please visit unity.com/spatial.


305
00:15:01,734 --> 00:15:03,736 line:-1
I'm excited to see
all the amazing things


306
00:15:03,736 --> 00:15:08,274 line:-1
that you'll create with Unity
and this new device.


307
00:15:08,274 --> 00:15:10,810 line:-1
John: Unity is an amazing way
to hit the ground running


308
00:15:10,810 --> 00:15:12,445 line:-1
and build immersive apps.


309
00:15:12,445 --> 00:15:15,515 line:-1
And it works great with
RealityKit on this new platform.


310
00:15:15,515 --> 00:15:18,351 line:-1
You can get started today
preparing your projects.


311
00:15:18,351 --> 00:15:20,853 line:0
If you want to create
a fully immersive experience


312
00:15:20,853 --> 00:15:23,022 line:0
with Unity,
I recommend the session


313
00:15:23,022 --> 00:15:27,093 line:0
"Bring your Unity VR app
to a fully immersive space."


314
00:15:27,093 --> 00:15:30,329 line:0
And don't miss "Build great
games for spatial computing"


315
00:15:30,329 --> 00:15:32,799 line:0
to get an overview
of game development technologies


316
00:15:32,799 --> 00:15:34,934 position:50%
for this platform.


317
00:15:34,934 --> 00:15:37,470 line:-1
We can't wait to see
what you create.


318
00:15:37,470 --> 00:15:39,438 line:-1
Vladimir: Thanks for watching.


319
00:15:39,438 --> 00:15:42,208 line:0 position:90% align:right
♪

