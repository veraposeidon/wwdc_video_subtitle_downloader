2
00:00:00,334 --> 00:00:06,340 line:-1
â™ª â™ª


3
00:00:10,010 --> 00:00:14,481 line:-2
Nikolas: Hello and welcome to "Support
external cameras in your iPadOS app."


4
00:00:14,515 --> 00:00:17,050 line:-2
I'm Nikolas Gelo
from the Camera Software team,


5
00:00:17.084 --> 00:00:21.855 line:-2 align:center
and this session about how your iPad app
can start using external cameras.


6
00:00:21.889 --> 00:00:24.925 line:-2 align:center
Stage Manager's powerful set
of features include the ability


7
00:00:24,958 --> 00:00:28,462 line:-2
to extend your iPad's display
across multiple screens.


8
00:00:28.495 --> 00:00:32.232 line:-2 align:center
And with iPadOS 17,
your app can start using external cameras


9
00:00:32.266 --> 00:00:35.302 line:-2 align:center
such as the one
in the Apple Studio Display.


10
00:00:35.335 --> 00:00:38.071 line:-1 align:center
On this iPad Pro, FaceTime is open,


11
00:00:38,105 --> 00:00:41,275 line:-2
and it's using the camera
in the display that it's connected to.


12
00:00:41.308 --> 00:00:44.444 line:-2 align:center
This is great because now the people
on the other side of the call


13
00:00:44.478 --> 00:00:46.847 line:-2 align:center
have a better viewing angle of me
when I run the app


14
00:00:46,880 --> 00:00:49,183 line:-1
on this big Apple Studio Display.


15
00:00:49,216 --> 00:00:51,251 line:-1
I can also use Center Stage with it,


16
00:00:51,285 --> 00:00:54,021 line:-2
which helps keep me
in the frame as I move around.


17
00:00:58,592 --> 00:01:02,162 line:-2
FaceTime, Code Scanner,
and WebKit use external cameras,


18
00:01:02.196 --> 00:01:05.098 line:-2 align:center
and they are great examples
of what your app can do.


19
00:01:05,132 --> 00:01:07,601 line:0
When using monitors
that don't have built-in cameras,


20
00:01:07,634 --> 00:01:09,570 line:0
like the Apple Pro Display XDR,


21
00:01:09,603 --> 00:01:12,606 line:0
people often place a USB camera
on top of it.


22
00:01:12,639 --> 00:01:15,142 align:center
If the USB camera is connected
to the monitor,


23
00:01:15,175 --> 00:01:18,145 line:0
then when the monitor
is plugged into the iPad,


24
00:01:18,178 --> 00:01:21,048 line:0
the camera will also be available
to your app.


25
00:01:21.081 --> 00:01:24.151 line:-2 align:center
Your iPad app
can use external cameras and webcams


26
00:01:24.184 --> 00:01:26.453 line:-1 align:center
to take photos and record movies.


27
00:01:26.486 --> 00:01:28.956 line:-2 align:center
They also support
other system camera features,


28
00:01:28,989 --> 00:01:31,625 line:-2
like the Portrait Blur
and Studio Light video effects


29
00:01:31,658 --> 00:01:33,660 line:-1
available from Control Center.


30
00:01:34.862 --> 00:01:38.866 line:-2 align:center
iPads with USB-C connectors
support external cameras.


31
00:01:38,899 --> 00:01:42,469 line:-2
Your app can use devices
that conform to the USB Video Class,


32
00:01:42,503 --> 00:01:44,838 line:-1
or UVC, specification.


33
00:01:44,872 --> 00:01:49,443 line:-2
It defines a standard for USB devices
to support video streaming.


34
00:01:49,476 --> 00:01:52,713 line:-2
And there are many popular cameras
your app can use.


35
00:01:52,746 --> 00:01:55,215 line:-2
Some external cameras
have built-in microphones,


36
00:01:55,249 --> 00:01:57,384 line:-1
which are also available to your app.


37
00:01:57.417 --> 00:02:01.722 line:-2 align:center
Some manufacturers make non-camera devices
that conform to the UVC spec,


38
00:02:01,755 --> 00:02:05,259 line:-2
like HDMI switchers
that change between multiple inputs


39
00:02:05.292 --> 00:02:07.528 line:-1 align:center
to output a single video stream.


40
00:02:07,561 --> 00:02:11,565 line:-2
iPadOS allows your app
to use devices like these.


41
00:02:11.598 --> 00:02:14.001 line:-2 align:center
External camera support
is a great enhancement


42
00:02:14.034 --> 00:02:16.570 line:-1 align:center
to iPad's rich media ecosystem.


43
00:02:16,603 --> 00:02:21,308 line:-2
I'll show how your app can use them
by starting with discovery and usage.


44
00:02:21.341 --> 00:02:25.846 line:-2 align:center
Next, I'll circle back
and demystify video rotation.


45
00:02:25.879 --> 00:02:28.549 line:-2 align:center
Then I'll cover how
your app can use microphones


46
00:02:28,582 --> 00:02:30,817 line:-1
that are included with external cameras.


47
00:02:30,851 --> 00:02:34,721 line:-2
And lastly,
I'll discuss best practices for your app.


48
00:02:34,755 --> 00:02:39,059 line:-2
First up, I'll discuss how your iPad app
can start using external cameras.


49
00:02:39.092 --> 00:02:41.528 line:-2 align:center
iPad apps use the camera
for many features,


50
00:02:41,562 --> 00:02:44,131 line:-1
like taking photos, recording movies,


51
00:02:44,164 --> 00:02:47,801 line:-2
or sending camera frames
over the network for video calls.


52
00:02:47.835 --> 00:02:52.739 line:-2 align:center
The AVFoundation framework allows your app
to use built-in and external cameras,


53
00:02:52,773 --> 00:02:56,643 line:-2
specifically,
with its AVCapture-prefixed classes.


54
00:02:56.677 --> 00:02:59.279 line:-2 align:center
Let's review how
an app can use the camera.


55
00:02:59,313 --> 00:03:04,952 line:-2
First, an app uses AVCaptureDevices,
which represent cameras and microphones.


56
00:03:04.985 --> 00:03:07.988 line:-2 align:center
Then they are wrapped
in AVCaptureDeviceInputs,


57
00:03:08,021 --> 00:03:11,258 line:-2
which allow them to be plugged
into an AVCaptureSession.


58
00:03:11.291 --> 00:03:15.829 line:-2 align:center
The AVCaptureSession is the central
control object of the AVCapture graph.


59
00:03:16,530 --> 00:03:20,501 align:center
AVCaptureOutputs render data
from inputs in various ways.


60
00:03:20,534 --> 00:03:23,403 align:center
The MovieFileOutput
records QuickTime movies.


61
00:03:23,437 --> 00:03:27,674 line:0
The PhotoOutput captures
high-quality stills and Live Photos.


62
00:03:27,708 --> 00:03:31,912 line:0
Data outputs, such as the VideoDataOutput
or AudioDataOutput,


63
00:03:31,945 --> 00:03:36,517 align:center
deliver video or audio buffers
from the camera or mic to your app.


64
00:03:37,484 --> 00:03:42,122 line:0
And there are other kinds of data outputs,
such as Metadata and Depth.


65
00:03:42,155 --> 00:03:45,325 align:center
For live camera preview,
there's a special type of output,


66
00:03:45,359 --> 00:03:49,963 line:0
the AVCaptureVideoPreviewLayer,
which is a subclass of CALayer.


67
00:03:50,864 --> 00:03:54,501 align:center
Data flows from the capture inputs
to compatible outputs


68
00:03:54,535 --> 00:03:56,937 align:center
through AVCaptureConnections.


69
00:03:56,970 --> 00:04:01,975 align:center
These classes are available on iOS,
macOS, and tvOS.


70
00:04:02.976 --> 00:04:05.812 line:-2 align:center
If you're new to AVCapture,
I invite you to learn more


71
00:04:05.846 --> 00:04:10.117 line:-2 align:center
at the Capture Setup start page
on developer.apple.com.


72
00:04:10.951 --> 00:04:16.123 line:-2 align:center
New in iPadOS 17, your app can
access external cameras with AVCapture.


73
00:04:16,156 --> 00:04:18,492 line:-1
If your app already uses built-in cameras,


74
00:04:18,525 --> 00:04:21,862 line:-2
you can make simple updates
to start using external ones.


75
00:04:21.895 --> 00:04:23.597 line:-1 align:center
Discovering them is easy.


76
00:04:23,630 --> 00:04:28,101 line:-2
Each external camera is represented
by an AVCaptureDevice instance.


77
00:04:28,135 --> 00:04:30,604 line:-1
And you can find them with existing API


78
00:04:30,637 --> 00:04:35,742 line:-2
from AVCaptureDevice
and AVCaptureDeviceDiscoverySession.


79
00:04:35,776 --> 00:04:38,745 line:-2
There are three main attributes
of an AVCaptureDevice:


80
00:04:38,779 --> 00:04:42,382 line:-1
Its media type, device type, and position.


81
00:04:42,416 --> 00:04:46,820 line:-2
External cameras provide video media data
just like built-in cameras do.


82
00:04:46.854 --> 00:04:49.656 line:-1 align:center
And their device type is external.


83
00:04:49.690 --> 00:04:53.727 line:-2 align:center
For macOS app developers who are familiar
with using external cameras,


84
00:04:53.760 --> 00:04:57.631 line:-2 align:center
this deprecates
the external unknown device type.


85
00:04:57,664 --> 00:05:00,968 line:-2
Because external cameras
can move independently from the iPad,


86
00:05:01,001 --> 00:05:04,171 line:-1
their device position is unspecified.


87
00:05:04,204 --> 00:05:06,540 line:-1
These three attributes can be used


88
00:05:06,573 --> 00:05:10,644 line:-2
to find external cameras
with the AVCapture API.


89
00:05:10.677 --> 00:05:13.413 line:-2 align:center
It's easy to start using
external cameras in your app.


90
00:05:13,447 --> 00:05:16,683 line:-2
In this session,
I'll modify the popular sample camera app,


91
00:05:16.717 --> 00:05:21.555 line:-2 align:center
AVCam, to stream from the external camera
in an Apple Studio Display.


92
00:05:21,588 --> 00:05:25,158 line:-2
You can download the completed version
of AVCam with all of the changes


93
00:05:25,192 --> 00:05:28,829 line:-2
I make in this session
from developer.apple.com.


94
00:05:29,630 --> 00:05:31,999 line:-1
Currently, the app uses built-in cameras,


95
00:05:32,032 --> 00:05:34,835 line:-2
and it lets the user switch
between a front and rear-facing camera


96
00:05:34.868 --> 00:05:36.570 line:-1 align:center
when a button is pressed.


97
00:05:36.603 --> 00:05:40.474 line:-2 align:center
When AVCam launches,
it starts with a rear-facing camera.


98
00:05:40,507 --> 00:05:42,576 line:-2
I'll change the code
to have the app prefer looking


99
00:05:42.609 --> 00:05:45.179 line:-2 align:center
for an external camera
before a built-in one.


100
00:05:48,849 --> 00:05:51,418 line:-2
With the iPad connected
to the Apple Studio Display,


101
00:05:51,451 --> 00:05:55,589 line:-2
I'll run the app, and when it launches,
it will use the external camera.


102
00:05:58,158 --> 00:05:59,259 line:-1
This is great.


103
00:05:59,293 --> 00:06:04,464 line:-2
AVCam is now using an external camera,
and all it needed was a few lines of code.


104
00:06:04.498 --> 00:06:08.101 line:-2 align:center
The AVCaptureVideoPreviewLayer
mirrors external cameras by default,


105
00:06:08,135 --> 00:06:11,805 line:-2
which is suitable for using the camera
in the Apple Studio Display.


106
00:06:11.839 --> 00:06:14.775 line:-2 align:center
You can disable this behavior
if you prefer.


107
00:06:14,808 --> 00:06:17,778 line:-2
I'll describe how to do this
in the best practices section


108
00:06:17,811 --> 00:06:19,246 line:-1
at the end of this session.


109
00:06:19.279 --> 00:06:22.316 line:-2 align:center
Now I'll move the app
to the iPad's display.


110
00:06:24,484 --> 00:06:28,021 line:-2
And just for fun,
I'll unplug the external camera.


111
00:06:29,923 --> 00:06:32,693 line:-1
Uh-oh, the app's camera preview is frozen,


112
00:06:32,726 --> 00:06:35,095 line:-1
and it's not using any camera now.


113
00:06:35.128 --> 00:06:38.899 line:-2 align:center
AVCam will need more changes to handle
connection and disconnection events


114
00:06:38.932 --> 00:06:40.367 line:-1 align:center
of external cameras.


115
00:06:40,400 --> 00:06:44,137 line:-2
External cameras require special care
because, unlike built-in ones,


116
00:06:44,171 --> 00:06:48,342 line:-2
the user can connect and disconnect them
from the iPad at any time.


117
00:06:48,375 --> 00:06:52,379 line:-2
Your app can monitor these events
to know when a camera has become available


118
00:06:52.412 --> 00:06:54.648 line:-1 align:center
or can no longer be used.


119
00:06:54,681 --> 00:06:57,217 line:-2
If the same physical device
is reconnected,


120
00:06:57.251 --> 00:07:01.788 line:-2 align:center
it will be represented using
a new instance of AVCaptureDevice.


121
00:07:01,822 --> 00:07:04,191 line:-1
There is existing API your app can use


122
00:07:04.224 --> 00:07:07.160 line:-2 align:center
to listen for connection
and disconnection events.


123
00:07:08,695 --> 00:07:13,567 line:-2
You can key-value observe the isConnected
property on AVCaptureDevice


124
00:07:13,600 --> 00:07:18,071 line:-2
or the devices property
on an AVCaptureDeviceDiscoverySession


125
00:07:18.105 --> 00:07:21.175 line:-1 align:center
that updates as cameras come and go.


126
00:07:21,208 --> 00:07:25,746 line:-2
AVCaptureDevices also post notifications
when their connection status changes,


127
00:07:25,779 --> 00:07:30,350 line:-2
and your app can observe them
to monitor a camera's availability.


128
00:07:30,384 --> 00:07:32,819 align:center
The system calls
key value observation code


129
00:07:32,853 --> 00:07:35,622 align:center
and posts notifications
on background queues.


130
00:07:35,656 --> 00:07:37,724 align:center
So be sure to synchronize your handling


131
00:07:37,758 --> 00:07:41,161 line:0
with your AVCaptureSession queue
and the main thread.


132
00:07:42.162 --> 00:07:44.898 line:-2 align:center
Going back to AVCam,
I'll add some code to listen


133
00:07:44,932 --> 00:07:48,569 line:-2
for connection and disconnection events
of an external camera.


134
00:07:48,602 --> 00:07:51,171 line:-2
After the app looks
for the default device,


135
00:07:51,205 --> 00:07:54,341 line:0
it observes
when the camera is disconnected.


136
00:07:54,374 --> 00:07:58,011 line:0
And when that happens,
AVCam switches to a built-in camera.


137
00:07:58.745 --> 00:08:02.516 line:-2 align:center
Now when the app launches,
it still uses an external camera.


138
00:08:02,549 --> 00:08:06,687 line:-2
And when it disconnects,
the app switches to a built-in camera.


139
00:08:10.290 --> 00:08:12.359 line:-2 align:center
But when the external camera
is reconnected,


140
00:08:12,392 --> 00:08:14,461 line:-1
AVCam doesn't switch to it.


141
00:08:18.065 --> 00:08:21.702 line:-2 align:center
How should AVCam handle external cameras
being connected while it's running?


142
00:08:21,735 --> 00:08:24,438 line:-2
Should it switch to it
after I've plugged it in?


143
00:08:25,372 --> 00:08:28,609 line:-2
A tricky aspect of adopting
external cameras in your iPad app


144
00:08:28,642 --> 00:08:31,678 line:-2
is handling connection
and disconnection events.


145
00:08:31.712 --> 00:08:35.415 line:-2 align:center
To make this easier,
iPadOS is introducing API


146
00:08:35.449 --> 00:08:37.985 line:-1 align:center
for automatic camera selection.


147
00:08:38.018 --> 00:08:41.154 line:-2 align:center
The API allows your app
to integrate with the operating system


148
00:08:41.188 --> 00:08:43.790 line:-1 align:center
to use the best available camera.


149
00:08:43.824 --> 00:08:47.528 line:-2 align:center
It is another way
for your app to change cameras.


150
00:08:47.561 --> 00:08:51.231 line:-2 align:center
macOS Ventura introduced API
for automatic camera selection


151
00:08:51.265 --> 00:08:53.667 line:-1 align:center
to support Continuity Camera.


152
00:08:53,700 --> 00:08:57,604 line:-2
The behaviors I describe
in this session are specific to iOS.


153
00:08:58,205 --> 00:09:00,941 line:-4
For more information on how
to use this API for Mac,


154
00:09:00.974 --> 00:09:05.245 line:-4 align:center
see our previous session "Bringing
Continuity Camera to your macOS app"


155
00:09:05,279 --> 00:09:10,017 line:-4
from 2022 and its section
"Building a magical experience."


156
00:09:11.251 --> 00:09:14.888 line:-2 align:center
Automatic camera selection works
by using two new class properties


157
00:09:14.922 --> 00:09:17.824 line:-1 align:center
introduced to AVCaptureDevice on iOS:


158
00:09:17,858 --> 00:09:20,194 line:-1
userPreferredCamera


159
00:09:20,227 --> 00:09:22,362 line:-1
and systemPreferredCamera.


160
00:09:23,330 --> 00:09:26,233 line:-2
Both of these properties
are key-value observable.


161
00:09:27,267 --> 00:09:29,937 line:-2
userPreferredCamera
is a read/write property


162
00:09:29,970 --> 00:09:33,507 line:-2
that indicates the user's choice
of what camera should be used.


163
00:09:33.540 --> 00:09:37.377 line:-2 align:center
It should be set whenever a user
picks a camera in your app.


164
00:09:37,411 --> 00:09:41,582 line:-2
Doing so allows the system
to learn the user's preference.


165
00:09:43,050 --> 00:09:45,886 line:-2
systemPreferredCamera
is a read-only property


166
00:09:45,919 --> 00:09:50,657 line:-2
which specifies the best camera
to use as determined by the system.


167
00:09:50,691 --> 00:09:54,528 line:-2
By default, the system recommends
using the front camera,


168
00:09:54.561 --> 00:09:56.997 line:-2 align:center
but if you would like
to use a back camera instead,


169
00:09:57,030 --> 00:10:00,667 line:-2
your app can inform the system
of its desired behavior.


170
00:10:00,701 --> 00:10:02,870 line:-2
As different cameras
are chosen by the user,


171
00:10:02.903 --> 00:10:04.938 line:-1 align:center
the recommendation changes.


172
00:10:04.972 --> 00:10:08.275 line:-2 align:center
But you might be wondering how
the system know which camera is best.


173
00:10:08,308 --> 00:10:09,943 line:-1
I'll dive into that in a bit.


174
00:10:09.977 --> 00:10:14.715 line:-2 align:center
I'll first describe AVCaptureDevice's
userPreferredCamera property.


175
00:10:14.748 --> 00:10:17.784 line:-2 align:center
For this property,
the system stores a short history


176
00:10:17,818 --> 00:10:22,656 line:-2
of chosen cameras for each app
across launches and system reboots.


177
00:10:22,689 --> 00:10:25,392 line:-2
It allows your app
to combine the user's history


178
00:10:25,425 --> 00:10:29,630 line:-2
with the system's knowledge
of which cameras are currently connected.


179
00:10:29,663 --> 00:10:32,199 line:-1
So if a camera is disconnected,


180
00:10:32.232 --> 00:10:34.568 line:-2 align:center
the system returns
the next available camera


181
00:10:34,601 --> 00:10:36,637 line:-1
based on the user's history.


182
00:10:37.638 --> 00:10:39.706 line:-1 align:center
If there is no user selection history,


183
00:10:39.740 --> 00:10:42.142 line:-2 align:center
or none of the preferred cameras
are connected,


184
00:10:42.176 --> 00:10:45.612 line:-2 align:center
the system will always try
to return a camera that's ready to use


185
00:10:45,646 --> 00:10:49,116 line:-2
and prioritize cameras
that have been previously streamed.


186
00:10:49.149 --> 00:10:51.952 line:-2 align:center
Your app can use this property
to let the system store


187
00:10:51,985 --> 00:10:53,987 line:-1
your user's camera preference.


188
00:10:55,222 --> 00:10:57,991 line:-2
AVCaptureDevice's
systemPreferredCamera property


189
00:10:58,025 --> 00:11:00,928 line:-2
intelligently returns
the best camera to use.


190
00:11:00,961 --> 00:11:03,664 line:-1
It first checks the user's preference.


191
00:11:03,697 --> 00:11:06,466 line:-2
And when the user connects
an external camera to the iPad,


192
00:11:06,500 --> 00:11:09,203 line:-1
the system returns the new device.


193
00:11:09,236 --> 00:11:12,139 line:-2
This is because,
when a user connects a new camera,


194
00:11:12.172 --> 00:11:15.742 line:-2 align:center
they're implicitly indicating
their intent to use it.


195
00:11:15,776 --> 00:11:19,680 line:-2
These two inputs determine
the system preferred camera.


196
00:11:20.547 --> 00:11:23.650 line:-2 align:center
The automatic camera selection API
is flexible for an app


197
00:11:23.684 --> 00:11:26.220 line:-2 align:center
to choose how it integrates
with the system.


198
00:11:26.253 --> 00:11:29.122 line:-1 align:center
While only iPad supports external cameras,


199
00:11:29,156 --> 00:11:33,493 line:-2
iPhone apps can also use the API
for its user preferred camera storage.


200
00:11:33,527 --> 00:11:35,863 line:-1
Some apps allow users to change cameras,


201
00:11:35,896 --> 00:11:39,333 line:-2
while others stick to one
without giving a way to switch.


202
00:11:39.366 --> 00:11:44.304 line:-2 align:center
The API allows apps to choose between
automatic and manual camera selection.


203
00:11:45,105 --> 00:11:48,909 line:-2
FaceTime, Code Scanner,
and WebKit are great examples


204
00:11:48,942 --> 00:11:52,713 line:-2
that have different camera selection
behaviors to suit their needs.


205
00:11:52.746 --> 00:11:54.181 line:-1 align:center
When FaceTime launches,


206
00:11:54,214 --> 00:11:57,117 line:-2
it always uses the front
or external camera.


207
00:11:57.150 --> 00:12:01.788 line:-2 align:center
And during calls, it allows users
to switch between built-in cameras.


208
00:12:01.822 --> 00:12:06.460 line:-2 align:center
But when an external camera is used,
it hides the camera switch button.


209
00:12:06,493 --> 00:12:09,897 line:-2
FaceTime enables this behavior
by setting userPreferredCamera


210
00:12:09,930 --> 00:12:14,334 line:-2
when it switches devices and observing
the systemPreferredCamera property


211
00:12:14,368 --> 00:12:17,204 line:-1
for when an external device is plugged in.


212
00:12:17.237 --> 00:12:20.140 line:-2 align:center
It also makes its own decisions
for when it is appropriate


213
00:12:20,174 --> 00:12:23,010 line:-1
to use the automatic camera selection API.


214
00:12:23.043 --> 00:12:25.412 line:-2 align:center
For example,
while you can use the back camera


215
00:12:25,445 --> 00:12:26,980 line:-1
in a FaceTime Video call,


216
00:12:27,014 --> 00:12:29,416 line:-2
it always uses
the front or external camera


217
00:12:29,449 --> 00:12:32,252 line:-2
on the main screen
that shows the list of calls.


218
00:12:32.286 --> 00:12:34.988 line:-2 align:center
Code Scanner,
available from Control Center,


219
00:12:35.022 --> 00:12:36.723 line:-1 align:center
has different behavior.


220
00:12:36.757 --> 00:12:39.593 line:-2 align:center
It uses the back-facing camera
when it launches,


221
00:12:39,626 --> 00:12:42,529 line:-2
and it doesn't allow the user
to change cameras,


222
00:12:42.563 --> 00:12:45.933 line:-2 align:center
but it does listen
to the systemPreferredCamera property


223
00:12:45.966 --> 00:12:48.902 line:-1 align:center
and switches when notified.


224
00:12:48.936 --> 00:12:53.407 line:-2 align:center
The WebKit framework allows webpages
to access the iPad's cameras.


225
00:12:53.440 --> 00:12:55.542 line:-1 align:center
While it allows switching to any camera,


226
00:12:55,576 --> 00:12:59,346 line:-2
it returns the system preferred camera
as the first one in its list.


227
00:12:59.379 --> 00:13:02.182 line:-2 align:center
Now that I've shown you
how automatic camera selection works,


228
00:13:02,216 --> 00:13:04,952 line:-1
I'll add support for it in AVCam.


229
00:13:04,985 --> 00:13:07,654 line:-1
AVCam is a traditional photography app,


230
00:13:07,688 --> 00:13:10,791 line:-2
since you can take photos
and record movies with it.


231
00:13:10.824 --> 00:13:12.893 line:-2 align:center
It's different
from FaceTime and Code Scanner,


232
00:13:12,926 --> 00:13:16,196 line:-2
which are communication and utility apps,
respectively,


233
00:13:16,230 --> 00:13:19,233 line:-1
and WebKit, which is a system framework.


234
00:13:19,266 --> 00:13:22,669 line:-2
Now instead of needing a series
of "if, else if" statements


235
00:13:22.703 --> 00:13:25.038 line:-2 align:center
to find the external camera
with fallbacks,


236
00:13:25.072 --> 00:13:29.243 line:-2 align:center
AVCam just needs one line
to get the system preferred camera.


237
00:13:29.276 --> 00:13:33.113 line:-2 align:center
Since this is the first time the app is
using the automatic camera selection API,


238
00:13:33.146 --> 00:13:35.916 line:-2 align:center
the system returns
the built-in front camera.


239
00:13:35.949 --> 00:13:39.520 line:-2 align:center
But AVCam prefers
to continue starting with the back camera.


240
00:13:39,553 --> 00:13:41,822 line:-2
Before it gets
the system preferred camera,


241
00:13:41.855 --> 00:13:44.825 line:-2 align:center
the app checks if this is the first time
it has queried for it


242
00:13:44.858 --> 00:13:48.061 line:-2 align:center
by looking for a value stored
in the app's user defaults.


243
00:13:48,095 --> 00:13:51,565 line:-2
If no value is saved,
then the app hasn't set its initial state


244
00:13:51,598 --> 00:13:54,134 line:-1
for automatic camera selection.


245
00:13:54.168 --> 00:13:56.570 line:-1 align:center
So if this is the first time launching,


246
00:13:56,603 --> 00:14:00,240 line:-2
the app sets the user preferred camera
to be the back device.


247
00:14:00,274 --> 00:14:04,144 line:-2
The app finds the back camera
using an AVCaptureDeviceDiscoverySession,


248
00:14:04,178 --> 00:14:08,148 align:center
which sorts the list of the devices
using the provided device types.


249
00:14:08,182 --> 00:14:11,485 align:center
Then it sets the user preferred camera
and saves a value


250
00:14:11,518 --> 00:14:15,455 align:center
in the app's user preferences,
so it only does this setup once.


251
00:14:16,390 --> 00:14:19,960 line:-2
To handle connections and disconnections
of external cameras,


252
00:14:19,993 --> 00:14:24,364 line:-2
it doesn't have to observe the connection
status of a specific camera anymore.


253
00:14:24.398 --> 00:14:29.203 line:-2 align:center
Instead, AVCam key value observes
the system preferred camera property.


254
00:14:29,236 --> 00:14:33,540 line:-2
This allows it to automatically switch
to the best available camera.


255
00:14:33.574 --> 00:14:35.209 line:-1 align:center
In its KVO handling,


256
00:14:35,242 --> 00:14:39,213 line:-2
the app gets the new system
preferred camera and switches to it.


257
00:14:39.246 --> 00:14:41.849 line:-2 align:center
but what if AVCam
is in the middle of a recording?


258
00:14:41,882 --> 00:14:45,152 align:center
The app shouldn't interrupt the recording
by switching cameras.


259
00:14:45,185 --> 00:14:49,523 line:0
So the app only switches if it is not
in the middle of a recording.


260
00:14:49.556 --> 00:14:51.825 line:-1 align:center
Then when the movie recording finishes,


261
00:14:51,859 --> 00:14:53,961 line:-2
the app queries
for the system preferred camera


262
00:14:53,994 --> 00:14:57,631 line:-2
to see if it is different
from what it is currently using.


263
00:14:57.664 --> 00:15:01.335 line:-2 align:center
If the system preferred camera did change,
the app switches to it.


264
00:15:01.368 --> 00:15:04.304 line:-2 align:center
This way it doesn't interrupt
the recording.


265
00:15:04.338 --> 00:15:06.473 line:-2 align:center
Decisions like these
are steps you'll have to make


266
00:15:06,507 --> 00:15:10,511 line:-2
when adopting external cameras
and the automatic camera selection API.


267
00:15:10,544 --> 00:15:13,046 line:-1
Do what makes the most sense for your app.


268
00:15:13,847 --> 00:15:17,251 line:0
AVCam has a button to switch cameras
and behaves by changing


269
00:15:17,284 --> 00:15:19,753 align:center
between front and back devices.


270
00:15:19,786 --> 00:15:22,389 align:center
On this iPad Pro,
there are multiple cameras


271
00:15:22,422 --> 00:15:24,525 line:0
that can be used at both positions.


272
00:15:24.558 --> 00:15:29.429 line:-2 align:center
So AVCam has some logic for choosing
which camera to use at a given position.


273
00:15:29.463 --> 00:15:33.700 line:-2 align:center
How should the button work now
that the app supports external cameras?


274
00:15:33.734 --> 00:15:37.504 line:-2 align:center
I'll choose to treat an external camera
like it is front-facing.


275
00:15:37,538 --> 00:15:40,707 line:-2
The camera
in this Apple Studio Display is facing me


276
00:15:40,741 --> 00:15:42,776 line:-1
like the iPad's built-in front camera.


277
00:15:43,544 --> 00:15:47,414 line:0
If the changeCamera function
has no specific device to switch to,


278
00:15:47,447 --> 00:15:50,083 line:0
the app checks the position
of the current device.


279
00:15:50,117 --> 00:15:53,287 line:-2
In the switch statement that checks
the current device's position,


280
00:15:53,320 --> 00:15:56,757 line:-2
the app looks for a rear-facing camera
if it is currently using one


281
00:15:56.790 --> 00:15:59.927 line:-1 align:center
with an unspecified or front position.


282
00:15:59.960 --> 00:16:03.897 line:-2 align:center
External cameras report
that their position is unspecified.


283
00:16:03,931 --> 00:16:06,433 align:center
And if the app
is using a rear-facing camera,


284
00:16:06,466 --> 00:16:10,103 line:0
it switches to an external device
if one is available.


285
00:16:10,137 --> 00:16:14,575 align:center
Otherwise, it switches
to a built-in front facing camera.


286
00:16:14,608 --> 00:16:17,277 align:center
To find external cameras, the app creates


287
00:16:17,311 --> 00:16:21,915 line:0
a AVCaptureDeviceDiscoverySession
using the external device type,


288
00:16:21,949 --> 00:16:26,420 align:center
the video media type,
and unspecified device position.


289
00:16:27,421 --> 00:16:31,992 align:center
Then in the switch statement when
the current device's position is back,


290
00:16:32,025 --> 00:16:34,628 line:0
it first looks for an external camera.


291
00:16:34,661 --> 00:16:38,966 line:0
And if one is not found, it switches
to a built-in front facing camera.


292
00:16:39,700 --> 00:16:42,803 line:-2
Then when the app finds the camera
it would like to use,


293
00:16:42,836 --> 00:16:45,038 line:-1
it tells the system of the selection


294
00:16:45,072 --> 00:16:50,110 line:-2
by setting the userPreferredCamera class
property on AVCaptureDevice.


295
00:16:50.143 --> 00:16:54.248 line:-2 align:center
Setting this property allows the system
to learn the user's preferences.


296
00:16:55,182 --> 00:16:57,751 line:-2
You can choose how your app
will support external cameras


297
00:16:57,784 --> 00:17:00,454 line:-2
and how to allow a user
to switch between them.


298
00:17:00.487 --> 00:17:03.423 line:-2 align:center
For AVCam,
I chose to allow a user to switch


299
00:17:03,457 --> 00:17:06,460 line:-1
between front, back, and external cameras


300
00:17:06,493 --> 00:17:09,496 line:-2
by treating external cameras
like they are front-facing.


301
00:17:09.530 --> 00:17:13.834 line:-2 align:center
This way, the camera switch button
only changes between two devices.


302
00:17:13,867 --> 00:17:16,870 line:-2
AVCam is almost ready
to support external cameras.


303
00:17:16,904 --> 00:17:19,239 line:-1
There is just one more aspect to handle.


304
00:17:19.273 --> 00:17:21.175 line:-1 align:center
This whole time I've been using AVCam,


305
00:17:21,208 --> 00:17:24,578 line:-2
the iPad has been mounted in landscape
with the USB-C port on the right.


306
00:17:24.611 --> 00:17:29.249 line:-2 align:center
If I rotate the iPad, the external
camera's preview is now upside down.


307
00:17:32.753 --> 00:17:35.088 line:-2 align:center
But the external camera
in the display hasn't moved.


308
00:17:35.122 --> 00:17:37.057 line:-1 align:center
Just the iPad has.


309
00:17:40,027 --> 00:17:43,864 line:-2
AVCam doesn't have this rotation problem
with built-in cameras though.


310
00:17:43.897 --> 00:17:46.700 line:-2 align:center
This is because the app doesn't know
how to orient external cameras


311
00:17:46.733 --> 00:17:50.137 line:-2 align:center
whose position
is independent from the iPad.


312
00:17:50,170 --> 00:17:52,472 line:-1
AVCam will need further modifications


313
00:17:52,506 --> 00:17:55,843 line:-2
to properly display
an external camera's video preview.


314
00:17:55.876 --> 00:17:58.912 line:-2 align:center
Next up, I'll discuss
why video rotation is important


315
00:17:58,946 --> 00:18:03,650 line:-2
so that live preview and captured photos
and movies appear correctly.


316
00:18:03.684 --> 00:18:06.653 line:-2 align:center
Video rotation is not a new concept
for camera apps.


317
00:18:06,687 --> 00:18:09,523 line:-2
But when using external cameras,
it is important to know


318
00:18:09,556 --> 00:18:12,226 line:-2
that they move independently
from the iPad.


319
00:18:12,259 --> 00:18:14,494 line:-1
Apps are used to built-in cameras.


320
00:18:14.528 --> 00:18:17.297 line:-2 align:center
And because of this,
they rely on the iPad's orientation


321
00:18:17.331 --> 00:18:22.669 line:-2 align:center
to rotate the camera's video and use
the AVCaptureVideoOrientation enum.


322
00:18:22,703 --> 00:18:25,572 line:-2
This is what AVCam
was doing in the previous demo.


323
00:18:25.606 --> 00:18:30.310 line:-2 align:center
It tried rotating the external camera
to match the iPad's orientation.


324
00:18:30,344 --> 00:18:34,414 line:-2
In iPadOS 17,
AVCaptureVideoOrientation is deprecated,


325
00:18:34.448 --> 00:18:37.050 line:-1 align:center
as well as the API that use this enum.


326
00:18:37.084 --> 00:18:39.386 line:-1 align:center
It describes how the iPad is oriented


327
00:18:39,419 --> 00:18:42,356 line:-2
and assumes
the camera rotates with the device.


328
00:18:42,389 --> 00:18:45,158 line:-2
It's not expressive enough
for orienting external cameras,


329
00:18:45,192 --> 00:18:47,227 line:-1
which move independently.


330
00:18:47,261 --> 00:18:51,431 line:-2
To use this enum, an app typically
converts from UIDeviceOrientation,


331
00:18:51,465 --> 00:18:56,236 line:-2
which also describes the iPad and is
an indirect signal for orienting a camera.


332
00:18:56,270 --> 00:19:00,641 line:-2
So we're introducing new API
to handle video rotation.


333
00:19:00.674 --> 00:19:03.310 line:-1 align:center
New to all platforms, including iPadOS,


334
00:19:03,343 --> 00:19:08,348 line:-2
the AVCaptureDeviceRotationCoordinator
class can help properly orient any camera.


335
00:19:08.382 --> 00:19:11.752 line:-2 align:center
The class's initializer
takes an AVCaptureDevice


336
00:19:11,785 --> 00:19:16,723 line:-2
and optionally a CALayer
that displays the camera's video preview.


337
00:19:16.757 --> 00:19:19.393 line:-2 align:center
Apps often use
AVCaptureVideoPreviewLayer


338
00:19:19,426 --> 00:19:22,763 line:-2
or AVSampleBufferDisplayLayer
to show camera preview.


339
00:19:22.796 --> 00:19:27.467 line:-2 align:center
Both of these are subclasses of CALayer
and can be passed to the initializer.


340
00:19:27,501 --> 00:19:29,903 line:-2
Apps that use Metal
or other rendering methods


341
00:19:29,937 --> 00:19:34,208 line:-2
can simply pass the layer of the UIView
displaying the camera's preview.


342
00:19:34.241 --> 00:19:36.977 line:-1 align:center
The coordinator has two properties:


343
00:19:37,010 --> 00:19:40,180 line:-2
A video rotation angle
for horizon-level preview


344
00:19:40,214 --> 00:19:43,217 line:-2
and a separate angle
for horizon-level capture.


345
00:19:43.250 --> 00:19:46.320 line:-2 align:center
Both of these read-only properties
return an angle in degrees


346
00:19:46.353 --> 00:19:48.422 line:-1 align:center
and are key-value observable.


347
00:19:49,489 --> 00:19:52,826 line:-2
Previewing and capturing
content horizon-level means


348
00:19:52.860 --> 00:19:55.128 line:-2 align:center
that the video frames
from the camera are always upright


349
00:19:55.162 --> 00:19:58.565 line:-2 align:center
relative to gravity,
no matter if the device is in portrait,


350
00:19:58.599 --> 00:20:00.968 line:-1 align:center
landscape, or upside down.


351
00:20:02,135 --> 00:20:05,072 line:-2
Use the
videoRotationAngleForHorizonLevelPreview


352
00:20:05,105 --> 00:20:10,444 line:-2
to display video frames in the CALayer
passed to the coordinator's initializer.


353
00:20:10,477 --> 00:20:14,248 line:-2
It describes how much rotation
to apply for preview.


354
00:20:14,281 --> 00:20:18,752 line:-2
The angle is relative to the UIKit
and SwiftUI coordinate systems.


355
00:20:19.786 --> 00:20:22.389 line:-2 align:center
The
videoRotationAngleForHorizonLevelCapture


356
00:20:22,422 --> 00:20:24,491 line:-1
allows your app to take photos and movies,


357
00:20:24.525 --> 00:20:28.095 line:-2 align:center
so they are always upright
when someone views them later.


358
00:20:28,128 --> 00:20:32,099 line:-2
This property describes
the physical orientation of the camera.


359
00:20:32,132 --> 00:20:35,769 line:-2
And its value may be different
than the angle the app needs for preview.


360
00:20:35,802 --> 00:20:38,405 line:-2
These two properties
have different purposes.


361
00:20:38.438 --> 00:20:41.175 line:-2 align:center
To explain video rotation,
I'll start with scenarios


362
00:20:41,208 --> 00:20:43,877 line:-2
you are familiar with
when using built-in cameras.


363
00:20:43,911 --> 00:20:46,113 line:-1
Later, when I modify AVCam,


364
00:20:46,146 --> 00:20:49,716 line:-2
I'll explain how these concepts apply
to external cameras.


365
00:20:49.750 --> 00:20:52.753 line:-2 align:center
The camera app on iPhone
is a good example of the differences


366
00:20:52,786 --> 00:20:56,924 line:-2
between the video rotation angles
for horizon-level preview and capture.


367
00:20:56,957 --> 00:20:59,893 line:-2
In this example of the app
displaying the back camera's preview,


368
00:20:59.927 --> 00:21:02.429 line:-1 align:center
the iPhone is in portrait.


369
00:21:02,462 --> 00:21:06,133 line:-2
The UIKit coordinate system's origin
is at the top left of the drawing area,


370
00:21:06,166 --> 00:21:08,735 line:-2
where its positive x-axis
extends to the right


371
00:21:08,769 --> 00:21:11,505 line:-1
and positive y-axis extends down.


372
00:21:11,538 --> 00:21:15,042 line:-2
The back camera sensor's coordinate system
has a different origin.


373
00:21:15,976 --> 00:21:18,812 line:-2
The camera sensor first scans
along the height of the phone,


374
00:21:18,846 --> 00:21:20,480 line:-1
then along the width.


375
00:21:20,514 --> 00:21:23,050 line:-2
To account for the physical orientation
of the camera,


376
00:21:23.083 --> 00:21:28.021 line:-2 align:center
the app rotates the camera's video frames
90 degrees for preview in the UI.


377
00:21:28.055 --> 00:21:30.557 line:-2 align:center
It also rotates photos and movies
it captures,


378
00:21:30.591 --> 00:21:33.427 line:-1 align:center
so they are upright when viewed later.


379
00:21:33,460 --> 00:21:37,164 line:-2
It has different behavior
when the iPhone is in landscape.


380
00:21:37,197 --> 00:21:42,002 line:-2
The app only displays the UI in portrait,
no matter the device's orientation.


381
00:21:42.035 --> 00:21:45.706 line:-2 align:center
You can tell based on where
the home affordance indicator is.


382
00:21:45,739 --> 00:21:50,344 line:-2
For Camera app on iPhone,
it always stays on the side with the port.


383
00:21:50,377 --> 00:21:54,414 align:center
The UIKit coordinate system's origin is
still at the top left of the drawing area,


384
00:21:54,448 --> 00:21:58,318 align:center
and in this case, it stays fixed
to a single location on the device,


385
00:21:58,352 --> 00:22:02,422 align:center
since the app's UI only supports
one orientation.


386
00:22:02,456 --> 00:22:06,927 line:-3
And the back camera sensor's coordinate
system still differs from the UI's.


387
00:22:06.960 --> 00:22:09.363 line:-3 align:center
Since the app
only displays the UI in portrait,


388
00:22:09.396 --> 00:22:12.666 line:-3 align:center
it applies a constant
90 degrees of rotation for preview,


389
00:22:12.699 --> 00:22:15.302 line:-2 align:center
no matter the iPhone's orientation.


390
00:22:15,335 --> 00:22:18,305 line:-3
But unlike for preview,
the app applies a different amount


391
00:22:18,338 --> 00:22:22,676 line:-3
of rotation when taking photos and movies
when the iPhone is in landscape.


392
00:22:22,709 --> 00:22:25,779 line:-3
When the iPhone is in the camera
sensor's native orientation,


393
00:22:25,812 --> 00:22:30,984 line:-3
the app does not need to rotate photos
or movies for them to appear upright.


394
00:22:31.018 --> 00:22:34.188 line:-2 align:center
All of this talk of rotation
really makes your head spin.


395
00:22:34.221 --> 00:22:38.492 line:-2 align:center
But the AVCaptureDeviceRotationCoordinator
takes care of this complexity


396
00:22:38,525 --> 00:22:43,263 line:-2
and provides correct angles to preview
and capture from all cameras.


397
00:22:43.297 --> 00:22:48.202 line:-2 align:center
Rely on it to provide angles rather
than trying to calculate them yourself.


398
00:22:48,235 --> 00:22:49,803 line:-1
As your app switches cameras,


399
00:22:49,837 --> 00:22:53,006 line:-2
be sure
to create a new rotation coordinator.


400
00:22:53.040 --> 00:22:54.975 line:-1 align:center
To apply video rotation,


401
00:22:55,008 --> 00:23:00,147 line:-2
use the angles the coordinator provides
with new API on AVCaptureConnection.


402
00:23:00,180 --> 00:23:04,985 line:-2
Only connections that deliver video
or depth media data support rotation.


403
00:23:05,018 --> 00:23:07,321 line:-2
To check whether
a connection supports an angle,


404
00:23:07.354 --> 00:23:11.358 line:-2 align:center
you can call
its isVideoRotationAngleSupported method.


405
00:23:11,391 --> 00:23:13,427 line:-1
To have the connection perform rotation,


406
00:23:13,460 --> 00:23:17,698 line:-2
set its videoRotationAngle property
to a supported value.


407
00:23:17,731 --> 00:23:20,133 line:-2
Use
videoRotationAngleForHorizonLevelPreview


408
00:23:20,167 --> 00:23:22,569 line:-1
to display the camera preview.


409
00:23:22.603 --> 00:23:26.640 line:-2 align:center
Apps using AVCaptureVideoPreviewLayer
can apply the property's value


410
00:23:26,673 --> 00:23:31,111 line:-2
to an AVCaptureConnection instance's
videoRotationAngle property.


411
00:23:31,144 --> 00:23:33,614 line:-2
Apps can also use it
when displaying buffers


412
00:23:33,647 --> 00:23:36,917 line:-1
from a video data output in a CALayer.


413
00:23:36,950 --> 00:23:41,321 line:-2
To synchronize with system animations,
change the preview rotation immediately


414
00:23:41.355 --> 00:23:43.757 line:-1 align:center
in your app's key value observation code.


415
00:23:44,591 --> 00:23:47,928 line:0
Your app can expect to receive updates
to this property on the main queue


416
00:23:47,961 --> 00:23:49,963 align:center
to update its UI.


417
00:23:49,997 --> 00:23:52,633 line:-2
Not all apps use
AVCaptureVideoPreviewLayer


418
00:23:52,666 --> 00:23:54,501 line:-1
for displaying camera preview.


419
00:23:54.535 --> 00:23:57.471 line:-2 align:center
Some apps display buffers
from a video data output


420
00:23:57.504 --> 00:24:00.541 line:-1 align:center
when applying custom effects or filters.


421
00:24:00,574 --> 00:24:06,480 line:-2
One option for displaying custom preview
is to use the AVSampleBufferDisplayLayer.


422
00:24:06,513 --> 00:24:08,982 line:-2
Avoid requesting rotation
by setting the angle


423
00:24:09,016 --> 00:24:12,186 line:-2
on the video data output's
AVCaptureConnection.


424
00:24:12.219 --> 00:24:15.923 line:-2 align:center
Changing the connection's angle
causes a frame delivery interruption


425
00:24:15.956 --> 00:24:18.792 line:-2 align:center
as the capture render pipeline
reconfigures itself


426
00:24:18,825 --> 00:24:21,295 line:-1
to apply the new amount of rotation.


427
00:24:21,328 --> 00:24:26,233 line:0
Instead, rotate the CALayer
displaying the camera preview.


428
00:24:26,266 --> 00:24:31,305 line:0
Doing so allows your app's camera preview
to rotate smoothly.


429
00:24:31.338 --> 00:24:34.141 line:-2 align:center
Use
videoRotationAngleForHorizonLevelCapture


430
00:24:34,174 --> 00:24:38,545 line:-2
when photos and movies,
so they're level relative to gravity.


431
00:24:38,579 --> 00:24:41,415 line:-2
Your app can apply the property's value
on capture connections


432
00:24:41,448 --> 00:24:45,152 line:-1
to a photo output or movie file output.


433
00:24:45,185 --> 00:24:47,821 line:-2
Alternatively,
if your app uses a video data output


434
00:24:47.855 --> 00:24:50.891 line:-2 align:center
with an AVAssetWriter
for recording custom movies,


435
00:24:50.924 --> 00:24:54.461 line:-2 align:center
avoid rotating the video
with AVCaptureConnection.


436
00:24:54,494 --> 00:24:58,532 line:0
Instead, set the rotation
with an AVAssetWriterInput instance's


437
00:24:58,565 --> 00:25:03,003 line:0
transform property,
which alters the output file's metadata.


438
00:25:03,036 --> 00:25:06,807 line:0
With this approach, video apps
apply the rotation during playback,


439
00:25:06,840 --> 00:25:11,979 line:0
which uses less energy than rotating
each frame with the capture connection.


440
00:25:12,012 --> 00:25:14,882 line:0
Your app needs to convert
the rotation angle from degrees


441
00:25:14,915 --> 00:25:18,819 line:0
because an asset writer input
uses a CGAffineTransform


442
00:25:18,852 --> 00:25:21,255 line:0
that applies rotations in radians.


443
00:25:21,989 --> 00:25:25,859 line:-2
Some outputs efficiently apply rotation
without added overhead.


444
00:25:25.893 --> 00:25:31.465 line:-2 align:center
For instance, a movie file output applies
rotation using a QuickTime track matrix.


445
00:25:31.498 --> 00:25:35.035 line:-2 align:center
The photo output
handles orientation with Exif tags.


446
00:25:35,068 --> 00:25:39,273 line:-2
And the preview layer transforms
its contents to perform rotations.


447
00:25:39,306 --> 00:25:42,476 line:-2
However, your app may increase
a device's power consumption


448
00:25:42,509 --> 00:25:45,913 line:-2
if has the video
or depth data outputs perform rotation


449
00:25:45,946 --> 00:25:49,850 line:0
because they use more memory
and energy to rotate their buffers.


450
00:25:49,883 --> 00:25:52,486 line:0
Instead, your app
can take a more efficient approach


451
00:25:52,519 --> 00:25:57,324 align:center
by rotating the CALayer that previews
buffers from video or depth outputs.


452
00:25:58.725 --> 00:26:02.496 line:-2 align:center
Use AVCaptureDeviceRotationCoordinator
on all available platforms,


453
00:26:02,529 --> 00:26:06,033 line:-1
including iOS, tvOS, and macOS.


454
00:26:06,066 --> 00:26:09,469 line:-2
Mac Catalyst and iOS apps on Mac
can also use it.


455
00:26:10,404 --> 00:26:14,641 line:-2
Your app can use the rotation coordinator
to correctly orient photos or movies


456
00:26:14,675 --> 00:26:17,311 line:-1
and display video preview for any camera.


457
00:26:17.344 --> 00:26:19.713 line:-2 align:center
And it helps your app
handle complex layouts


458
00:26:19,746 --> 00:26:23,383 line:-2
with Stage Manager
or when it is on an external display.


459
00:26:24.184 --> 00:26:28.856 line:-2 align:center
Now it's time for the final changes
to support external cameras in AVCam.


460
00:26:28.889 --> 00:26:33.026 line:-2 align:center
When configuring the capture session,
the app sets up its camera preview.


461
00:26:33.060 --> 00:26:35.929 line:-2 align:center
So it creates
a device rotation coordinator,


462
00:26:35.963 --> 00:26:40.133 line:-2 align:center
which gives the app the rotation angles
it needs for preview and capture.


463
00:26:40.934 --> 00:26:44.404 line:-2 align:center
When creating a coordinator,
the app updates the preview layer


464
00:26:44.438 --> 00:26:46.840 line:-2 align:center
with the current rotation angle
for preview.


465
00:26:47,741 --> 00:26:51,411 line:0
It also observes changes to the angle
and updates the preview.


466
00:26:52,479 --> 00:26:54,348 line:-1
When AVCam switches devices,


467
00:26:54.381 --> 00:26:56.617 line:-2 align:center
it also creates
a new rotation coordinator,


468
00:26:56,650 --> 00:26:59,186 line:-2
so the preview looks right
for the new camera.


469
00:27:00.187 --> 00:27:03.090 line:-2 align:center
When taking photos,
the app uses the rotation angle


470
00:27:03.123 --> 00:27:07.661 line:-2 align:center
for capture to make sure they're upright
when someone views them later.


471
00:27:07,694 --> 00:27:10,364 line:-2
And it does the same
when recording movies.


472
00:27:11.064 --> 00:27:15.035 line:-2 align:center
With these changes, AVCam is ready
to support external cameras.


473
00:27:15.068 --> 00:27:18.672 line:-2 align:center
Now when I rotate the iPad,
the external camera appears correctly.


474
00:27:26,680 --> 00:27:28,649 line:-2
We've covered a lot so far
in this session,


475
00:27:28,682 --> 00:27:31,118 line:-2
and I thank you
for following along with me.


476
00:27:31.151 --> 00:27:34.221 line:-2 align:center
Now that I've shown how your iPad app
can use external cameras,


477
00:27:34,254 --> 00:27:38,492 line:-2
I'll discuss how you can also use
microphones included with these devices.


478
00:27:38.525 --> 00:27:41.094 line:-1 align:center
Some webcams and displays include mics.


479
00:27:41.128 --> 00:27:45.065 line:-2 align:center
When they are plugged into an iPad,
they can be used by your app.


480
00:27:45,098 --> 00:27:48,569 line:-2
iPadOS 17 has improved support
for external microphones


481
00:27:48.602 --> 00:27:50.838 line:-1 align:center
on iPads with USB-C.


482
00:27:50,871 --> 00:27:54,474 line:-2
Telephony apps that use
Core Audio's AUVoiceIO audio unit


483
00:27:54.508 --> 00:27:59.313 line:-2 align:center
can now use external microphones like
those included with webcams or displays.


484
00:27:59.346 --> 00:28:01.782 line:-2 align:center
Previously,
the only external wired devices


485
00:28:01,815 --> 00:28:04,685 line:-1
these apps could use were headset mics.


486
00:28:04.718 --> 00:28:09.156 line:-2 align:center
AUVoiceIO is a popular interface,
since it performs echo cancellation,


487
00:28:09.189 --> 00:28:12.693 line:-2 align:center
and new tunings have been introduced
for external mics.


488
00:28:12,726 --> 00:28:15,529 line:-2
Voice Isolation mode
available from Control Center


489
00:28:15,562 --> 00:28:19,199 line:-2
removes unwanted background noise,
such as typing on keyboards,


490
00:28:19,233 --> 00:28:23,237 line:-2
mouse clicks, or leaf blowers
running somewhere in the neighborhood.


491
00:28:23,270 --> 00:28:26,907 line:-2
Your app can use this system feature
with external microphones.


492
00:28:27.808 --> 00:28:32.079 line:-2 align:center
The iOS audio routing system allows
only one microphone to be used at a time.


493
00:28:32,112 --> 00:28:35,749 line:-2
It also automatically changes
to the last connected microphone.


494
00:28:35.782 --> 00:28:38.685 line:-2 align:center
This is because,
just like when connecting a camera,


495
00:28:38,719 --> 00:28:43,190 line:-2
the user is indicating the newly
connected microphone should be used.


496
00:28:43,223 --> 00:28:47,427 line:-2
On iOS, the system returns only one
AVCaptureDevice for the microphone.


497
00:28:47,461 --> 00:28:51,765 line:-2
You can find it by searching
for the device with the audio media type


498
00:28:51,798 --> 00:28:56,336 line:-2
or with the new microphone device type,
which deprecates builtInMicrophone


499
00:28:56.370 --> 00:28:59.740 line:-2 align:center
because not all mics
are built-in to the iPad.


500
00:28:59,773 --> 00:29:03,243 line:-2
The audio routing system decides
which available microphone to use,


501
00:29:03.277 --> 00:29:05.679 line:-1 align:center
be it built-in or external.


502
00:29:05.712 --> 00:29:07.481 line:-1 align:center
When the system changes the input route,


503
00:29:07,514 --> 00:29:10,884 line:-2
the microphone AVCaptureDevice's
localizedName property changes


504
00:29:10.918 --> 00:29:13.020 line:-1 align:center
to reflect the device in use.


505
00:29:13,987 --> 00:29:17,658 line:-2
Your app can use AVAudioSession
for more control over the microphone.


506
00:29:17.691 --> 00:29:20.327 line:-2 align:center
You can use it
to configure your app's audio behaviors


507
00:29:20,360 --> 00:29:22,596 line:-1
by setting a category or mode.


508
00:29:22.629 --> 00:29:27.134 line:-2 align:center
And you can choose to use a specific mic,
like one included with an external camera,


509
00:29:27,167 --> 00:29:29,937 line:-1
by setting the preferred input.


510
00:29:29,970 --> 00:29:33,540 line:-2
For the final topic of this session,
I'll discuss some best practices


511
00:29:33,574 --> 00:29:36,343 line:-1
for your app when using external cameras.


512
00:29:37,277 --> 00:29:40,747 line:-2
As you begin adoption, consider
what makes most sense for your app.


513
00:29:40.781 --> 00:29:43.383 line:-2 align:center
Earlier, I showed how FaceTime,
Code Scanner,


514
00:29:43,417 --> 00:29:46,687 line:-2
and WebKit chose to support
external cameras differently.


515
00:29:46,720 --> 00:29:50,691 line:-2
Use them as examples
of different ways your app can adopt.


516
00:29:50.724 --> 00:29:53.760 line:-2 align:center
Configure your iPad
for wireless debugging with Xcode


517
00:29:53,794 --> 00:29:57,231 line:-2
while the USB-C port is in use
by an external camera.


518
00:29:57.264 --> 00:29:59.967 line:-2 align:center
Some capabilities that your app
can expect from built-in cameras


519
00:30:00,000 --> 00:30:02,736 line:-1
may not be supported by external devices.


520
00:30:02,769 --> 00:30:06,507 line:-2
For example, if your app relies
on depth data capture for some feature,


521
00:30:06,540 --> 00:30:10,511 line:-2
you might have to disable it
when an external camera is in use.


522
00:30:10.544 --> 00:30:12.913 line:-2 align:center
Apps that use multiple cameras
at the same time


523
00:30:12,946 --> 00:30:16,517 line:-2
with an AVCaptureMultiCamSession
can add external cameras


524
00:30:16,550 --> 00:30:18,685 line:-1
for creative capture setups.


525
00:30:18.719 --> 00:30:21.321 line:-2 align:center
iPadOS gives external cameras
some treatment


526
00:30:21,355 --> 00:30:23,790 line:-2
that it also applies
to front-facing cameras.


527
00:30:23,824 --> 00:30:27,528 line:-2
The AVCaptureVideoPreviewLayer
mirrors external cameras by default.


528
00:30:27,561 --> 00:30:31,031 line:-2
This works well
when the camera is facing the iPad user.


529
00:30:31.064 --> 00:30:33.767 line:-1 align:center
But this isn't suitable for all use cases.


530
00:30:33,800 --> 00:30:36,403 line:-2
If your app's users stream
from HDMI switchers


531
00:30:36,436 --> 00:30:38,672 line:-2
or point the external camera
away from them,


532
00:30:38.705 --> 00:30:42.242 line:-2 align:center
consider allowing users
to disable preview mirroring.


533
00:30:42.276 --> 00:30:45.746 line:-2 align:center
In a previous section,
I described camera rotation.


534
00:30:45,779 --> 00:30:48,282 line:-2
While your app likely won't need
to apply video rotation


535
00:30:48.315 --> 00:30:51.084 line:-2 align:center
for an external camera,
be aware that if you do,


536
00:30:51.118 --> 00:30:55.522 line:-2 align:center
the system rotates external cameras
clockwise towards the scene it is facing.


537
00:30:55.556 --> 00:30:58.992 line:-2 align:center
This is the same way
it applies rotation for built-in cameras.


538
00:31:00,127 --> 00:31:03,130 line:-2
Prepare your app to handle cameras
with different capabilities.


539
00:31:04,031 --> 00:31:07,568 line:-2
For example, some external cameras
may only report two formats,


540
00:31:07,601 --> 00:31:10,904 line:-1
like a VGA format of 640x480


541
00:31:10,938 --> 00:31:14,675 line:-1
and an HD format of 1280x720.


542
00:31:14,708 --> 00:31:16,844 line:-2
And some external cameras
support pixel formats


543
00:31:16.877 --> 00:31:18.879 line:-1 align:center
that are not typically used on iOS.


544
00:31:18,912 --> 00:31:21,381 line:-2
We've chosen to convert these
to more common formats


545
00:31:21.415 --> 00:31:24.384 line:-1 align:center
that iOS camera apps are used to handling.


546
00:31:24.418 --> 00:31:30.023 line:-2 align:center
Uncompressed formats like yuvs
and 2vuy are converted to 420v.


547
00:31:30.057 --> 00:31:35.529 line:-2 align:center
And compressed formats like streaming
JPEG and H264 are converted to 420f.


548
00:31:36.463 --> 00:31:39.766 line:-2 align:center
Because an external camera
can have formats of any size,


549
00:31:39,800 --> 00:31:43,303 line:-2
it may not support
all AVCaptureSessionPresets.


550
00:31:43,337 --> 00:31:48,909 line:-2
For example, the HD 4K preset requires
the device to have a compatible format.


551
00:31:49.710 --> 00:31:51.812 line:-2 align:center
Your app can check
whether it can use a preset


552
00:31:51.845 --> 00:31:56.216 line:-2 align:center
by calling the supportsSessionPreset
method on AVCaptureDevice.


553
00:31:56,250 --> 00:31:57,985 line:-2
Your app can configure
an external camera,


554
00:31:58.018 --> 00:32:02.122 line:-2 align:center
including changing its resolution,
frame rate, and zoom factor.


555
00:32:02,155 --> 00:32:05,225 line:-2
iPadOS supports a limited set
of the camera controls


556
00:32:05.259 --> 00:32:08.529 line:-2 align:center
available
in the USB Video Class specification.


557
00:32:08,562 --> 00:32:12,366 line:-2
So query the AVCaptureDevice
for its capabilities.


558
00:32:12,399 --> 00:32:15,235 line:-2
Let's wrap up everything
I just talked about.


559
00:32:15,269 --> 00:32:19,173 line:-2
I showed how you can discover
and use external cameras,


560
00:32:19,206 --> 00:32:22,509 line:-2
how to properly rotate
a camera's video frames,


561
00:32:22,543 --> 00:32:24,845 line:-1
using external microphones,


562
00:32:24,878 --> 00:32:28,115 line:-1
and lastly, best practices for your app.


563
00:32:28,148 --> 00:32:32,252 line:-2
We're excited to see how you start
using external cameras in your iPad app.


564
00:32:32,286 --> 00:32:34,354 line:-1
Thank you, and I hope your app rocks.


565
00:32:34,388 --> 00:32:37,958 align:center
â™ª â™ª

