1
00:00:04,003 --> 00:00:07,174 line:-1
Hello and welcome to WWDC.


2
00:00:08,275 --> 00:00:11,211 line:0
Hello, everybody, and welcome to
"What's New in ResearchKit."


3
00:00:11,278 --> 00:00:12,412 line:0
My name is Pariece McKinney,


4
00:00:12,479 --> 00:00:14,681 line:0
and I'm a software engineer
on the health team.


5
00:00:14,748 --> 00:00:16,315 line:0
Later in the talk, we'll also be joined


6
00:00:16,383 --> 00:00:19,353 line:0
by my fellow colleague
and software engineer, Joey LaBarck.


7
00:00:19,419 --> 00:00:22,089 line:-2
Thank you for taking the time to join,
and we're extremely excited


8
00:00:22,155 --> 00:00:25,225 line:-2
to show you all the new updates
ResearchKit has to offer.


9
00:00:25,292 --> 00:00:27,561 line:-2
There's quite a bit to cover,
so let's jump right in.


10
00:00:28,762 --> 00:00:30,998 line:-2
In order to make things
easier to follow this year,


11
00:00:31,064 --> 00:00:33,100 line:-1
we created a ResearchKit sticker pack,


12
00:00:33,166 --> 00:00:36,803 line:-2
where each sticker corresponds to
a particular topic of this talk.


13
00:00:36,870 --> 00:00:37,938 line:-1
At the end of each topic,


14
00:00:38,005 --> 00:00:40,507 line:-2
we'll collect the sticker
for that particular subject


15
00:00:40,574 --> 00:00:43,944 line:-2
and slap it on the back of our laptop,
which is pretty empty at the moment.


16
00:00:45,179 --> 00:00:46,947 line:-2
Now that everyone knows
how to follow along,


17
00:00:47,014 --> 00:00:49,850 line:-2
let's get started with our first topic:
community updates.


18
00:00:51,351 --> 00:00:53,453 line:-2
Each year,
we're excited about the new apps


19
00:00:53,520 --> 00:00:55,055 line:-1
that take advantage of our frameworks


20
00:00:55,122 --> 00:00:58,225 line:-2
to advance health and learnings
in various health areas.


21
00:00:58,292 --> 00:01:02,229 line:-2
To name a few,
the Spirit Trial app built by Hello Thread


22
00:01:02,296 --> 00:01:06,834 line:-2
was created in support of a clinical trial
on advanced pancreatic cancer.


23
00:01:06,900 --> 00:01:10,938 line:-2
Also, CareEvolution and the NIH
launched the All of Us app


24
00:01:11,004 --> 00:01:13,173 line:-2
to speed up health research
and breakthroughs


25
00:01:13,240 --> 00:01:16,577 line:-2
by building a community
of a million or more people across the US


26
00:01:16,643 --> 00:01:19,780 line:-2
with the aim
to advance personalized medicine.


27
00:01:19,847 --> 00:01:22,182 line:-2
We've also seen apps
utilize our frameworks


28
00:01:22,249 --> 00:01:26,587 line:-2
to build high-quality apps very quickly
in response to COVID-19.


29
00:01:26,653 --> 00:01:28,288 line:-1
The Stanford First Responder app


30
00:01:28,355 --> 00:01:32,159 line:-2
aims to help first responders
navigate the challenges of COVID-19.


31
00:01:32,226 --> 00:01:35,662 line:-2
And the University of Nebraska
Medical Center 1-Check app


32
00:01:35,729 --> 00:01:40,434 line:-2
aims to provide real-time situational
awareness of COVID-19 to investigators.


33
00:01:41,535 --> 00:01:45,138 line:-2
Last year, Apple also announced
and released the Research app,


34
00:01:45,205 --> 00:01:47,207 line:-1
which heavily utilizes ResearchKit,


35
00:01:47,274 --> 00:01:49,877 line:-2
while paving the way
for conducting large-scale studies


36
00:01:49,943 --> 00:01:51,178 line:-1
all through your iPhone.


37
00:01:53,280 --> 00:01:55,482 line:-2
Last year, we also announced
that we would release


38
00:01:55,549 --> 00:01:57,284 line:-1
a newly redesigned website,


39
00:01:57,351 --> 00:01:59,186 line:-2
and we're proud to share
that website with you,


40
00:01:59,253 --> 00:02:02,656 line:-2
which launched in late 2019,
at researchandcare.org.


41
00:02:04,024 --> 00:02:06,660 line:-2
On our overview page,
you can read about the frameworks


42
00:02:06,727 --> 00:02:11,098 line:-2
and their capabilities and features
before diving in to create your own app.


43
00:02:12,733 --> 00:02:14,701 line:-1
If you navigate to the ResearchKit page,


44
00:02:14,768 --> 00:02:17,871 line:-2
you can find even more information
about the models it provides,


45
00:02:17,938 --> 00:02:19,106 line:-1
as well as case studies


46
00:02:19,173 --> 00:02:23,277 line:-2
that showcase amazing examples of studies
and programs built in the community,


47
00:02:23,343 --> 00:02:24,845 line:-1
like the one you see here.


48
00:02:26,113 --> 00:02:28,849 line:-2
We also announced
our new Investigator Support Program,


49
00:02:28,916 --> 00:02:31,618 line:-2
through which researchers
can submit proposals for Watches


50
00:02:31,685 --> 00:02:33,153 line:-1
to support their studies.


51
00:02:33,487 --> 00:02:35,255 line:-2
You can now read about that
on our website,


52
00:02:35,322 --> 00:02:38,458 line:-2
and learn how to reach out to us
if you're interested in the program.


53
00:02:38,525 --> 00:02:42,029 line:-2
And lastly, we welcome all of you
to reach out to us through our website


54
00:02:42,095 --> 00:02:44,998 line:-2
so that we can hear about
all the amazing work you all are doing.


55
00:02:46,733 --> 00:02:48,969 line:-2
Now that we've collected
our community update sticker,


56
00:02:49,036 --> 00:02:52,239 line:-2
let's move on to the next topic,
which is onboarding updates.


57
00:02:54,741 --> 00:02:56,777 line:-1
For the vast majority of study-based apps,


58
00:02:56,844 --> 00:02:59,146 line:-2
the onboarding views
are usually the first thing


59
00:02:59,213 --> 00:03:01,648 line:-2
your participants will see
and interact with.


60
00:03:01,715 --> 00:03:05,586 line:-2
Knowing this, it's extremely important
to convey exactly what the study is,


61
00:03:05,652 --> 00:03:08,755 line:-2
and what the participant should expect
if they decide to join.


62
00:03:10,023 --> 00:03:11,225 line:-1
As you can see here,


63
00:03:11,291 --> 00:03:14,061 line:-2
we've moved towards leaning on
the instruction-Steps capability


64
00:03:14,127 --> 00:03:16,230 line:-1
to support custom text and images


65
00:03:16,296 --> 00:03:19,933 line:-2
so that you can have complete control
over the content you wish to display.


66
00:03:21,134 --> 00:03:23,403 line:-2
Let's take a look at the code
to create this step.


67
00:03:24,805 --> 00:03:27,674 line:-2
After importing ResearchKit,
the first thing we'll do


68
00:03:27,741 --> 00:03:31,979 line:-2
is initialize the instruction-Step
and pass in a unique identifier.


69
00:03:32,045 --> 00:03:34,014 line:-1
After setting the title and detail-Text,


70
00:03:34,081 --> 00:03:36,550 line:-2
the last thing we have to do
is set the image property


71
00:03:36,617 --> 00:03:39,286 line:-2
to the heath_blocks image
seen in the previous slide.


72
00:03:39,953 --> 00:03:43,090 line:-2
In the second step of our onboarding flow,
we're using Instruction-Step again,


73
00:03:43,156 --> 00:03:45,792 line:-2
but this time,
we also incorporate body items,


74
00:03:45,859 --> 00:03:50,130 line:-2
which is an extremely useful feature
to further educate your participants.


75
00:03:50,197 --> 00:03:53,200 line:-2
In this example,
we use SF Symbols for our icons,


76
00:03:53,267 --> 00:03:55,669 line:-2
but it's important to note
that everyone watching this video


77
00:03:55,736 --> 00:03:58,071 line:-1
has access to these icons and more.


78
00:03:58,138 --> 00:04:01,375 line:-2
So, if you're interested,
feel free to download the SF Symbols app


79
00:04:01,441 --> 00:04:04,344 line:-2
to find the icons
that match your use case.


80
00:04:04,411 --> 00:04:06,480 line:-2
Let's take a look at the code
to create this step.


81
00:04:07,214 --> 00:04:11,051 line:-2
Much like the previous code slide,
we initialize the ORK-Instruction-Step


82
00:04:11,118 --> 00:04:13,253 line:-1
and pass in our unique identifier.


83
00:04:13,320 --> 00:04:17,057 line:-2
After setting our title property,
we also set our image property again,


84
00:04:17,124 --> 00:04:19,927 line:-2
but this time
we pass in an informed_consent image


85
00:04:19,993 --> 00:04:21,628 line:-1
seen in the slide before.


86
00:04:22,462 --> 00:04:26,934 line:-2
Next, we initialize our first body-Item,
making sure that we pass in an image


87
00:04:27,000 --> 00:04:29,703 line:-2
and that we set our body-Item-Style
to dot-image.


88
00:04:30,871 --> 00:04:34,107 line:0
The last thing we have to do
is append our newly-created body-Item


89
00:04:34,174 --> 00:04:37,377 line:0
to the body-Items array
that sits on the Instruction-Step.


90
00:04:39,246 --> 00:04:43,150 line:-2
Now let's take a look at an enhancement
we've made to our Web-View-Step.


91
00:04:43,217 --> 00:04:46,486 line:-2
Previously, presenting the user
with an overview of the consent document


92
00:04:46,553 --> 00:04:48,121 line:-1
and collecting the signature for it


93
00:04:48,188 --> 00:04:50,357 line:-1
were handled by two different steps.


94
00:04:50,424 --> 00:04:53,160 line:-2
Now we've added
the signature capture functionality


95
00:04:53,227 --> 00:04:54,428 line:-1
to the Web-View-Step


96
00:04:54,494 --> 00:04:57,297 line:-2
so that you can present
the overview of the consent document


97
00:04:57,364 --> 00:05:00,400 line:-2
and ask for the participant's signature
within the same view.


98
00:05:01,502 --> 00:05:02,970 line:-1
Let's see how this step is created.


99
00:05:04,338 --> 00:05:08,408 line:-2
The first thing we have to do
is initialize the ORK-Web-View-Step,


100
00:05:08,475 --> 00:05:12,145 line:-2
passing in an identifier
and the HTML content you wish to display.


101
00:05:12,980 --> 00:05:14,781 line:-1
And the last thing we have to do is set


102
00:05:14,848 --> 00:05:17,518 line:-2
the show-Signature-After-Content attribute
to "true,"


103
00:05:17,584 --> 00:05:19,520 line:-2
and this will ensure
that the signature view


104
00:05:19,586 --> 00:05:22,656 line:-2
is shown below the HTML content
when the step is presented.


105
00:05:23,724 --> 00:05:27,227 line:-2
This year, we're also introducing
the Request-Permission-Step.


106
00:05:27,294 --> 00:05:30,230 line:-2
Previously, if you wanted
to request access to Health data,


107
00:05:30,297 --> 00:05:33,066 line:-2
you would have to do so
outside of the ResearchKit flow.


108
00:05:33,133 --> 00:05:36,036 line:-2
Which means you had to create
the necessary views to ask for access,


109
00:05:36,103 --> 00:05:38,105 line:-1
and maintain those views yourself.


110
00:05:38,172 --> 00:05:41,508 line:-2
Now all you have to do
is initialize the Request-Permission-Step


111
00:05:41,575 --> 00:05:44,077 line:-2
and pass in the HealthKit types
you want access to,


112
00:05:44,144 --> 00:05:47,247 line:-2
and we'll do the heavy lifting
of requesting the data for you.


113
00:05:47,314 --> 00:05:49,249 line:-1
Now you can do more with less code


114
00:05:49,316 --> 00:05:52,186 line:-2
while making the experience
and flow of your app much better.


115
00:05:53,053 --> 00:05:56,757 line:-2
Let's take a look at the code
to create the ORK-Request-Permission-Step.


116
00:05:58,425 --> 00:06:02,262 line:-2
We start off by creating
a set of HK-Sample-Types,


117
00:06:02,329 --> 00:06:05,065 line:-2
and these represent the types
you want to write access for.


118
00:06:05,132 --> 00:06:07,601 line:-1
Then we create a set of HK-Object-Types,


119
00:06:07,668 --> 00:06:10,304 line:-2
and these represent the types
you want to read access for.


120
00:06:12,105 --> 00:06:15,342 line:-2
Next, we initialize
the ORK-HealthKit-Permission-Type,


121
00:06:15,409 --> 00:06:17,978 line:-2
making sure that we pass in
the HK-Types-To-Write,


122
00:06:18,045 --> 00:06:20,681 line:-1
and HK-Types-To-Read sets created above.


123
00:06:21,849 --> 00:06:23,183 line:0
And the last thing we have to do


124
00:06:23,250 --> 00:06:26,153 line:0
is initialize
the ORK-Request-Permission-Step,


125
00:06:26,220 --> 00:06:28,622 line:0
and pass in an array of permission types


126
00:06:28,689 --> 00:06:31,658 line:0
that currently only has
our HK-Permission-Type within it.


127
00:06:33,093 --> 00:06:35,696 line:-2
That brings us to a close
for the onboarding update session,


128
00:06:35,762 --> 00:06:37,197 line:-1
so let's collect our sticker.


129
00:06:37,965 --> 00:06:39,266 line:-1
Now that we have our sticker,


130
00:06:39,333 --> 00:06:42,202 line:-2
let's keep moving forward
and talk about survey enhancements.


131
00:06:44,438 --> 00:06:45,739 line:-1
Before we show any questions,


132
00:06:45,806 --> 00:06:47,608 line:-2
we always want to give the user
some insight


133
00:06:47,674 --> 00:06:49,676 line:-1
on what the point of the survey is.


134
00:06:49,743 --> 00:06:51,979 line:-2
To do this,
we use an Instruction-Step again


135
00:06:52,045 --> 00:06:53,847 line:-1
to provide some brief context,


136
00:06:53,914 --> 00:06:56,250 line:-2
but this time,
we also provide an icon image


137
00:06:56,316 --> 00:07:00,320 line:-2
that is left-aligned to the screen,
which is all handled by ResearchKit.


138
00:07:02,890 --> 00:07:04,825 line:-2
In the second step
of the onboarding survey,


139
00:07:04,892 --> 00:07:09,429 line:-2
we use our ORK-Form-Step to collect
basic information about the participant.


140
00:07:09,496 --> 00:07:10,797 line:-1
But as you can see here,


141
00:07:10,864 --> 00:07:14,368 line:-2
we've made some UI improvements
by using labels to display errors,


142
00:07:14,434 --> 00:07:16,537 line:-1
as opposed to previously using alerts,


143
00:07:16,603 --> 00:07:19,640 line:-2
which didn't always make for
the best user experience.


144
00:07:19,706 --> 00:07:23,577 line:-2
Let's fix those errors and move on
to the next step in our onboarding survey.


145
00:07:26,880 --> 00:07:30,217 line:-2
In the third step,
we preview the new SES-Answer-Format,


146
00:07:30,284 --> 00:07:32,719 line:-2
which can help present
scale-based questions.


147
00:07:32,786 --> 00:07:34,288 line:-1
Much like the example here,


148
00:07:34,354 --> 00:07:36,590 line:-2
where we asked the user
to select the option


149
00:07:36,657 --> 00:07:39,459 line:-2
that they feel best depicts
the current state of their health.


150
00:07:39,993 --> 00:07:42,296 line:-2
Let's look at the code
needed to present this step.


151
00:07:43,397 --> 00:07:47,034 line:-2
The first thing we do
is initialize the SES-Answer-Format


152
00:07:47,100 --> 00:07:50,671 line:-2
and pass in the top-Rung-Text
and bottom-Rung-Text, as seen here.


153
00:07:51,672 --> 00:07:55,275 line:-2
The last thing we have to do
is simply initialize our ORK-Form-Item


154
00:07:55,342 --> 00:07:58,345 line:-2
and pass in the SES-Answer-Format
created above.


155
00:07:59,813 --> 00:08:00,814 line:-1
In this step,


156
00:08:00,881 --> 00:08:04,051 line:-2
we use a Continuous-Scale-Answer-Format
and a Scale-Answer-Format


157
00:08:04,117 --> 00:08:07,988 line:-2
to get information on the participant's
current stress level and pain level.


158
00:08:08,055 --> 00:08:11,391 line:-2
In the past, if the user wasn't
comfortable enough to answer the question,


159
00:08:11,458 --> 00:08:13,093 line:-1
or simply didn't know the answer,


160
00:08:13,160 --> 00:08:16,597 line:-2
they would either leave the question blank
or provide an answer that wasn't accurate


161
00:08:16,663 --> 00:08:18,565 line:-1
because the question might be required.


162
00:08:19,266 --> 00:08:22,202 line:-2
Now we've added the ability
to use the ORK-Dont-Know-Button


163
00:08:22,269 --> 00:08:24,505 line:-1
with select answer formats.


164
00:08:24,571 --> 00:08:27,341 line:-2
This will allow the participants
to select the "I don't know" button


165
00:08:27,407 --> 00:08:30,344 line:-2
when they don't want to answer
the questions presented to them.


166
00:08:30,410 --> 00:08:32,913 line:0
You can also pass in custom text,
as seen here,


167
00:08:32,980 --> 00:08:35,716 line:0
to replace the default
"I don't know" text.


168
00:08:35,782 --> 00:08:38,385 line:0
Let's take a look at the code
for the second scaled question


169
00:08:38,452 --> 00:08:40,320 line:0
to see how we added
the "Don't know" button


170
00:08:40,386 --> 00:08:41,855 line:0
and added custom text.


171
00:08:47,227 --> 00:08:50,931 line:-2
First, we initialize
the ORK-Scale-Answer-Format


172
00:08:50,998 --> 00:08:53,734 line:-1
and pass in all the required values.


173
00:08:53,800 --> 00:08:56,503 line:-2
Next, we set
the should-Show-Dont-Know-Button attribute


174
00:08:56,570 --> 00:08:57,971 line:-1
to "true."


175
00:08:58,038 --> 00:09:00,374 line:0
Then we set
the custom-Dont-Know-Button-Text


176
00:09:00,440 --> 00:09:01,842 line:0
to "Prefer not to answer,"


177
00:09:01,909 --> 00:09:04,611 line:0
and this will override
the default text "I don't know."


178
00:09:05,712 --> 00:09:08,815 line:0
The last thing we have to do
is initialize the ORK-Form-Item


179
00:09:08,882 --> 00:09:11,785 line:0
and pass in the Scale-Answer-Format
created above.


180
00:09:13,921 --> 00:09:17,457 line:-2
In the last question of the survey,
we use an ORK-Text-Answer-Format


181
00:09:17,524 --> 00:09:21,328 line:-2
to collect any additional information
the participant thinks we should know.


182
00:09:21,395 --> 00:09:24,331 line:-2
Previously, we supported
setting the maximum character count,


183
00:09:24,398 --> 00:09:25,399 line:-1
but there was no visual


184
00:09:25,465 --> 00:09:29,169 line:-2
to let the user know what their limit is,
or how close they were to approaching it.


185
00:09:29,236 --> 00:09:31,338 line:-2
Now we've added
a maximum character count label


186
00:09:31,405 --> 00:09:33,707 line:-2
so that the user can have
a much better idea


187
00:09:33,774 --> 00:09:37,578 line:-2
of how much information they can provide
and base their response off that.


188
00:09:37,644 --> 00:09:39,146 line:-1
We've also added a "Clear" button


189
00:09:39,213 --> 00:09:41,982 line:-2
so that the user can remove any text
that they've typed in.


190
00:09:42,883 --> 00:09:44,818 line:-2
Let's check out the code
to make this happen.


191
00:09:47,254 --> 00:09:51,124 line:-2
First, we initialize
the ORK-Text-Answer-Format.


192
00:09:52,292 --> 00:09:55,529 line:-2
Then we begin to set some properties
on the Answer-Format,


193
00:09:55,596 --> 00:10:02,069 line:-2
such as setting multiple-Lines to "true,"
setting maximum-Length to "280,"


194
00:10:02,135 --> 00:10:05,939 line:-2
and setting hide-Character-Count-Label
and hide-Clear-Button to "false"


195
00:10:06,006 --> 00:10:08,375 line:-2
to make sure
that both of these UI elements are shown


196
00:10:08,442 --> 00:10:09,710 line:-1
when this step is presented.


197
00:10:11,211 --> 00:10:14,848 line:0
And the last thing we have to do
is initialize our ORK-Question-Step


198
00:10:14,915 --> 00:10:17,618 line:0
and pass in the text-Answer-Format
created above.


199
00:10:19,086 --> 00:10:20,854 line:-1
After finishing the onboarding survey,


200
00:10:20,921 --> 00:10:25,125 line:-2
we present the participant
with the new ORK-Review-View-Controller.


201
00:10:25,192 --> 00:10:27,261 line:-2
One of the biggest challenges
for any study


202
00:10:27,327 --> 00:10:30,297 line:-2
is making sure that the data entered
by the participant is accurate.


203
00:10:30,864 --> 00:10:34,535 line:-2
As humans, making mistakes
in our everyday lives is very common.


204
00:10:34,601 --> 00:10:36,403 line:-1
So when participants fill out surveys,


205
00:10:36,470 --> 00:10:39,973 line:-2
it might be safe to assume
that a small mistake might have happened.


206
00:10:40,040 --> 00:10:41,375 line:-1
To help alleviate this problem,


207
00:10:41,441 --> 00:10:44,244 line:-2
ResearchKit now provides
a Review-View-Controller


208
00:10:44,311 --> 00:10:46,813 line:-2
that will allow the participant
to view a breakdown


209
00:10:46,880 --> 00:10:50,150 line:-2
of all the questions they were asked,
and the response they gave.


210
00:10:50,217 --> 00:10:52,052 line:0
If they want to update
any of those questions,


211
00:10:52,119 --> 00:10:54,588 line:0
they can simply click "Edit"
and update their answer.


212
00:10:55,489 --> 00:10:58,325 line:-2
Let's look at the code
to present the Review-View-Controller.


213
00:10:59,293 --> 00:11:02,663 line:-2
First, we initialize
the Review-View-Controller,


214
00:11:02,729 --> 00:11:07,467 line:-2
which requires us to pass in a task
and a result object,


215
00:11:07,534 --> 00:11:10,637 line:-2
which, in this case, we get
from the task-View-Controller object


216
00:11:10,704 --> 00:11:14,474 line:-2
passed back to us by the
did-Finish-With-Reason delegate method.


217
00:11:14,541 --> 00:11:17,744 line:-2
But keep in mind that you can
also initialize your task separately,


218
00:11:17,811 --> 00:11:22,149 line:-2
and also pass in a result that may have
been saved at an earlier time.


219
00:11:22,216 --> 00:11:26,453 line:-2
Next, we set ourselves as the delegate,
and this requires us to implement


220
00:11:26,520 --> 00:11:30,023 line:-2
the did-Update-Result
and did-Select-Incomplete cell methods.


221
00:11:30,724 --> 00:11:32,960 line:-2
Then, after setting
our review-Title and text,


222
00:11:33,026 --> 00:11:35,629 line:-2
we're done creating
our first Review-View-Controller.


223
00:11:36,697 --> 00:11:39,032 line:-2
Now that we've finished
reviewing our survey enhancements


224
00:11:39,099 --> 00:11:40,868 line:-1
and collected our well-deserved sticker,


225
00:11:40,934 --> 00:11:43,537 line:-2
let's move on to the next topic,
which is active tasks.


226
00:11:47,207 --> 00:11:49,476 line:-2
Let's first take a look
at the improvements we've made


227
00:11:49,543 --> 00:11:50,978 line:-1
to our hearing task.


228
00:11:51,845 --> 00:11:55,315 line:-2
For the Environment-SPL-Meter-Step,
we added a new animation


229
00:11:55,382 --> 00:11:59,686 line:-2
that clearly indicates if you're within
the set threshold for background noise,


230
00:11:59,753 --> 00:12:00,954 line:-1
as seen here.


231
00:12:01,755 --> 00:12:05,058 line:-2
We also made updates
to our dB-HL-Tone-Audiometry-Step


232
00:12:05,125 --> 00:12:08,562 line:-2
by tweaking the button UI,
adding better haptics,


233
00:12:08,629 --> 00:12:10,597 line:-1
changing the progress indicator to a label


234
00:12:10,664 --> 00:12:13,467 line:-2
to make it more clear to the participant
how far they've made it,


235
00:12:13,534 --> 00:12:16,970 line:-2
and we also added calibration data
to support AirPods Pros.


236
00:12:17,871 --> 00:12:20,274 line:-2
Let's collect our hearing sticker
before moving on.


237
00:12:21,108 --> 00:12:22,609 line:-1
Now that we have our hearing sticker,


238
00:12:22,676 --> 00:12:25,579 line:-2
let's chat about our next topic,
which is 3D models.


239
00:12:26,380 --> 00:12:27,581 line:-1
When running a study,


240
00:12:27,648 --> 00:12:30,217 line:-2
giving your participants
clear and informative visuals


241
00:12:30,284 --> 00:12:33,353 line:-2
to explain a specific concept
can be invaluable,


242
00:12:33,420 --> 00:12:35,589 line:-2
especially if they can
also interact with it.


243
00:12:36,190 --> 00:12:39,259 line:-2
Using 3D models to do this is, by far,
one of the best solutions


244
00:12:39,326 --> 00:12:42,529 line:-2
to educate your participants,
while also increasing engagement.


245
00:12:43,430 --> 00:12:47,734 line:-2
However, writing the code necessary
to present 3D models and maintaining it


246
00:12:47,801 --> 00:12:49,803 line:-1
can be cumbersome to say the least.


247
00:12:49,870 --> 00:12:52,739 line:-2
So, whether you're trying to present
something as simple as a human hand,


248
00:12:52,806 --> 00:12:55,642 line:-2
or something more complex
such as the human muscular system,


249
00:12:55,709 --> 00:12:59,246 line:-2
we've made the process of
presenting 3D models much easier for you


250
00:12:59,313 --> 00:13:00,914 line:-1
by creating two new classes.


251
00:13:01,915 --> 00:13:04,952 line:-2
Those two classes
are the ORK-3D-Model-Step,


252
00:13:05,018 --> 00:13:07,487 line:-1
and the ORK-USDZ-Model-Manager.


253
00:13:07,554 --> 00:13:08,689 line:-1
Using these two classes,


254
00:13:08,755 --> 00:13:12,326 line:-2
you can now quickly present 3D models
within your ResearchKit app by...


255
00:13:12,392 --> 00:13:16,597 line:-2
first, adding a USDZ file
to your Xcode project.


256
00:13:16,663 --> 00:13:19,967 line:-2
Second, creating
a USDZ-Model-Manager instance


257
00:13:20,033 --> 00:13:23,036 line:-2
and passing in the name
of the desired USDZ file


258
00:13:23,103 --> 00:13:25,038 line:-1
that was imported in your project.


259
00:13:25,105 --> 00:13:28,575 line:-1
And third, initialize an ORK-3D-Model-Step


260
00:13:28,642 --> 00:13:31,812 line:-2
with the USDZ-Model-Manager instance
and present it.


261
00:13:33,447 --> 00:13:36,917 line:-2
And just like that, you can now present
high-quality 3D models


262
00:13:36,984 --> 00:13:39,353 line:-2
that your users can interact with
and touch


263
00:13:39,419 --> 00:13:41,755 line:-2
without having to maintain
any of the code yourself.


264
00:13:42,656 --> 00:13:45,759 line:-2
Before moving on, we wanted to point out
that we're well-aware


265
00:13:45,826 --> 00:13:48,896 line:-2
that creating your own model
can take a good amount of time.


266
00:13:48,962 --> 00:13:51,765 line:-2
However, there are models
accessible to you online


267
00:13:51,832 --> 00:13:54,268 line:-2
that you can download for free
to practice with.


268
00:13:54,334 --> 00:13:55,636 line:-1
So, in the upcoming example,


269
00:13:55,702 --> 00:13:58,405 line:-2
we use a toy robot
and a toy drummer 3D model


270
00:13:58,472 --> 00:14:01,775 line:-2
that are both publicly available
at the URL seen here.


271
00:14:01,842 --> 00:14:03,210 line:-1
Let's get started.


272
00:14:03,277 --> 00:14:06,780 line:-2
In the first example,
we'll present the toy robot model.


273
00:14:06,847 --> 00:14:08,282 line:-1
Selection has been enabled,


274
00:14:08,348 --> 00:14:12,252 line:-2
and the user is required to touch
any part of the model before continuing.


275
00:14:14,221 --> 00:14:17,157 line:-2
In the second example,
we'll present the drummer model.


276
00:14:17,224 --> 00:14:18,525 line:-1
Selection is disabled,


277
00:14:18,592 --> 00:14:21,128 line:-2
but certain objects on the model
have been pre-highlighted


278
00:14:21,195 --> 00:14:22,996 line:-1
to draw the user's attention.


279
00:14:23,063 --> 00:14:26,867 line:-2
The user also has full control
to inspect the highlighted areas.


280
00:14:26,934 --> 00:14:31,038 line:-2
Let's take a look at some code to see
how simple it is to present a 3D model.


281
00:14:32,940 --> 00:14:36,243 line:-2
First, we initialize
our USDZ-Model-Manager,


282
00:14:36,310 --> 00:14:39,580 line:-2
passing in the name of the USDZ file
that we wish to present.


283
00:14:40,447 --> 00:14:43,383 line:-2
Next, we set a few properties
on the Model-Manager,


284
00:14:43,450 --> 00:14:46,520 line:-1
such as allows-Selection, highlight-Color,


285
00:14:46,587 --> 00:14:49,623 line:-2
and setting
enable-Continue-After-Selection to "false"


286
00:14:49,690 --> 00:14:52,392 line:-2
to ensure that the user
isn't blocked from moving forward.


287
00:14:52,459 --> 00:14:55,562 line:-2
Next, we pass in
our optional array-Of-Identifiers,


288
00:14:55,629 --> 00:14:58,065 line:-2
where each identifier
maps to a specific object


289
00:14:58,131 --> 00:15:01,001 line:-2
on the model we want to highlight
before we present it.


290
00:15:01,068 --> 00:15:04,938 line:0
Then the last thing we do
is initialize the ORK-3D-Model-Step


291
00:15:05,005 --> 00:15:07,875 line:0
and pass in the USDZ-Model-Manager
created above.


292
00:15:08,675 --> 00:15:12,312 line:-2
So, some of you might be wondering,
"Why create a Model-Manager class


293
00:15:12,379 --> 00:15:16,049 line:-2
instead of just adding that functionality
to the 3D-Model-Step itself?"


294
00:15:16,116 --> 00:15:20,087 line:-2
And the reason is to make the process
of creating a custom 3D model experience


295
00:15:20,153 --> 00:15:23,690 line:-2
much easier for any developer
interested in doing so.


296
00:15:23,757 --> 00:15:24,925 line:-1
To understand it further,


297
00:15:24,992 --> 00:15:28,228 line:-2
we need to learn about the parent class
of the USDZ-Model-Manager,


298
00:15:28,295 --> 00:15:30,797 line:-1
which is the ORK-3D-Model-Manager.


299
00:15:30,864 --> 00:15:31,932 line:-1
Let's take a look.


300
00:15:32,633 --> 00:15:36,537 line:-2
The ORK-3D-Model-Manager class
is an abstract class that we've created


301
00:15:36,603 --> 00:15:38,672 line:-1
which shouldn't be used directly.


302
00:15:38,739 --> 00:15:41,708 line:-2
The point of the 3D-Model-Manager
is to be a subclass


303
00:15:41,775 --> 00:15:44,745 line:-2
while requiring the subclass
to implement specific features


304
00:15:44,811 --> 00:15:47,948 line:-2
that we believe
every 3D model experience should have.


305
00:15:48,015 --> 00:15:49,483 line:-1
So, after creating your subclass


306
00:15:49,550 --> 00:15:51,652 line:-2
and making sure
that these features are handled,


307
00:15:51,718 --> 00:15:54,888 line:-2
you can then move forward to add
all the extra functionality you want,


308
00:15:54,955 --> 00:15:57,324 line:-1
as seen here with the USDZ-Model-Manager.


309
00:15:58,158 --> 00:15:59,560 line:-1
If the talk were to end here,


310
00:15:59,626 --> 00:16:02,596 line:-2
we definitely believe
that using the USDZ-Model-Manager


311
00:16:02,663 --> 00:16:05,532 line:-2
could create endless possibilities
for your ResearchKit app.


312
00:16:05,599 --> 00:16:07,801 line:-1
However, we are open source,


313
00:16:07,868 --> 00:16:10,737 line:-2
and we always encourage
members of the community to contribute


314
00:16:10,804 --> 00:16:12,539 line:-1
to help push ResearchKit forward.


315
00:16:13,240 --> 00:16:15,676 line:-2
With that being said,
we're excited to announce


316
00:16:15,742 --> 00:16:18,879 line:-2
that someone from the community
has also taken the opportunity


317
00:16:18,946 --> 00:16:21,048 line:-1
to create their own Model-Manager class.


318
00:16:22,649 --> 00:16:27,621 line:-2
BioDigital, an interactive 3D software
platform for anatomy visualization,


319
00:16:27,688 --> 00:16:31,692 line:-2
has provided
the ORK-BioDigital-Model-Manager class


320
00:16:31,758 --> 00:16:34,094 line:-1
so that their already powerful iOS SDK


321
00:16:34,161 --> 00:16:37,931 line:-2
can now be integrated easily
into any ResearchKit project.


322
00:16:37,998 --> 00:16:39,733 line:-1
Some of their features include:


323
00:16:39,800 --> 00:16:42,870 line:-2
presenting custom models
created via their admin portal,


324
00:16:42,936 --> 00:16:46,406 line:-2
programmatically adding labels,
colors and annotations


325
00:16:46,473 --> 00:16:48,442 line:-1
to any model loaded within your app.


326
00:16:48,509 --> 00:16:51,445 line:-2
And since all of our digital models
are loaded via the web,


327
00:16:51,512 --> 00:16:54,147 line:-2
you can dynamically add new models
to your project


328
00:16:54,214 --> 00:16:56,517 line:-1
without having to update any code.


329
00:16:56,583 --> 00:16:58,285 line:-1
Let's see a couple of examples in action.


330
00:16:59,553 --> 00:17:01,955 line:-2
In the first example,
we use an instruction step


331
00:17:02,022 --> 00:17:05,291 line:-2
to inform the user that we'll present
an interactive human model.


332
00:17:05,358 --> 00:17:08,628 line:-2
This could be used in many situations
that most of us have experienced,


333
00:17:08,694 --> 00:17:13,032 line:-2
such as visiting a physical therapy clinic
or an orthopedic physician's office


334
00:17:13,099 --> 00:17:16,236 line:-2
where you're usually given
a piece of paper to describe your pain,


335
00:17:16,303 --> 00:17:19,138 line:-2
or circle the area
on some kind of picture.


336
00:17:19,205 --> 00:17:22,542 line:-2
Now we can get rid of paper
and make the experience much better.


337
00:17:24,744 --> 00:17:26,980 line:-1
As you see here, we've loaded our model


338
00:17:27,047 --> 00:17:30,984 line:-2
while also being presented with a card
that contains useful information


339
00:17:31,051 --> 00:17:34,588 line:-2
that can be updated via
BioDigital's admin portal, or their SDK.


340
00:17:35,722 --> 00:17:37,691 line:-1
Users can also interact with the model


341
00:17:37,758 --> 00:17:40,994 line:-2
so that they can reach and view
the exact areas of interest.


342
00:17:42,863 --> 00:17:45,532 line:-2
After clicking on the muscle
where pain has been experienced,


343
00:17:45,599 --> 00:17:47,034 line:-1
we're also presented with a label


344
00:17:47,100 --> 00:17:50,671 line:-2
that can give us even more information
on that specific organ.


345
00:17:50,737 --> 00:17:53,507 line:-2
This can be updated
via BioDigital's admin portal,


346
00:17:53,574 --> 00:17:55,342 line:-1
or locally through their SDK.


347
00:17:56,910 --> 00:17:59,313 line:-1
In the next example, we imagine a scenario


348
00:17:59,379 --> 00:18:02,249 line:-2
where a patient has visited a hospital
for chest pain.


349
00:18:02,316 --> 00:18:06,053 line:-2
After receiving a CT scan,
the physician would like to give a visual


350
00:18:06,119 --> 00:18:10,090 line:-2
to show the patient the exact arteries
that are experiencing blockages.


351
00:18:10,157 --> 00:18:13,527 line:-2
To do this, we'll present
an interactive 3D human heart model


352
00:18:13,594 --> 00:18:17,698 line:-2
with dynamically-added annotations
to specific coronary arteries,


353
00:18:17,764 --> 00:18:20,801 line:-2
all done directly
through BioDigital-Model-Manager class.


354
00:18:23,804 --> 00:18:26,440 line:-2
As you can see here,
we presented our heart model


355
00:18:26,507 --> 00:18:29,843 line:-2
along with another card view
for additional information.


356
00:18:29,910 --> 00:18:31,778 line:-2
The user can then interact
with the heart model


357
00:18:31,845 --> 00:18:34,181 line:-2
and select
the programmatically added annotations


358
00:18:34,248 --> 00:18:38,151 line:-2
to find more information on the severity
of each individual blockage.


359
00:18:38,752 --> 00:18:41,622 line:-2
Let's take a look at the code
to present the animated heart model.


360
00:18:43,023 --> 00:18:47,294 line:-2
After importing ResearchKit and HumanKit,
which is provided by BioDigital,


361
00:18:47,361 --> 00:18:48,595 line:-1
we first initialize


362
00:18:48,662 --> 00:18:51,431 line:-1
the ORK-BioDigital-Model-Manager instance.


363
00:18:52,199 --> 00:18:53,734 line:-1
Then we set a couple of properties


364
00:18:53,800 --> 00:18:57,237 line:-2
that were inherited
from the ORK-3D-Model-Manager class,


365
00:18:57,304 --> 00:19:00,941 line:-2
such as highlight-Color
and identifiers-Of-Objects-To-Highlight.


366
00:19:02,042 --> 00:19:05,979 line:-2
Then we focus on some properties
and instance methods added by BioDigital,


367
00:19:06,046 --> 00:19:09,082 line:-1
such as identifiers-Of-Objects-To-Hide,


368
00:19:09,149 --> 00:19:12,586 line:-2
the load method, where we pass in the ID
of the model we want to present,


369
00:19:12,653 --> 00:19:14,121 line:-1
in this case, the heart model,


370
00:19:14,188 --> 00:19:15,522 line:-1
and the annotate method,


371
00:19:15,589 --> 00:19:18,258 line:-2
where we pass in the identifier
of the object we want to annotate,


372
00:19:18,325 --> 00:19:20,494 line:-1
in this case, the right coronary artery.


373
00:19:20,561 --> 00:19:23,997 line:0
After setting the title and text,
the last thing we have to do


374
00:19:24,064 --> 00:19:26,633 line:0
is initialize the ORK-3D-Model-Step,


375
00:19:26,700 --> 00:19:29,636 line:0
and pass in the BioDigital-Model-Manager
created above.


376
00:19:30,804 --> 00:19:34,174 line:-2
To find out more information
about BioDigital and their SDK,


377
00:19:34,241 --> 00:19:36,276 line:-1
visit their GitHub page, seen here.


378
00:19:38,645 --> 00:19:40,447 line:-2
Now that we've collected
our 3D model sticker,


379
00:19:40,514 --> 00:19:42,449 line:-1
I'll hand things over to my teammate Joey


380
00:19:42,516 --> 00:19:44,918 line:-2
to talk about building
a custom active task.


381
00:19:44,985 --> 00:19:46,119 line:-1
Take it away, Joey.


382
00:19:46,920 --> 00:19:49,823 line:-2
Thanks, Pariece, for those awesome updates
coming to ResearchKit.


383
00:19:49,890 --> 00:19:51,258 line:-1
Today, I'm going to be showing you


384
00:19:51,325 --> 00:19:53,627 line:-2
how to create
your very own custom active task.


385
00:19:55,162 --> 00:19:57,264 line:-2
So, we've collected
a bunch of stickers already...


386
00:19:58,131 --> 00:19:59,967 line:-2
so to collect
our front-facing camera sticker,


387
00:20:00,033 --> 00:20:03,670 line:-2
we will walk through the process
of creating an active task in ResearchKit.


388
00:20:03,737 --> 00:20:06,406 line:-2
Then we will open Xcode
and implement a custom application


389
00:20:06,473 --> 00:20:07,741 line:-1
to show off our new task.


390
00:20:09,176 --> 00:20:10,677 line:-1
Our task is going to show the user


391
00:20:10,744 --> 00:20:13,080 line:-2
a preview of what they're recording
in real time.


392
00:20:13,146 --> 00:20:15,816 line:-2
We'll let the user control
when to start and stop recording,


393
00:20:15,883 --> 00:20:18,318 line:-2
and show a timer for how long
they have been recording for.


394
00:20:19,853 --> 00:20:21,889 line:-2
Additionally,
the user will have the opportunity


395
00:20:21,955 --> 00:20:25,192 line:-2
to review and retry the recording,
in case they want another take.


396
00:20:26,760 --> 00:20:29,296 line:-2
Before we get into it,
I want to give you a quick refresher


397
00:20:29,363 --> 00:20:32,366 line:-2
on the relevant classes and protocols
included in ResearchKit


398
00:20:32,432 --> 00:20:33,700 line:-1
to help you accomplish this.


399
00:20:34,968 --> 00:20:38,572 line:-2
First, your application needs to create
an ORK-Task object.


400
00:20:39,640 --> 00:20:42,309 line:-2
ORK-Task is a protocol
which your app can use


401
00:20:42,376 --> 00:20:45,179 line:-2
to reference a collection
of various step objects.


402
00:20:45,245 --> 00:20:48,148 line:-2
Most applications can use
the concrete ORK-Ordered,


403
00:20:48,215 --> 00:20:51,451 line:-2
or ORK-Navigable-Ordered-Task
included in ResearchKit.


404
00:20:53,086 --> 00:20:54,721 line:-1
The task object you create


405
00:20:54,788 --> 00:20:58,358 line:-2
is then injected
into an ORK-Task-View-Controller object.


406
00:20:58,425 --> 00:21:01,195 line:-2
This object is responsible for showing
each step in your task


407
00:21:01,261 --> 00:21:02,796 line:-1
as they are de-queued.


408
00:21:02,863 --> 00:21:06,033 line:-2
Your application has no need
to subclass ORK-Task-View-Controller,


409
00:21:06,099 --> 00:21:07,301 line:-1
so you can use it as-is.


410
00:21:09,369 --> 00:21:11,638 line:-1
Additionally, ORK-Task-View-Controller


411
00:21:11,705 --> 00:21:14,208 line:-2
is a subclass
of UI-View-Controller internally,


412
00:21:14,274 --> 00:21:15,642 line:-1
so you can present it in your app


413
00:21:15,709 --> 00:21:18,545 line:-2
as you normally would
any other View-Controller in UIKit.


414
00:21:20,647 --> 00:21:23,317 line:-1
Finally, the ORK-Task-Result is an object


415
00:21:23,383 --> 00:21:26,587 line:-2
which contains the aggregate results
for each step in your task.


416
00:21:27,888 --> 00:21:29,656 line:-2
The results that are collected
from the task


417
00:21:29,723 --> 00:21:31,792 line:-2
are then delegated
back to your application


418
00:21:31,859 --> 00:21:33,227 line:-1
upon completion of the task,


419
00:21:33,293 --> 00:21:35,529 line:-2
using the ORK-Task-View-Controller
delegate.


420
00:21:37,064 --> 00:21:40,701 line:-2
This is the essential round trip
from your application into ResearchKit,


421
00:21:40,767 --> 00:21:41,802 line:-1
and then back.


422
00:21:41,869 --> 00:21:44,805 line:-2
Since I'm going to be showing you
how to create your very own active task,


423
00:21:44,872 --> 00:21:46,173 line:-1
we need to dive one level deeper


424
00:21:46,240 --> 00:21:48,775 line:-2
with some coding examples
that will set up our active task.


425
00:21:50,210 --> 00:21:53,647 line:-2
So first, our application needs to create
a collection of ORK-Step


426
00:21:53,714 --> 00:21:57,384 line:-2
and ORK-Active-Step objects
to make up the data model of our task.


427
00:21:58,719 --> 00:22:01,421 line:-2
Since we will be creating
a Front-Facing-Camera-Active task,


428
00:22:01,488 --> 00:22:05,459 line:-2
we will really create a task
which includes an Active-Step subclass.


429
00:22:06,827 --> 00:22:10,197 line:-2
First, import the ORK-Active-Step header
from ResearchKit


430
00:22:10,264 --> 00:22:12,833 line:-2
and create a new subclass
of ORK-Active-Step.


431
00:22:12,900 --> 00:22:15,602 line:-2
We'll name this class
ORK-Front-Facing-Camera-Step.


432
00:22:17,471 --> 00:22:19,606 line:-2
I'm also going to add
three additional properties here


433
00:22:19,673 --> 00:22:20,774 line:-1
I would like to configure.


434
00:22:22,576 --> 00:22:23,777 line:-1
An NS-Time-Interval,


435
00:22:23,844 --> 00:22:26,446 line:-2
to limit the maximum duration
we want to record for,


436
00:22:26,513 --> 00:22:29,783 line:-2
and two Booleans for allowing the user
to review their recording,


437
00:22:29,850 --> 00:22:32,519 line:-2
as well as allowing them
to retry their recording.


438
00:22:34,021 --> 00:22:36,190 line:-2
Next, we will declare
the View-Controller type


439
00:22:36,256 --> 00:22:38,125 line:-1
to display when the step is de-queued.


440
00:22:38,192 --> 00:22:40,294 line:-1
In the case of an ORK-Active-Step,


441
00:22:40,360 --> 00:22:43,597 line:-2
this should be a subclass
of ORK-Active-Step-View-Controller,


442
00:22:43,664 --> 00:22:44,665 line:-1
which you can implement


443
00:22:44,731 --> 00:22:47,334 line:-2
similar to any UI-View-Controller
in UIKit.


444
00:22:47,801 --> 00:22:50,003 line:-2
The ORK-Task-View-Controller
presenting your task


445
00:22:50,070 --> 00:22:53,173 line:-2
is responsible for instantiating
the associated View-Controller


446
00:22:53,240 --> 00:22:54,741 line:-1
of each step in your task.


447
00:22:56,443 --> 00:22:57,878 line:-1
Here's a quick look at the interface


448
00:22:57,945 --> 00:23:00,714 line:-2
of our ORK-Front-Facing-Camera-
Step-View-Controller,


449
00:23:00,781 --> 00:23:03,750 line:-2
which subclasses
ORK-Active-Step-View-Controller.


450
00:23:05,619 --> 00:23:07,821 line:-1
In our ORK-Front-Facing-Camera-Step,


451
00:23:07,888 --> 00:23:09,623 line:-2
we will declare
the type of View-Controller


452
00:23:09,690 --> 00:23:11,024 line:-1
to associate with the step,


453
00:23:11,091 --> 00:23:14,494 line:-2
so we can override the step-View-
Controller-Class method of the superclass.


454
00:23:15,629 --> 00:23:17,364 line:-1
In this case, we will return


455
00:23:17,431 --> 00:23:20,934 line:-2
the ORK-Front-Facing-Camera-
Step-View-Controller class object.


456
00:23:22,369 --> 00:23:25,439 line:0
You can use a custom UI-View
to represent the content of your step.


457
00:23:26,840 --> 00:23:29,877 line:0
So here, our ORK-Front-Facing-Camera-
Step-Content-View


458
00:23:29,943 --> 00:23:31,879 line:0
is a simple subclass of UI-View.


459
00:23:33,280 --> 00:23:34,681 line:0
I've declared some View events here


460
00:23:34,748 --> 00:23:37,985 line:0
which we can use to pass relevant events
back to our View-Controller,


461
00:23:38,051 --> 00:23:39,620 line:0
as well as a block typedef.


462
00:23:41,154 --> 00:23:42,356 line:-1
Inside of our interface,


463
00:23:42,422 --> 00:23:44,224 line:-2
we have a method
to set the block parameter


464
00:23:44,291 --> 00:23:46,660 line:-2
to invoke when events are passed
from the content view.


465
00:23:48,529 --> 00:23:51,498 line:-2
Since we want to give the user a preview
of the recording in real time,


466
00:23:51,565 --> 00:23:54,234 line:-2
we will pass the AV-Capture-Session
to the content view,


467
00:23:54,301 --> 00:23:56,270 line:-2
and internally,
the content view will set up


468
00:23:56,336 --> 00:23:58,238 line:-1
an AV-Capture-Video-Preview-Layer.


469
00:23:59,540 --> 00:24:03,677 line:0
And finally, we have added a method
to start our timer with a maximum duration


470
00:24:03,744 --> 00:24:07,247 line:0
as well as a method to show certain
recording options before submitting.


471
00:24:08,949 --> 00:24:12,085 line:-2
We can now add this content view
into our View-Controller.


472
00:24:12,152 --> 00:24:14,588 line:-2
We already have a reference
to an AV-Capture-Session


473
00:24:14,655 --> 00:24:16,456 line:-1
which is initialized in another method.


474
00:24:18,192 --> 00:24:22,329 line:-2
We also have a property to reference our
ORK-Front-Facing-Camera-Step-Content-View.


475
00:24:23,897 --> 00:24:25,499 line:0
By the time we reach view-Did-Load,


476
00:24:25,566 --> 00:24:27,634 line:0
we are ready to initialize
our content view.


477
00:24:29,036 --> 00:24:31,905 line:0
Next, we will handle events
coming from our content view.


478
00:24:31,972 --> 00:24:34,374 line:0
We'll use weak-Self here
to avoid a reference cycle.


479
00:24:36,777 --> 00:24:38,612 line:0
We will add our content view as a subview.


480
00:24:40,047 --> 00:24:42,216 line:0
And finally,
we will set the Preview-Layer session


481
00:24:42,282 --> 00:24:44,384 line:0
using our AV-Capture-Session from before.


482
00:24:46,186 --> 00:24:47,554 line:0
After our step finishes,


483
00:24:47,621 --> 00:24:51,725 line:0
ORK-Active-Step-View-Controller
asks for the ORK-Step-Result.


484
00:24:51,792 --> 00:24:54,828 line:0
This is your View-Controller's call
to add the appropriate results


485
00:24:54,895 --> 00:24:56,930 line:0
and any data you collect to be delegated


486
00:24:56,997 --> 00:24:59,266 line:0
back to the application
when your step finishes.


487
00:25:00,567 --> 00:25:03,637 line:-2
In our case,
ORK-Front-Facing-Camera-Step-Result


488
00:25:03,704 --> 00:25:06,206 line:-2
is going to be a subclass
of ORK-File-Result.


489
00:25:08,175 --> 00:25:11,512 line:-2
We have also added an integer property
so we can keep track of how many times


490
00:25:11,578 --> 00:25:13,714 line:-2
the user deleted
and retried their recording.


491
00:25:15,916 --> 00:25:20,187 line:-2
If we revisit the View-Controller,
we override the superclass's result method


492
00:25:20,254 --> 00:25:23,524 line:-2
to append our custom
ORK-Front-Facing-Camera-Step-Result.


493
00:25:25,459 --> 00:25:29,496 line:-2
First, we create an instance of our
ORK-Front-Facing-Camera-Step-Result.


494
00:25:29,563 --> 00:25:31,265 line:-1
Then we set the relevant parameters,


495
00:25:31,331 --> 00:25:35,802 line:-2
such as the identifier, content-Type,
retry-Count, as well as the file-URL.


496
00:25:38,071 --> 00:25:39,573 line:0
Finally, we append our new-Results


497
00:25:39,640 --> 00:25:42,075 line:-2
into the current-Results collection
and return.


498
00:25:42,476 --> 00:25:44,244 line:-2
This effectively completes
the implementation


499
00:25:44,311 --> 00:25:45,746 line:-1
of our custom active task.


500
00:25:45,812 --> 00:25:47,648 line:-1
Let's jump into Xcode and try it out.


501
00:25:49,216 --> 00:25:52,819 line:-2
So here I have a demo application
that I've been working on


502
00:25:52,886 --> 00:25:55,022 line:-1
which includes ResearchKit as a submodule.


503
00:25:55,088 --> 00:25:57,324 line:-2
So I'm going to go ahead
and I'm going to create a method


504
00:25:57,391 --> 00:25:59,826 line:-2
which allows us to construct
and present our task.


505
00:25:59,893 --> 00:26:01,061 line:-1
Inside of this method,


506
00:26:01,128 --> 00:26:04,164 line:-2
we're going to instantiate our steps
that are part of our task.


507
00:26:04,231 --> 00:26:06,400 line:-2
So I'm going to go ahead
and create an instruction-Step


508
00:26:06,466 --> 00:26:08,302 line:-1
which welcomes the user to the task.


509
00:26:08,936 --> 00:26:10,671 line:-1
Then I'm going to use


510
00:26:10,737 --> 00:26:13,640 line:-2
the ORK-Front-Facing-Camera-Step
that we just created.


511
00:26:13,707 --> 00:26:16,743 line:-2
We'll set the maximum recording limit
to about 15 seconds,


512
00:26:16,810 --> 00:26:20,113 line:-2
and we'll allow the user
to retry and review their recording.


513
00:26:20,180 --> 00:26:23,083 line:-2
Then we'll go ahead
and add a completion step,


514
00:26:23,150 --> 00:26:24,585 line:-1
thanking the user for their time.


515
00:26:25,252 --> 00:26:26,787 line:-1
So, now that we have all of our steps,


516
00:26:26,854 --> 00:26:29,323 line:-2
we'll go ahead and create
an ORK-Task object.


517
00:26:29,389 --> 00:26:31,258 line:-1
So here we have an ORK-Ordered-Task


518
00:26:31,325 --> 00:26:33,260 line:-2
and we'll include
all of the steps from before...


519
00:26:34,461 --> 00:26:39,132 line:0
then create a task-View-Controller object
injecting our task as well.


520
00:26:41,802 --> 00:26:44,471 line:-1
Then we present this task-View-Controller.


521
00:26:45,906 --> 00:26:47,307 line:-1
In view-Did-Appear


522
00:26:47,374 --> 00:26:51,311 line:-2
we can go ahead and present
Front-Facing-Camera-Active-Task


523
00:26:51,378 --> 00:26:54,948 line:-2
and conform to the delegate,
the ORK-Task-View-Controller delegate.


524
00:26:55,949 --> 00:27:00,487 line:-2
Then we can make ourselves
the delegate for the task-View-Controller.


525
00:27:02,523 --> 00:27:08,295 line:-2
Then respond to the did-Finish-With reason
ORK-Task-View-Controller delegate method.


526
00:27:09,296 --> 00:27:12,199 line:-2
Inside of this method,
we're going to check to see


527
00:27:12,266 --> 00:27:15,602 line:-2
if the currently presented View-Controller
is the task-View-Controller,


528
00:27:15,669 --> 00:27:16,970 line:-1
and then dismiss it.


529
00:27:17,037 --> 00:27:21,341 line:-2
And we'll go ahead and try to extract
the ORK-Front-Facing-Camera-Step-Result.


530
00:27:22,442 --> 00:27:24,144 line:0
And once we have that result object,


531
00:27:24,211 --> 00:27:26,647 line:0
we can go ahead
and print the Recording File URL,


532
00:27:26,713 --> 00:27:27,915 line:0
as well as the retry-Count.


533
00:27:29,483 --> 00:27:31,451 line:-2
So let's go ahead
and run this on the device.


534
00:27:32,819 --> 00:27:36,924 line:-2
Okay, so here we have
our instruction-Step that we created,


535
00:27:36,990 --> 00:27:38,992 line:-1
and we're "Welcome to WWDC!"


536
00:27:39,059 --> 00:27:40,861 line:-1
So here we have our preview-Layer session,


537
00:27:40,928 --> 00:27:43,497 line:-2
which we can see our recording
in real time.


538
00:27:43,564 --> 00:27:45,599 line:0
We'll go ahead and click "Get Started."


539
00:27:45,666 --> 00:27:48,001 line:0
So here we have
our Front-Facing-Camera-Step,


540
00:27:48,068 --> 00:27:50,470 line:0
and I'll go ahead and create a recording.


541
00:27:50,537 --> 00:27:52,573 line:0
Hello and welcome to WWDC.


542
00:27:54,241 --> 00:27:55,843 line:-1
So let's go ahead and review this video.


543
00:27:56,643 --> 00:27:58,779 line:-1
<i>Hello and welcome to WWDC.</i>


544
00:28:00,013 --> 00:28:03,050 line:-2
Okay, let's go ahead and just retry that
'cause I didn't like that.


545
00:28:05,619 --> 00:28:07,754 line:0
Hello and welcome to WWDC.


546
00:28:09,056 --> 00:28:11,225 line:0
I think that one was good,
so I'll go ahead and submit.


547
00:28:11,959 --> 00:28:14,094 line:-2
Here's our completion-Step
thanking the user,


548
00:28:14,161 --> 00:28:16,096 line:-2
and we'll go ahead
and exit the task gracefully.


549
00:28:19,800 --> 00:28:22,402 line:-2
If we go back to Xcode,
we should be able to see in the console


550
00:28:23,070 --> 00:28:25,873 line:-2
that we have printed
the Recording File URL


551
00:28:25,939 --> 00:28:27,341 line:-1
as well as the retry-Count.


552
00:28:29,042 --> 00:28:30,878 line:-2
This concludes
our demonstration for today,


553
00:28:30,944 --> 00:28:33,814 line:-2
and we have implemented our own
custom Active-Step in ResearchKit


554
00:28:33,881 --> 00:28:36,250 line:-2
and constructed the task
in our application.


555
00:28:36,316 --> 00:28:39,553 line:-2
We then extracted the results object
to verify our result.


556
00:28:39,620 --> 00:28:42,322 line:-2
We hope you enjoyed. Thank you.
Pariece, back to you.


557
00:28:43,757 --> 00:28:46,860 line:-2
Thank you for that demo, Joey.
We hope everyone viewing enjoyed it,


558
00:28:46,927 --> 00:28:48,795 line:-2
and we're very excited to see
what you can do


559
00:28:48,862 --> 00:28:50,564 line:-1
with the new Front-Facing-Camera-Step,


560
00:28:50,631 --> 00:28:53,133 line:-2
or any task
that you decide to create yourself.


561
00:28:53,800 --> 00:28:56,303 line:-2
Now that we've collected
our Front-Facing-Camera-Step sticker,


562
00:28:56,370 --> 00:28:59,773 line:-2
that brings us to a close to
all of our ResearchKit updates this year.


563
00:28:59,840 --> 00:29:01,108 line:-1
But before moving on,


564
00:29:01,175 --> 00:29:03,911 line:-2
let's go over all the stickers
we've collected throughout our talk.


565
00:29:04,778 --> 00:29:08,282 line:-2
First, we talked about community updates,
where we mentioned a few apps


566
00:29:08,348 --> 00:29:10,617 line:-2
that have leveraged our frameworks
over the past year,


567
00:29:10,684 --> 00:29:13,287 line:-1
our new website at researchandcare.org,


568
00:29:13,353 --> 00:29:15,355 line:-1
and the new Investigator Support Program.


569
00:29:16,223 --> 00:29:18,258 line:-1
Then we moved on to onboarding updates.


570
00:29:18,325 --> 00:29:19,826 line:-1
We spoke about the new additions,


571
00:29:19,893 --> 00:29:22,996 line:-2
such as body items,
inline signature functionality


572
00:29:23,063 --> 00:29:24,565 line:-1
and the Request-Permission-Step.


573
00:29:25,566 --> 00:29:27,201 line:-1
Then we talked about survey enhancements,


574
00:29:27,267 --> 00:29:30,637 line:-2
where we previewed new error labels,
the "I don’t know" button,


575
00:29:30,704 --> 00:29:32,673 line:-2
and the Review-View-Controller,
to name a few.


576
00:29:34,308 --> 00:29:36,510 line:-2
Then we talked about
hearing test UI updates,


577
00:29:36,577 --> 00:29:38,679 line:-1
where we previewed UI enhancements


578
00:29:38,745 --> 00:29:41,815 line:-2
to the Environment-SPL-Meter
and Tone-Audiometry-Step.


579
00:29:42,983 --> 00:29:44,585 line:-1
Then we moved on to 3D models,


580
00:29:44,651 --> 00:29:47,888 line:-2
where we went over and previewed
the 3D-Model-Step,


581
00:29:47,955 --> 00:29:49,690 line:-1
the USDZ-Model-Manager,


582
00:29:49,756 --> 00:29:53,627 line:-2
and the BioDigital-Model-Manager classes
to add 3D models to your app.


583
00:29:54,461 --> 00:29:55,896 line:-1
And last, but not least,


584
00:29:55,963 --> 00:29:59,132 line:-2
Joey walked you through the process
of building your own active task,


585
00:29:59,199 --> 00:30:02,936 line:-2
while also previewing the functionality
of the new Front-Facing-Camera-Step.


586
00:30:04,404 --> 00:30:06,507 line:-2
We have a pretty solid collection
of stickers here,


587
00:30:06,573 --> 00:30:09,676 line:-2
but it wouldn't be complete
without the final ResearchKit sticker.


588
00:30:13,313 --> 00:30:15,949 line:-2
For more information
on the topics discussed today,


589
00:30:16,016 --> 00:30:18,252 line:-2
feel free to visit
the resources shared here.


590
00:30:19,920 --> 00:30:22,322 line:-2
As always,
we want to remind everyone watching


591
00:30:22,389 --> 00:30:23,824 line:-1
that we are open source,


592
00:30:23,891 --> 00:30:27,127 line:-2
and we welcome anyone using
or interested in ResearchKit


593
00:30:27,194 --> 00:30:31,532 line:-2
to visit our GitHub repo shown here
and contribute to help the framework grow.


594
00:30:32,799 --> 00:30:34,935 line:0
Thank you again for taking the time
to watch our talk,


595
00:30:35,002 --> 00:30:38,138 line:0
and we're looking forward to seeing
the powerful apps and experiences


596
00:30:38,205 --> 00:30:40,240 line:0
you will create with ResearchKit.
Thank you.

