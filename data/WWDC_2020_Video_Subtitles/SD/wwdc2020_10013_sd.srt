1
00:00:03,836 --> 00:00:06,807 line:-1
Hello and welcome to WWDC.


2
00:00:08,208 --> 00:00:09,376 line:0
Hello everyone.


3
00:00:09,443 --> 00:00:12,946 line:0
My name is Rich Forster,
and I'm a GPU software engineer at Apple.


4
00:00:13,580 --> 00:00:17,384 line:-2
In this session, I'm going to talk to you
about the new function pointers API


5
00:00:17,451 --> 00:00:18,986 line:-1
that we've added to Metal this year.


6
00:00:19,686 --> 00:00:21,855 line:-2
Let's start
with the humble function pointer.


7
00:00:22,756 --> 00:00:26,760 line:-2
Function pointers give us the power
to refer to code that we can call.


8
00:00:27,628 --> 00:00:31,265 line:-2
They make our code extensible
by allowing us to write our code


9
00:00:31,331 --> 00:00:34,468 line:-2
so that it can later call code
that we have never seen before.


10
00:00:35,903 --> 00:00:38,739 line:-1
The classic example is the callback,


11
00:00:38,805 --> 00:00:42,042 line:-2
where execution jumps to code
identified with a function pointer.


12
00:00:42,676 --> 00:00:45,212 line:-2
This lets us provide functions
for plug-ins,


13
00:00:45,279 --> 00:00:47,214 line:-1
specializations or notifications.


14
00:00:47,714 --> 00:00:49,616 line:-1
But we can do so much more.


15
00:00:50,217 --> 00:00:55,522 line:-2
Today I am going to talk about how we
expose function pointer support in Metal


16
00:00:55,589 --> 00:00:58,559 line:-2
and how we use visible functions
to achieve our goals.


17
00:00:59,326 --> 00:01:02,796 line:-2
I will cover the different
compilation models we support,


18
00:01:02,863 --> 00:01:05,432 line:-1
what they mean, and when to use them.


19
00:01:06,066 --> 00:01:08,802 line:-2
I will then discuss
tables of visible functions


20
00:01:08,869 --> 00:01:11,572 line:-2
and finish with a discussion
of performance.


21
00:01:12,039 --> 00:01:14,541 line:-2
So let's start
with function pointers in Metal.


22
00:01:15,642 --> 00:01:18,078 line:0
When we added function pointers to Metal,


23
00:01:18,145 --> 00:01:21,748 line:0
we knew there would be
a range of opportunities to use them.


24
00:01:21,815 --> 00:01:25,452 line:0
The obvious case is ray tracing,
where we use function pointers


25
00:01:25,519 --> 00:01:28,455 line:0
to specify
our custom intersection functions.


26
00:01:28,922 --> 00:01:31,725 line:0
And I would encourage you
to watch the ray tracing talk


27
00:01:31,792 --> 00:01:33,927 line:0
which accompanies this session.


28
00:01:35,095 --> 00:01:37,297 line:-1
Ray tracing is also a great place


29
00:01:37,364 --> 00:01:39,733 line:-2
to talk about other uses
of function pointers,


30
00:01:39,800 --> 00:01:41,835 line:-1
and that's where I'd like to start today.


31
00:01:42,803 --> 00:01:45,873 line:0
When we apply ray tracing
to the classic Cornell Box,


32
00:01:46,340 --> 00:01:48,709 line:0
we fire our rays into the scene,


33
00:01:48,775 --> 00:01:52,212 line:0
and when they hit surfaces,
we need to shade the intersections.


34
00:01:52,846 --> 00:01:56,617 line:0
Typically, we have the material
for the surface that we intersect,


35
00:01:56,683 --> 00:02:00,187 line:0
and then we will continue tracing
until we hit a light,


36
00:02:00,254 --> 00:02:03,490 line:0
at which point we will evaluate
the contribution of the light.


37
00:02:04,258 --> 00:02:07,094 line:-2
Let's revisit the process flow
for ray tracing.


38
00:02:07,928 --> 00:02:11,298 line:-2
First, we generate rays
which start from the camera


39
00:02:11,365 --> 00:02:12,933 line:-1
and are emitted into the scene.


40
00:02:13,834 --> 00:02:17,638 line:-2
We then test those rays for intersection
with the geometry in the scene.


41
00:02:19,106 --> 00:02:22,576 line:-2
Next, we compute a color
at each intersection point


42
00:02:22,643 --> 00:02:24,411 line:-1
and update the image.


43
00:02:24,478 --> 00:02:26,280 line:-1
This process is called shading.


44
00:02:27,214 --> 00:02:30,784 line:-2
The shading process
can also generate additional rays.


45
00:02:31,318 --> 00:02:34,154 line:-2
So we test those rays
for intersection with the scene


46
00:02:34,221 --> 00:02:37,257 line:-2
and repeat this process
as many times as we'd like


47
00:02:37,324 --> 00:02:40,194 line:-2
to simulate light
bouncing around the scene.


48
00:02:40,894 --> 00:02:44,865 line:-2
Today, we're going to simplify things
for this presentation


49
00:02:44,932 --> 00:02:48,669 line:-2
and start by considering a path tracer
that performs a single intersection


50
00:02:48,735 --> 00:02:51,171 line:-2
and then shades the result
of that intersection.


51
00:02:51,805 --> 00:02:55,809 line:-2
This will be in a single computer kernel
that creates a compute pipeline


52
00:02:55,876 --> 00:02:58,779 line:-2
that includes the code
for each of these three stages.


53
00:02:58,846 --> 00:03:01,748 line:-2
However,
the stage I want to focus on is shading.


54
00:03:02,416 --> 00:03:05,385 line:-2
This is the last step
before we output our image


55
00:03:05,452 --> 00:03:08,689 line:-2
and provides a range of opportunities
to use function pointers.


56
00:03:10,123 --> 00:03:13,460 line:0
Within our ray tracing kernel,
shading happens near the end.


57
00:03:14,361 --> 00:03:17,598 line:0
Once we have an intersection,
we find the matching material


58
00:03:17,664 --> 00:03:19,700 line:0
and perform our shading for that material.


59
00:03:20,334 --> 00:03:21,668 line:0
In this example,


60
00:03:21,735 --> 00:03:24,972 line:0
all of our material and lighting code
lives in the shade function


61
00:03:25,038 --> 00:03:26,807 line:0
which exists elsewhere in our file.


62
00:03:27,574 --> 00:03:29,543 line:-1
Let's dig deeper into the shade function.


63
00:03:30,911 --> 00:03:33,046 line:-1
Our shade function has several steps.


64
00:03:34,081 --> 00:03:35,749 line:-1
This is a simple path tracer,


65
00:03:35,816 --> 00:03:38,719 line:-2
so it immediately calculates the lighting
from the light


66
00:03:38,785 --> 00:03:41,121 line:-1
at the intersection point on the surface.


67
00:03:42,022 --> 00:03:46,393 line:-2
And then we use the material to apply
that lighting at the intersection point.


68
00:03:47,628 --> 00:03:52,633 line:-2
In terms of flow, we can consider lighting
and material as separate stages.


69
00:03:53,233 --> 00:03:56,803 line:-2
But there's more than one type of light
and more than one type of material.


70
00:03:58,372 --> 00:04:00,874 line:-2
We can break lighting
into separate types of light,


71
00:04:00,941 --> 00:04:03,744 line:-2
which will require different code
for each light type.


72
00:04:04,778 --> 00:04:08,615 line:-2
And the code for materials can be
even more varied than the code for lights.


73
00:04:09,082 --> 00:04:12,452 line:-2
We are going to use
the new visible function type in Metal


74
00:04:12,519 --> 00:04:15,355 line:-2
to help us work with our lighting
and material functions.


75
00:04:16,957 --> 00:04:22,196 line:-2
Visible is a new function qualification
attribute like vertex, fragment or kernel.


76
00:04:22,763 --> 00:04:25,766 line:-2
We can use the visible attributes
on function definitions,


77
00:04:25,832 --> 00:04:28,902 line:-2
and when we use the visible attribute,
we are declaring


78
00:04:28,969 --> 00:04:32,239 line:-2
that we want to manipulate
the function from the Metal API.


79
00:04:32,873 --> 00:04:37,477 line:-2
We check if we can use the API to perform
this manipulation with the device query.


80
00:04:38,612 --> 00:04:41,748 line:-2
With visible functions,
we can consider our code


81
00:04:41,815 --> 00:04:44,518 line:-1
as a flexible object that we can refer to.


82
00:04:45,052 --> 00:04:48,722 line:-2
In this case, let's consider the code
for our area lights.


83
00:04:49,256 --> 00:04:52,259 line:-2
That code is an object
that can exist outside of the kernel


84
00:04:52,326 --> 00:04:54,127 line:-1
that represents our pipeline.


85
00:04:54,194 --> 00:04:57,831 line:-2
The code can exist in another Metal file
or another Metal library.


86
00:04:59,466 --> 00:05:01,969 line:-2
To declare our lighting function
as visible,


87
00:05:02,035 --> 00:05:05,405 line:-2
we add the visible attribute
before the definition of the function.


88
00:05:06,373 --> 00:05:09,176 line:-2
This will allow us to create
a Metal function object


89
00:05:09,243 --> 00:05:11,678 line:-1
to represent the code in this function.


90
00:05:13,213 --> 00:05:17,718 line:-2
Our next step is to connect
our Metal shader code to our pipeline


91
00:05:17,784 --> 00:05:19,286 line:-1
so that we can call it.


92
00:05:20,087 --> 00:05:24,157 line:-2
First, we wrap our area light code
in a Metal function object.


93
00:05:24,925 --> 00:05:28,695 line:-2
Then the new Metal function object
can be added to the pipeline.


94
00:05:30,430 --> 00:05:33,200 line:-2
With the visible attribute
on our area light function,


95
00:05:33,267 --> 00:05:36,403 line:-2
we can wrap it in a Metal function object
on the CPU.


96
00:05:37,371 --> 00:05:41,208 line:-2
We create a Metal function object by name
for our visible function


97
00:05:41,275 --> 00:05:42,943 line:-1
using the standard methods.


98
00:05:44,678 --> 00:05:48,415 line:-2
We then add the function object
to the compute pipeline descriptor


99
00:05:48,482 --> 00:05:52,386 line:-2
as part of the linkedFunctions
to allow the pipeline creation process


100
00:05:52,452 --> 00:05:56,990 line:-2
to add it to the pipeline so that we can
refer to it later with a function pointer.


101
00:05:57,724 --> 00:06:00,794 line:-2
Now that we're talking about adding
visible functions to our pipelines,


102
00:06:00,861 --> 00:06:04,464 line:-2
we need to discuss the compilation
model choices that we have available.


103
00:06:05,599 --> 00:06:07,768 line:-1
Once we have Metal function objects


104
00:06:07,835 --> 00:06:10,404 line:-2
for each of our lighting
and material functions,


105
00:06:10,470 --> 00:06:12,272 line:-1
we can add them to our pipeline.


106
00:06:13,674 --> 00:06:18,245 line:-2
When we build our pipeline, we can take
a copy of each of those visible functions.


107
00:06:18,912 --> 00:06:21,181 line:-1
We call this "single compilation,"


108
00:06:21,248 --> 00:06:24,718 line:-2
since we then have a single object
that represents our pipeline


109
00:06:24,785 --> 00:06:27,187 line:-2
and all of the visible functions
that it uses.


110
00:06:29,223 --> 00:06:33,126 line:-2
We use the same linkedFunctions object
that we saw earlier


111
00:06:33,193 --> 00:06:35,929 line:-2
to list the functions that we may call
from our pipeline.


112
00:06:36,630 --> 00:06:41,735 line:-2
Then we create our ComputePipelineState
using the standard pipeline creation API.


113
00:06:43,837 --> 00:06:46,640 line:-2
The creation of our pipeline
results in an object


114
00:06:46,707 --> 00:06:49,943 line:-2
that contains both a specialized version
of our kernel code


115
00:06:50,010 --> 00:06:53,146 line:-2
and specialized copies
of all of our functions.


116
00:06:53,847 --> 00:06:57,150 line:-2
This specialization is similar
to link-time optimization,


117
00:06:57,217 --> 00:06:59,820 line:-2
where the kernel code
and the visible functions


118
00:06:59,887 --> 00:07:02,256 line:-1
can be optimized based on their usage.


119
00:07:03,323 --> 00:07:08,529 line:-2
However, this optimization can increase
the time taken to create our pipeline


120
00:07:08,595 --> 00:07:13,400 line:-2
and results in a larger pipeline object
due to the copies of the function objects


121
00:07:13,467 --> 00:07:15,302 line:-1
that we add into the pipeline.


122
00:07:16,036 --> 00:07:20,040 line:-2
But what we may want to do is have our
function objects outside of our pipeline


123
00:07:20,107 --> 00:07:24,745 line:-2
as separate objects that our pipeline
can call but does not have to copy.


124
00:07:25,445 --> 00:07:28,649 line:-2
This is the foundation
of a separately compiled pipeline.


125
00:07:30,317 --> 00:07:32,920 line:-1
When we create each Metal function object,


126
00:07:32,986 --> 00:07:36,990 line:-2
we can compile each function
to a stand-alone GPU binary form


127
00:07:37,057 --> 00:07:39,960 line:-2
so that we can keep
the function code separate


128
00:07:40,027 --> 00:07:42,529 line:-1
and reuse it across multiple pipelines.


129
00:07:44,364 --> 00:07:48,435 line:-2
To compile our functions to binary,
we will use a function descriptor.


130
00:07:49,169 --> 00:07:53,340 line:-2
This allows us to add options to
the creation of a Metal function object.


131
00:07:54,141 --> 00:07:56,443 line:-1
In the case of creating our function,


132
00:07:56,510 --> 00:08:00,113 line:-2
this snippet of code creates
the same resulting Metal function


133
00:08:00,180 --> 00:08:02,449 line:-1
as the same method with a name parameter.


134
00:08:03,050 --> 00:08:07,921 line:-2
However, the functionDescriptor lets us
specify more configuration options.


135
00:08:09,389 --> 00:08:12,092 line:-1
We request binary precompilation


136
00:08:12,159 --> 00:08:14,528 line:-2
by using the "options" property
of the descriptor.


137
00:08:15,128 --> 00:08:19,032 line:-2
The function creation will now precompile
our function to binary.


138
00:08:21,335 --> 00:08:23,270 line:-1
We then provide our new function


139
00:08:23,337 --> 00:08:26,607 line:-2
in the binary function's array
of the linkedFunctions object.


140
00:08:27,241 --> 00:08:31,011 line:-2
This indicates that we are referring
to the binary version of the function


141
00:08:31,078 --> 00:08:34,581 line:-2
rather than requesting
copying and specialization of the function


142
00:08:34,648 --> 00:08:36,082 line:-1
for the compute pipeline.


143
00:08:36,717 --> 00:08:40,153 line:-2
As you can see, we can mix and match
precompiled functions


144
00:08:40,220 --> 00:08:41,722 line:-1
with those we want specialized.


145
00:08:42,523 --> 00:08:46,493 line:-2
And then we use the standard call
to create the pipeline, as before.


146
00:08:47,594 --> 00:08:50,797 line:-2
Now that we have covered both single
and separate compilation,


147
00:08:50,864 --> 00:08:53,600 line:-2
this is a good point
to compare the advantages of each.


148
00:08:54,501 --> 00:08:59,439 line:0
For single compilation, we create visible
functions using our standard methods.


149
00:08:59,973 --> 00:09:03,043 line:0
For separate compilation,
we will precompile to binary


150
00:09:03,110 --> 00:09:05,212 line:0
to allow us to share the compile binary


151
00:09:05,279 --> 00:09:09,449 line:0
and avoid the binary compilation
of our function during pipeline creation.


152
00:09:10,651 --> 00:09:13,120 line:0
When we configure our pipeline descriptor,


153
00:09:13,187 --> 00:09:16,757 line:0
we use the functions array
to indicate that we want them specialized


154
00:09:16,823 --> 00:09:21,295 line:0
and the binaryFunctions array to indicate
that we want to use the binary versions.


155
00:09:22,529 --> 00:09:24,431 line:0
The result of specialization


156
00:09:24,498 --> 00:09:27,534 line:0
is a larger pipeline
in the single-compilation case.


157
00:09:28,368 --> 00:09:31,138 line:0
Separate compilation
will result in a pipeline


158
00:09:31,205 --> 00:09:33,473 line:0
that adds calls to binary functions,


159
00:09:33,540 --> 00:09:35,776 line:0
and the binary functions will be shared.


160
00:09:37,044 --> 00:09:41,882 line:0
Specialization of functions also requires
a longer pipeline creation time


161
00:09:41,949 --> 00:09:44,117 line:0
than adding calls to binary functions.


162
00:09:44,618 --> 00:09:48,422 line:0
As I mentioned earlier, this is similar
to link-time optimization,


163
00:09:48,488 --> 00:09:52,059 line:0
where the compiler can take advantage
of knowing the whole pipeline


164
00:09:52,125 --> 00:09:55,662 line:0
but requires extra build time
to apply the specializations.


165
00:09:57,097 --> 00:09:59,366 line:0
All of that function specialization


166
00:09:59,433 --> 00:10:02,870 line:0
means that single compilation
has the best runtime performance.


167
00:10:03,737 --> 00:10:06,740 line:0
The flexibility
of the separately compiled pipeline


168
00:10:06,807 --> 00:10:10,844 line:0
means that there is some runtime overhead
to calling our binary functions.


169
00:10:11,245 --> 00:10:12,412 line:-1
As we saw earlier,


170
00:10:12,479 --> 00:10:16,250 line:-2
you can mix sets of precompiled functions
and functions for specialization,


171
00:10:16,316 --> 00:10:19,353 line:-2
but a fully specialized,
single-compilation pipeline


172
00:10:19,419 --> 00:10:20,988 line:-1
will offer the best performance.


173
00:10:21,655 --> 00:10:23,156 line:-1
It should always be possible


174
00:10:23,223 --> 00:10:26,627 line:-2
to create a new single-compilation
pipeline in the background


175
00:10:26,693 --> 00:10:30,531 line:-2
to replace any separately compiled
functions in an existing pipeline.


176
00:10:31,465 --> 00:10:33,800 line:-2
Going back
to our separate compilation pipeline,


177
00:10:34,234 --> 00:10:37,504 line:-2
we have our array of functions available
to call from the pipeline.


178
00:10:37,938 --> 00:10:41,341 line:-2
However, whenever you think
you have a fixed set of functions,


179
00:10:41,408 --> 00:10:43,443 line:-1
another function always appears.


180
00:10:44,545 --> 00:10:48,782 line:-2
In this case, we have a new wood material
that we want to add to our pipeline.


181
00:10:49,483 --> 00:10:52,819 line:-2
Incremental compilation is intended
for adding new functions


182
00:10:52,886 --> 00:10:54,321 line:-1
to an existing pipeline.


183
00:10:55,055 --> 00:10:57,691 line:-2
The appearance of new functions
is typically quite common


184
00:10:57,758 --> 00:10:59,259 line:-1
in dynamic environments,


185
00:10:59,326 --> 00:11:03,030 line:-2
especially games where streaming
may load new assets with new shaders.


186
00:11:04,364 --> 00:11:05,732 line:0
Putting this into code,


187
00:11:06,333 --> 00:11:10,370 line:0
first we need to make the choice
to support incremental compilation


188
00:11:10,437 --> 00:11:12,806 line:0
when we create
our initial compute pipeline.


189
00:11:13,307 --> 00:11:16,710 line:0
The default is to not support
incremental compilation


190
00:11:16,777 --> 00:11:19,847 line:0
because enabling the later addition
of binary functions


191
00:11:19,913 --> 00:11:23,550 line:0
means that pipeline creation has to expect
possible calls to binary functions


192
00:11:23,617 --> 00:11:26,420 line:0
even if none are specified
at pipeline creation time.


193
00:11:27,621 --> 00:11:31,325 line:0
We then use a function descriptor
to create the Metal function object


194
00:11:31,391 --> 00:11:34,428 line:0
for our wood shader
as a precompiled binary function.


195
00:11:35,696 --> 00:11:39,900 line:0
Finally, we use a newly added method
on ComputePipelineState


196
00:11:39,967 --> 00:11:44,171 line:0
to create a compute pipeline
with any additional binary functions.


197
00:11:45,506 --> 00:11:48,675 line:-2
Next, I want to talk
about visible function tables.


198
00:11:49,343 --> 00:11:52,279 line:-2
Visible function tables
are how we pass function pointers


199
00:11:52,346 --> 00:11:54,781 line:-1
to our visible functions to the GPU.


200
00:11:56,817 --> 00:11:59,319 line:-2
Going back to the set
of the lighting and material functions


201
00:11:59,386 --> 00:12:01,588 line:-1
that we considered for our shading,


202
00:12:01,655 --> 00:12:04,791 line:-2
we need to provide these
to the kernel running on the GPU.


203
00:12:06,193 --> 00:12:09,029 line:0
To allow us to group
our related functions together


204
00:12:09,096 --> 00:12:11,565 line:0
and pass them to the GPU,


205
00:12:11,632 --> 00:12:15,335 line:0
we create visible function tables
using the Metal API.


206
00:12:16,236 --> 00:12:21,208 line:0
Visible function tables are then an object
that we can pass to our Metal shader code.


207
00:12:23,143 --> 00:12:26,079 line:0
Before we start,
let's add some using declarations


208
00:12:26,146 --> 00:12:30,684 line:0
to define our function pointer types to
avoid making our code examples too wordy.


209
00:12:31,652 --> 00:12:34,955 line:0
Visible function tables can be specified
as kernel parameters,


210
00:12:35,022 --> 00:12:37,224 line:0
and they use buffer binding points.


211
00:12:37,291 --> 00:12:39,593 line:0
We can also pass them in argument buffers.


212
00:12:40,928 --> 00:12:44,898 line:0
Then, in our shaders,
we access our functions by index.


213
00:12:44,965 --> 00:12:48,802 line:0
We can take a pointer to the function
or call it directly from the table.


214
00:12:50,170 --> 00:12:53,707 line:0
On the CPU,
we allocate the visible function tables


215
00:12:53,774 --> 00:12:55,676 line:0
from the ComputePipelineState


216
00:12:55,742 --> 00:12:58,579 line:0
based on the number of function entries
we want in the table.


217
00:12:59,646 --> 00:13:02,716 line:0
We then populate the table
with handles to the functions


218
00:13:02,783 --> 00:13:05,485 line:0
that we specified
when creating the pipeline state.


219
00:13:06,987 --> 00:13:09,923 line:0
Finally, when we come to use the table,


220
00:13:09,990 --> 00:13:14,027 line:0
we set it on our computeCommandEncoder
or argumentEncoder as required.


221
00:13:14,728 --> 00:13:18,265 line:0
Don't forget to call useResource
if using an argumentEncoder.


222
00:13:18,765 --> 00:13:21,602 line:-2
To ensure that using
incrementally compiled pipelines


223
00:13:21,668 --> 00:13:23,637 line:-1
is as low-cost as possible,


224
00:13:23,704 --> 00:13:27,074 line:-2
we ensure that you can reuse
the visible function tables


225
00:13:27,140 --> 00:13:28,842 line:-1
from the ancestor pipelines.


226
00:13:29,576 --> 00:13:32,713 line:-2
The handles that are already in the table
are still valid,


227
00:13:33,614 --> 00:13:36,917 line:-2
and you just need to add
the new function handles to the table.


228
00:13:36,984 --> 00:13:40,320 line:-2
You do not need to create and build
an entirely new table.


229
00:13:40,787 --> 00:13:42,856 line:-1
And finally, you just need to make sure


230
00:13:42,923 --> 00:13:47,227 line:-2
that you do not access the newly added
function handles from older pipelines.


231
00:13:48,195 --> 00:13:49,463 line:-1
Last but not least today,


232
00:13:49,530 --> 00:13:51,698 line:-2
I want to discuss
the performance considerations


233
00:13:51,765 --> 00:13:54,101 line:-2
of using function pointers
in your application.


234
00:13:54,968 --> 00:13:57,771 line:-2
There's three main areas
we will cover in performance.


235
00:13:58,572 --> 00:14:01,608 line:-2
Let's start with function groups
for optimization.


236
00:14:02,509 --> 00:14:04,611 line:-1
Going back to our earlier diagram,


237
00:14:04,678 --> 00:14:08,815 line:-2
we could already see that we had groups
of functions for specific purposes.


238
00:14:08,882 --> 00:14:12,386 line:-2
However, pipeline creation is unaware
of these relationships.


239
00:14:13,587 --> 00:14:17,391 line:-2
We can group the functions
based upon their use in the shader.


240
00:14:17,457 --> 00:14:20,594 line:-2
We know which functions
we will be using for lighting


241
00:14:20,661 --> 00:14:22,429 line:-1
and which we will use for materials.


242
00:14:23,864 --> 00:14:27,100 line:-2
To express the grouping of functions
in our shading function,


243
00:14:27,167 --> 00:14:30,938 line:-2
we've updated it to include
function groups for the calls we make.


244
00:14:31,605 --> 00:14:34,842 line:-2
In Metal,
function groups let us tell the compiler


245
00:14:34,908 --> 00:14:36,677 line:-1
where the functions will be used.


246
00:14:37,644 --> 00:14:41,415 line:-2
In our shader code,
we apply function groups attributes


247
00:14:41,481 --> 00:14:43,984 line:-1
to the lines where we invoke our functions


248
00:14:44,051 --> 00:14:46,687 line:-2
to give names
to the group of possible functions


249
00:14:46,753 --> 00:14:48,589 line:-1
that are callable from that location.


250
00:14:49,623 --> 00:14:53,660 line:-2
Then, when configuring
our compute pipeline descriptor,


251
00:14:53,727 --> 00:14:56,163 line:-1
we specify the groups in a dictionary


252
00:14:56,230 --> 00:14:59,399 line:-2
with the setter functions
that may be called for each group.


253
00:15:00,200 --> 00:15:03,971 line:-2
This gives the compiler
the maximum amount of information possible


254
00:15:04,037 --> 00:15:07,474 line:-2
and can help with the optimization
when generating the pipeline.


255
00:15:08,442 --> 00:15:11,678 line:-2
On top of the specialization
that the compiler performs


256
00:15:11,745 --> 00:15:14,014 line:-1
for functions in our functions array,


257
00:15:14,081 --> 00:15:17,751 line:-2
the compiler is able to take advantage
of any commonalities


258
00:15:17,818 --> 00:15:20,153 line:-1
between the setter functions in each group


259
00:15:20,220 --> 00:15:24,258 line:-2
and then apply that to the call site
marked with the function groups attribute.


260
00:15:25,259 --> 00:15:30,364 line:-2
All this new flexibility also means that
you can now implement recursive functions.


261
00:15:31,398 --> 00:15:35,602 line:-2
If we go back to where we started
with the ray tracing process flow,


262
00:15:35,669 --> 00:15:39,173 line:-2
this model of ray tracing,
where we consider multiple bounces,


263
00:15:39,239 --> 00:15:42,309 line:-2
can be implemented in either an iterative
or recursive manner.


264
00:15:43,510 --> 00:15:47,114 line:-2
If we focus on the relationship
between intersection and shading,


265
00:15:47,181 --> 00:15:48,982 line:-1
we can follow this call graph.


266
00:15:50,517 --> 00:15:52,486 line:-1
With our recursive path tracer,


267
00:15:52,553 --> 00:15:55,656 line:-2
after an intersection,
we shade the intersection point.


268
00:15:56,623 --> 00:16:00,093 line:-2
In this case,
we hit our new wood material function.


269
00:16:00,794 --> 00:16:03,697 line:-2
This wood material includes
a reflection component,


270
00:16:03,764 --> 00:16:07,568 line:-2
and so it intersects another ray with
the scene and shades the intersection.


271
00:16:08,635 --> 00:16:11,905 line:-2
Again, we intersect a surface
covered in the wood material.


272
00:16:12,606 --> 00:16:15,542 line:-2
This then reflects
and intersects the scene again.


273
00:16:16,376 --> 00:16:18,712 line:-1
We hit the wood material one more time.


274
00:16:19,246 --> 00:16:23,350 line:-2
We could continue, but typically you would
limit the depth in a recursive ray tracer


275
00:16:23,417 --> 00:16:26,253 line:-2
for both performance
and to avoid overflowing the stack,


276
00:16:26,320 --> 00:16:27,721 line:-1
so we will stop here.


277
00:16:28,355 --> 00:16:30,090 line:0
To support the varying stack usage


278
00:16:30,157 --> 00:16:33,493 line:0
for compute kernels
that call chains of visible functions,


279
00:16:33,560 --> 00:16:36,463 line:0
we expose the maxCallStackDepth property


280
00:16:36,530 --> 00:16:38,365 line:0
on the compute pipeline descriptor


281
00:16:38,432 --> 00:16:43,103 line:0
so that we can specify how deep we expect
to call functions from our kernel.


282
00:16:43,704 --> 00:16:45,072 line:0
The default is 1


283
00:16:45,138 --> 00:16:49,009 line:0
so that the typical use cases of visible
functions and intersection functions


284
00:16:49,076 --> 00:16:50,377 line:0
work out of the box.


285
00:16:50,978 --> 00:16:55,015 line:0
This value is expected to be used
for any chains of visible function calls,


286
00:16:55,082 --> 00:16:57,651 line:0
but in the case of ray tracing,
this code could have been written


287
00:16:57,718 --> 00:17:00,787 line:0
in an iterative manner
to reduce stack usage.


288
00:17:01,488 --> 00:17:04,558 line:-2
The last performance consideration
I want to discuss today


289
00:17:04,625 --> 00:17:07,861 line:-2
was the impact of divergence
when we use function pointers.


290
00:17:08,395 --> 00:17:10,597 line:0
Before diving into function pointers,
though,


291
00:17:10,664 --> 00:17:14,101 line:0
I should highlight that last year's
"Ray Tracing with Metal" presentation


292
00:17:14,167 --> 00:17:18,238 line:0
covered high-level methods to handle
the divergence inherent in ray tracing


293
00:17:18,305 --> 00:17:21,008 line:0
when subsequent bounces
become less coherent.


294
00:17:21,508 --> 00:17:25,345 line:-2
This included ray coherency
with block linear layout,


295
00:17:25,412 --> 00:17:27,580 line:-1
ray compaction for active rays


296
00:17:27,647 --> 00:17:31,018 line:-2
and interleaved tiling
for load balancing across GPUs.


297
00:17:31,685 --> 00:17:34,988 line:-2
I recommend reviewing that presentation
for a great review of ideas


298
00:17:35,055 --> 00:17:36,757 line:-1
of ray tracing optimizations.


299
00:17:37,958 --> 00:17:39,660 line:-1
For function pointers, however,


300
00:17:39,726 --> 00:17:42,329 line:-2
we need to consider divergence
at the thread level.


301
00:17:43,063 --> 00:17:45,299 line:-1
When we dispatch our threadgroups,


302
00:17:45,365 --> 00:17:48,402 line:-2
we know that they execute
in smaller groups of threads,


303
00:17:48,468 --> 00:17:50,270 line:-1
defined as a SIMD group.


304
00:17:50,337 --> 00:17:53,006 line:-2
In this example,
we have eight SIMD groups.


305
00:17:54,374 --> 00:17:56,543 line:-1
The threads in the SIMD group perform best


306
00:17:56,610 --> 00:17:59,680 line:-2
when they execute the same instruction
at the same time.


307
00:18:01,181 --> 00:18:04,551 line:-2
Divergence occurs
when the next instruction to execute


308
00:18:04,618 --> 00:18:07,221 line:-2
is different
for the threads of the SIMD group,


309
00:18:07,287 --> 00:18:09,823 line:-2
typically, when they reach a branch
in our shader code.


310
00:18:10,624 --> 00:18:13,227 line:-2
This is normally handled
by letting a subset of the threads


311
00:18:13,293 --> 00:18:17,030 line:-2
execute their instruction
while the other threads are left unused.


312
00:18:17,764 --> 00:18:19,166 line:-1
We have the best performance


313
00:18:19,233 --> 00:18:22,769 line:-2
when all threads are actively executing
useful instructions.


314
00:18:24,571 --> 00:18:28,375 line:-2
Function pointers are another case
that can lead to divergence.


315
00:18:28,442 --> 00:18:31,144 line:-2
When we invoke a function
via a function pointer,


316
00:18:31,211 --> 00:18:35,015 line:-2
we need to consider how divergent
the setter function pointers will be.


317
00:18:35,649 --> 00:18:38,252 line:-1
In the worst case, within a SIMD group,


318
00:18:38,318 --> 00:18:40,521 line:-2
each thread
could be calling a different function,


319
00:18:40,587 --> 00:18:42,956 line:-2
and the execution time
will be the time to execute


320
00:18:43,023 --> 00:18:46,293 line:-2
each of the required functions
one after the other.


321
00:18:47,494 --> 00:18:49,663 line:-1
But if we consider the entire threadgroup,


322
00:18:49,730 --> 00:18:52,332 line:-2
we may have enough work
to create full SIMD groups.


323
00:18:54,301 --> 00:18:56,203 line:-1
To handle our divergence,


324
00:18:56,270 --> 00:19:00,974 line:-2
we are going to reorder the function calls
to introduce coherence to our SIMD groups.


325
00:19:01,575 --> 00:19:03,877 line:-2
This means that the function call
for one thread


326
00:19:03,944 --> 00:19:07,114 line:-2
will likely be executed
by another thread in the threadgroup.


327
00:19:08,549 --> 00:19:12,886 line:-2
In terms of code, we will start
by writing all the function parameters


328
00:19:12,953 --> 00:19:14,688 line:-1
and the index of the thread


329
00:19:14,755 --> 00:19:17,124 line:-2
and the function to call
to threadgroup memory.


330
00:19:17,724 --> 00:19:21,962 line:-2
We will then use our favorite sort
to sort a function indices.


331
00:19:23,297 --> 00:19:26,466 line:-2
Next, we invoke the functions
in their sorted order.


332
00:19:27,401 --> 00:19:30,170 line:0
The results of the functions
go back to threadgroup memory,


333
00:19:30,771 --> 00:19:33,407 line:0
and then each thread
can read its result from there.


334
00:19:33,874 --> 00:19:36,643 line:-2
We can also implement a similar version
using device memory


335
00:19:36,710 --> 00:19:38,512 line:-1
for our parameters and results.


336
00:19:39,179 --> 00:19:41,315 line:-1
In the case of calling complex functions,


337
00:19:41,381 --> 00:19:43,851 line:-2
this should reduce the overhead
of divergence.


338
00:19:44,551 --> 00:19:47,821 line:-2
There's a lot of great things you can do
with function pointers in Metal.


339
00:19:48,388 --> 00:19:51,925 line:-2
Today we've covered the creation and use
of visible functions


340
00:19:51,992 --> 00:19:54,528 line:-2
and how we add them
to visible function tables


341
00:19:54,595 --> 00:19:57,664 line:-2
to provide functions
that we can call from our compute kernels.


342
00:19:58,765 --> 00:20:00,767 line:-2
We've discussed
the different compilation models


343
00:20:00,834 --> 00:20:03,270 line:-2
that allow you to choose
how you balance pipeline size


344
00:20:03,337 --> 00:20:05,973 line:-2
and creation time
against runtime performance


345
00:20:06,039 --> 00:20:09,042 line:-2
and needing to be able
to dynamically add functions.


346
00:20:09,576 --> 00:20:12,446 line:-2
And we finished
on some performance considerations


347
00:20:12,513 --> 00:20:15,115 line:-2
for using function pointers
in your application.


348
00:20:15,549 --> 00:20:17,818 line:-2
I've really enjoyed
working on function pointers this year,


349
00:20:17,885 --> 00:20:20,053 line:-2
and I'm really glad
to be able to share it with you.


350
00:20:20,120 --> 00:20:22,556 line:-1
I hope you've had a great WWDC.

