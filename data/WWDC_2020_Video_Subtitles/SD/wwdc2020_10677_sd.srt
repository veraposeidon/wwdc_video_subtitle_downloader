1
00:00:03,836 --> 00:00:06,840 line:-1
Hello and welcome to WWDC.


2
00:00:07,774 --> 00:00:11,512 line:0
Hi, I am Dhruv.
I am a GPU software engineer at Apple,


3
00:00:11,578 --> 00:00:15,082 line:0
and I am here to talk about implementing
customized machine learning operations


4
00:00:15,148 --> 00:00:17,618 line:0
using the new
Metal Performance Shaders Graph.


5
00:00:17,684 --> 00:00:18,752 line:0
Let us begin.


6
00:00:19,253 --> 00:00:21,922 line:-2
MPS is a library of Metal based
high performance


7
00:00:21,989 --> 00:00:25,726 line:-2
GPU accelerated primitives
for varied fields like image processing,


8
00:00:25,792 --> 00:00:28,695 line:-2
linear algebra,
ray tracing and machine learning.


9
00:00:29,863 --> 00:00:33,133 line:-2
MPS team optimizes Metal kernels
to give the best performance


10
00:00:33,200 --> 00:00:35,936 line:-2
on each hardware
across Apple's various platforms.


11
00:00:38,672 --> 00:00:41,575 line:-2
We have an exciting set of new features
to discuss today.


12
00:00:42,476 --> 00:00:45,913 line:-2
We'll talk about performance improvements
made across MPS,


13
00:00:46,480 --> 00:00:49,883 line:-2
discuss how to leverage
the full 32-bit floating point support


14
00:00:49,950 --> 00:00:51,418 line:-1
in machine learning...


15
00:00:52,519 --> 00:00:55,656 line:-1
reveal the new MPSNDArray primitive,


16
00:00:55,722 --> 00:00:59,326 line:0
and finally, we will introduce
the new Metal Performance Shaders Graph.


17
00:01:00,894 --> 00:01:03,664 line:-2
Allow me to go over
some of the amazing improvements


18
00:01:03,730 --> 00:01:06,733 line:-1
we added to image processing in MPS.


19
00:01:07,534 --> 00:01:10,437 line:-2
We tuned and improved
our distance transform filter.


20
00:01:10,504 --> 00:01:13,974 line:-2
It made for 15 times faster features
in Final Cut Pro.


21
00:01:14,875 --> 00:01:17,978 line:-2
MPS also has
a new edge detection primitive


22
00:01:18,045 --> 00:01:20,247 line:-1
using the EDLines algorithm.


23
00:01:20,314 --> 00:01:23,617 line:-2
It improved the Measure app
and made it ten times faster,


24
00:01:23,684 --> 00:01:26,920 line:-2
which enables it to do
even better line segment detection


25
00:01:26,987 --> 00:01:28,522 line:-1
in higher resolution.


26
00:01:30,591 --> 00:01:33,861 line:-2
We have also expanded support
for our CNN primitives.


27
00:01:35,863 --> 00:01:37,998 line:-1
We now have full FP32 support


28
00:01:38,065 --> 00:01:40,634 line:-2
for convolution
and fully connected primitives,


29
00:01:40,701 --> 00:01:43,737 line:-2
so developers do not need to recalculate
their hyper-parameters


30
00:01:43,804 --> 00:01:46,607 line:-2
or refactor their code
to get the same accuracy.


31
00:01:47,741 --> 00:01:51,178 line:-2
To enable this, implement
the kernelWeightsDataType method


32
00:01:51,245 --> 00:01:54,381 line:-2
on your data source provider
and set it to float32.


33
00:01:56,683 --> 00:01:58,685 line:0
Please refer to our previous years' talks


34
00:01:58,752 --> 00:02:02,189 line:0
for more details on how to implement
a convolution data source provider.


35
00:02:05,125 --> 00:02:08,395 line:-2
There is a new MPS primitive
called MPSNDArray.


36
00:02:09,229 --> 00:02:14,168 line:-2
MPSNDArray and corresponding operations
can support up to 16 dimensions,


37
00:02:14,234 --> 00:02:16,370 line:-2
which is more than enough
for machine learning


38
00:02:16,436 --> 00:02:18,372 line:-1
and various other scientific domains.


39
00:02:19,206 --> 00:02:21,275 line:-1
Also, there are virtually no restrictions


40
00:02:21,341 --> 00:02:24,077 line:-2
on the dimension sizes
in this new primitive


41
00:02:24,144 --> 00:02:26,380 line:-1
as long as you can fit them in memory.


42
00:02:29,516 --> 00:02:31,084 line:-1
To create an MPSNDArray,


43
00:02:31,151 --> 00:02:34,688 line:-2
first use an MPSNDArrayDescriptor
to specify a shape


44
00:02:34,755 --> 00:02:36,557 line:-1
and a data type for the elements.


45
00:02:37,057 --> 00:02:40,160 line:-2
Then pass it to the initializer,
along with the Metal device


46
00:02:40,227 --> 00:02:42,829 line:-2
on which you wish to allocate
the MPSNDArray.


47
00:02:46,667 --> 00:02:48,435 line:0
MPSNDArray provides converters


48
00:02:48,502 --> 00:02:53,106 line:0
to and from our already existing
MTLTexture based MPSImageBatch types.


49
00:02:54,341 --> 00:02:58,111 line:0
And it can even import and export data
using your Metal buffers.


50
00:03:00,948 --> 00:03:03,584 line:-2
Now let's get to the meat
of what we would be talking about:


51
00:03:03,650 --> 00:03:06,486 line:-2
the new Metal Performance Shaders
Graph framework.


52
00:03:08,422 --> 00:03:11,925 line:-2
MPSGraph sits on top
of the MPS framework in the stack.


53
00:03:12,793 --> 00:03:15,195 line:-2
We use it to extend
Metal's compute functionality


54
00:03:15,262 --> 00:03:16,930 line:-1
to multidimensional tensors.


55
00:03:18,298 --> 00:03:21,301 line:-2
The new MPSGraph framework
will be supported on macOS,


56
00:03:21,368 --> 00:03:25,572 line:-2
iOS, iPadOS and tvOS,
same as the MPS framework.


57
00:03:26,807 --> 00:03:29,042 line:-2
You can include the new framework
in your project


58
00:03:29,109 --> 00:03:31,078 line:-1
from the "Build Phases" tab in Xcode.


59
00:03:31,144 --> 00:03:33,680 line:-2
It is right next to
the Metal Performance Shaders framework.


60
00:03:37,017 --> 00:03:39,019 line:-1
We have a lot to cover.


61
00:03:39,086 --> 00:03:41,655 line:-1
We will introduce the new MPSGraph,


62
00:03:42,589 --> 00:03:46,894 line:-2
walk through the different APIs available
to write custom compute functions,


63
00:03:47,628 --> 00:03:51,865 line:0
and finally, look at writing and executing
machine learning training graphs.


64
00:03:53,967 --> 00:03:57,037 line:0
Let's start looking at the basics
of the MPSGraph.


65
00:03:59,106 --> 00:04:02,543 line:-2
MPSGraph represents
a DAG of operations and tensors.


66
00:04:04,945 --> 00:04:09,349 line:-2
The operations are nodes of the graph
representing a unit of computation.


67
00:04:09,416 --> 00:04:12,286 line:-2
Here we have an example
of three basic math operations:


68
00:04:12,352 --> 00:04:14,354 line:-1
multiply, add, subtract.


69
00:04:15,856 --> 00:04:17,057 line:-1
Along with operations,


70
00:04:17,124 --> 00:04:21,327 line:-2
tensors are the edges of the graph
defining the dataflow in the graph.


71
00:04:21,394 --> 00:04:22,829 line:-1
We can see in our example


72
00:04:22,896 --> 00:04:25,832 line:-2
the tensors are flowing through
our basic math operations.


73
00:04:28,836 --> 00:04:33,173 line:-2
This symbolic representation allows us
to abstract away numerous data primitives


74
00:04:33,240 --> 00:04:36,944 line:-2
and provide a unified interface
to get the best performance on the GPU.


75
00:04:38,445 --> 00:04:42,549 line:-2
The MPSGraph object maintains ownership
for all the tensors and operations


76
00:04:42,616 --> 00:04:44,685 line:-1
created using methods on the graph.


77
00:04:47,487 --> 00:04:51,491 line:-2
MPSGraphTensors represent
a symbolic abstraction of data.


78
00:04:51,558 --> 00:04:55,596 line:-1
It consists of a shape, data type,


79
00:04:55,662 --> 00:04:59,132 line:-2
and a reference to the operation
responsible for creating the tensor.


80
00:05:02,469 --> 00:05:05,272 line:-2
Here we can see
how to create a constantTensor


81
00:05:05,339 --> 00:05:08,008 line:-2
simply by calling the constant method
on the graph.


82
00:05:10,911 --> 00:05:14,581 line:-2
Operations in the graph connect with
each other via three kinds of edges...


83
00:05:16,416 --> 00:05:18,685 line:-1
input tensors, which represent tensors


84
00:05:18,752 --> 00:05:20,888 line:-2
that act as data inputs
to the operation...


85
00:05:22,623 --> 00:05:25,726 line:-2
output tensors, which are created
by the operation itself...


86
00:05:26,860 --> 00:05:30,464 line:-2
and finally, a special kind of edge
called control dependency.


87
00:05:31,798 --> 00:05:34,368 line:-2
These are a set of operations
the graph would execute


88
00:05:34,434 --> 00:05:36,236 line:-1
before the current operation


89
00:05:36,303 --> 00:05:40,174 line:-2
even if the operation itself does not
depend on these set of operations.


90
00:05:42,442 --> 00:05:44,278 line:-1
Just like the constant operation,


91
00:05:44,344 --> 00:05:48,215 line:-2
operations can be created by calling
simple intuitive methods on the graph.


92
00:05:48,916 --> 00:05:51,685 line:-2
Here we see how to add two tensors
in the graph.


93
00:05:53,954 --> 00:05:56,423 line:-2
MPSGraph provides
a numerous set of operations


94
00:05:56,490 --> 00:05:58,625 line:-1
to manipulate tensors in the graph.


95
00:05:58,692 --> 00:06:01,128 line:-2
For example,
you could reshape a one-dimension tensor


96
00:06:01,195 --> 00:06:02,896 line:-1
into a two-dimension tensor.


97
00:06:04,498 --> 00:06:07,734 line:-2
You can slice apart that tensor
and take a small piece of it.


98
00:06:09,837 --> 00:06:13,106 line:-2
You can concatenate that piece
back into the original tensor


99
00:06:13,173 --> 00:06:14,942 line:-1
to create an even bigger one.


100
00:06:16,710 --> 00:06:19,379 line:-2
You can transpose tensors
in any dimension.


101
00:06:21,849 --> 00:06:25,252 line:-2
And finally,
you can even create a zero-length slice.


102
00:06:25,319 --> 00:06:28,055 line:-2
Zero-sized tensors
are supported in MPSGraph.


103
00:06:28,722 --> 00:06:30,624 line:-1
This enables some dynamic use cases


104
00:06:30,691 --> 00:06:34,328 line:-2
like recurrent neural network operations
on variable length sequences.


105
00:06:35,896 --> 00:06:38,966 line:-2
We support a plethora of operations
on the MPSGraph,


106
00:06:39,600 --> 00:06:42,569 line:-2
from multiple variants of convolutions
and reductions


107
00:06:42,636 --> 00:06:46,206 line:-2
to all the basic math operations
you may need in your compute graphs.


108
00:06:48,175 --> 00:06:50,444 line:-2
Let's start putting
some of these operations together


109
00:06:50,511 --> 00:06:53,380 line:-2
to create and execute
a custom compute function


110
00:06:53,447 --> 00:06:55,415 line:-1
with our very first MPSGraph.


111
00:06:56,650 --> 00:06:57,918 line:-1
In recent years,


112
00:06:57,985 --> 00:07:00,120 line:-2
machine learning research
has found novel ways


113
00:07:00,187 --> 00:07:02,189 line:-1
to handle natural language processing.


114
00:07:03,090 --> 00:07:07,461 line:-2
One such innovation was a new
kind of activation function used in BERT.


115
00:07:08,762 --> 00:07:11,498 line:-2
This activation
is called Gaussian Error Linear Unit,


116
00:07:11,565 --> 00:07:13,233 line:-1
commonly known as GeLU.


117
00:07:14,268 --> 00:07:17,804 line:-2
For our example, we will try to implement
a custom GeLU function


118
00:07:17,871 --> 00:07:20,440 line:-1
on the GPU using MPSGraph.


119
00:07:22,809 --> 00:07:25,145 line:-1
This is a simple three-step process.


120
00:07:25,212 --> 00:07:29,416 line:-2
We define the inputs to the graph,
write a set of operations to perform,


121
00:07:29,483 --> 00:07:32,052 line:-2
and finally,
execute the graph on provided data.


122
00:07:33,887 --> 00:07:36,290 line:-2
Let's start
by defining the inputs to the graph.


123
00:07:37,925 --> 00:07:41,195 line:-2
Our GeLU activation function
consists of a single input.


124
00:07:42,529 --> 00:07:46,200 line:-2
Input tensors are created
using placeholder operations in the graph,


125
00:07:46,733 --> 00:07:50,737 line:-2
which, as the name suggests,
act as placeholders during run time.


126
00:07:50,804 --> 00:07:53,674 line:-2
They are replaced
by caller provided input data.


127
00:07:55,509 --> 00:07:59,179 line:-2
We show here the API call
to create an example placeholder


128
00:07:59,246 --> 00:08:02,249 line:-2
of the type float32
with three columns and two rows.


129
00:08:04,518 --> 00:08:07,621 line:-2
Users might have varying sizes of inputs
going into the graph


130
00:08:07,688 --> 00:08:09,590 line:-1
known only at run time.


131
00:08:10,023 --> 00:08:12,292 line:-2
For example,
in the machine learning domain,


132
00:08:12,359 --> 00:08:15,095 line:-2
users frequently pass in
variable length sequences


133
00:08:15,162 --> 00:08:17,764 line:-1
or differing batch sizes of input images.


134
00:08:19,333 --> 00:08:23,971 line:-2
For these scenarios, MPSGraph supports
dynamic sizes in placeholders.


135
00:08:24,037 --> 00:08:27,608 line:-2
Simply specify
the size of the dimension as -1,


136
00:08:27,674 --> 00:08:32,645 line:-2
and the graph will evaluate shapes from
the corresponding fed inputs at run time.


137
00:08:35,249 --> 00:08:39,586 line:-2
If even the number of dimensions
of the incoming input is unknown,


138
00:08:39,653 --> 00:08:42,523 line:-2
simply pass a nil
to the placeholder shape.


139
00:08:42,589 --> 00:08:45,058 line:-1
MPSGraph fully supports type inference


140
00:08:45,125 --> 00:08:48,395 line:-2
and will propagate the shapes at run time
all through the graph.


141
00:08:50,364 --> 00:08:53,934 line:-2
Now that we have defined the inputs
to the graph, we can go to step two


142
00:08:54,468 --> 00:08:58,005 line:-2
and write out our custom compute function
in the graph.


143
00:08:59,907 --> 00:09:02,209 line:-2
Usually,
we expect to use the GeLU activation


144
00:09:02,276 --> 00:09:04,811 line:-1
at various points in our neural network.


145
00:09:04,878 --> 00:09:08,448 line:-2
So, for modularity, we will define
a helper function on our graph


146
00:09:08,515 --> 00:09:10,284 line:-1
which takes a tensor as an input.


147
00:09:11,051 --> 00:09:12,786 line:-1
Let's add the necessary operations


148
00:09:12,853 --> 00:09:15,989 line:-2
to apply the activation
on the given input tensor.


149
00:09:18,292 --> 00:09:21,895 line:-2
First, let's define some of the constants
used in our GeLU neuron.


150
00:09:23,397 --> 00:09:25,732 line:-2
We simply call the constant method
on the graph


151
00:09:25,799 --> 00:09:29,069 line:-2
with a scalar passed in
and set it to float32 dataType.


152
00:09:30,571 --> 00:09:34,074 line:-2
Next up, we have a unary math operation:
namely squareRoot.


153
00:09:35,809 --> 00:09:39,112 line:-2
MPSGraph provides
basic unary math operations.


154
00:09:39,179 --> 00:09:41,481 line:-2
We just call the squareRoot method
on the graph


155
00:09:41,548 --> 00:09:43,851 line:-2
with the half constant tensor
as the input.


156
00:09:45,752 --> 00:09:48,288 line:-2
Now that we have
our constants and inputs prepped,


157
00:09:48,355 --> 00:09:51,325 line:-2
we start doing some compute
with a couple of multiplies.


158
00:09:53,327 --> 00:09:55,996 line:-2
These operations
implicitly support broadcasting,


159
00:09:56,063 --> 00:09:58,799 line:-2
so the result tensor shape
would be automatically inferred


160
00:09:58,866 --> 00:10:01,735 line:-2
to be the same shape
as the input to the neuron.


161
00:10:03,070 --> 00:10:04,638 line:-1
We pass the two input tensors


162
00:10:04,705 --> 00:10:07,875 line:-2
into the multiplication method
on the graph to do just that.


163
00:10:09,576 --> 00:10:12,513 line:-2
This little unary method
forms the heart of the GeLU neuron,


164
00:10:12,579 --> 00:10:14,114 line:-1
known as error function.


165
00:10:16,717 --> 00:10:20,053 line:-2
Once more, we simply pass in
the input to the unary operation


166
00:10:20,120 --> 00:10:22,823 line:-2
and get back the output tensor
on the left-hand side,


167
00:10:22,890 --> 00:10:24,491 line:-1
ready for further computation.


168
00:10:26,426 --> 00:10:30,264 line:-2
Finally, we finish off the activation
with an add and a multiply.


169
00:10:32,966 --> 00:10:35,836 line:-2
Just as before,
we create the binary math operations,


170
00:10:35,903 --> 00:10:39,640 line:-2
and the output of the multiplication
is returned from our GeLU function.


171
00:10:42,743 --> 00:10:46,446 line:-2
We have successfully and quite easily
constructed a graph of operations


172
00:10:46,513 --> 00:10:48,315 line:-1
representing our GeLU neuron.


173
00:10:50,083 --> 00:10:52,986 line:-2
We can finish off
with the third and final step,


174
00:10:53,053 --> 00:10:55,455 line:-1
which is seeing how we execute this graph.


175
00:10:57,858 --> 00:11:00,227 line:-1
Running the graph is very easy.


176
00:11:00,294 --> 00:11:02,529 line:-1
Firstly, we pass the dictionary of feeds


177
00:11:02,596 --> 00:11:04,665 line:-2
which map to
the placeholders in the graph.


178
00:11:05,999 --> 00:11:08,502 line:-2
Next,
we specify the list of target tensors


179
00:11:08,569 --> 00:11:12,272 line:-2
we want the graph to evaluate
and return the results for.


180
00:11:12,339 --> 00:11:15,709 line:-2
These results are returned in a dictionary
on the left-hand side.


181
00:11:17,077 --> 00:11:20,647 line:-2
Finally, the users can optionally pass
a list of target operations


182
00:11:20,714 --> 00:11:22,749 line:-1
which the graph guarantees to execute.


183
00:11:25,219 --> 00:11:29,089 line:-2
As we saw, at execution time,
developers can feed placeholders


184
00:11:29,156 --> 00:11:31,959 line:-1
by passing MPSGraphTensorData objects,


185
00:11:32,492 --> 00:11:34,461 line:-1
which in turn returns a set of outputs


186
00:11:34,528 --> 00:11:37,264 line:-2
using the same
MPSGraphTensorData object.


187
00:11:38,866 --> 00:11:42,936 line:0
MPSGraphTensorData helps abstract
over the numerous data primitives


188
00:11:43,003 --> 00:11:45,072 line:0
available in the Metal ecosystem.


189
00:11:45,138 --> 00:11:47,307 line:0
You can initialize it with a Metal buffer.


190
00:11:48,675 --> 00:11:52,145 line:0
You can create a four-dimensional
tensor data using an MPSImageBatch.


191
00:11:53,747 --> 00:11:57,251 line:0
We abstract over MPSVectors
and MPSMatrices as well.


192
00:11:58,018 --> 00:12:00,687 line:0
And finally,
the new MPSNDArray primitive


193
00:12:00,754 --> 00:12:03,757 line:0
can also be used to initialize
the MPSGraphTensorData.


194
00:12:05,692 --> 00:12:07,127 line:-1
So, we put it all together.


195
00:12:08,462 --> 00:12:10,731 line:-1
We start by creating an MPSGraph.


196
00:12:11,298 --> 00:12:14,201 line:-2
We define the inputs to the graph
with placeholders.


197
00:12:14,868 --> 00:12:16,703 line:-1
We call our GeLU helper function


198
00:12:16,770 --> 00:12:19,406 line:-2
to write out
the necessary operations in the graph.


199
00:12:20,774 --> 00:12:25,179 line:0
Finally, we execute the graph
by passing the input data as feeds


200
00:12:25,245 --> 00:12:27,581 line:0
requesting the GeLU tensor as a target.


201
00:12:28,115 --> 00:12:31,585 line:-2
And that's all that is needed
to execute a custom compute function


202
00:12:31,652 --> 00:12:34,888 line:-2
on any multidimensional tensor
on the GPU.


203
00:12:36,590 --> 00:12:40,661 line:-2
We just witnessed how you can use
basic math operations in the MPSGraph


204
00:12:40,727 --> 00:12:42,930 line:-1
to create a custom compute function.


205
00:12:43,864 --> 00:12:47,467 line:-2
Usually, for every operation,
output would be written out to memory.


206
00:12:49,303 --> 00:12:52,706 line:-2
The next operation would read
from this same global memory,


207
00:12:53,240 --> 00:12:57,277 line:-2
and this would end up causing unneeded
memory traffic and performance issues,


208
00:12:57,344 --> 00:12:59,112 line:-1
especially on the GPU.


209
00:13:00,647 --> 00:13:04,551 line:-2
However, MPSGraph compiler
applies a special optimization


210
00:13:04,618 --> 00:13:07,588 line:-2
to automatically fuse such operations
for the users.


211
00:13:07,654 --> 00:13:09,256 line:-1
We call this stitching.


212
00:13:10,591 --> 00:13:14,394 line:-2
The MPSGraph compiler
recognizes all adjacent operations


213
00:13:14,461 --> 00:13:16,663 line:-1
and passes it to the Metal compiler.


214
00:13:18,899 --> 00:13:21,435 line:-2
The Metal compiler
fuses the operations together


215
00:13:21,502 --> 00:13:24,137 line:-1
to create a single optimized Metal shader.


216
00:13:24,204 --> 00:13:27,441 line:-2
This leads to no memory overhead
and improves performance.


217
00:13:29,276 --> 00:13:32,145 line:-2
MPSGraph compiler
goes even one step further.


218
00:13:33,080 --> 00:13:36,450 line:-2
For any math operations
around hand tuned MPS kernels,


219
00:13:36,517 --> 00:13:39,853 line:-2
like convolution, matrix multiplication,
or reduction,


220
00:13:40,587 --> 00:13:44,825 line:-2
MPSGraph recognizes adjacent stitchable
operations to create a region...


221
00:13:47,060 --> 00:13:51,164 line:-2
and once more passes the region
of operations to the Metal compiler


222
00:13:51,231 --> 00:13:54,801 line:-2
for them to be fused
directly into the hand tuned MPS kernel,


223
00:13:54,868 --> 00:13:59,039 line:-2
giving the best of hand tuned
MPS optimizations for each hardware


224
00:13:59,106 --> 00:14:02,009 line:-2
and the memory savings
from automatic fusion of operations


225
00:14:02,075 --> 00:14:03,544 line:-1
by the Metal compiler.


226
00:14:05,245 --> 00:14:09,850 line:-2
Using the stitching optimization makes
GeLU go almost ten to 50 times faster.


227
00:14:11,685 --> 00:14:14,421 line:-1
We even gain significant memory savings.


228
00:14:16,190 --> 00:14:19,092 line:-2
All this is done
always and automatically for you


229
00:14:19,159 --> 00:14:21,261 line:-1
without a single line of code needed.


230
00:14:23,163 --> 00:14:26,700 line:-2
One such custom compute function
is machine learning inference.


231
00:14:27,334 --> 00:14:30,470 line:-2
Inference is the process
of applying a network on an input


232
00:14:30,537 --> 00:14:32,206 line:-1
and producing an output.


233
00:14:34,141 --> 00:14:36,777 line:-2
The network is made up
of a collection of operations,


234
00:14:36,844 --> 00:14:40,047 line:-2
such as convolution
and neuron activation layers,


235
00:14:40,113 --> 00:14:44,751 line:-2
which, as we showed, can be expressed
with operations in MPSGraph.


236
00:14:45,919 --> 00:14:49,189 line:-2
These layers, in turn,
depend upon a set of trained parameters.


237
00:14:50,724 --> 00:14:53,260 line:-2
During inference,
these parameters are fixed.


238
00:14:53,327 --> 00:14:56,263 line:-2
Their values are determined
during the training phase.


239
00:14:56,330 --> 00:14:57,764 line:-1
Therefore, for inference,


240
00:14:57,831 --> 00:15:01,201 line:-2
we can use constants to represent
these parameters in our MPSGraph.


241
00:15:02,736 --> 00:15:05,906 line:-2
With support for these
wide variety of operations in MPSGraph,


242
00:15:05,973 --> 00:15:09,443 line:-2
we now support recurrent neural networks
in the graph as well.


243
00:15:09,510 --> 00:15:11,545 line:-1
I'd like to introduce my colleague, Chris.


244
00:15:11,612 --> 00:15:13,547 line:-1
He will show us an exciting demo


245
00:15:13,614 --> 00:15:16,216 line:-2
of a text generation inference network
in action.


246
00:15:17,985 --> 00:15:21,054 line:-2
Thanks, Dhruv.
I'm Chris. I'm a GPU software engineer,


247
00:15:21,121 --> 00:15:24,258 line:-2
and I am here to make your iPad Pro
write a Shakespearean play.


248
00:15:25,526 --> 00:15:28,896 line:-2
We do this using the Long Short Term
Memory based Text Generator model.


249
00:15:32,332 --> 00:15:34,601 line:-2
The generator loop works
on a single character input,


250
00:15:34,668 --> 00:15:35,903 line:-1
in this case the letter O,


251
00:15:35,969 --> 00:15:38,805 line:-2
which is the last letter
in our initialization string "Romeo."


252
00:15:39,640 --> 00:15:42,009 line:-2
We feed the character index
into the embedding layer,


253
00:15:42,075 --> 00:15:44,278 line:-1
which is a gather operation in MPSGraph.


254
00:15:46,180 --> 00:15:47,614 line:0
This produces a single vector,


255
00:15:47,681 --> 00:15:50,050 line:0
and we feed this rank-one tensor
to the LSTM layer,


256
00:15:50,117 --> 00:15:52,419 line:0
which has a constant set
of trained parameters.


257
00:15:54,188 --> 00:15:57,191 line:0
The result of the LSTM layer
is fed to the un-embedding layer,


258
00:15:57,257 --> 00:16:01,094 line:0
which can be implemented with a matrix
multiplication operation in MPSGraph...


259
00:16:02,429 --> 00:16:05,599 line:0
and the state of the LSTM layer
is updated for the next iteration.


260
00:16:07,301 --> 00:16:09,770 line:0
Then the results are multiplied
by the inverse temperature.


261
00:16:11,438 --> 00:16:15,242 line:0
MPSGraph automatically broadcasts
this scalar value to the vector length.


262
00:16:15,309 --> 00:16:17,644 line:0
The result is then fed
into the softmax layer,


263
00:16:17,711 --> 00:16:20,848 line:0
which gives us a probability distribution
for the next possible character.


264
00:16:22,182 --> 00:16:25,752 line:-2
We sample the distribution of predicted
characters from the softmax layer.


265
00:16:25,819 --> 00:16:27,788 line:-2
This gives us the index
of the next character,


266
00:16:27,855 --> 00:16:30,057 line:-2
which we can look up
in our index-to-character table.


267
00:16:31,491 --> 00:16:33,393 line:-2
Finally,
we move the newly generated result


268
00:16:33,460 --> 00:16:36,496 line:-2
as the input to the next iteration
to produce the next character.


269
00:16:38,832 --> 00:16:41,768 line:-2
Now let's see this network created
with MPSGraph in action.


270
00:16:42,569 --> 00:16:45,272 line:-2
We have implemented
an LSTM-based text generator network


271
00:16:45,339 --> 00:16:46,540 line:-1
with the new MPSGraph


272
00:16:46,607 --> 00:16:49,543 line:-2
that is running here in an app
on the iPad Pro.


273
00:16:50,310 --> 00:16:52,880 line:-2
MPSGraph allows our users
to implement these models,


274
00:16:52,946 --> 00:16:55,249 line:-2
and thanks to the flexibility
of the new graph interface,


275
00:16:55,315 --> 00:16:57,885 line:-2
it's easy to make tweaks to the models
to run experiments


276
00:16:57,951 --> 00:17:00,420 line:-2
and still enjoy
the benefits of optimized kernels.


277
00:17:01,188 --> 00:17:03,090 line:-2
The network has been trained
on a large text file


278
00:17:03,156 --> 00:17:05,392 line:-2
containing writings of Shakespeare
that we can see by clicking


279
00:17:05,459 --> 00:17:07,461 line:-2
the "Show Training DataSet" link
at the top.


280
00:17:08,028 --> 00:17:10,130 line:-2
Here we can see
a short excerpt of the text.


281
00:17:12,699 --> 00:17:16,236 line:-2
Now let's see if we can use the network
to generate Shakespearean-looking text.


282
00:17:16,303 --> 00:17:18,539 line:-2
We have set by default
the initial text to be "Romeo."


283
00:17:18,605 --> 00:17:20,840 line:-2
So let's see what happens
when we hit "Generate."


284
00:17:22,776 --> 00:17:25,979 line:-2
As we can see, the model is producing text
that looks like Shakespeare's texts,


285
00:17:26,046 --> 00:17:27,548 line:-1
at least to my untrained eye.


286
00:17:29,383 --> 00:17:32,419 line:-2
We can choose another initial word,
so let's type here "Juliet."


287
00:17:40,527 --> 00:17:41,862 line:-1
And hit "Generate" again.


288
00:17:42,863 --> 00:17:45,299 line:-2
Now the produced text
starts with the word "Juliet."


289
00:17:46,700 --> 00:17:50,270 line:-2
The length of the generated text can be
controlled by the slider at the bottom.


290
00:17:52,573 --> 00:17:54,474 line:-1
This will generate a longer piece of text.


291
00:17:56,844 --> 00:17:59,646 line:-2
We can also change
the temperature variable with a slider.


292
00:17:59,713 --> 00:18:01,081 line:-1
The reciprocal of this value


293
00:18:01,148 --> 00:18:03,951 line:-2
is used to multiply the input values
going into the softmax layer,


294
00:18:04,017 --> 00:18:07,487 line:-2
which creates a more smooth and flat
distribution for high-temperature values


295
00:18:07,554 --> 00:18:10,224 line:-2
and a more sharp distribution
for low-temperature values.


296
00:18:10,924 --> 00:18:12,759 line:-2
This has the effect
of making the sampling process


297
00:18:12,826 --> 00:18:15,963 line:-2
become more random with high temperatures
and less random with low temperatures.


298
00:18:16,029 --> 00:18:17,798 line:-2
Let's move the temperature slider
to about two


299
00:18:17,865 --> 00:18:19,967 line:-2
to see if it generates
more surprising text.


300
00:18:24,304 --> 00:18:28,208 line:-2
It does look more random to me. I'm unsure
if this is even proper English anymore.


301
00:18:28,809 --> 00:18:32,079 line:-2
Let's try setting it to three
and hit "Generate" again.


302
00:18:33,514 --> 00:18:36,750 line:-2
Okay, yeah. Now it's starting to look
like pure random letter soup.


303
00:18:38,018 --> 00:18:40,020 line:-2
I want to get back
to more conventional Shakespeare,


304
00:18:40,087 --> 00:18:43,690 line:-2
so let's move the temperature slider
back to 0.1 and see what happens.


305
00:18:46,894 --> 00:18:49,596 line:-2
Okay, that's better.
Now the model seems to be generating text


306
00:18:49,663 --> 00:18:51,832 line:-2
that resembles
the training data set more closely.


307
00:18:53,267 --> 00:18:56,203 line:-2
The MPSGraph not only enables us
to run these models in the graph,


308
00:18:56,270 --> 00:18:59,606 line:-2
it also enables the user to make a wide
variety of customizations to the models


309
00:18:59,673 --> 00:19:01,408 line:-2
while still enjoying the benefits
of tuned kernels


310
00:19:01,475 --> 00:19:03,277 line:-1
thanks to the stitching capabilities.


311
00:19:04,044 --> 00:19:07,481 line:-2
This allows support for a wide array
of models, enables rapid prototyping,


312
00:19:07,548 --> 00:19:10,951 line:-2
and reduces the amount of workarounds
and hacks needed to support a model.


313
00:19:11,451 --> 00:19:13,420 line:-1
That's all I have. Back to you, Dhruv.


314
00:19:14,555 --> 00:19:15,722 line:-1
Thanks, Chris.


315
00:19:15,789 --> 00:19:17,691 line:-1
We saw how easy and intuitive it was


316
00:19:17,758 --> 00:19:20,627 line:-2
to write custom compute functions
with MPSGraph.


317
00:19:20,694 --> 00:19:22,629 line:-1
Now let's look at features in MPSGraph


318
00:19:22,696 --> 00:19:26,834 line:-2
you can leverage to easily and optimally
train your neural networks.


319
00:19:28,502 --> 00:19:29,870 line:-1
The training process involves


320
00:19:29,937 --> 00:19:33,640 line:-2
repeatedly attempting
to execute the network on known data.


321
00:19:34,942 --> 00:19:37,377 line:0
Each attempt updates
the set of parameters,


322
00:19:37,444 --> 00:19:40,514 line:0
improving the ability of the network
to work correctly.


323
00:19:42,749 --> 00:19:45,819 line:0
When the network works well,
the training process is stopped.


324
00:19:48,288 --> 00:19:51,191 line:-2
Now we can look at how to use
the new MPSGraph


325
00:19:51,258 --> 00:19:53,193 line:-1
to implement some of these ideas.


326
00:19:55,195 --> 00:19:56,597 line:-1
For the purposes of our talk,


327
00:19:56,663 --> 00:19:59,533 line:-2
we will implement
a simple digit classification network.


328
00:20:01,235 --> 00:20:02,503 line:-1
As we saw before,


329
00:20:02,569 --> 00:20:05,772 line:-2
for doing computations with the MPSGraph,
there are three major steps.


330
00:20:07,040 --> 00:20:09,877 line:-2
Here is our road map
to training our neural network.


331
00:20:09,943 --> 00:20:12,379 line:-2
The first and the last step
remain the same.


332
00:20:12,446 --> 00:20:14,548 line:-1
We will dive deeper into step two


333
00:20:14,615 --> 00:20:16,783 line:-2
and take a look
at what operations we must create


334
00:20:16,850 --> 00:20:19,219 line:-2
to train the parameters
of our neural network.


335
00:20:21,088 --> 00:20:24,057 line:-2
As before,
first we define our set of inputs.


336
00:20:26,059 --> 00:20:29,463 line:-2
We define placeholders for our inputs
and target labels.


337
00:20:29,530 --> 00:20:34,001 line:-2
We use -1 to specify a variable length
batchSize for our network.


338
00:20:35,869 --> 00:20:39,840 line:-2
Next, we must specify the trainable
parameters we spoke of before.


339
00:20:39,907 --> 00:20:42,910 line:-2
With MPSGraph, these parameters
are part of the graph itself.


340
00:20:44,845 --> 00:20:47,814 line:-2
As a simple example,
we will be looking at training


341
00:20:47,881 --> 00:20:50,150 line:-2
a single layered
convolution neural network.


342
00:20:51,285 --> 00:20:55,055 line:-2
This network has a set of weights
corresponding to the convolution


343
00:20:55,122 --> 00:20:58,559 line:-2
and biases to be added
to the result of the convolution.


344
00:20:59,159 --> 00:21:01,361 line:-2
These are the parameters
we would be updating


345
00:21:01,428 --> 00:21:03,230 line:-1
as part of the training process.


346
00:21:04,831 --> 00:21:06,600 line:-1
To specify these parameters,


347
00:21:06,667 --> 00:21:09,770 line:-2
we will utilize variable support
in the MPSGraph.


348
00:21:10,370 --> 00:21:13,273 line:-1
Variables retain values across graph runs,


349
00:21:14,174 --> 00:21:18,679 line:-2
so you do not need to pass these
as inputs to the graph for each iteration.


350
00:21:19,680 --> 00:21:23,617 line:-2
To create a variable,
we call the variable method on the graph,


351
00:21:23,684 --> 00:21:27,287 line:-2
providing initial values, shape,
and an element dataType.


352
00:21:31,124 --> 00:21:34,995 line:-2
Now that we have our parameters to train,
let's specify our forward pass,


353
00:21:35,062 --> 00:21:37,965 line:-2
which also happens to be
the inference network for our model.


354
00:21:39,833 --> 00:21:43,103 line:-2
First up, we look at how to create
a convolution layer.


355
00:21:44,738 --> 00:21:47,541 line:-2
Convolution layer is the workhorse
of the neural network,


356
00:21:47,608 --> 00:21:50,010 line:-1
where most of the computation occurs,


357
00:21:50,077 --> 00:21:53,514 line:-2
and the MPSGraphConvolution layer
supports numerous variants.


358
00:21:56,884 --> 00:22:00,854 line:-2
To create a convolution layer,
we first create a convolution descriptor.


359
00:22:03,924 --> 00:22:07,628 line:-2
Next, we pass this descriptor
to the convolution method on the graph.


360
00:22:08,896 --> 00:22:11,298 line:-2
We support numerous padding styles
on our convolution.


361
00:22:12,466 --> 00:22:16,103 line:-2
Developers can explicitly set padding
in height and width


362
00:22:16,170 --> 00:22:18,906 line:-2
or use convenience padding modes
SAME and VALID,


363
00:22:18,972 --> 00:22:21,842 line:-2
which apply padding
exactly like TensorFlow.


364
00:22:23,443 --> 00:22:26,079 line:-2
Sometimes tensor dimensions
have a semantic meaning


365
00:22:26,146 --> 00:22:28,015 line:-1
attached to them for convenience.


366
00:22:28,916 --> 00:22:32,686 line:-2
This is where MPSGraph
TensorNamedDataLayout helps.


367
00:22:32,753 --> 00:22:35,722 line:-2
It conveys which dimension
corresponds to what name,


368
00:22:35,789 --> 00:22:38,592 line:-1
like batch, channel, height or width.


369
00:22:40,160 --> 00:22:44,198 line:-1
MPSGraph supports NCHW and NHWC formats,


370
00:22:44,264 --> 00:22:47,801 line:-2
which are commonly used for image data
in TensorFlow and PyTorch.


371
00:22:49,403 --> 00:22:52,005 line:-2
Weights can also be specified
in multiple formats


372
00:22:52,072 --> 00:22:55,642 line:-2
like the OIHW format,
which has been used in MPS,


373
00:22:55,709 --> 00:22:59,947 line:-2
or the HWIO format used by
third-party frameworks like TensorFlow.


374
00:23:01,982 --> 00:23:06,086 line:-2
When it comes to passing the values of
our weight variables to the convolution,


375
00:23:06,153 --> 00:23:08,755 line:-2
we would utilize
the readVariable operation.


376
00:23:09,289 --> 00:23:12,626 line:-2
It returns a tensor
representing the value of the variable


377
00:23:12,693 --> 00:23:15,062 line:-2
at this point
during the execution of the graph.


378
00:23:18,765 --> 00:23:21,735 line:-2
In our training network,
we read the weights variable


379
00:23:21,802 --> 00:23:24,238 line:-2
and pass the returned tensor
to the convolution.


380
00:23:26,740 --> 00:23:31,278 line:-2
The convolution layer will use
the shape of the weights tensor passed in


381
00:23:31,345 --> 00:23:34,982 line:-2
to infer kernel sizes
and number of output feature channels.


382
00:23:36,717 --> 00:23:38,986 line:-1
MPSGraph provides the convenience


383
00:23:39,052 --> 00:23:42,756 line:-2
of not needing to explicitly call
the readVariable operation.


384
00:23:42,823 --> 00:23:46,026 line:-2
If the variable tensor
is directly passed to any operation,


385
00:23:46,093 --> 00:23:49,096 line:-2
the graph will implicitly add
readVariable operations


386
00:23:49,162 --> 00:23:50,397 line:-1
for your convenience.


387
00:23:52,366 --> 00:23:54,434 line:-1
For the bias after the convolution,


388
00:23:54,501 --> 00:23:58,071 line:-2
we will call the add node,
which implicitly supports broadcasting.


389
00:23:59,673 --> 00:24:03,644 line:-2
For nonlinearity, we apply
the rectified Linear Unit function,


390
00:24:03,710 --> 00:24:05,612 line:-1
which is a commonly used activation.


391
00:24:07,014 --> 00:24:09,316 line:0
We reshape
the four-dimensional reLU output


392
00:24:09,383 --> 00:24:11,018 line:0
to a two-dimensional tensor,


393
00:24:11,084 --> 00:24:13,787 line:0
which happens to be the same shape
as our labels.


394
00:24:14,555 --> 00:24:17,357 line:0
Its dimensions represent
an unknown batch size


395
00:24:17,424 --> 00:24:22,229 line:0
and the number of classes to classify to,
which, in our case, are the ten digits.


396
00:24:23,764 --> 00:24:28,635 line:0
Finally, we add a softMax layer
to estimate probabilities of each class.


397
00:24:28,702 --> 00:24:30,838 line:0
We set the axis to be -1,


398
00:24:30,904 --> 00:24:33,473 line:0
which helps us indicate
the fastest moving axis.


399
00:24:35,609 --> 00:24:39,146 line:-2
We have successfully defined
the forward pass for our neural network.


400
00:24:39,213 --> 00:24:40,948 line:-1
Now we define the loss function,


401
00:24:41,014 --> 00:24:43,951 line:-2
which we will try to minimize
to train our neural network.


402
00:24:45,319 --> 00:24:48,922 line:-2
We will use the commonly used
Softmax Cross Entropy loss function.


403
00:24:51,425 --> 00:24:53,660 line:0
We define the loss
by passing in the labels


404
00:24:53,727 --> 00:24:56,463 line:0
and the evaluated reshapeTensor.


405
00:24:56,530 --> 00:25:00,434 line:0
We utilize reductionSum to accumulate
the losses across the batch


406
00:25:00,501 --> 00:25:02,436 line:0
into a single scalar loss value.


407
00:25:04,972 --> 00:25:07,708 line:-2
Now that we have defined
our loss value to minimize,


408
00:25:07,774 --> 00:25:10,544 line:-2
we need to calculate the gradients
for the computed loss


409
00:25:10,611 --> 00:25:12,913 line:-1
with respect to the trainable parameters.


410
00:25:13,847 --> 00:25:17,718 line:-2
To do that, we must backpropagate
the gradients using the chain rule.


411
00:25:20,921 --> 00:25:22,256 line:-1
To begin our chain rule,


412
00:25:22,322 --> 00:25:25,726 line:-2
the first step is to calculate
the gradient of the loss with itself,


413
00:25:25,792 --> 00:25:27,261 line:-1
which happens to be 1.


414
00:25:29,062 --> 00:25:32,299 line:-2
After that,
we need to utilize gradient operations


415
00:25:32,366 --> 00:25:34,868 line:-2
and the other operations
available in the graph.


416
00:25:36,003 --> 00:25:37,871 line:0
We use them to apply chain rule


417
00:25:37,938 --> 00:25:41,508 line:0
by multiplying partial derivatives
of each layer all the way


418
00:25:41,575 --> 00:25:45,512 line:0
till we get the gradients of the loss
with respect to each trainable parameter.


419
00:25:47,581 --> 00:25:50,350 line:-2
However,
MPSGraph provides a convenience method


420
00:25:50,417 --> 00:25:53,954 line:-2
which gives the gradients of a tensor
with respect to a list of tensors.


421
00:25:54,021 --> 00:25:56,156 line:-1
We call this automatic differentiation.


422
00:25:58,058 --> 00:26:01,328 line:-2
It automatically writes out
the backward pass of the graph


423
00:26:01,395 --> 00:26:05,098 line:-2
and returns a dictionary of tensors
and the corresponding gradients.


424
00:26:07,301 --> 00:26:10,204 line:-2
You can use the gradient method
to write out the gradient function


425
00:26:10,270 --> 00:26:12,906 line:-1
for even any basic math function.


426
00:26:12,973 --> 00:26:16,210 line:-2
We take a simple logarithm operation here
for our example.


427
00:26:17,444 --> 00:26:19,780 line:0
The gradient method correctly creates


428
00:26:19,847 --> 00:26:22,783 line:0
a reciprocal operation
as a partial derivative


429
00:26:22,850 --> 00:26:25,152 line:0
and multiplies it
with the starting gradient


430
00:26:25,219 --> 00:26:27,187 line:0
which, as we discussed, is always 1.


431
00:26:29,056 --> 00:26:32,526 line:0
However, we end up
with a set of unused operations.


432
00:26:32,593 --> 00:26:35,128 line:0
Once more,
the graph compiler helps us out here.


433
00:26:36,430 --> 00:26:40,667 line:0
The graph is pruned to eliminate
any dead code whose results are unused,


434
00:26:41,568 --> 00:26:45,172 line:0
and any constants like 1
are folded and eliminated.


435
00:26:47,107 --> 00:26:49,142 line:-1
So in the case of our neural network,


436
00:26:49,209 --> 00:26:51,178 line:-2
we would take the gradient
of the loss tensor


437
00:26:51,245 --> 00:26:53,313 line:-2
with respect to the weights
and the biases.


438
00:26:55,649 --> 00:26:59,486 line:-2
Once we have a gradient of loss
with respect to trainable parameters,


439
00:26:59,553 --> 00:27:01,355 line:-1
we can update the variables.


440
00:27:03,123 --> 00:27:05,392 line:-1
To calculate updates to the tensors,


441
00:27:05,459 --> 00:27:08,262 line:-2
we use the stochastic gradient
descent optimizer.


442
00:27:08,328 --> 00:27:11,732 line:-2
It takes in a learningRate,
the original weight value,


443
00:27:11,798 --> 00:27:13,367 line:-1
and the gradient for the weights


444
00:27:13,433 --> 00:27:15,769 line:-2
which we get by using
the gradients dictionary.


445
00:27:17,371 --> 00:27:20,707 line:-2
Finally, we use the assign variable
operation in the graph


446
00:27:20,774 --> 00:27:23,810 line:-2
to assign the new update tensor value
to the variable.


447
00:27:25,779 --> 00:27:28,048 line:-1
Final step is the same as before.


448
00:27:28,582 --> 00:27:32,085 line:-2
We wrote out our training graph,
and now we need to execute it.


449
00:27:33,654 --> 00:27:35,856 line:-2
Our training loop
is quite straightforward.


450
00:27:35,923 --> 00:27:37,658 line:-1
For each iteration,


451
00:27:37,724 --> 00:27:41,695 line:-2
we get a sample of training input images
and corresponding labels.


452
00:27:41,762 --> 00:27:44,097 line:-1
We pass these into the graph as feeds.


453
00:27:45,465 --> 00:27:48,936 line:-2
Then we request the lossTensor
be targeted and returned.


454
00:27:49,603 --> 00:27:53,473 line:-2
Every iteration, the weights
and bias variables would get updated,


455
00:27:53,540 --> 00:27:56,677 line:-2
since we also target
the assignment operations in the graph.


456
00:27:58,245 --> 00:28:02,382 line:-2
The graph compiles once
for each unique type of inputs and outputs


457
00:28:02,449 --> 00:28:04,218 line:-1
on the very first invocation,


458
00:28:04,685 --> 00:28:08,789 line:-2
and the executables are automatically
cached for any further iterations


459
00:28:08,856 --> 00:28:10,657 line:-1
to get the best performance.


460
00:28:12,292 --> 00:28:15,929 line:-2
MPSGraph also offers
asynchronous run methods.


461
00:28:15,996 --> 00:28:19,800 line:-2
This execution call is non-blocking
and will immediately return


462
00:28:19,867 --> 00:28:22,536 line:-2
without waiting for the GPU
to finish computing.


463
00:28:23,437 --> 00:28:26,673 line:0
The optional executionDescriptor
can be utilized


464
00:28:26,740 --> 00:28:29,543 line:0
to synchronize between the CPU
and the GPU.


465
00:28:32,446 --> 00:28:35,883 line:-2
We use one such synchronization method
on the descriptor.


466
00:28:35,949 --> 00:28:38,652 line:-2
Users can register
their completion handlers,


467
00:28:38,719 --> 00:28:42,222 line:-2
which will be called once the GPU
is finished executing the graph.


468
00:28:43,657 --> 00:28:46,126 line:-2
In the past years,
we have showcased the virtue


469
00:28:46,193 --> 00:28:50,130 line:-2
of overlapping CPU encoding
and the GPU execution.


470
00:28:50,197 --> 00:28:53,867 line:-2
The training iterations we execute
can use the same principles.


471
00:28:56,970 --> 00:28:59,473 line:-1
We create a semaphore with a value of 2.


472
00:29:00,874 --> 00:29:02,209 line:-1
We signal the semaphore


473
00:29:02,276 --> 00:29:05,045 line:-2
from the completion handler
of our execution descriptor.


474
00:29:06,680 --> 00:29:10,184 line:-2
Inside the loop, we wait on the semaphore,
and once through,


475
00:29:10,250 --> 00:29:14,121 line:-2
we asynchronously execute our graph
so it immediately returns.


476
00:29:15,789 --> 00:29:20,561 line:0
For users who wish to integrate MPSGraph
into their existing Metal work flow,


477
00:29:20,627 --> 00:29:23,830 line:0
MPSGraph offers
low-level execution methods


478
00:29:23,897 --> 00:29:27,100 line:0
in which you can pass
your own existing MTLCommandQueues.


479
00:29:28,702 --> 00:29:31,405 line:0
MPSGraph even provides MPS style ability


480
00:29:31,471 --> 00:29:34,875 line:0
to encode the graph
on your MPSCommandBuffers.


481
00:29:37,578 --> 00:29:40,247 line:0
Users can specify
their own results dictionary,


482
00:29:40,314 --> 00:29:43,884 line:0
giving them fine-grained control
over their output allocations.


483
00:29:45,953 --> 00:29:47,487 line:-1
Now we go back to Chris.


484
00:29:47,554 --> 00:29:50,991 line:-2
He will show our digit classifier
training network in action.


485
00:29:52,292 --> 00:29:55,028 line:-2
Now that Dhruv has shown us
the new MPSGraph for training,


486
00:29:55,095 --> 00:29:58,832 line:-2
let's see how we can use it to implement
digit classification on an iPhone 11.


487
00:29:59,633 --> 00:30:01,969 line:-2
We have implemented
a simple convolutional neural network


488
00:30:02,035 --> 00:30:03,804 line:-1
using the new MPSGraph framework,


489
00:30:03,871 --> 00:30:06,540 line:-2
and we can use this to classify digits
drawn by a user.


490
00:30:07,975 --> 00:30:11,078 line:-2
Upon opening the app, we start off
with a completely untrained graph.


491
00:30:12,312 --> 00:30:13,814 line:-1
On the inference tab, we can see that


492
00:30:13,881 --> 00:30:17,317 line:-2
currently the network is doing a lousy job
trying to label these numbers.


493
00:30:17,951 --> 00:30:21,221 line:-2
It can't predict this 1.
Nor can it predict this zero.


494
00:30:22,823 --> 00:30:24,391 line:-1
But if I go back to the training tab,


495
00:30:24,458 --> 00:30:27,160 line:-2
I can press the "play" button
to kick off a small batch of training.


496
00:30:28,128 --> 00:30:31,932 line:-2
We use the auto differentiation feature
of MPSGraph to get weight gradients


497
00:30:31,999 --> 00:30:34,234 line:-2
and target operations
to update our weight variables


498
00:30:34,301 --> 00:30:36,270 line:-1
to easily implement training.


499
00:30:36,336 --> 00:30:38,605 line:-2
The loss for each iteration
is plotted at the top,


500
00:30:38,672 --> 00:30:41,208 line:-2
and we can see it going down
as the network is trained.


501
00:30:42,743 --> 00:30:45,979 line:-2
We train for only a few hundred iterations
with a small batch size,


502
00:30:46,046 --> 00:30:49,082 line:-2
and we already have almost 95% accuracy
on the test set.


503
00:30:51,084 --> 00:30:52,753 line:-1
Going back to the inference tab...


504
00:30:53,787 --> 00:30:55,589 line:-1
we can test our newly trained graph.


505
00:31:00,994 --> 00:31:04,665 line:-2
We can see it has already learned
to classify our inputs with good accuracy.


506
00:31:05,566 --> 00:31:08,969 line:-2
The new MPSGraph makes it easy to build
custom machine learning models,


507
00:31:09,036 --> 00:31:11,238 line:-2
and use them for both training
and inference.


508
00:31:11,305 --> 00:31:14,007 line:-2
This example of how you can use MPSGraph
to build, train,


509
00:31:14,074 --> 00:31:18,078 line:-2
and execute a digit classifier
will be available as sample code online.


510
00:31:18,545 --> 00:31:20,547 line:-1
Now back to Dhruv for more on training.


511
00:31:21,648 --> 00:31:26,086 line:-2
Thanks, Chris, for showing us the power
of the MPSGraph training on an iPhone.


512
00:31:26,587 --> 00:31:29,122 line:-1
MPSGraph adds the capability to support


513
00:31:29,189 --> 00:31:32,025 line:-2
even more sophisticated
neural network architectures.


514
00:31:33,794 --> 00:31:36,063 line:-1
Let's look at one such example.


515
00:31:36,129 --> 00:31:40,334 line:-2
This time, we want to create new sets
of real looking handwritten digits.


516
00:31:40,934 --> 00:31:42,402 line:-1
However, there is an issue.


517
00:31:42,469 --> 00:31:44,905 line:-2
There is no way for the machine
to determine


518
00:31:44,972 --> 00:31:47,541 line:-2
what constitutes
a real-looking handwritten digit.


519
00:31:49,877 --> 00:31:52,646 line:-1
The answer to our problem is competition.


520
00:31:52,713 --> 00:31:56,550 line:-2
Humans have for many years
used competition to better each other


521
00:31:56,617 --> 00:32:00,220 line:-2
and achieve heights of excellence
which they can't by themselves.


522
00:32:01,154 --> 00:32:02,589 line:-1
We do the same here,


523
00:32:02,656 --> 00:32:06,527 line:-2
training two neural networks
by making them compete against each other.


524
00:32:06,593 --> 00:32:08,795 line:-1
One tries to create handwritten digits


525
00:32:08,862 --> 00:32:11,198 line:-2
and the other tries
to evaluate its quality.


526
00:32:12,699 --> 00:32:16,336 line:-2
The first of our networks
is the generator, the artist.


527
00:32:16,403 --> 00:32:19,506 line:-2
Its purpose is to take
a random set of values as seed


528
00:32:19,573 --> 00:32:22,176 line:-2
and generate
a real-looking handwritten digit.


529
00:32:23,777 --> 00:32:26,079 line:-1
The generator network is quite simple.


530
00:32:26,146 --> 00:32:29,883 line:-2
We take our random set of values
and pass them through three stages


531
00:32:29,950 --> 00:32:33,954 line:-2
to progressively increase the image size
to create our handwritten digit.


532
00:32:34,655 --> 00:32:37,324 line:-2
Let's quickly go through
some of the new layers here.


533
00:32:38,759 --> 00:32:41,361 line:-2
Firstly,
we see some convolution transposes.


534
00:32:43,597 --> 00:32:45,999 line:-1
Convolution transpose is a unique layer


535
00:32:46,066 --> 00:32:49,303 line:-2
which derives from the gradient
of a convolution operation.


536
00:32:49,369 --> 00:32:52,573 line:-2
So for a stride two,
the output size would be twice as big


537
00:32:52,639 --> 00:32:54,775 line:-1
rather than half the size of the input.


538
00:32:55,342 --> 00:32:57,411 line:-1
To describe a convolution transpose,


539
00:32:57,477 --> 00:33:00,747 line:-2
we pass the descriptor
for the corresponding convolution


540
00:33:00,814 --> 00:33:02,716 line:-1
and the output shape we expect.


541
00:33:05,252 --> 00:33:08,355 line:-2
Another new-looking layer here
is batch normalization.


542
00:33:09,623 --> 00:33:13,360 line:-2
Normalization layers are
a very important part of neural networks.


543
00:33:13,427 --> 00:33:17,030 line:-2
They help us ensure our trained values
and their corresponding gradients


544
00:33:17,097 --> 00:33:18,932 line:-1
don't vanish or explode.


545
00:33:21,068 --> 00:33:24,471 line:-2
To normalize a tensor, we need to use
the statistics for the tensor.


546
00:33:25,873 --> 00:33:28,375 line:-2
MPSGraph has methods
to get mean and variance


547
00:33:28,442 --> 00:33:30,744 line:-1
of the tensor on selected axes.


548
00:33:31,879 --> 00:33:34,615 line:-2
The axes we choose
give us an opportunity to select


549
00:33:34,681 --> 00:33:38,218 line:-2
if we want batch normalization,
instance normalization,


550
00:33:38,285 --> 00:33:39,620 line:-1
or any other variant.


551
00:33:41,388 --> 00:33:46,059 line:-2
For batch normalization, we would choose
batch, height, and width dimensions.


552
00:33:47,928 --> 00:33:52,466 line:0
Then we call the normalization layer
with trainable gamma and beta parameters.


553
00:33:56,036 --> 00:33:59,406 line:-2
The second layer is the discriminator,
our detective.


554
00:33:59,940 --> 00:34:04,745 line:-2
Its purpose is to take a handwritten digit
and classify it as real or fake.


555
00:34:06,547 --> 00:34:09,416 line:-2
We already saw how to write
classifier networks.


556
00:34:09,483 --> 00:34:11,652 line:-1
This network is very similar.


557
00:34:11,717 --> 00:34:14,755 line:-2
Only difference is that
instead of ten digits,


558
00:34:14,821 --> 00:34:16,924 line:-1
now we have one class to predict.


559
00:34:16,989 --> 00:34:19,126 line:-2
That is the realness
of the incoming image.


560
00:34:20,561 --> 00:34:24,231 line:-2
The discriminator has another new layer:
namely, dropout.


561
00:34:25,732 --> 00:34:28,802 line:-2
The dropout layer
randomly drops values of the input


562
00:34:28,869 --> 00:34:31,605 line:-1
by making them zero at a given rate.


563
00:34:31,672 --> 00:34:36,009 line:-2
At the same time, it boosts the rest
of the values by the inverse of the rate


564
00:34:36,076 --> 00:34:39,079 line:-2
to retain the energy
of the propagated features.


565
00:34:40,614 --> 00:34:43,516 line:-2
Now that we have looked
at the forward pass for both networks,


566
00:34:43,583 --> 00:34:45,853 line:-2
we'll look into training
for the two networks.


567
00:34:48,822 --> 00:34:50,958 line:-2
Let's start
with our discriminator network.


568
00:34:52,559 --> 00:34:57,130 line:-2
We control if we pass real or fake images
into the discriminator.


569
00:34:57,197 --> 00:34:58,532 line:-1
The discriminator's objective


570
00:34:58,599 --> 00:35:01,602 line:-2
is to predict the realness
of the incoming image,


571
00:35:01,668 --> 00:35:05,372 line:-2
so for real images, it should predict 1
for the probability of being real,


572
00:35:05,439 --> 00:35:09,109 line:-2
and for fake images,
it should predict a probability of zero.


573
00:35:11,011 --> 00:35:12,379 line:0
For the generated images,


574
00:35:12,446 --> 00:35:15,082 line:0
we subtract the discriminator result
from 1


575
00:35:15,148 --> 00:35:17,784 line:0
to instead get the fakeness
of the input images.


576
00:35:19,319 --> 00:35:21,722 line:-2
We use the commonly used
cross entropy loss


577
00:35:21,788 --> 00:35:26,226 line:-2
to quantify how far our discriminator was
from the correct real or fake prediction.


578
00:35:29,396 --> 00:35:32,766 line:-2
Finally, we want to provide
the discriminator equal opportunity


579
00:35:32,833 --> 00:35:36,870 line:-2
to learn to classify real and fake images
without introducing bias.


580
00:35:37,571 --> 00:35:41,308 line:-2
So for each iteration, we pass
the same number of real and fake images


581
00:35:41,375 --> 00:35:43,277 line:-1
and add their losses together.


582
00:35:45,112 --> 00:35:46,413 line:-1
With the loss in hand,


583
00:35:46,480 --> 00:35:49,917 line:-2
we use the automatic differentiation
feature of the MPSGraph.


584
00:35:50,751 --> 00:35:55,455 line:-2
Notice how we ask for the gradients for
the list of discriminator variables only.


585
00:35:55,522 --> 00:35:58,992 line:-2
This is because we only wish to train
the discriminator in this pass.


586
00:36:00,861 --> 00:36:03,297 line:-1
We have the makings of a good detective.


587
00:36:03,363 --> 00:36:07,167 line:-2
Now let's look at training our artist
to generate realistic digits.


588
00:36:08,569 --> 00:36:10,237 line:-1
As we described before,


589
00:36:10,304 --> 00:36:14,575 line:-2
we use the discriminator to quantify
how realistic our generated image is.


590
00:36:15,209 --> 00:36:18,245 line:-2
The generator will try to learn
to fool the discriminator


591
00:36:18,312 --> 00:36:21,081 line:-2
into predicting
that the generated image is real.


592
00:36:22,649 --> 00:36:24,985 line:-2
And once more,
we use the cross entropy loss


593
00:36:25,052 --> 00:36:28,522 line:-2
to quantify how far
the probability of being real was.


594
00:36:30,057 --> 00:36:32,759 line:-2
We use this generator loss
to get the gradients.


595
00:36:34,228 --> 00:36:38,732 line:-2
Notice again, we only get the gradients
for the generator variables.


596
00:36:38,799 --> 00:36:40,901 line:-2
This is because
we don't want the discriminator


597
00:36:40,968 --> 00:36:43,637 line:-1
to learn to predict fake images as real.


598
00:36:44,638 --> 00:36:48,675 line:-2
MPSGraph will automatically differentiate
through both networks


599
00:36:48,742 --> 00:36:51,512 line:-2
and return gradients
for the generator variables only.


600
00:36:53,013 --> 00:36:57,618 line:-2
With the gradients for both networks,
we can update the variables just as before


601
00:36:57,684 --> 00:36:59,386 line:-1
by applying optimizers.


602
00:37:00,654 --> 00:37:04,124 line:-2
And now we see how to execute
the training for the two networks.


603
00:37:06,293 --> 00:37:09,363 line:-1
MPSGraph makes it really easy to execute.


604
00:37:09,429 --> 00:37:11,698 line:0
We simply pass both losses as targets


605
00:37:11,765 --> 00:37:15,402 line:0
and request both the generator
and discriminator update operations


606
00:37:15,469 --> 00:37:17,404 line:0
in a single run call.


607
00:37:17,471 --> 00:37:21,141 line:0
The MPSGraph will compile and optimize
across both networks


608
00:37:21,208 --> 00:37:23,143 line:0
and execute them together.


609
00:37:25,112 --> 00:37:30,184 line:-2
We just saw how easy it was to write out
two networks within a single MPSGraph


610
00:37:30,250 --> 00:37:33,720 line:-2
and execute them together
with a single execution call.


611
00:37:34,588 --> 00:37:37,391 line:-2
Let's ask Chris
to generate some digits for us.


612
00:37:38,659 --> 00:37:39,660 line:-1
Hello again.


613
00:37:39,726 --> 00:37:43,530 line:-2
Now that we know how these networks work,
let's see them in action on our iPad Pro.


614
00:37:43,597 --> 00:37:46,366 line:-2
I'll hit the "play" button
on the "train" tab to begin training.


615
00:37:48,268 --> 00:37:50,504 line:-2
On the top, we
see the loss for the generator network


616
00:37:50,571 --> 00:37:53,106 line:-2
and the bottom shows the loss
for the discriminator network.


617
00:37:54,241 --> 00:37:57,544 line:-2
In the center, we can see images
generated by the generator network,


618
00:37:57,611 --> 00:37:58,645 line:-1
and as the networks train,


619
00:37:58,712 --> 00:38:01,081 line:-2
we will see these generated numbers
start to resemble digits.


620
00:38:02,516 --> 00:38:04,785 line:-2
Just like we saw
in the digit classifier demo,


621
00:38:04,852 --> 00:38:08,555 line:-2
we use the auto differentiation feature
of MPSGraph to update the trainable layers


622
00:38:08,622 --> 00:38:10,924 line:-2
in both the generator
and discriminator networks.


623
00:38:10,991 --> 00:38:13,594 line:-2
Both networks are trained
using a single MPSGraph.


624
00:38:15,128 --> 00:38:17,397 line:-2
We can see these networks
are already battling each other,


625
00:38:17,464 --> 00:38:20,701 line:-2
but it'll take time before the generator
is able to produce believable digits.


626
00:38:21,235 --> 00:38:22,636 line:-1
We can pause this training...


627
00:38:24,771 --> 00:38:27,541 line:-2
and jump to the "inference" tab
to test the networks


628
00:38:27,608 --> 00:38:29,843 line:-2
after they have trained
for a few hundred epochs.


629
00:38:33,146 --> 00:38:35,516 line:-1
Here we see a 5, 9.


630
00:38:36,550 --> 00:38:38,118 line:-1
I don't know what that is.


631
00:38:38,886 --> 00:38:40,521 line:-1
7, 9.


632
00:38:41,755 --> 00:38:43,323 line:-1
They look like digits to me.


633
00:38:43,390 --> 00:38:46,493 line:-2
All of this is running on an iPad Pro
using MPSGraph.


634
00:38:46,560 --> 00:38:48,128 line:-1
Okay, back to Dhruv.


635
00:38:49,196 --> 00:38:50,364 line:-1
Thanks again, Chris.


636
00:38:51,198 --> 00:38:55,102 line:-2
In summary,
we introduced the new MPSGraph framework.


637
00:38:56,370 --> 00:39:00,874 line:-2
We learned how to write and execute
custom compute functions using MPSGraph.


638
00:39:02,009 --> 00:39:06,246 line:-2
We saw how the MPSGraph compiler
stitches and optimizes operations


639
00:39:06,313 --> 00:39:09,316 line:-2
across your entire graph
to give the best performance.


640
00:39:10,784 --> 00:39:15,255 line:0
And finally, we saw how easy it is
to train neural networks using MPSGraph


641
00:39:15,322 --> 00:39:19,059 line:0
with support for features like variables
and automatic differentiation.


642
00:39:20,194 --> 00:39:21,295 line:-1
Thank you for listening.


643
00:39:21,361 --> 00:39:24,231 line:-2
Please check out
our sample code and documentation,


644
00:39:24,298 --> 00:39:26,233 line:-1
and have a great WWDC.

