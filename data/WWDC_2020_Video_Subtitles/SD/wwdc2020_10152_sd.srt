1
00:00:03,711 --> 00:00:06,632 line:-1
Hello and welcome to WWDC.


2
00:00:08,090 --> 00:00:11,845 line:0
Hello. My name is Anil Katti
and I'm excited to share with you


3
00:00:11,929 --> 00:00:15,724 line:0
some of the amazing new features
we've introduced this year in Core ML.


4
00:00:16,183 --> 00:00:17,851 line:-1
Core ML makes it easy for you


5
00:00:17,935 --> 00:00:20,395 line:-2
to seamlessly integrate machine learning
into your app,


6
00:00:20,479 --> 00:00:25,067 line:-2
unlocking the door to countless
amazing experiences for your users.


7
00:00:25,150 --> 00:00:29,947 line:-2
Your Core ML model is at the heart of
what makes all these experiences possible.


8
00:00:30,405 --> 00:00:34,993 line:-2
Today, we are introducing new features
that are centered around this model.


9
00:00:35,452 --> 00:00:37,871 line:-2
In this session,
we're going to cover a few topics,


10
00:00:37,955 --> 00:00:40,958 line:-2
from a new way to deploy your models,
to encrypting them,


11
00:00:41,041 --> 00:00:43,418 line:-1
and some enhancements in Xcode.


12
00:00:43,502 --> 00:00:44,753 line:-1
Let's get started.


13
00:00:44,837 --> 00:00:49,716 line:-2
We designed Core ML with
your app development workflow in mind.


14
00:00:49,800 --> 00:00:53,428 line:-2
Once you have a model,
you can integrate it into your app


15
00:00:53,512 --> 00:00:57,057 line:-2
by simply dragging and dropping it
into your Xcode project.


16
00:00:57,140 --> 00:01:00,519 line:-2
Xcode compiles your model
into an optimal format


17
00:01:00,602 --> 00:01:03,146 line:-1
for running on-device.


18
00:01:03,230 --> 00:01:04,690 line:-1
When you submit your app,


19
00:01:04,772 --> 00:01:07,317 line:-2
the compiled model
is bundled with your app.


20
00:01:07,401 --> 00:01:11,613 line:-2
Together, they go to the App Store
and then to your users' devices.


21
00:01:11,697 --> 00:01:16,118 line:-2
Bundling a model with your app works great
and we highly recommend doing it.


22
00:01:16,201 --> 00:01:22,124 line:-2
That way, the model is readily available
as soon as a user installs the app.


23
00:01:22,207 --> 00:01:24,918 line:-1
There are scenarios where you might need


24
00:01:25,002 --> 00:01:28,922 line:-2
more flexibility and control
over the model delivery process.


25
00:01:29,006 --> 00:01:32,467 line:-2
Today, we're introducing
Core ML Model Deployment


26
00:01:32,551 --> 00:01:35,179 line:-1
to give you that flexibility.


27
00:01:35,846 --> 00:01:38,849 line:-2
Core ML Model Deployment
provides you a new way


28
00:01:38,932 --> 00:01:40,976 line:-1
to deliver models to your apps.


29
00:01:41,059 --> 00:01:42,769 line:-1
Using the Model Deployment dashboard,


30
00:01:42,853 --> 00:01:47,524 line:-2
models can be stored, managed
and deployed via Apple cloud.


31
00:01:47,608 --> 00:01:51,778 line:-2
Devices periodically retrieve updates
as they become available.


32
00:01:51,862 --> 00:01:53,780 line:-1
Model Deployment gives you


33
00:01:53,864 --> 00:01:59,369 line:-2
the ability to develop and deploy models
independent of the app update cycle,


34
00:01:59,453 --> 00:02:04,416 line:-2
a new way to group and manage
models that work together,


35
00:02:04,499 --> 00:02:08,753 line:-2
and the option to target models
to specific device populations.


36
00:02:09,253 --> 00:02:13,884 line:-2
We're really excited about these features,
so let's explore each one in more detail.


37
00:02:13,967 --> 00:02:16,261 line:-1
Let's start with independent development.


38
00:02:17,971 --> 00:02:20,474 line:0
Typically, when you retrain your models,


39
00:02:20,557 --> 00:02:24,436 line:0
you probably plan to bundle them
with your next app update.


40
00:02:25,854 --> 00:02:31,276 line:0
But what if you're updating your models
at a different pace than your app?


41
00:02:31,360 --> 00:02:34,863 line:0
In the past,
you'd have to push more app updates


42
00:02:34,947 --> 00:02:37,574 line:0
just to get the newer models
in your users' hands.


43
00:02:38,825 --> 00:02:40,577 line:-1
Now, with Model Deployment,


44
00:02:40,661 --> 00:02:43,622 line:-2
you can quickly and easily
update your models


45
00:02:43,705 --> 00:02:46,542 line:-1
without updating the app itself.


46
00:02:46,625 --> 00:02:48,544 line:-1
Next up: model collections.


47
00:02:50,379 --> 00:02:54,174 line:-2
Model collections are a great way
to group one or more models


48
00:02:54,258 --> 00:02:56,969 line:-1
that relate to a feature in your app.


49
00:02:57,052 --> 00:03:00,138 line:-2
For example,
let's say you're working on a game


50
00:03:00,222 --> 00:03:04,893 line:-2
and one of its levels needs
a set of models to support a feature.


51
00:03:04,977 --> 00:03:07,271 line:-1
You can keep these models in sync


52
00:03:07,354 --> 00:03:10,858 line:-2
by grouping them
into a single model collection.


53
00:03:10,941 --> 00:03:12,818 line:-1
When you deploy a model collection,


54
00:03:12,901 --> 00:03:17,114 line:-2
that deployment keeps all the models
within a collection together


55
00:03:17,197 --> 00:03:20,325 line:-1
and atomically delivers them to your app.


56
00:03:20,409 --> 00:03:24,288 line:-2
I'm eager to show all this in action,
but before we jump into the demo,


57
00:03:24,371 --> 00:03:27,791 line:-2
let me describe how we would go about
adopting this feature.


58
00:03:28,375 --> 00:03:31,712 line:-2
So, there are three steps
in adopting Model Deployment.


59
00:03:31,795 --> 00:03:34,840 line:-2
The first step is to use
the new Core ML API


60
00:03:34,923 --> 00:03:37,551 line:-1
to opt-in for Model Deployment.


61
00:03:37,634 --> 00:03:43,140 line:-2
Next, prepare the model for deployment
by creating a model archive.


62
00:03:43,223 --> 00:03:44,641 line:-1
You can do this in Xcode.


63
00:03:46,268 --> 00:03:49,021 line:-2
The last step
is to upload the prepared model


64
00:03:49,104 --> 00:03:52,983 line:-2
and deploy
on the Model Deployment dashboard.


65
00:03:53,066 --> 00:03:55,777 line:-2
You will only need to repeat
steps two and three


66
00:03:55,861 --> 00:03:58,155 line:-1
every time you update your model.


67
00:03:58,238 --> 00:04:00,866 line:-2
Let's take a closer look
at these steps with a demo.


68
00:04:00,949 --> 00:04:03,619 line:-2
I have a simple app
that classifies flowers


69
00:04:03,702 --> 00:04:07,164 line:-2
and applies cool visual effects
when you double-tap on a picture.


70
00:04:07,247 --> 00:04:09,166 line:-1
It uses two Core ML models:


71
00:04:09,249 --> 00:04:12,294 line:-2
an image classifier
and a style transfer model.


72
00:04:13,420 --> 00:04:15,506 line:-1
I chose to integrate Model Deployment


73
00:04:15,589 --> 00:04:19,259 line:-2
so I could decouple updating models
from the app update process


74
00:04:19,343 --> 00:04:21,803 line:-1
and iterate on models independently.


75
00:04:22,429 --> 00:04:26,975 line:-2
So, the first step is to use the new API
to opt-in for Model Deployment.


76
00:04:27,059 --> 00:04:29,478 line:-1
Let's see how to do that in Xcode.


77
00:04:29,895 --> 00:04:32,564 line:-1
I have my Xcode project open.


78
00:04:32,648 --> 00:04:35,108 line:-1
Although this app does a couple of things,


79
00:04:35,192 --> 00:04:39,363 line:-2
for this demo, let's just focus
on the flower classification feature.


80
00:04:39,905 --> 00:04:43,242 line:-2
Here is the key method
we are going to implement today.


81
00:04:43,325 --> 00:04:48,413 line:-2
It classifies the flower in a given image
and updates the UI with the class label.


82
00:04:48,956 --> 00:04:51,959 line:-2
The first thing I want to do
when this method is invoked


83
00:04:52,042 --> 00:04:57,130 line:-2
is create an instance of FlowerClassifier
and store it in a variable.


84
00:04:57,214 --> 00:05:00,509 line:-2
This would allow me to access
the preloaded model in subsequent calls


85
00:05:00,592 --> 00:05:03,846 line:-2
and not have to load the model
every single time.


86
00:05:04,555 --> 00:05:08,684 line:-2
So, let me get started
by checking for the preloaded case.


87
00:05:14,064 --> 00:05:17,192 line:-2
Here, I check to see
if the variable is already set


88
00:05:17,276 --> 00:05:21,530 line:-2
and if so, use that to classify the image
and return immediately.


89
00:05:21,947 --> 00:05:24,700 line:-2
Next, let's implement the logic
to load the model.


90
00:05:26,159 --> 00:05:29,538 line:-2
Recall that models
are grouped into collections.


91
00:05:29,621 --> 00:05:32,583 line:-2
I will show how to create
and deploy model collections


92
00:05:32,666 --> 00:05:34,751 line:-1
on the new dashboard in a few minutes.


93
00:05:34,835 --> 00:05:39,756 line:-2
But here, I'm interested in accessing
the collection that was already deployed.


94
00:05:39,840 --> 00:05:42,676 line:-2
I can do that by simply calling
beginAccessing method


95
00:05:42,759 --> 00:05:44,887 line:-1
on MLModelCollection.


96
00:05:48,765 --> 00:05:52,728 line:-2
The first time this method is called
for a model collection with an identifier,


97
00:05:52,811 --> 00:05:57,232 line:-2
the system downloads all models
in that collection on a background queue


98
00:05:57,316 --> 00:06:00,694 line:-2
and registers for future updates
to those models.


99
00:06:00,777 --> 00:06:03,989 line:-2
You can monitor the download
using the progress object.


100
00:06:05,115 --> 00:06:09,620 line:-2
Here the model collection identifier
we are using is "FlowerModels."


101
00:06:09,703 --> 00:06:11,455 line:-1
Let's just keep a note of that


102
00:06:11,538 --> 00:06:15,501 line:-2
since this is required
while creating the model collection later.


103
00:06:16,418 --> 00:06:20,506 line:-2
This method also returns an instance
of MLModelCollection asynchronously


104
00:06:20,589 --> 00:06:22,424 line:-1
as a result type.


105
00:06:22,508 --> 00:06:26,136 line:-2
Let's see how we can access
the downloaded models from this result.


106
00:06:31,141 --> 00:06:34,311 line:-2
When this operation succeeds,
we get an instance of model collection


107
00:06:34,394 --> 00:06:37,439 line:-1
which contains model collection entries.


108
00:06:37,523 --> 00:06:39,733 line:-1
There's one entry per model.


109
00:06:39,816 --> 00:06:43,237 line:-2
I can access the model collection entry
for our FlowerClassifier model


110
00:06:43,320 --> 00:06:45,614 line:-1
using the model name as the key.


111
00:06:45,697 --> 00:06:50,577 line:-2
Inside the entry is a model URL
that points to the compiled model


112
00:06:50,661 --> 00:06:54,665 line:-2
which was downloaded and placed
in the app's container by the system.


113
00:06:55,290 --> 00:06:57,835 line:-1
Accessing a model collection could fail.


114
00:06:57,918 --> 00:07:00,629 line:-2
For instance,
if there is no network connectivity


115
00:07:00,712 --> 00:07:04,091 line:-2
the first time this is called,
downloading models will fail.


116
00:07:04,174 --> 00:07:06,260 line:-2
It is important
to handle the failure case.


117
00:07:06,343 --> 00:07:11,515 line:-2
In this example, we simply log the error
and fall back to using the bundled model.


118
00:07:11,598 --> 00:07:15,352 line:-2
Next, let's implement the logic
to load the model.


119
00:07:20,107 --> 00:07:23,735 line:-2
I implemented a simple helper method
to load the model.


120
00:07:23,819 --> 00:07:27,197 line:-1
It takes an optional modelURL as input


121
00:07:27,281 --> 00:07:30,868 line:-2
and uses that to load
the FlowerClassifier model.


122
00:07:30,951 --> 00:07:33,495 line:-1
If the URL is nil, it just falls back


123
00:07:33,579 --> 00:07:36,415 line:-2
and loads the model
that is bundled with the app.


124
00:07:37,624 --> 00:07:39,877 line:-2
The last step
is to use this FlowerClassifier


125
00:07:39,960 --> 00:07:41,461 line:-1
for classifying the image.


126
00:07:46,466 --> 00:07:48,010 line:-1
Here's the code for that.


127
00:07:48,093 --> 00:07:50,137 line:-1
When the model loading succeeds,


128
00:07:50,220 --> 00:07:53,140 line:-2
we use the loaded model
to classify the image


129
00:07:53,223 --> 00:07:57,060 line:-2
and also store it in the variable
for subsequent classification requests.


130
00:07:57,144 --> 00:08:00,230 line:-2
We have a separate method
to handle the model load failures,


131
00:08:00,314 --> 00:08:03,859 line:-2
which, in this case, displays
a suitable error message to the user.


132
00:08:05,277 --> 00:08:08,906 line:-2
This is all the code that's required
to prepare the app for Model Deployment.


133
00:08:08,989 --> 00:08:12,951 line:-2
Now, how can I prepare the model itself
for deployment?


134
00:08:13,035 --> 00:08:15,204 line:-1
Well, I can do that in Xcode.


135
00:08:15,287 --> 00:08:17,706 line:-1
If you click on the model in Xcode,


136
00:08:17,789 --> 00:08:21,585 line:-2
you'll see that we have introduced
a new utilities tab this year


137
00:08:21,668 --> 00:08:24,421 line:-1
which has a section for Model Deployment.


138
00:08:25,881 --> 00:08:30,552 line:-2
I can prepare a model for deployment
by creating a model archive.


139
00:08:31,887 --> 00:08:35,432 line:-2
Okay, Xcode created
FlowerClassifier.mlarchive


140
00:08:35,515 --> 00:08:37,976 line:-1
and saved it on the disk.


141
00:08:38,059 --> 00:08:40,479 line:-1
I can locate the file by clicking here.


142
00:08:42,773 --> 00:08:46,276 line:-2
It is placed
right next to our original model file.


143
00:08:46,360 --> 00:08:51,281 line:-2
The last step is to deploy this model
on the Model Deployment dashboard.


144
00:08:51,365 --> 00:08:53,408 line:-1
Xcode provides a button that takes you


145
00:08:53,492 --> 00:08:56,912 line:-2
right to the Model Deployment dashboard
in Safari.


146
00:08:56,995 --> 00:08:58,872 line:-2
The first thing you'll notice
on the dashboard


147
00:08:58,956 --> 00:09:01,834 line:-2
is that we have a way
to create a model collection.


148
00:09:01,917 --> 00:09:05,045 line:-2
I'll start by creating a new
model collection for our flower models


149
00:09:05,128 --> 00:09:07,589 line:-1
and name it "FlowerModels."


150
00:09:07,673 --> 00:09:10,217 line:-2
This should match with
what was specified in the app.


151
00:09:13,720 --> 00:09:16,306 line:-1
Next, let's provide a nice description.


152
00:09:16,390 --> 00:09:17,516 line:-1
Something like...


153
00:09:18,225 --> 00:09:24,857 line:-2
"collection of models
built for flower images."


154
00:09:26,191 --> 00:09:28,694 line:-1
And then specify the two models


155
00:09:28,777 --> 00:09:30,946 line:-2
that we plan to collect
in this collection,


156
00:09:32,155 --> 00:09:34,533 line:-1
the first being a FlowerClassfier.


157
00:09:35,784 --> 00:09:39,872 line:-1
And then we have a FlowerStylizer.


158
00:09:41,081 --> 00:09:43,000 line:-1
And then click on the create button.


159
00:09:43,750 --> 00:09:48,297 line:-2
Next, I can deploy the models
by creating a new deployment.


160
00:09:48,380 --> 00:09:50,549 line:-1
I will call it Global Deployment


161
00:09:50,632 --> 00:09:54,386 line:-2
since I intend to deploy these models
to my app on all devices.


162
00:09:59,474 --> 00:10:02,978 line:-2
I can upload the model archives I created
against each of these model names.


163
00:10:03,061 --> 00:10:06,315 line:-2
Let me pick the FlowerClassfier first
and then the Stylizer


164
00:10:06,398 --> 00:10:08,692 line:-2
and click on the deploy button
on the top right.


165
00:10:15,324 --> 00:10:16,867 line:-1
In the model collection page,


166
00:10:16,950 --> 00:10:19,786 line:-2
I can verify that the deployment
I created just now


167
00:10:19,870 --> 00:10:21,455 line:-1
is in the active status.


168
00:10:21,538 --> 00:10:23,373 line:-1
So this looks good.


169
00:10:23,874 --> 00:10:26,335 line:-2
These models are made available
on all devices


170
00:10:26,418 --> 00:10:29,505 line:-2
running the version of my app
that uses this model collection.


171
00:10:29,588 --> 00:10:33,050 line:-2
Let me launch the app
and try classifying flowers now.


172
00:10:38,722 --> 00:10:43,101 line:-2
I picked a dahlia and see
that it's being classified as dahlia.


173
00:10:43,519 --> 00:10:45,812 line:-1
Let me try a hibiscus this time.


174
00:10:47,064 --> 00:10:49,775 line:-1
The app seems to get that right as well.


175
00:10:49,858 --> 00:10:53,570 line:-2
The model that I used here was
only trained on three different classes


176
00:10:53,654 --> 00:10:55,739 line:-1
and rose was not one of them.


177
00:10:55,822 --> 00:10:58,700 line:-2
Let me try a rose image
and see what happens.


178
00:11:01,203 --> 00:11:04,998 line:-2
As expected,
the app does not seem to recognize rose.


179
00:11:06,166 --> 00:11:09,294 line:-2
Let's say I want to enhance my app
to classify rose.


180
00:11:09,378 --> 00:11:12,548 line:-2
Since I've already adopted
Model Deployment in this app,


181
00:11:12,631 --> 00:11:14,925 line:-2
I can easily add this feature
by deploying a model


182
00:11:15,008 --> 00:11:18,178 line:-2
retrained with rose images
using Model Deployment.


183
00:11:18,262 --> 00:11:19,304 line:-1
For the sake of this demo,


184
00:11:19,388 --> 00:11:22,641 line:-2
I've already prepared
the updated model for deployment.


185
00:11:23,976 --> 00:11:27,896 line:-2
Let's go to the deployment dashboard
and see how to update a model.


186
00:11:27,980 --> 00:11:31,733 line:-2
I can deploy the updated model
by creating a new deployment.


187
00:11:31,817 --> 00:11:34,820 line:-2
This time,
I will pick the improved classifier


188
00:11:34,903 --> 00:11:37,698 line:-2
and the same stylizer
and click on the deploy button.


189
00:11:42,995 --> 00:11:45,247 line:-1
Like before, these updated models


190
00:11:45,330 --> 00:11:47,958 line:-2
are made available to my app
on all devices,


191
00:11:48,041 --> 00:11:50,586 line:-1
but it might not happen immediately.


192
00:11:50,669 --> 00:11:54,464 line:-2
Each device figures out the right time
to download the model in the background


193
00:11:54,548 --> 00:11:57,801 line:-2
and makes it available to the app
on its next launch.


194
00:11:58,343 --> 00:12:01,221 line:-2
Let's see what will happen
when my app gets launched


195
00:12:01,305 --> 00:12:05,142 line:-2
after the OS has synced
the updated models to the device.


196
00:12:05,225 --> 00:12:08,478 line:-2
Picking the same rose image
that was not classified previously,


197
00:12:08,562 --> 00:12:10,564 line:-2
I see that it is getting classified
as a rose this time.


198
00:12:11,732 --> 00:12:14,151 line:-1
So without changing a single line of code,


199
00:12:14,234 --> 00:12:16,653 line:-2
we've enhanced the user experience
by improving the model,


200
00:12:16,737 --> 00:12:18,030 line:-1
and I think this is really cool.


201
00:12:18,655 --> 00:12:20,741 line:-2
Next, let's talk about
targeted deployments.


202
00:12:22,075 --> 00:12:24,036 line:-1
Typically, when your app is young,


203
00:12:24,119 --> 00:12:27,664 line:-2
it might have only one set of models
for all your users.


204
00:12:27,748 --> 00:12:31,210 line:-2
However, as your app evolves,
it might make more sense


205
00:12:31,293 --> 00:12:35,339 line:-2
for you to use specialized models
for different populations.


206
00:12:35,422 --> 00:12:38,967 line:-2
One solution is simply to bundle
all models in your app


207
00:12:39,051 --> 00:12:40,969 line:-1
and use the right one at the runtime,


208
00:12:41,053 --> 00:12:42,638 line:-1
but it's not very efficient.


209
00:12:42,721 --> 00:12:44,223 line:-1
And what if the models are large


210
00:12:44,306 --> 00:12:47,392 line:-2
and you want to keep
the app download size small?


211
00:12:47,476 --> 00:12:49,895 line:-2
With targeted deployments,
you can define rules


212
00:12:49,978 --> 00:12:54,483 line:-2
so that each user's device
only gets the model it needs.


213
00:12:55,192 --> 00:12:57,110 line:-1
Let's see how to set one of these up.


214
00:12:57,694 --> 00:13:00,822 line:-2
Recently, I made an improvement
to our FlowerClassifier,


215
00:13:00,906 --> 00:13:03,492 line:-1
but specifically made it for iPads.


216
00:13:03,575 --> 00:13:06,328 line:-2
It turns out the camera angle
and the light setting


217
00:13:06,411 --> 00:13:07,913 line:-1
in images taken on an iPad


218
00:13:07,996 --> 00:13:11,041 line:-2
are slightly different
from those on an iPhone.


219
00:13:11,124 --> 00:13:13,377 line:-2
Although I want to use
a new model on iPads,


220
00:13:13,460 --> 00:13:17,297 line:-2
the existing model works just fine
on all other devices.


221
00:13:17,381 --> 00:13:22,886 line:-2
Let's take a look at how we can target
the iPad-specific model to just iPads.


222
00:13:23,595 --> 00:13:27,224 line:-2
Back on the dashboard,
I can either clone an existing deployment


223
00:13:27,307 --> 00:13:28,976 line:-1
or create a new one.


224
00:13:29,059 --> 00:13:32,479 line:-2
For now, I'll create a new one
and call it Targeting iPads.


225
00:13:36,233 --> 00:13:39,528 line:-2
First, I get to pick the default models
for this deployment.


226
00:13:39,611 --> 00:13:41,947 line:-2
These models will be delivered
on all devices


227
00:13:42,030 --> 00:13:43,907 line:-1
that do not match the deployment rules.


228
00:13:54,668 --> 00:13:57,504 line:-2
After that, I can add
an additional targeting rule.


229
00:13:57,588 --> 00:14:00,048 line:-2
You can see
all the different criteria I can target.


230
00:14:00,132 --> 00:14:02,801 line:-2
I'll pick the device class
and select iPad.


231
00:14:02,885 --> 00:14:06,597 line:-2
So for this targeting rule,
I get to pick the iPad-specific models.


232
00:14:20,903 --> 00:14:23,113 line:-1
I can now deploy these models.


233
00:14:23,197 --> 00:14:26,575 line:-2
Devices pull the right model
based on the device class.


234
00:14:26,658 --> 00:14:28,952 line:-1
No additional change required in the app.


235
00:14:29,036 --> 00:14:32,998 line:-2
We showed you how easy it is
to use Core ML Model Deployment


236
00:14:33,081 --> 00:14:35,209 line:-1
to help with some interesting use cases.


237
00:14:35,292 --> 00:14:37,002 line:-2
Here are some things
that you should keep in mind


238
00:14:37,085 --> 00:14:38,420 line:-1
as you use this feature.


239
00:14:38,504 --> 00:14:41,882 line:-2
First, we strongly suggest
testing each model locally


240
00:14:41,965 --> 00:14:46,053 line:-2
before uploading it
on the Deployment dashboard.


241
00:14:46,136 --> 00:14:49,932 line:-2
This will ensure that your users
do not end up with models that don't work.


242
00:14:51,642 --> 00:14:57,397 line:-2
Next, be aware that the models you deploy
won't be available on devices right away.


243
00:14:57,481 --> 00:15:01,443 line:-2
Each device's system decides when to
download the model in the background.


244
00:15:01,527 --> 00:15:04,905 line:-2
Therefore, your app
should always have a fallback plan


245
00:15:04,988 --> 00:15:07,533 line:-1
when the deployed models aren't available.


246
00:15:09,034 --> 00:15:13,539 line:-2
Lastly, model collection provides
a convenient way to organize models.


247
00:15:13,622 --> 00:15:15,499 line:-2
We recommend
grouping your model collections


248
00:15:15,582 --> 00:15:18,627 line:-1
around each of your app's features.


249
00:15:18,710 --> 00:15:20,796 line:-1
So, to summarize what we've shown you:


250
00:15:20,879 --> 00:15:24,508 line:-2
Core ML Model Deployment is a new way
to deliver models to your users,


251
00:15:24,591 --> 00:15:26,677 line:-1
independent of app updates.


252
00:15:26,760 --> 00:15:30,848 line:-2
Model collections give you a new way
to group and work with your models,


253
00:15:30,931 --> 00:15:33,267 line:-1
and targeted deployments are super helpful


254
00:15:33,350 --> 00:15:37,479 line:-2
when you want to deploy models
to separate populations.


255
00:15:37,563 --> 00:15:40,148 line:-2
We think these features
will give you more flexibility


256
00:15:40,232 --> 00:15:44,695 line:-2
and make it more convenient
to deliver models to your users.


257
00:15:44,778 --> 00:15:47,573 line:-2
I'll hand it over to John Durant,
and he can tell us more


258
00:15:47,656 --> 00:15:50,826 line:-2
about some other exciting features
we have for you this year.


259
00:15:52,536 --> 00:15:53,704 line:-1
Thank you, Anil.


260
00:15:53,787 --> 00:15:55,956 line:-2
Hi, everyone,
and thank you for joining us.


261
00:15:56,039 --> 00:15:58,208 line:-2
We're really excited
to share these features with you,


262
00:15:58,292 --> 00:16:01,044 line:-2
and we can't wait to see
the amazing apps you'll build with them.


263
00:16:01,128 --> 00:16:03,922 line:-2
So far we've covered
some new and faster ways


264
00:16:04,006 --> 00:16:05,549 line:-1
to get your models to your users.


265
00:16:05,966 --> 00:16:08,510 line:-2
Now let's take a look
at how you can encrypt those models.


266
00:16:08,886 --> 00:16:11,471 line:-2
With model encryption,
you can distribute your models,


267
00:16:11,555 --> 00:16:14,766 line:-2
knowing that they are encrypted
at rest and in transit.


268
00:16:14,850 --> 00:16:17,561 line:-2
Let's take a look at what that means
and how it works.


269
00:16:17,978 --> 00:16:21,565 line:-2
Whether your model is bundled
with your app or deployed to the cloud,


270
00:16:21,648 --> 00:16:24,568 line:-2
what Xcode actually encrypts
is the compiled Core ML model.


271
00:16:24,651 --> 00:16:27,905 line:-2
This compiled model,
not the original .mlmodel file,


272
00:16:27,988 --> 00:16:31,658 line:-2
is what actually lives inside your app
on a user's device.


273
00:16:31,742 --> 00:16:34,369 line:-2
So, how do you encrypt
this compiled model?


274
00:16:34,453 --> 00:16:36,371 line:0
Easy. With Xcode.


275
00:16:36,455 --> 00:16:38,790 line:0
The first thing you'll need
is an encryption key.


276
00:16:38,874 --> 00:16:41,293 line:-2
I'll show you how to make a key
in a few minutes.


277
00:16:41,376 --> 00:16:45,214 line:-2
With the key, you can tell Xcode
to encrypt your model at build time.


278
00:16:45,297 --> 00:16:49,635 line:-2
Or you can use a key to encrypt
a model archive when you generate it.


279
00:16:49,718 --> 00:16:52,554 line:-2
Either way, the compiled model
stays encrypted in transit


280
00:16:52,638 --> 00:16:54,932 line:-1
and at rest on a user's device.


281
00:16:55,015 --> 00:16:58,644 line:-2
So, how do you use
an encrypted model at runtime?


282
00:16:58,727 --> 00:17:01,813 line:-2
Well, you use an encrypted model
just as you would a regular one.


283
00:17:02,231 --> 00:17:04,816 line:-2
Core ML automatically decrypts
the model for you,


284
00:17:04,900 --> 00:17:07,986 line:-2
but the decrypted model
only exists in memory.


285
00:17:08,069 --> 00:17:12,156 line:-2
The compiled model in the file system
remains encrypted at all times.


286
00:17:13,116 --> 00:17:15,160 line:-2
The first time you load
your encrypted model,


287
00:17:15,243 --> 00:17:17,788 line:-2
the OS securely fetches
and securely stores


288
00:17:17,871 --> 00:17:20,749 line:-2
the model's decryption key
on your app's behalf.


289
00:17:20,832 --> 00:17:22,917 line:-2
After that, your app won't need
a network connection


290
00:17:23,001 --> 00:17:24,586 line:-1
to load the same model again.


291
00:17:25,045 --> 00:17:27,339 line:-2
Let's jump in to Xcode
and see just how easy it is


292
00:17:27,422 --> 00:17:28,924 line:-1
to adopt model encryption.


293
00:17:29,007 --> 00:17:31,969 line:-2
I'll go back to the same app
that Anil was using before.


294
00:17:32,052 --> 00:17:34,513 line:-2
Let's say I want to encrypt
our image classification model.


295
00:17:35,013 --> 00:17:38,058 line:-2
The first thing I need to do
is create an encryption key.


296
00:17:38,141 --> 00:17:40,561 line:-2
To do that,
I'll open up the model in Xcode,


297
00:17:40,644 --> 00:17:43,105 line:-2
and I'm gonna go over here
to the utilities tab


298
00:17:44,314 --> 00:17:46,608 line:-2
and I'm gonna click on
"Create Encryption Key."


299
00:17:49,027 --> 00:17:52,281 line:-2
What we see here is that Xcode associates
the encryption key with a team,


300
00:17:52,364 --> 00:17:54,199 line:-2
and so it's important
to choose the same team account


301
00:17:54,283 --> 00:17:56,076 line:-1
that you use for building your app.


302
00:17:56,159 --> 00:17:59,746 line:-2
When I click on Continue,
Xcode sends a request to Apple cloud


303
00:17:59,830 --> 00:18:01,748 line:-1
which generates a new encryption key.


304
00:18:01,832 --> 00:18:06,670 line:-2
The server securely stores the key
and sends a copy back to Xcode.


305
00:18:06,753 --> 00:18:11,091 line:-2
So now we can see that Xcode generated
a new file with extension .mlmodelkey,


306
00:18:11,175 --> 00:18:13,969 line:-2
and it's dropped it
right next to my Core ML model.


307
00:18:14,052 --> 00:18:17,514 line:-2
So here we can see we have the .mlmodel
and the .mlmodelkey.


308
00:18:19,766 --> 00:18:21,560 line:-1
Okay, great. Now we have a key.


309
00:18:21,643 --> 00:18:25,314 line:-2
Now we can take this key and share it
on our team's secure key repository


310
00:18:25,397 --> 00:18:27,608 line:-2
so that other developers on our team
can use it.


311
00:18:29,276 --> 00:18:32,321 line:-2
Now that we have a key,
we can use it to encrypt our model.


312
00:18:32,404 --> 00:18:34,573 line:-2
First, let's look at the scenario
Anil showed earlier,


313
00:18:34,656 --> 00:18:38,702 line:-2
where he deployed the model
with the Core ML Model Deployment.


314
00:18:38,785 --> 00:18:40,829 line:-2
This time,
when I go create a model archive,


315
00:18:42,080 --> 00:18:45,792 line:-2
Xcode pre-selects the .mlmodelkey
sitting beside my model.


316
00:18:45,876 --> 00:18:46,877 line:-1
Let's click Continue,


317
00:18:48,170 --> 00:18:51,381 line:-2
and we'll see that Xcode generates
a model archive just like before,


318
00:18:51,465 --> 00:18:54,718 line:-2
but this time
it encrypts the contents of the archive.


319
00:18:54,801 --> 00:18:57,221 line:-2
The remaining steps
are exactly the same as before.


320
00:18:57,304 --> 00:18:59,848 line:-2
I can simply deploy
this encrypted model archive


321
00:18:59,932 --> 00:19:02,684 line:-2
by uploading it
to the Core ML Model Deployment dashboard


322
00:19:02,768 --> 00:19:03,936 line:-1
as Anil did earlier.


323
00:19:04,353 --> 00:19:06,146 line:-1
Okay, so that's great for deployments.


324
00:19:06,230 --> 00:19:09,024 line:-2
But what if I wanted to bundle the model
within the app itself?


325
00:19:09,107 --> 00:19:11,276 line:-2
Well, there's a way to encrypt
those models too.


326
00:19:11,360 --> 00:19:14,571 line:-2
In this app, I have a second model
called FlowerStylizer.


327
00:19:15,280 --> 00:19:18,075 line:-2
I'll run the app again
so we can see what this does.


328
00:19:18,158 --> 00:19:20,953 line:-2
When I pick an image
and then double-tap it,


329
00:19:21,036 --> 00:19:24,039 line:-2
we see that a cool style transfer effect
gets applied.


330
00:19:24,122 --> 00:19:25,123 line:-1
Looking good!


331
00:19:25,207 --> 00:19:27,459 line:-2
If you'd like to build
one of these models yourself,


332
00:19:27,543 --> 00:19:28,836 line:-1
you can check out the session called


333
00:19:28,919 --> 00:19:32,256 line:-2
"Build Image and Video Style
Transfer Models in Create ML."


334
00:19:32,339 --> 00:19:35,217 line:-2
Now this model is packaged
with my app bundle.


335
00:19:35,300 --> 00:19:37,803 line:-2
If I want to encrypt it,
I have to generate a key for it


336
00:19:37,886 --> 00:19:40,722 line:-2
and then tell Xcode
to encrypt the model at build time.


337
00:19:40,806 --> 00:19:42,516 line:-1
First, I'll generate a key for this model.


338
00:19:45,644 --> 00:19:48,772 line:-2
We see that FlowerClassifier.mlmodelkey
has been saved to disk.


339
00:19:50,232 --> 00:19:54,319 line:-2
Now what I need to do is tell Xcode to use
this key for encryption at build time.


340
00:19:56,363 --> 00:19:58,782 line:-2
I'm gonna go ahead
and grab these compiler flags.


341
00:19:58,866 --> 00:20:00,659 line:-2
I'm gonna go over
to my project properties,


342
00:20:00,742 --> 00:20:03,287 line:-1
Build Phases, Compile Sources,


343
00:20:03,370 --> 00:20:05,581 line:-2
and I'm going to look for my model.
There it is.


344
00:20:05,664 --> 00:20:08,834 line:-1
I've got FlowerStylizer.mlmodel.


345
00:20:08,917 --> 00:20:11,003 line:-2
And I'm gonna go over here
to Compiler Flags.


346
00:20:12,379 --> 00:20:15,966 line:-2
And I'm going to go ahead and paste in
dash-dash encrypt,


347
00:20:16,049 --> 00:20:20,053 line:-2
and then a pointer
to the .mlmodelkey file on disk.


348
00:20:21,680 --> 00:20:23,640 line:-2
Once we've done that,
we can go ahead and build again.


349
00:20:27,060 --> 00:20:28,645 line:-1
So now, each time when I build the app,


350
00:20:28,729 --> 00:20:30,689 line:-2
the Core ML Compiler
will compile the model


351
00:20:30,772 --> 00:20:33,901 line:-2
and then encrypt it
with the model's encryption key.


352
00:20:33,984 --> 00:20:37,487 line:-2
That means the app now has
this encrypted, compiled model built in.


353
00:20:37,571 --> 00:20:40,782 line:-2
Okay, so now let's look at
how we can load the encrypted model.


354
00:20:41,909 --> 00:20:45,954 line:-2
If we go over here, we see we have
a function called "Stylize the Image."


355
00:20:46,038 --> 00:20:49,416 line:-2
Now, since model loading needs
a network connection the first time,


356
00:20:49,499 --> 00:20:52,169 line:-2
we've introduced
an asynchronous model loading method.


357
00:20:52,252 --> 00:20:55,005 line:-1
That's right here. FlowerStylizer.load.


358
00:20:55,088 --> 00:20:57,174 line:-2
We're going to deprecate
the default initializer


359
00:20:57,257 --> 00:21:00,302 line:-2
and we strongly recommend
switching to the new .load method,


360
00:21:00,385 --> 00:21:04,389 line:-2
as it gives you an opportunity
to handle model load errors.


361
00:21:05,140 --> 00:21:07,809 line:-2
Load automatically fetches the key
from Apple cloud


362
00:21:07,893 --> 00:21:10,103 line:-1
and works just like you'd expect it to.


363
00:21:10,187 --> 00:21:13,857 line:-2
Even though Core ML needs network access
to get the key the first time,


364
00:21:13,941 --> 00:21:16,318 line:-2
it won't ever need
to fetch that key again.


365
00:21:16,401 --> 00:21:20,030 line:-2
For example, let's say you close your app
and later launch it again.


366
00:21:20,113 --> 00:21:22,783 line:-2
This time,
Core ML doesn't make a network request


367
00:21:22,866 --> 00:21:25,494 line:-2
because the OS
securely stored the key locally.


368
00:21:26,370 --> 00:21:28,580 line:-2
You can see we're getting back
a result of "T"


369
00:21:28,664 --> 00:21:32,084 line:-2
that contains the model,
and we can unwrap it in the success case,


370
00:21:32,167 --> 00:21:36,421 line:-2
at which point we have our model
and we can continue stylizing as before,


371
00:21:36,505 --> 00:21:38,590 line:-1
or we also have a failure case.


372
00:21:38,674 --> 00:21:41,051 line:-2
In the failure case,
we have a helper method


373
00:21:41,134 --> 00:21:44,930 line:-2
and you'll notice here we specifically
trap for a modelKeyFetch error.


374
00:21:45,013 --> 00:21:47,182 line:-2
And in that case,
we may want to let the user know


375
00:21:47,266 --> 00:21:50,894 line:-2
that they need network connectivity
or to try again later.


376
00:21:50,978 --> 00:21:54,064 line:-2
And that's it. Adopting model encryption
really is that simple.


377
00:21:54,481 --> 00:21:58,068 line:-2
So to recap, you can use model encryption
in three easy steps.


378
00:21:58,151 --> 00:22:01,238 line:-2
First, generate an encryption key
with Xcode.


379
00:22:01,321 --> 00:22:04,741 line:-2
Next, encrypt your model
with the encryption key.


380
00:22:04,825 --> 00:22:09,371 line:-2
And finally, load and use
the encrypted model on the device.


381
00:22:09,454 --> 00:22:13,250 line:-1
Create, encrypt, load. It's that simple.


382
00:22:14,126 --> 00:22:17,838 line:-2
Model encryption works seamlessly
whether you bundle a model in your app


383
00:22:17,921 --> 00:22:20,215 line:-1
or send one through a Model Deployment.


384
00:22:20,299 --> 00:22:24,845 line:-2
All you have to do is create a key,
encrypt your model, and call .load.


385
00:22:24,928 --> 00:22:28,432 line:-2
We'll handle the rest of it
so you can focus on making a great app.


386
00:22:28,891 --> 00:22:32,811 line:-2
Before we finish, we have a few more
exciting Xcode updates for Core ML


387
00:22:32,895 --> 00:22:34,062 line:-1
that we'd like to share with you.


388
00:22:34,897 --> 00:22:37,566 line:-2
During our demos, you may have noticed
that Xcode now shows you


389
00:22:37,649 --> 00:22:39,985 line:-1
a lot more information about your model.


390
00:22:40,068 --> 00:22:43,155 line:-2
At a glance, you can now see
which OS versions a model supports,


391
00:22:43,238 --> 00:22:47,451 line:-2
its class labels, and even
some internal neural network details.


392
00:22:47,534 --> 00:22:49,870 line:-2
Another new feature
we think is particularly useful,


393
00:22:49,953 --> 00:22:52,789 line:-2
not to mention fun,
is the interactive model preview.


394
00:22:54,249 --> 00:22:57,377 line:-2
Now you can interactively preview
and experiment with your model


395
00:22:57,461 --> 00:23:00,839 line:-2
directly in Xcode,
before you write a single line of code.


396
00:23:00,923 --> 00:23:03,300 line:-2
We support previews
for a wide variety of models,


397
00:23:03,383 --> 00:23:05,302 line:-1
such as image segmentation,


398
00:23:06,345 --> 00:23:10,891 line:-2
pose detection, depth estimation,
and many more,


399
00:23:10,974 --> 00:23:14,228 line:-2
including all the models you can train
with Create ML.


400
00:23:14,311 --> 00:23:16,939 line:-2
The full list of preview types
is listed here,


401
00:23:17,022 --> 00:23:21,068 line:-2
and we encourage you to explore the models
available on developer.apple.com.


402
00:23:22,319 --> 00:23:24,446 line:-2
We are also happy to announce
that Core ML models


403
00:23:24,530 --> 00:23:27,699 line:-2
are now first-class citizens
in Xcode Playgrounds.


404
00:23:27,783 --> 00:23:31,453 line:-2
Simply drag and drop a Core ML model
into your resources folder.


405
00:23:31,537 --> 00:23:34,373 line:-2
Now your Playground gets
the same auto-generated class interface


406
00:23:34,456 --> 00:23:36,124 line:-1
as an Xcode project.


407
00:23:36,208 --> 00:23:38,752 line:-2
This allows you to programmatically
experiment with your model


408
00:23:38,836 --> 00:23:41,797 line:-1
in a live, interactive coding session.


409
00:23:41,880 --> 00:23:44,758 line:-2
Playgrounds are also a great way
to share your model demonstrations


410
00:23:44,842 --> 00:23:46,218 line:-1
with friends and colleagues.


411
00:23:46,760 --> 00:23:49,471 line:-2
We've covered a lot of ground today,
so let's do a quick recap.


412
00:23:49,930 --> 00:23:52,516 line:-1
We introduced Core ML Model Deployment,


413
00:23:52,599 --> 00:23:56,854 line:-2
which allows you to deliver Core ML models
independently from your app.


414
00:23:56,937 --> 00:23:59,356 line:-2
This makes it really easy
to quickly distribute


415
00:23:59,439 --> 00:24:02,025 line:-2
and target your models
as you improve them.


416
00:24:02,109 --> 00:24:04,778 line:-2
We think this will greatly accelerate
the app development process


417
00:24:04,862 --> 00:24:07,447 line:-2
and how quickly
you can adopt machine learning.


418
00:24:08,365 --> 00:24:10,534 line:-1
We also introduced model encryption,


419
00:24:10,617 --> 00:24:13,745 line:-2
which protects your models in transit
and at rest,


420
00:24:13,829 --> 00:24:17,708 line:-2
without having to set up
your own hosting and key management.


421
00:24:17,791 --> 00:24:19,835 line:-1
Now you can encrypt Core ML models,


422
00:24:19,918 --> 00:24:24,047 line:-2
whether they ship with your app
or as part of a Model Deployment.


423
00:24:24,131 --> 00:24:27,217 line:-2
And finally, we added
some Core ML enhancements to Xcode,


424
00:24:27,301 --> 00:24:31,555 line:-2
making it easier for you to understand,
preview and interact with your models.


425
00:24:32,014 --> 00:24:35,601 line:-2
Thank you for watching our session
and enjoy the rest of WWDC.

