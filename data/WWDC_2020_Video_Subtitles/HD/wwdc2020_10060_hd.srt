1
00:00:03,937 --> 00:00:07,040 line:-1
Hello, and welcome to WWDC.


2
00:00:07,608 --> 00:00:09,977 line:0
Hi, I'm Danny Mandel,


3
00:00:10,043 --> 00:00:12,312 line:0
and I'm here to talk about
how we make sure


4
00:00:12,379 --> 00:00:17,217 line:0
your SiriKit Media apps have the
highest-quality Siri experience possible.


5
00:00:17,918 --> 00:00:19,853 line:-1
Why do we care about quality?


6
00:00:20,287 --> 00:00:23,824 line:-2
I think we all want to build things
people will enjoy using,


7
00:00:23,891 --> 00:00:27,561 line:-2
and nobody enjoys using
bad voice implementations.


8
00:00:27,628 --> 00:00:30,397 line:-2
Additionally, the trust barrier
for voice assistants


9
00:00:30,464 --> 00:00:33,834 line:-2
is even higher
than with a traditional user interface.


10
00:00:33,901 --> 00:00:37,871 line:-2
So the reliability needs to be even better
to maintain usage.


11
00:00:37,938 --> 00:00:41,208 line:-2
If you're going to take the time
to build SiriKit Media support,


12
00:00:41,275 --> 00:00:42,743 line:-1
take the time to make it good.


13
00:00:43,777 --> 00:00:46,113 line:-1
This might sound kind of silly,


14
00:00:46,180 --> 00:00:48,215 line:-2
but the single most important thing
you can do


15
00:00:48,282 --> 00:00:50,317 line:-2
is play something
when someone asks to play.


16
00:00:51,451 --> 00:00:52,819 line:-1
And think about it.


17
00:00:52,886 --> 00:00:56,356 line:-2
If the first time someone is excited
to use your app with voice


18
00:00:56,423 --> 00:00:59,860 line:-2
and nothing plays,
they probably won't ask again.


19
00:00:59,927 --> 00:01:03,330 line:-2
So having a robust playback stack
is the first place


20
00:01:03,397 --> 00:01:05,766 line:-2
you're going to want to invest
your Siri engineering resources.


21
00:01:07,534 --> 00:01:11,271 line:-2
And the next thing we want to do is
make sure that we start playback quickly.


22
00:01:11,939 --> 00:01:15,809 line:-2
Over the past year, we've learned that
one of the single biggest failure cases


23
00:01:15,876 --> 00:01:17,678 line:-1
in SiriKit Media apps are timeouts.


24
00:01:18,745 --> 00:01:21,215 line:-1
Particularly in environments like CarPlay,


25
00:01:21,281 --> 00:01:23,750 line:-2
starting playback quickly
is really important.


26
00:01:24,151 --> 00:01:27,387 line:-2
In cases like CarPlay,
when you're hands-free on the road,


27
00:01:27,454 --> 00:01:29,623 line:-1
we can be more aggressive with timeouts,


28
00:01:29,690 --> 00:01:33,727 line:-2
and your app will get killed off
if it doesn't start playback quickly.


29
00:01:33,794 --> 00:01:38,165 line:-2
To help, we added a couple new options
for performance enhancements this year,


30
00:01:38,232 --> 00:01:39,766 line:-1
so make sure to check out


31
00:01:39,833 --> 00:01:43,704 line:-2
"Expand your SiriKit Media Intents
to More Platforms" for more details.


32
00:01:45,239 --> 00:01:47,541 line:-2
Another way to make
a high-quality experience


33
00:01:47,608 --> 00:01:50,611 line:-2
is to let Siri understand
your listeners' preferences.


34
00:01:50,677 --> 00:01:54,748 line:-2
The way you do this is by adopting
the Siri user vocabulary API.


35
00:01:55,682 --> 00:01:59,152 line:-2
Similarly, you can help Siri
to understand your app's catalog


36
00:01:59,219 --> 00:02:02,789 line:-1
by adopting Siri's global vocabulary API.


37
00:02:02,856 --> 00:02:06,159 line:-2
We'll do a deep dive on both of these
topics a little later in this talk.


38
00:02:08,228 --> 00:02:10,663 line:-2
When you're choosing
the perfect thing to play,


39
00:02:10,731 --> 00:02:13,734 line:-2
you're going to want to allow people
to ask in different ways.


40
00:02:14,201 --> 00:02:17,004 line:-2
The more utterances
you can support in your app,


41
00:02:17,070 --> 00:02:21,175 line:-2
the more likely people are going to
want to use it in their everyday lives.


42
00:02:21,241 --> 00:02:25,812 line:-2
After all, the promise of Siri
is that it's an intelligent assistant.


43
00:02:25,879 --> 00:02:27,748 line:-1
And it's only truly intelligent


44
00:02:27,814 --> 00:02:31,385 line:-2
if we support a wide variety
of natural-language utterances.


45
00:02:31,885 --> 00:02:35,322 line:-2
So let's take a look at some of the most
common natural-language patterns


46
00:02:35,389 --> 00:02:38,258 line:-1
we see across all SiriKit Media apps.


47
00:02:38,325 --> 00:02:40,694 line:-1
What do we mean by perfect-ish?


48
00:02:40,761 --> 00:02:45,299 line:-2
Ultimately, perfect-ish is the best guess
when you don't know what someone wants.


49
00:02:46,033 --> 00:02:49,636 line:-2
And we see greater than half
of all SiriKit Media requests


50
00:02:49,703 --> 00:02:50,904 line:-1
follow this kind of pattern.


51
00:02:50,971 --> 00:02:55,909 line:-2
Requests as simple as "play your app"
or "play music on your app."


52
00:02:55,976 --> 00:02:58,312 line:-1
And that makes this generic case,


53
00:02:58,378 --> 00:03:01,782 line:-2
when someone doesn't tell you specifically
what they actually want,


54
00:03:01,849 --> 00:03:04,718 line:-2
the single most important use case
to get right.


55
00:03:04,785 --> 00:03:06,954 line:-1
By making sure you handle this scenario,


56
00:03:07,020 --> 00:03:10,824 line:-2
you can service a huge amount
of listeners off the bat.


57
00:03:10,891 --> 00:03:14,761 line:-2
It's up to you to decide
what perfect-ish means for your app.


58
00:03:14,828 --> 00:03:16,163 line:-1
But make sure it does something


59
00:03:16,230 --> 00:03:18,932 line:-2
that will give people
that classic surprise and delight.


60
00:03:19,766 --> 00:03:22,769 line:0
The way you'll know someone asked
for these very generic cases


61
00:03:22,836 --> 00:03:25,105 line:0
is you'll either get a nil media search


62
00:03:25,172 --> 00:03:28,675 line:0
or a media search containing
a media type of music.


63
00:03:28,742 --> 00:03:31,945 line:-2
Our next important use case
is the "play something" use case,


64
00:03:32,012 --> 00:03:35,582 line:-2
where people specify the title
of what it is they want to play.


65
00:03:35,649 --> 00:03:37,484 line:-1
They won't say what the media type is,


66
00:03:37,551 --> 00:03:41,955 line:-2
so it could be a song, album,
artist, podcast, you won't know.


67
00:03:42,022 --> 00:03:44,458 line:-2
It's important
that when you implement this case,


68
00:03:44,525 --> 00:03:48,128 line:-2
you accommodate for different media types
and execute a very broad search.


69
00:03:49,329 --> 00:03:51,398 line:0
The way you'll recognize
this kind of request


70
00:03:51,465 --> 00:03:54,067 line:0
is that there will only be
a media name populated


71
00:03:54,134 --> 00:03:56,003 line:0
in the media-search object.


72
00:03:56,069 --> 00:03:58,539 line:0
We see about 30% of queries like this.


73
00:03:59,006 --> 00:04:02,309 line:-2
Moving down the list,
we start to see more precise queries,


74
00:04:02,376 --> 00:04:05,646 line:-2
with a combination of artist
and some other search field.


75
00:04:05,712 --> 00:04:09,049 line:0
So make sure you support
these compound searches with artists.


76
00:04:09,116 --> 00:04:11,485 line:0
In this case,
you'll get a populated media name


77
00:04:11,552 --> 00:04:13,754 line:0
with the title of what someone asked for,


78
00:04:13,820 --> 00:04:17,690 line:0
and then also an artist's name
with the artist they're looking for.


79
00:04:17,757 --> 00:04:20,459 line:0
As we start to get more specific
in the query types,


80
00:04:20,527 --> 00:04:22,563 line:0
we do see the usage start to go down


81
00:04:22,629 --> 00:04:26,200 line:0
and see usage of this pattern
at around five percent of requests.


82
00:04:26,266 --> 00:04:29,469 line:-2
A final category where we see
a lot of usage is playlists.


83
00:04:29,536 --> 00:04:31,705 line:-2
So make sure you support
playlist searching.


84
00:04:31,772 --> 00:04:34,808 line:0
Again, this is
one of the more specific queries,


85
00:04:34,875 --> 00:04:38,545 line:0
and we do see its usage
at around five percent of the time.


86
00:04:38,612 --> 00:04:41,281 line:0
When someone includes a playlist query
in their utterance,


87
00:04:41,348 --> 00:04:44,751 line:0
we'll get the media-name property
populated with the playlist query


88
00:04:44,818 --> 00:04:47,554 line:0
and the media-type property
will be set to "playlist."


89
00:04:48,188 --> 00:04:49,556 line:-1
The list does continue,


90
00:04:49,623 --> 00:04:52,926 line:-2
as there's a number of other search fields
in INMediaSearch.


91
00:04:52,993 --> 00:04:55,596 line:-2
But you can see
with just these four use cases,


92
00:04:55,662 --> 00:05:00,667 line:-2
we've captured more than 90%
of the current SiriKit Media traffic.


93
00:05:00,734 --> 00:05:04,838 line:-2
Please do implement as many other fields
as makes sense for your app.


94
00:05:04,905 --> 00:05:08,242 line:-2
But it does make sense to prioritize
your engineering and QA


95
00:05:08,308 --> 00:05:10,410 line:-1
around the popular use cases,


96
00:05:10,477 --> 00:05:12,946 line:-2
as these are what people
are most likely to use.


97
00:05:13,013 --> 00:05:14,915 line:-1
And one final note on this.


98
00:05:14,982 --> 00:05:18,051 line:-2
We've also seen that
the better your Siri support is,


99
00:05:18,118 --> 00:05:22,656 line:-2
the more likely it is that people
will make more complicated Siri requests.


100
00:05:22,723 --> 00:05:26,894 line:-2
So as you make it better,
expect the usage patterns to change.


101
00:05:26,960 --> 00:05:28,428 line:-1
That's a good thing.


102
00:05:28,495 --> 00:05:31,164 line:-2
That means they like
using your app with Siri.


103
00:05:31,231 --> 00:05:33,400 line:-2
We just looked
at the high-traffic utterances


104
00:05:33,467 --> 00:05:36,436 line:-2
and saw how we can capture
the vast majority of usage


105
00:05:36,503 --> 00:05:38,238 line:-1
with just a few intents.


106
00:05:38,305 --> 00:05:40,507 line:-2
So let's look at those intents
in the debugger,


107
00:05:40,574 --> 00:05:43,544 line:-2
and see what the media search looks like
in each case.


108
00:05:46,480 --> 00:05:49,683 line:-2
All right,
we're gonna put a breakpoint here,


109
00:05:49,750 --> 00:05:51,985 line:-2
so we can see
what the media search looks like.


110
00:06:01,762 --> 00:06:05,265 line:-2
The first utterance we'll look at
is the empty play case.


111
00:06:05,332 --> 00:06:06,700 line:-1
"Play ControlAudio."


112
00:06:16,743 --> 00:06:18,812 line:-1
All right. Looking at our breakpoint,


113
00:06:18,879 --> 00:06:22,082 line:-2
we can see that in this case,
there is no media search.


114
00:06:22,149 --> 00:06:25,485 line:-2
This makes sense because
we didn't specify any search criteria.


115
00:06:26,053 --> 00:06:29,122 line:-2
Now let's look at
"play music in ControlAudio".


116
00:06:41,134 --> 00:06:44,505 line:0
In this case, we can see that
we have the music media type set,


117
00:06:44,571 --> 00:06:47,007 line:0
and all the other fields are empty.


118
00:06:47,474 --> 00:06:52,613 line:-2
Now a sample case of "play
Special Disaster Team in ControlAudio".


119
00:07:08,295 --> 00:07:09,663 line:0
And as we expected,


120
00:07:09,730 --> 00:07:13,166 line:0
we see "Special Disaster Team"
in our media name.


121
00:07:13,934 --> 00:07:18,772 line:-2
Now let's try a more advanced case
and include both a title and an artist.


122
00:07:30,184 --> 00:07:35,489 line:0
All right, here we can see that we have
a media name of "Maybe Sometime."


123
00:07:35,556 --> 00:07:40,694 line:0
And similarly,
"Special Disaster Team" in artist name.


124
00:07:40,761 --> 00:07:43,197 line:0
And the rest of the fields
aren't populated.


125
00:07:43,263 --> 00:07:45,432 line:-1
The last one to check was playlists.


126
00:07:45,499 --> 00:07:49,436 line:-2
So we're going to try
"play my WWDC playlist in ControlAudio".


127
00:08:07,321 --> 00:08:09,690 line:0
Since we included the word "playlist"
in the utterance,


128
00:08:09,756 --> 00:08:13,627 line:0
we can see we have the playlist media type
as a parameter


129
00:08:13,694 --> 00:08:17,631 line:0
and then we also have a media name
of WWDC.


130
00:08:17,698 --> 00:08:19,066 line:-1
With just those few intents,


131
00:08:19,132 --> 00:08:22,903 line:-2
we can capture the vast majority
of Siri traffic in our intent handler.


132
00:08:23,570 --> 00:08:27,608 line:-2
Now let's do a deep dive
on SiriKit Media vocabulary features.


133
00:08:27,674 --> 00:08:32,379 line:-2
Siri's natural-language-processing system
is a machine-learned system.


134
00:08:32,746 --> 00:08:35,849 line:-2
And what that means
is there's a probabilistic model


135
00:08:35,916 --> 00:08:37,851 line:-1
that will try and predict someone's intent


136
00:08:37,918 --> 00:08:40,621 line:-2
when they ask Siri
to perform a particular action.


137
00:08:41,421 --> 00:08:44,091 line:-2
What it also means
is that the model has been trained


138
00:08:44,157 --> 00:08:45,792 line:-1
to recognize particular features.


139
00:08:46,927 --> 00:08:50,130 line:-2
For example, you don't need to teach Siri
about music genres,


140
00:08:50,197 --> 00:08:53,133 line:-1
media types, sorts, or release dates,


141
00:08:53,200 --> 00:08:55,469 line:-2
because the Siri model
has already been trained


142
00:08:55,536 --> 00:08:58,705 line:-2
to recognize these features
when people ask.


143
00:08:58,772 --> 00:09:02,843 line:-2
And generally speaking, this is good from
an engineering and a usage perspective.


144
00:09:03,477 --> 00:09:07,147 line:-2
For engineering, it means that we don't
need to do additional model training


145
00:09:07,214 --> 00:09:10,717 line:-2
every time a new app adopts
SiriKit Media Intents.


146
00:09:10,784 --> 00:09:13,687 line:-2
And from a usage perspective,
it's also nice,


147
00:09:13,754 --> 00:09:17,257 line:-2
because if someone knows
how to use one SiriKit Media app,


148
00:09:17,324 --> 00:09:19,526 line:-1
they know how to use them all.


149
00:09:19,593 --> 00:09:24,131 line:-2
However, like with all systems,
sometimes this can cause problems.


150
00:09:25,365 --> 00:09:27,734 line:-1
For example, in ControlAudio,


151
00:09:27,801 --> 00:09:30,637 line:-2
say we have a playlist called
"70s punk classics."


152
00:09:31,805 --> 00:09:35,175 line:-2
By default, the Siri model
is probably going to parse this


153
00:09:35,242 --> 00:09:38,846 line:-2
as a media release date
corresponding to the 1970s


154
00:09:38,912 --> 00:09:41,148 line:-1
and a media name of punk classics.


155
00:09:41,882 --> 00:09:43,917 line:-1
So ControlAudio is going to get an intent


156
00:09:43,984 --> 00:09:46,653 line:-2
that doesn't exactly map
to the name of that playlist.


157
00:09:47,754 --> 00:09:52,259 line:-2
The way we solve this
is to sync additional vocabulary to Siri,


158
00:09:52,326 --> 00:09:55,429 line:-2
so that Siri knows
that "70s punk classics"


159
00:09:55,495 --> 00:09:57,998 line:-1
is the name of a playlist in ControlAudio.


160
00:09:58,799 --> 00:10:01,502 line:-2
Now let's look at two different ways
to accomplish this.


161
00:10:01,568 --> 00:10:04,438 line:-2
The first way we can teach Siri
about our catalog


162
00:10:04,505 --> 00:10:08,041 line:-2
is by using
Siri's user vocabulary feature.


163
00:10:08,108 --> 00:10:10,544 line:-2
You're going to want to use
the user vocabulary feature


164
00:10:10,611 --> 00:10:13,280 line:-2
for things that apply
only to a particular person,


165
00:10:13,347 --> 00:10:16,183 line:-2
as opposed to all people
that use your app.


166
00:10:16,250 --> 00:10:20,921 line:-2
You share the vocabulary with Siri
using the INVocabulary API.


167
00:10:20,988 --> 00:10:22,689 line:-1
So let's take a quick look at that.


168
00:10:24,591 --> 00:10:28,295 line:-2
You just get a reference
to the shared instance of INVocabulary.


169
00:10:29,696 --> 00:10:32,766 line:-2
Create an ordered set
with the values you want to store.


170
00:10:32,833 --> 00:10:34,034 line:-1
One note here.


171
00:10:34,101 --> 00:10:37,171 line:-2
Make sure the important ones
are at the beginning of the set,


172
00:10:37,237 --> 00:10:39,306 line:-1
as Siri does pay attention to the order.


173
00:10:41,275 --> 00:10:44,878 line:-2
Then call setVocabularyStrings
on the type you want to store,


174
00:10:44,945 --> 00:10:48,482 line:-2
which, in this case,
is mediaPlaylistTitle.


175
00:10:48,549 --> 00:10:50,984 line:-1
When you're working with INVocabulary,


176
00:10:51,051 --> 00:10:54,021 line:-2
you'll generally want to focus
on user-created content


177
00:10:54,087 --> 00:10:55,322 line:-1
like someone's playlists.


178
00:10:55,956 --> 00:11:00,327 line:-2
However, you could also use it to bias
speech-and-natural-language recognition


179
00:11:00,394 --> 00:11:04,731 line:-2
towards the taste profile around
music artists or subscribed podcasts.


180
00:11:05,365 --> 00:11:09,002 line:-2
Global vocabulary, on the other hand,
is appropriate for things


181
00:11:09,069 --> 00:11:12,105 line:-2
that are available for all people
that use your app.


182
00:11:12,172 --> 00:11:16,276 line:-2
And unlike user vocabulary,
since global vocabulary is static,


183
00:11:16,343 --> 00:11:19,780 line:-2
you package it up in a .plist
that you distribute as part of your app.


184
00:11:20,614 --> 00:11:24,384 line:-2
Note that you only need to include things
that are particular to your app.


185
00:11:24,451 --> 00:11:28,255 line:-2
So you don't need to include
popular music or podcast entities,


186
00:11:28,322 --> 00:11:32,092 line:-2
as those are generally already recognized
by Siri as part of its NL model.


187
00:11:32,659 --> 00:11:36,496 line:-2
So here's an example
of a global vocabulary .plist.


188
00:11:36,563 --> 00:11:39,800 line:-2
The first thing to note is that
this example is syncing data


189
00:11:39,867 --> 00:11:43,036 line:-2
to the INPlayMediaIntent.playlistTitle
field.


190
00:11:43,103 --> 00:11:46,807 line:-2
The next thing to note is that
the identifier for the vocabulary item


191
00:11:46,874 --> 00:11:48,909 line:-1
is "70s punk anthems".


192
00:11:48,976 --> 00:11:52,379 line:-2
The identifier is the value
that you'll receive from Siri,


193
00:11:52,446 --> 00:11:56,016 line:-1
in the INMediaSearch mediaName field.


194
00:11:56,083 --> 00:11:59,219 line:-2
This identifier is going to be the key
to let Siri know


195
00:11:59,286 --> 00:12:01,655 line:-1
that the string "70s punk anthems"


196
00:12:01,722 --> 00:12:04,424 line:-2
matches up to a playlist
in your app catalog.


197
00:12:06,093 --> 00:12:09,429 line:0
As you can see here, we have a number
of different types of vocabulary


198
00:12:09,496 --> 00:12:12,833 line:0
that you'll want to use depending on
the media types your application supports.


199
00:12:13,767 --> 00:12:16,069 line:0
You'll note that the data type
for user vocabulary


200
00:12:16,136 --> 00:12:18,972 line:0
and the key in global vocabulary
have different naming,


201
00:12:19,039 --> 00:12:21,775 line:0
but they ultimately sync to Siri
in the same place.


202
00:12:22,376 --> 00:12:26,413 line:0
For music apps, we have playlistTitle's
and musicArtistName's.


203
00:12:27,247 --> 00:12:30,050 line:0
For audiobook apps,
we have audiobookTitle's


204
00:12:30,117 --> 00:12:32,152 line:0
and audiobookAuthorName's.


205
00:12:32,853 --> 00:12:36,056 line:0
And radio and podcasting apps
can use the showTitle type.


206
00:12:36,123 --> 00:12:39,493 line:-2
Let's take a look
at how using the Siri vocabulary features


207
00:12:39,560 --> 00:12:42,496 line:-2
can influence the intent
Siri delivers to your app.


208
00:12:42,563 --> 00:12:46,233 line:-2
We'll use the example,
"Put on some '70s punk classics"


209
00:12:46,300 --> 00:12:47,901 line:-1
as an intent that Siri could deliver


210
00:12:47,968 --> 00:12:50,671 line:-2
that might not match up
with what your app expects.


211
00:12:50,737 --> 00:12:52,806 line:-2
So let's take a look at that
in the debugger.


212
00:12:57,477 --> 00:12:59,580 line:-2
All right.
So now we're gonna go set the scheme


213
00:13:00,380 --> 00:13:02,182 line:-1
and test with that utterance.


214
00:13:11,425 --> 00:13:12,693 line:-1
And we'll run it.


215
00:13:13,760 --> 00:13:18,131 line:0
Okay. So the intent we got
isn't quite matching up


216
00:13:18,198 --> 00:13:21,301 line:0
with the playlist title
that we were hoping for.


217
00:13:21,368 --> 00:13:27,207 line:0
We have a genre name of "punk,"
we have a decade of the '70s.


218
00:13:27,274 --> 00:13:30,143 line:0
So let's go fix that. All right.


219
00:13:30,210 --> 00:13:36,416 line:0
So we're going to add the vocabulary
into our app delegate.


220
00:13:36,483 --> 00:13:38,585 line:0
One important thing to note
about this code


221
00:13:38,652 --> 00:13:41,455 line:0
is that the vocabulary is an ordered set.


222
00:13:41,889 --> 00:13:44,558 line:0
And the reason for this
is that Siri is going to prioritize


223
00:13:44,625 --> 00:13:46,627 line:0
the items at the beginning of the list.


224
00:13:46,693 --> 00:13:50,197 line:0
So make sure that the most important items
are at the beginning,


225
00:13:50,264 --> 00:13:53,634 line:0
as there are a limit to the number
of items that Siri will recognize.


226
00:13:54,434 --> 00:13:57,804 line:-2
Now that it's set up,
let's run the ControlAudio app


227
00:13:57,871 --> 00:14:01,041 line:-2
and make sure it has a chance to sync up
to the Siri server.


228
00:14:01,508 --> 00:14:05,512 line:-2
A note about this. In a real-world
scenario, it may take a bit of time


229
00:14:05,579 --> 00:14:08,482 line:-2
before the vocabulary is synced up
to the Siri server


230
00:14:08,549 --> 00:14:11,251 line:-2
as it's subject to network
and power conditions.


231
00:14:15,889 --> 00:14:17,791 line:-1
All right. It synced up,


232
00:14:17,858 --> 00:14:21,261 line:-2
so let's run the intent handler again
with the same phrase


233
00:14:21,328 --> 00:14:23,130 line:-1
and look at the intent we get.


234
00:14:26,400 --> 00:14:28,836 line:0
Okay. The first thing to note


235
00:14:28,902 --> 00:14:33,540 line:0
is that we got the media type of playlist
set in the media search.


236
00:14:33,941 --> 00:14:36,310 line:0
Siri recognized
it got a user vocabulary hit,


237
00:14:36,376 --> 00:14:38,145 line:0
and it set the media type for us.


238
00:14:38,212 --> 00:14:40,214 line:0
And the media name is as we hoped,


239
00:14:40,280 --> 00:14:43,917 line:0
and it has the full string
"'70s punk classics" in it.


240
00:14:43,984 --> 00:14:48,422 line:-2
That's user vocabulary. Let's take
a similar look at global vocabulary.


241
00:14:48,488 --> 00:14:53,393 line:-2
As a reminder, global vocabulary .plist
is available to everyone using your app


242
00:14:53,460 --> 00:14:56,763 line:-2
as opposed to user vocabulary,
which is on a per-user basis.


243
00:14:56,830 --> 00:14:59,066 line:-1
So the first thing we're gonna do


244
00:14:59,132 --> 00:15:03,370 line:-2
is we're gonna add our vocabulary .plist
to ControlAudio.


245
00:15:10,677 --> 00:15:12,212 line:-1
And let's take a look at it.


246
00:15:15,649 --> 00:15:19,353 line:-2
All right. Let's focus
on the parameter vocabularies key.


247
00:15:19,419 --> 00:15:22,689 line:-2
The first thing we'll do
is look at the parameter names.


248
00:15:22,756 --> 00:15:26,727 line:-2
In this case, we're defining vocabulary
for playlist titles,


249
00:15:26,793 --> 00:15:30,564 line:-2
so we see the value is
INPlayMediaIntent.playlistTitle.


250
00:15:32,099 --> 00:15:35,602 line:-2
Now we can see
that the parameter vocabulary


251
00:15:35,669 --> 00:15:39,006 line:-2
has a value
for Vocabulary Item Identifier.


252
00:15:39,072 --> 00:15:43,243 line:-2
The identifier is the value you'll receive
in the Intents Media Search.


253
00:15:43,310 --> 00:15:46,313 line:-2
And in this case,
we tweaked it from the previous example


254
00:15:46,380 --> 00:15:48,315 line:-1
and called it "'70s punk anthems."


255
00:15:48,382 --> 00:15:52,119 line:-2
So now that we have
the global vocabulary file added,


256
00:15:52,186 --> 00:15:55,322 line:-2
let's give it a whirl and see what we get
in the intent handler.


257
00:16:08,502 --> 00:16:10,938 line:-1
Okay. Looking at the intent again,


258
00:16:11,004 --> 00:16:13,574 line:-2
we can see
that we got the playlist media type...


259
00:16:14,575 --> 00:16:19,379 line:-2
and we see our expected playlist title
of '70s punk anthems.


260
00:16:20,647 --> 00:16:23,617 line:-2
And that's how you can use
Siri global vocabulary


261
00:16:23,684 --> 00:16:26,286 line:-2
to make sure that Siri knows
about the entities


262
00:16:26,353 --> 00:16:28,989 line:-2
that are important
to everyone using your app.


263
00:16:29,056 --> 00:16:34,061 line:-2
One of the bigger Siri use cases we see
with media apps are Now Playing controls,


264
00:16:34,127 --> 00:16:36,430 line:-2
so you're going to want to make sure
to test these out.


265
00:16:36,496 --> 00:16:42,236 line:-2
iOS's Now Playing support is implemented
using the MPRemoteCommandCenter class.


266
00:16:42,970 --> 00:16:45,472 line:-2
The way this works
is you register a command handler


267
00:16:45,539 --> 00:16:47,674 line:-1
for a particular Now Playing command.


268
00:16:47,741 --> 00:16:49,409 line:-1
Some examples of Now Playing commands


269
00:16:49,476 --> 00:16:52,646 line:-2
are "play," "pause," "next track"
or "previous track."


270
00:16:52,713 --> 00:16:55,883 line:-2
The basic idea is that if there's
a button in control center


271
00:16:55,949 --> 00:16:57,885 line:-1
or on the CarPlay Now Playing screen,


272
00:16:57,951 --> 00:17:00,420 line:-2
then there's a corresponding
Now Playing command class.


273
00:17:00,487 --> 00:17:03,357 line:0
And there's a really great existing
sample code project


274
00:17:03,423 --> 00:17:06,727 line:0
that dives into the details
of the Now Playing API called


275
00:17:06,792 --> 00:17:08,729 line:0
Becoming a Now Playable App.


276
00:17:08,795 --> 00:17:10,763 line:0
And I'd encourage you
to take a look at that


277
00:17:10,830 --> 00:17:14,167 line:0
if you're interested in more details
about how this all works.


278
00:17:15,335 --> 00:17:19,705 line:-2
Siri acts as a simple voice interface
on top of particular Now Playing commands.


279
00:17:19,772 --> 00:17:23,810 line:-2
This behavior isn't new. In fact,
it's been around for many years now.


280
00:17:24,478 --> 00:17:27,513 line:-2
So, what happens when you issue
a Now Playing command to Siri?


281
00:17:28,916 --> 00:17:31,585 line:-2
Like most Siri commands,
the first thing that happens


282
00:17:31,652 --> 00:17:33,787 line:-1
is Siri recognizes what someone says.


283
00:17:34,254 --> 00:17:36,990 line:-2
In this case,
the utterance is "next track."


284
00:17:37,858 --> 00:17:42,362 line:-2
Once Siri does that, it sends a command
to the MPRemoteCommandCenter.


285
00:17:42,429 --> 00:17:45,165 line:-2
In this case,
because the person said, "Next track,"


286
00:17:45,232 --> 00:17:47,267 line:-1
it's going to send the next-track command.


287
00:17:48,001 --> 00:17:52,206 line:-2
Finally, your app's registered handler
for next-track command is invoked


288
00:17:52,272 --> 00:17:55,509 line:-2
and you have the opportunity
to handle the next-track command.


289
00:17:56,009 --> 00:17:58,045 line:-1
Note that since this implementation


290
00:17:58,111 --> 00:18:00,881 line:-2
is the same thing
that's handling button presses,


291
00:18:00,948 --> 00:18:03,317 line:-2
your Siri handling
and Now Playing button presses


292
00:18:03,383 --> 00:18:05,619 line:-1
will have identical implementations.


293
00:18:06,019 --> 00:18:08,488 line:-1
In most cases, this is probably okay.


294
00:18:08,555 --> 00:18:11,458 line:-2
It's just something you'll want to keep
in mind as you're implementing them.


295
00:18:11,525 --> 00:18:15,562 line:-2
Let's walk through a few of the commands
and how you invoke them via Siri.


296
00:18:16,029 --> 00:18:18,432 line:-2
Note that the utterance examples
we're using here


297
00:18:18,498 --> 00:18:22,469 line:-2
are just one of the many
natural-language utterances Siri supports


298
00:18:22,536 --> 00:18:24,238 line:-1
to accomplish these actions.


299
00:18:24,805 --> 00:18:27,074 line:-2
When you're implementing
your Now Playing support,


300
00:18:27,140 --> 00:18:30,677 line:-2
Siri takes care of that for you
so you don't need to worry about it.


301
00:18:30,744 --> 00:18:32,012 line:-1
You just need to make sure


302
00:18:32,079 --> 00:18:36,016 line:-2
that your MPRemoteCommandCenter
implementation works correctly with Siri.


303
00:18:37,317 --> 00:18:39,253 line:-1
First up is the pause command.


304
00:18:39,319 --> 00:18:42,155 line:-2
You invoke it with Siri
by saying something like "pause,"


305
00:18:42,222 --> 00:18:45,259 line:-2
and it routes to MPRemoteCommandCenter's
pause command.


306
00:18:46,527 --> 00:18:50,597 line:-2
Next we have play, and you can use this
to resume music when it's paused.


307
00:18:50,898 --> 00:18:53,901 line:-2
You invoke it with Siri
by saying something like "resume,"


308
00:18:53,967 --> 00:18:56,770 line:-2
and it routes to
MPRemoteCommandCenter's playCommand.


309
00:18:58,672 --> 00:19:00,274 line:-1
Next we have previous track.


310
00:19:00,340 --> 00:19:03,277 line:-2
You invoke it with Siri
by saying something like "previous track,"


311
00:19:03,343 --> 00:19:05,412 line:-2
and it routes
to the previousTrackCommand.


312
00:19:07,147 --> 00:19:08,448 line:-1
Next we have next track.


313
00:19:08,515 --> 00:19:11,351 line:-2
You invoke it with Siri
when you say something like "next track,"


314
00:19:11,418 --> 00:19:13,287 line:-1
and it routes to the nextTrackCommand.


315
00:19:13,987 --> 00:19:15,822 line:-1
Moving on, we have skip forward.


316
00:19:15,889 --> 00:19:17,624 line:-2
When you say something
like "skip forward,"


317
00:19:17,691 --> 00:19:19,860 line:-1
it goes to the skipForwardCommand.


318
00:19:19,927 --> 00:19:21,595 line:-1
Something interesting about skip forward


319
00:19:21,662 --> 00:19:24,965 line:-2
is that someone can tell Siri
how far they want to skip forward.


320
00:19:25,032 --> 00:19:28,068 line:-2
Siri will package this up
in the command's interval property.


321
00:19:28,135 --> 00:19:30,537 line:-1
Next we have skip back.


322
00:19:30,604 --> 00:19:32,539 line:-2
When someone says something
like "skip back,"


323
00:19:32,606 --> 00:19:34,908 line:-1
it routes to the skipBackwardCommand.


324
00:19:34,975 --> 00:19:39,146 line:-2
Like skip forward, people can say
how far they want you to go back,


325
00:19:39,213 --> 00:19:41,882 line:-2
and you'll receive this
in the command's interval property.


326
00:19:41,949 --> 00:19:44,918 line:-2
There are a few more commands
that don't show up on the lock screen


327
00:19:44,985 --> 00:19:46,286 line:-1
that you want to be aware of.


328
00:19:46,353 --> 00:19:50,057 line:0
changeRepeatMode and changeShuffleMode
take an argument


329
00:19:50,123 --> 00:19:53,327 line:0
as to whether the mode
should be enabled or disabled.


330
00:19:53,393 --> 00:19:55,495 line:0
Also, note that these are only used


331
00:19:55,562 --> 00:19:58,632 line:0
to turn the repeat and shuffle settings
on or off.


332
00:19:58,699 --> 00:20:01,301 line:0
If you want to start playback shuffled
or on repeat,


333
00:20:01,368 --> 00:20:03,871 line:0
use INPlayMediaIntent for that.


334
00:20:03,937 --> 00:20:06,240 line:0
changePlaybackRate
also takes an argument


335
00:20:06,306 --> 00:20:08,575 line:0
as you can say what speed
you want to play something at.


336
00:20:08,642 --> 00:20:11,845 line:0
For example, "Play it slower,"
or "Play at half speed."


337
00:20:11,912 --> 00:20:14,948 line:-2
Similar to the way we can control
Now Playing interactions


338
00:20:15,015 --> 00:20:17,251 line:-1
by implementing the Now Playing commands,


339
00:20:17,317 --> 00:20:20,854 line:-2
we can help Siri answer questions
people ask about what's playing


340
00:20:20,921 --> 00:20:24,191 line:-2
by setting properties
in MPNowPlayingInfoCenter.


341
00:20:24,825 --> 00:20:28,829 line:-2
A few of the supported properties
are MPMediaItemPropertyTitle,


342
00:20:28,896 --> 00:20:31,532 line:-2
which you can use by saying,
"What song is this?"


343
00:20:31,598 --> 00:20:33,700 line:-1
MPMediaItemPropertyArtist,


344
00:20:33,767 --> 00:20:36,303 line:-2
which you could get with,
"What band is this?"


345
00:20:36,370 --> 00:20:39,039 line:-1
And MPMediaItemPropertyAlbumTitle,


346
00:20:39,106 --> 00:20:42,276 line:-2
which you'd similarly get by asking,
"What album is this?"


347
00:20:42,342 --> 00:20:45,879 line:-2
And when it comes to errors, there's
three ways you can let someone know


348
00:20:45,946 --> 00:20:47,681 line:-1
that you don't support the command.


349
00:20:47,748 --> 00:20:49,650 line:-2
You might want to do it
a couple different ways


350
00:20:49,716 --> 00:20:52,052 line:-2
depending on what's appropriate
for your app.


351
00:20:53,053 --> 00:20:55,923 line:-2
The easiest way is to just
not implement the command.


352
00:20:55,989 --> 00:20:59,526 line:-2
If you don't install a handler
in MPRemoteCommandCenter,


353
00:20:59,593 --> 00:21:02,496 line:-2
Siri will still gracefully give
an error dialogue.


354
00:21:04,565 --> 00:21:06,767 line:-2
You can also temporarily disable
the command.


355
00:21:07,134 --> 00:21:10,637 line:-2
And this might be useful in a context
where you normally support something,


356
00:21:10,704 --> 00:21:12,773 line:-1
but don't in certain circumstances.


357
00:21:12,840 --> 00:21:15,709 line:-2
For instance, maybe you disable
the next-track command


358
00:21:15,776 --> 00:21:18,946 line:-2
if you're playing an advertisement
on an ad-supported music stream.


359
00:21:20,781 --> 00:21:23,083 line:-1
Finally, you can fail the command


360
00:21:23,150 --> 00:21:25,619 line:-2
which will generate
a generic error dialogue.


361
00:21:26,119 --> 00:21:28,789 line:-2
Typically, you'll only do this
in exceptional cases,


362
00:21:28,856 --> 00:21:30,824 line:-1
but Siri will still handle this.


363
00:21:31,391 --> 00:21:32,626 line:-1
One last thing.


364
00:21:33,594 --> 00:21:37,497 line:-2
A quality SiriKit Media experience
is one that people know about.


365
00:21:38,332 --> 00:21:40,701 line:0
This is a challenge
with any voice integration.


366
00:21:40,767 --> 00:21:43,103 line:0
Sometimes people are unaware
of the hard work


367
00:21:43,170 --> 00:21:45,639 line:0
that you've put into making
an awesome voice experience


368
00:21:45,706 --> 00:21:48,408 line:0
because, you know,
out of sight, out of mind.


369
00:21:49,376 --> 00:21:52,746 line:0
But we also see that people are
more likely to use Siri


370
00:21:52,813 --> 00:21:54,715 line:0
when they know about the functionality.


371
00:21:55,148 --> 00:21:56,617 line:0
How much more likely?


372
00:21:57,351 --> 00:22:00,754 line:0
We've seen Siri engagement increase
up to ten times


373
00:22:00,821 --> 00:22:03,524 line:0
when there's some education
about the feature in the app.


374
00:22:04,424 --> 00:22:07,094 line:-2
Of course,
you'll want to present this in your style


375
00:22:07,160 --> 00:22:10,130 line:-2
and match your app's
overall look and feel.


376
00:22:10,197 --> 00:22:14,635 line:-2
But if you want people to use your app
more easily by just asking Siri,


377
00:22:15,035 --> 00:22:17,771 line:-2
you're definitely going to want
to tell them about it.


378
00:22:18,338 --> 00:22:19,706 line:-1
Thanks for watching.


379
00:22:19,773 --> 00:22:23,577 line:-2
We really want people to have
a great experience using your app


380
00:22:23,644 --> 00:22:26,180 line:-1
and a great experience using Siri.


381
00:22:26,246 --> 00:22:27,848 line:-1
So don't forget.


382
00:22:27,915 --> 00:22:32,519 line:-2
A high-quality Siri experience
is one people will actually use.


383
00:22:32,586 --> 00:22:35,789 line:-1
And I hope you really enjoyed WWDC20.

