2
00:00:00,167 --> 00:00:03,003 line:-1
♪ Mellow instrumental
hip-hop music ♪


3
00:00:03,003 --> 00:00:09,977 line:0 size:2% align:right
♪


4
00:00:09,977 --> 00:00:13,981 line:-1
Namaskar!
Hello and welcome to WWDC22.


5
00:00:13,981 --> 00:00:17,651 line:-1
My name is Vrushali Mundhe,
engineer on the Create ML team,


6
00:00:17.651 --> 00:00:22.456 line:-1 position:50%
and I am excited to share with
you what's new in Create ML.


7
00:00:22,456 --> 00:00:24,524 line:-1
Create ML allows you
to easily train


8
00:00:24,524 --> 00:00:27,628 line:-1
powerful machine learning models
with data you have collected


9
00:00:27.628 --> 00:00:32.566 line:-1 position:50%
to deliver unique experiences
and enhance your apps.


10
00:00:32,566 --> 00:00:36,003 line:-1
Create ML ships as an app
bundled with Xcode,


11
00:00:36.003 --> 00:00:38.906 line:-1 position:50%
letting you quickly build
and train Core ML models


12
00:00:38,906 --> 00:00:41,808 line:-1
right on your Mac with no code.


13
00:00:41.808 --> 00:00:44.978 line:-1 position:50%
Create ML is also available
as a Swift framework


14
00:00:44,978 --> 00:00:47,147 line:-1
shipping in SDK.


15
00:00:47,147 --> 00:00:51,251 line:-1
Using its APIs, you can easily
automate model creation


16
00:00:51,251 --> 00:00:54,588 line:-1
or create dynamic experiences
powered by training


17
00:00:54.588 --> 00:00:57.758 line:-1 position:50%
directly from
within your own app.


18
00:00:57,758 --> 00:01:00,427 position:50%
To learn more about Create ML's
core capabilities,


19
00:01:00,427 --> 00:01:04,031 line:0
you can check out
these previous sessions.


20
00:01:04.031 --> 00:01:08.135 line:-1 position:50%
In this session, we'll talk
about what's new in Create ML.


21
00:01:08,135 --> 00:01:10,704 line:-1
We will start with new features
in the Create ML app


22
00:01:10,704 --> 00:01:12,806 line:-1
that can help evaluate
the accuracy


23
00:01:12,806 --> 00:01:14,942 line:-1
and utility of your models.


24
00:01:14.942 --> 00:01:18.578 line:-1 position:50%
We will then turn our attention
to the Create ML framework,


25
00:01:18,578 --> 00:01:20,681 line:-1
its extended capabilities,


26
00:01:20,681 --> 00:01:23,550 line:-1
and ability to now highly
customize models


27
00:01:23,550 --> 00:01:26,119 line:-1
for your own app.


28
00:01:26,119 --> 00:01:28,188 line:-1
Let's start by reviewing
a typical workflow


29
00:01:28.188 --> 00:01:30.157 line:-1 position:50%
for model creation.


30
00:01:30,157 --> 00:01:33,160 line:-1
Given an identified task,
you begin by collecting


31
00:01:33.160 --> 00:01:35.629 line:-1 position:50%
and annotating data.


32
00:01:35.629 --> 00:01:40.033 line:-1 position:50%
Take, for example, wanting
to visually identify groceries.


33
00:01:40,033 --> 00:01:42,002 position:50%
For this image
classification task,


34
00:01:42,002 --> 00:01:45,839 position:50%
your starting point would be
collecting and labeling images;


35
00:01:45,839 --> 00:01:47,941 line:0
here, some fruits
and vegetables.


36
00:01:50,410 --> 00:01:53,780 line:-1
Create ML will then help you
train a model from this data,


37
00:01:53.780 --> 00:01:56.283 line:-1 position:50%
which can be used in your app.


38
00:01:56,283 --> 00:01:58,719 line:-1
However, before using
this model,


39
00:01:58.719 --> 00:02:02.756 line:-1 position:50%
an important step is to evaluate
how well it performs;


40
00:02:02,756 --> 00:02:05,826 line:-1
here, seeing how accurate
the model is on images,


41
00:02:05,826 --> 00:02:09,262 line:-1
which were not part
of the training set.


42
00:02:09,262 --> 00:02:11,431 position:50%
Depending on evaluation,


43
00:02:11,431 --> 00:02:14,735 line:0
you may iterate on the model
with additional data


44
00:02:14,735 --> 00:02:17,170 position:50%
and modified training settings


45
00:02:17,170 --> 00:02:19,773 line:0
or, once the model is
performing well enough,


46
00:02:19,773 --> 00:02:22,976 position:50%
you're ready to integrate it
into your app,


47
00:02:22,976 --> 00:02:26,947 position:50%
I would like to focus
on this evaluation step further.


48
00:02:26,947 --> 00:02:29,549 line:-1
When performing an evaluation,
we often turn


49
00:02:29.549 --> 00:02:33.053 line:-1 position:50%
to a set of metrics measured
by testing your model


50
00:02:33,053 --> 00:02:35,922 line:-1
on new data held out
from training.


51
00:02:35,922 --> 00:02:39,292 line:-1
You may start by looking
at a top-level accuracy metric


52
00:02:39.292 --> 00:02:41.695 line:-1 position:50%
or dive into
per-class statistics


53
00:02:41,695 --> 00:02:44,264 line:-1
to get a general sense
of the model's behavior


54
00:02:44,264 --> 00:02:48,769 line:-1
and ability to generalize
beyond what it was trained on.


55
00:02:48.769 --> 00:02:51.972 line:-1 position:50%
Ultimately, the model will be
responsible for empowering


56
00:02:51.972 --> 00:02:54.141 line:-1 position:50%
data-driven experience
in your app,


57
00:02:54,141 --> 00:02:55,742 line:-1
and during evaluation,


58
00:02:55,742 --> 00:03:00,313 line:-1
you want to identify the model's
main strengths and weaknesses


59
00:03:00,313 --> 00:03:03,283 line:-1
in terms of categories
of inputs or scenarios;


60
00:03:03.283 --> 00:03:07.754 line:-1 position:50%
it works well or may fall short
of expectations.


61
00:03:07,754 --> 00:03:10,657 line:-1
There are new features in the
Create ML app that can help you


62
00:03:10,657 --> 00:03:13,260 line:-1
on this part
of your model-creation journey.


63
00:03:13,260 --> 00:03:16,296 line:-1
Let me show you a project
that I'm working on.


64
00:03:16,296 --> 00:03:18,698 line:-1
Here, I have a project
set up to create a model


65
00:03:18.698 --> 00:03:20.767 line:-1 position:50%
to identify groceries.


66
00:03:20,767 --> 00:03:23,070 line:-1
I started with collecting
various fruit


67
00:03:23,070 --> 00:03:25,839 line:-1
and vegetable images
as my training data


68
00:03:25.839 --> 00:03:30.143 line:-1 position:50%
and labeled them appropriately.


69
00:03:30.143 --> 00:03:32.446 line:-1 position:50%
Here are my different classes
and number of images


70
00:03:32,446 --> 00:03:34,281 line:-1
for each class.


71
00:03:38,285 --> 00:03:43,557 line:-1
I have already trained my image
classifier for 25 iterations.


72
00:03:43.557 --> 00:03:46.259 line:-1 position:50%
Next, when I click
on the Evaluation tab,


73
00:03:46,259 --> 00:03:49,463 line:-1
I can add new test data --
a set of images


74
00:03:49.463 --> 00:03:53.433 line:-1 position:50%
apart from training data that
I had set aside for testing.


75
00:03:58,371 --> 00:04:03,510 line:-1
I will next click Evaluate
to begin testing.


76
00:04:03,510 --> 00:04:05,579 line:-1
After it finishes evaluation,


77
00:04:05.579 --> 00:04:08.615 line:-1 position:50%
the UI provides details
of the results.


78
00:04:08,615 --> 00:04:11,318 line:-1
On the top, there is
a high-level summary section


79
00:04:11,318 --> 00:04:14,721 line:-1
which gives a quick sense
of test accuracy.


80
00:04:14.721 --> 00:04:19.292 line:-1 position:50%
Here, the accuracy
of this test data is 89 percent.


81
00:04:19,292 --> 00:04:21,061 line:-1
Below in this Metrics tab,


82
00:04:21.061 --> 00:04:24.798 line:-1 position:50%
a table provides a wealth
of metrics for each class.


83
00:04:24,798 --> 00:04:28,668 line:-1
You can adjust what is shown
here using these drop-down menus


84
00:04:28.668 --> 00:04:31.138 line:-1 position:50%
and add additional metrics
like false positive


85
00:04:31,138 --> 00:04:32,606 line:-1
and false negative.


86
00:04:32.606 --> 00:04:34.674 line:-1 position:50%
Let's review one
of these classes.


87
00:04:34,674 --> 00:04:36,276 line:-1
How about Tomato?


88
00:04:36,276 --> 00:04:40,080 line:-1
The model classified 29 of
the 32 tomato images correctly.


89
00:04:40.080 --> 00:04:45.585 line:-1 position:50%
It also shows the precision
for this class is 91 percent,


90
00:04:45.585 --> 00:04:47.154 line:-1 position:50%
which means nine percent
of the time


91
00:04:47.154 --> 00:04:50.624 line:-1 position:50%
the model says something
is a tomato, it is incorrect.


92
00:04:50,624 --> 00:04:53,226 line:-1
While these numbers
and statistics are super useful,


93
00:04:53,226 --> 00:04:56,096 line:-1
it's sometimes even more
important to look at them


94
00:04:56,096 --> 00:04:58,465 line:-1
in the context
of the data itself.


95
00:04:58,465 --> 00:05:02,235 line:-1
When I click the precision,
it takes me to the images


96
00:05:02.235 --> 00:05:05.372 line:-1 position:50%
that were incorrectly
classified as tomato.


97
00:05:05.372 --> 00:05:08.875 line:-1 position:50%
Here are three of these cases
in the test data.


98
00:05:08.875 --> 00:05:12.145 line:-1 position:50%
For each image,
the app displays its thumbnail,


99
00:05:12.145 --> 00:05:14.447 line:-1 position:50%
the class the model
has predicted,


100
00:05:14,447 --> 00:05:16,550 line:-1
and the true label below it.


101
00:05:16.550 --> 00:05:19.052 line:-1 position:50%
In this first example,
while the model classified this


102
00:05:19.052 --> 00:05:22.589 line:-1 position:50%
as Tomato,
it was labeled as Potato.


103
00:05:22,589 --> 00:05:25,058 line:-1
But this sure appears
to be a tomato to me.


104
00:05:25,058 --> 00:05:27,694 line:-1
This seems like a case
of a mislabeled test data.


105
00:05:27,694 --> 00:05:31,631 line:-1
In fact, all three of these
examples seem to be mislabeled.


106
00:05:31.631 --> 00:05:33.567 line:-1 position:50%
This should be easy to address.


107
00:05:33,567 --> 00:05:35,135 line:-1
I'll make a note to double-check


108
00:05:35.135 --> 00:05:37.737 line:-1 position:50%
and revisit
my test-set labeling.


109
00:05:37.737 --> 00:05:40.006 line:-1 position:50%
This was clearly
an error on my part,


110
00:05:40.006 --> 00:05:42.943 line:-1 position:50%
but is it the only source
of error?


111
00:05:42,943 --> 00:05:44,844 line:-1
I got here
by exploring the metrics


112
00:05:44,844 --> 00:05:47,280 line:-1
on a random class of my choice.


113
00:05:47,280 --> 00:05:50,317 line:-1
You may wonder,
"Where should I start?"


114
00:05:50.317 --> 00:05:53.787 line:-1 position:50%
Or, "What should I
explore next?"


115
00:05:53,787 --> 00:05:58,225 line:-1
The top-level summary section
is here to help you out.


116
00:05:58,225 --> 00:05:59,292 line:-1
The app has selected


117
00:05:59,292 --> 00:06:01,795 line:-1
some of the most important
evaluation details


118
00:06:01,795 --> 00:06:05,765 line:-1
that can serve as a great place
to start your exploration.


119
00:06:05.765 --> 00:06:10.604 line:-1 position:50%
Let me restart from the top
and review the successful cases.


120
00:06:10,604 --> 00:06:15,742 line:-1
Clicking here,
this correct count...


121
00:06:15,742 --> 00:06:19,412 line:-1
Here, we can get a quick
glance of all the 162 images


122
00:06:19.412 --> 00:06:23.550 line:-1 position:50%
the model correctly classified.


123
00:06:23,550 --> 00:06:27,187 line:-1
Next, let me contrast this with
a review of all the failures


124
00:06:27,187 --> 00:06:31,258 line:-1
by clicking on the incorrect.


125
00:06:31.258 --> 00:06:33.660 line:-1 position:50%
There are 21 failures in total.


126
00:06:35,962 --> 00:06:38,765 line:-1
Here is that mislabeled
tomato again.


127
00:06:38,765 --> 00:06:40,934 line:-1
Let me check if there are
any other types of errors


128
00:06:40.934 --> 00:06:43.036 line:-1 position:50%
that can stand out.


129
00:06:43.036 --> 00:06:46.139 line:-1 position:50%
How about... this one?


130
00:06:46,139 --> 00:06:50,343 line:-1
This image is labeled
as Carrot,


131
00:06:50,343 --> 00:06:53,780 line:-1
but the model predicts
as Potato.


132
00:06:53,780 --> 00:06:56,483 line:-1
It's hard to tell
in this small thumbnail,


133
00:06:56,483 --> 00:07:01,154 line:-1
but let's confirm by clicking on
this image to get a better view.


134
00:07:01.154 --> 00:07:03.556 line:-1 position:50%
Well, this looks like
a foot to me.


135
00:07:03.556 --> 00:07:06.893 line:-1 position:50%
This clearly is not a long,
skinny carrot shape I'm used to


136
00:07:06.893 --> 00:07:09.562 line:-1 position:50%
but can be easily confused
as a potato.


137
00:07:09.562 --> 00:07:12.198 line:-1 position:50%
Perhaps I should consider
adding more shape variations


138
00:07:12.198 --> 00:07:14.501 line:-1 position:50%
to my training data for carrots.


139
00:07:14.501 --> 00:07:16.603 line:-1 position:50%
Let me make a note
of this as well.


140
00:07:16.603 --> 00:07:20.273 line:-1 position:50%
This time, I will click on
the arrow next to the filename


141
00:07:20,273 --> 00:07:23,243 line:-1
to bring me to this image
in the Finder.


142
00:07:25,679 --> 00:07:30,650 line:-1
I will right-click
and label this as red,


143
00:07:30.650 --> 00:07:33.520 line:-1 position:50%
as reminder of it being
something I want to revisit


144
00:07:33.520 --> 00:07:36.456 line:-1 position:50%
in my next round
of data collection.


145
00:07:36.456 --> 00:07:40.593 line:-1 position:50%
Let me continue my exploration
from within this expanded view.


146
00:07:40,593 --> 00:07:44,297 line:-1
Note that this view also shows
full prediction results,


147
00:07:44,297 --> 00:07:46,933 line:-1
listing the model's confidence
in every class.


148
00:07:46,933 --> 00:07:49,669 line:-1
It also lets me navigate
through examples


149
00:07:49,669 --> 00:07:53,473 line:-1
using these left
and right arrows.


150
00:07:53.473 --> 00:07:57.243 line:-1 position:50%
I'll move to another example
from here.


151
00:07:57,243 --> 00:07:58,912 line:-1
This is an interesting case.


152
00:07:58,912 --> 00:08:02,882 line:-1
It has multiple vegetables
in a single image.


153
00:08:02.882 --> 00:08:07.120 line:-1 position:50%
It says it's an eggplant
and it's true


154
00:08:07.120 --> 00:08:11.091 line:-1 position:50%
that there are eggplants here
but other things as well.


155
00:08:11,091 --> 00:08:13,960 line:-1
I need to think about whether
this is an important use case


156
00:08:13.960 --> 00:08:16.830 line:-1 position:50%
for me to consider in my app.


157
00:08:16.830 --> 00:08:19.599 line:-1 position:50%
Perhaps the UI can guide
my users to make sure


158
00:08:19.599 --> 00:08:22.769 line:-1 position:50%
they only point to one type
of grocery at a time,


159
00:08:22,769 --> 00:08:24,971 line:-1
or if I want to support
multiple types,


160
00:08:24.971 --> 00:08:28.141 line:-1 position:50%
I may want to consider
using an object detector --


161
00:08:28.141 --> 00:08:29.776 line:-1 position:50%
another template in the app --


162
00:08:29,776 --> 00:08:32,679 line:-1
rather than the whole
image classifier.


163
00:08:32,679 --> 00:08:34,481 line:-1
Coming back
to the summary section,


164
00:08:34,481 --> 00:08:37,884 line:-1
let me check out this line
about the top confusion.


165
00:08:37,884 --> 00:08:40,620 line:-1
Here it says
it's 'Pepper' as 'Bean'.


166
00:08:40,620 --> 00:08:44,257 line:-1
Let's click
to explore this case.


167
00:08:44.257 --> 00:08:46.259 line:-1 position:50%
Four images labeled as peppers


168
00:08:46,259 --> 00:08:49,729 line:-1
are incorrectly
classified as beans.


169
00:08:49.729 --> 00:08:51.598 line:-1 position:50%
These look like
spicy peppers to me,


170
00:08:51,598 --> 00:08:55,068 line:-1
but I guess they are green
like beans as well.


171
00:08:55.068 --> 00:08:58.805 line:-1 position:50%
I wonder if the model is having
trouble with peppers in general.


172
00:08:58,805 --> 00:09:05,812 line:-1
Let me switch this query option
from Incorrect to Correct...


173
00:09:05,812 --> 00:09:09,582 line:-1
...to contrast these failures
to correctly classified peppers.


174
00:09:09,582 --> 00:09:13,019 line:-1
It correctly classified
32 images;


175
00:09:13.019 --> 00:09:17.023 line:-1 position:50%
however, I do notice that
most of these are bell peppers.


176
00:09:17,023 --> 00:09:19,426 line:-1
I should check my training data
to make sure


177
00:09:19,426 --> 00:09:24,731 line:-1
I have a good representation
of multiple peppers as well.


178
00:09:24,731 --> 00:09:26,933 line:-1
This quick exploration
was a great reminder


179
00:09:26.933 --> 00:09:29.436 line:-1 position:50%
of how important
the quantity, quality,


180
00:09:29,436 --> 00:09:34,174 line:-1
and variety of training and test
data are for machine learning.


181
00:09:34.174 --> 00:09:36.543 line:-1 position:50%
In a matter of a few minutes,
the app helped me


182
00:09:36.543 --> 00:09:38.778 line:-1 position:50%
visually identify
some issues with labeling


183
00:09:38,778 --> 00:09:40,847 line:-1
and representation.


184
00:09:40,847 --> 00:09:43,516 line:-1
I need to make some tweaks
to my training data


185
00:09:43.516 --> 00:09:46.019 line:-1 position:50%
and see if it fixes
the issues we saw.


186
00:09:46.019 --> 00:09:49.622 line:-1 position:50%
It also revealed something
I hadn't considered before:


187
00:09:49,622 --> 00:09:52,759 line:-1
what happens if a user
captures multiple vegetables


188
00:09:52.759 --> 00:09:54.494 line:-1 position:50%
in a single photo?


189
00:09:54,494 --> 00:09:58,731 line:-1
I need to think about
my app design some more.


190
00:09:58,731 --> 00:10:00,834 line:-1
All of this exploration
was possible


191
00:10:00,834 --> 00:10:04,637 line:-1
because I had a collection
of labeled data to evaluate.


192
00:10:04,637 --> 00:10:08,942 line:-1
But what if I have unlabeled
examples I want to quickly test,


193
00:10:08.942 --> 00:10:11.277 line:-1 position:50%
or consider whether or not
I should explore


194
00:10:11,277 --> 00:10:15,181 line:-1
more camera angles
or lighting conditions?


195
00:10:15,181 --> 00:10:18,151 line:-1
Here is where
the Preview tab can help.


196
00:10:18.151 --> 00:10:21.020 line:-1 position:50%
I can drag a few examples my
colleague just sent to me here


197
00:10:21,020 --> 00:10:22,856 line:-1
and see how well it does.


198
00:10:36.603 --> 00:10:38.338 line:-1 position:50%
Or I can even test this live,


199
00:10:38,338 --> 00:10:41,374 line:-1
using my iPhone
as the Continuity Camera.


200
00:10:43,610 --> 00:10:45,745 line:-1
As I point
to these actual vegetables,


201
00:10:45,745 --> 00:10:49,516 line:-1
the model is able
to correctly classify them live.


202
00:10:49,516 --> 00:10:54,487 line:-1
Here, this is a pepper
and a tomato.


203
00:10:54.487 --> 00:10:56.689 line:-1 position:50%
To recap, you can now
dive deeper


204
00:10:56,689 --> 00:11:01,060 line:-1
into a trained model's behavior
on any labeled dataset.


205
00:11:01,060 --> 00:11:04,197 line:-1
The Evaluation pane provides
a detailed metric summary


206
00:11:04,197 --> 00:11:06,399 line:-1
with its extended options.


207
00:11:06,399 --> 00:11:09,502 line:-1
A new Explore tab provides
options which lets you filter


208
00:11:09,502 --> 00:11:12,171 line:-1
and visualize
the test evaluation results


209
00:11:12.171 --> 00:11:16.543 line:-1 position:50%
along with the associated data
in a new interactive UI,


210
00:11:16.543 --> 00:11:18.945 line:-1 position:50%
currently available
for image classifier,


211
00:11:18.945 --> 00:11:24.017 line:-1 position:50%
hand pose classifier,
and object detection templates.


212
00:11:24.017 --> 00:11:26.986 line:-1 position:50%
Live preview enables
immediate feedback.


213
00:11:26.986 --> 00:11:29.455 line:-1 position:50%
It's expanded
to image classifier,


214
00:11:29,455 --> 00:11:34,561 line:-1
hand action classifier, and body
action classifier templates.


215
00:11:34.561 --> 00:11:36.763 line:-1 position:50%
We have also extended
the feature to allow you


216
00:11:36,763 --> 00:11:39,332 line:-1
to select from
any attached webcam


217
00:11:39,332 --> 00:11:42,068 line:-1
and we also support
Continuity Cameras


218
00:11:42,068 --> 00:11:45,305 line:-1
on macOS Ventura.


219
00:11:45,305 --> 00:11:48,675 line:-1
That's a quick summary of
what's new in the Create ML app.


220
00:11:48.675 --> 00:11:50.577 line:-1 position:50%
Let's shift over
to discuss what's new


221
00:11:50.577 --> 00:11:52.445 line:-1 position:50%
in the Create ML framework.


222
00:11:54.914 --> 00:11:57.517 line:-1 position:50%
The Create ML framework
is available on macOS,


223
00:11:57,517 --> 00:11:59,819 line:-1
iOS, and iPadOS.


224
00:11:59.819 --> 00:12:04.524 line:-1 position:50%
This year, we are expanding
some of its support to tvOS 16.


225
00:12:04,524 --> 00:12:07,126 line:-1
The programmatic interface
not only lets you


226
00:12:07,126 --> 00:12:09,829 line:-1
automate model creation
at development time


227
00:12:09.829 --> 00:12:12.865 line:-1 position:50%
but also opens up
many opportunities to build


228
00:12:12.865 --> 00:12:17.070 line:-1 position:50%
dynamic features that learn
directly from users' input


229
00:12:17.070 --> 00:12:20.073 line:-1 position:50%
or on-device behavior,
providing personalized


230
00:12:20,073 --> 00:12:24,444 line:-1
and adaptive experiences
while preserving user privacy.


231
00:12:24,444 --> 00:12:27,780 position:50%
Note that task support
does differ per platform.


232
00:12:27,780 --> 00:12:31,150 line:0
For example, while tabular
classifiers and regressors


233
00:12:31,150 --> 00:12:34,587 position:50%
are available everywhere, some
of the tasks with larger data


234
00:12:34,587 --> 00:12:38,324 position:50%
and computation requirements,
such as those involving video,


235
00:12:38,324 --> 00:12:41,060 line:0
require macOS.


236
00:12:41.060 --> 00:12:43.096 line:-1 position:50%
One common question
you may have is,


237
00:12:43.096 --> 00:12:44.998 line:-1 position:50%
"What if I can't map my idea


238
00:12:44.998 --> 00:12:48.801 line:-1 position:50%
into one of these Create ML's
predefined tasks?"


239
00:12:48.801 --> 00:12:52.238 line:-1 position:50%
To help answer this question,
we are introducing a new member


240
00:12:52,238 --> 00:12:54,440 line:-1
to the Create ML family:


241
00:12:54.440 --> 00:12:56.609 line:-1 position:50%
Create ML Components.


242
00:12:56,609 --> 00:12:59,979 line:-1
Create ML Components exposes
the underlying building blocks


243
00:12:59.979 --> 00:13:02.482 line:-1 position:50%
of Create ML.


244
00:13:02,482 --> 00:13:05,585 line:-1
It allows you to combine them
together to create pipelines


245
00:13:05,585 --> 00:13:09,555 line:-1
and models customized
to your use case.


246
00:13:09,555 --> 00:13:11,457 line:0
I highly recommend you
checking out these sessions


247
00:13:11,457 --> 00:13:12,925 position:50%
to learn more.


248
00:13:12,925 --> 00:13:14,894 position:50%
In "Get to know
Create ML Components,"


249
00:13:14,894 --> 00:13:16,963 line:0
you will learn about
the building blocks


250
00:13:16,963 --> 00:13:19,599 line:0
and how they can
be composed together.


251
00:13:19,599 --> 00:13:22,635 line:0
In "Compose advanced models
with Create ML Components,"


252
00:13:22,635 --> 00:13:26,239 line:0
you dive deeper into using
async temporal components


253
00:13:26,239 --> 00:13:28,608 line:0
and customizing training.


254
00:13:28,608 --> 00:13:31,711 line:0
There are endless capabilities;
let me showcase one


255
00:13:31,711 --> 00:13:33,680 position:50%
that I am personally
excited about:


256
00:13:33,680 --> 00:13:35,848 position:50%
action repetition counting.


257
00:13:35,848 --> 00:13:40,086 line:-1
When I am not working, most
likely you'll find me dancing.


258
00:13:40,086 --> 00:13:41,354 line:-1
I'm a professionally trained


259
00:13:41.354 --> 00:13:44.691 line:-1 position:50%
Indian classical dance
Kathak artist.


260
00:13:44,691 --> 00:13:45,825 line:-1
To improve my form,


261
00:13:45,825 --> 00:13:49,562 line:-1
I often rely on repeatedly
practicing my routines.


262
00:13:49,562 --> 00:13:52,999 line:-1
As a choreographer/teacher,
I would like my performers


263
00:13:52,999 --> 00:13:56,235 line:-1
to practice steps for certain
counts and submit them to me.


264
00:13:56.235 --> 00:13:59.005 line:-1 position:50%
The new repetition counting
capabilities in Create ML


265
00:13:59,005 --> 00:14:01,474 line:-1
can help me actually do that!


266
00:14:01.474 --> 00:14:04.377 line:-1 position:50%
Here, this a chakkar -- twirl --


267
00:14:04,377 --> 00:14:06,713 line:-1
an integral part
of Kathak dance.


268
00:14:09,248 --> 00:14:11,951 line:-1
I would like to practice this
for certain counts daily


269
00:14:11,951 --> 00:14:14,587 line:-1
to build my form and my stamina.


270
00:14:14,587 --> 00:14:18,624 line:-1
I have an iOS app built using
Create ML that counts my moves.


271
00:14:18,624 --> 00:14:20,359 line:-1
Let's try it in action.


272
00:14:27,867 --> 00:14:30,303 line:-1
As I take my chakkars,
the count increases


273
00:14:30,303 --> 00:14:31,971 line:-1
to correspond to it.


274
00:14:31,971 --> 00:14:33,806 line:-1
Here, I have done five chakkars,


275
00:14:33,806 --> 00:14:36,743 line:-1
and the count reflects
exactly that.


276
00:14:36,743 --> 00:14:39,145 line:-1
Next, let's try a different
small routine


277
00:14:39,145 --> 00:14:41,981 line:-1
that consist of right-
and left-side movements.


278
00:14:41,981 --> 00:14:44,016 line:-1
The counter counts them as one.


279
00:14:57.029 --> 00:14:59.565 line:-1 position:50%
Here, the count shows three.


280
00:14:59,565 --> 00:15:02,902 line:-1
Let me try another
quick one-side arm movement.


281
00:15:17,283 --> 00:15:18,684 line:-1
That's four.


282
00:15:18,684 --> 00:15:20,820 line:-1
When combined
with Action Classification,


283
00:15:20.820 --> 00:15:24.557 line:-1 position:50%
this will allow you to count and
categorize repetitive actions


284
00:15:24.557 --> 00:15:26.359 line:-1 position:50%
at the same time.


285
00:15:26.359 --> 00:15:30.429 line:-1 position:50%
Repetition counting is available
as a runtime API.


286
00:15:30,429 --> 00:15:33,800 line:-1
It requires no training data,
and adding this functionality


287
00:15:33.800 --> 00:15:37.236 line:-1 position:50%
to your app can be
just a few lines of code.


288
00:15:37,236 --> 00:15:40,506 line:-1
Its implementation is based
on a pretrained model


289
00:15:40,506 --> 00:15:42,642 line:-1
designed to be class-agnostic.


290
00:15:42.642 --> 00:15:46.179 line:-1 position:50%
Meaning, while it works
on fitness or dance actions,


291
00:15:46.179 --> 00:15:49.949 line:-1 position:50%
such as jumping jacks,
squats, twirls, chakkars,


292
00:15:49.949 --> 00:15:52.552 line:-1 position:50%
it's also applicable
to a wide variety


293
00:15:52.552 --> 00:15:56.088 line:-1 position:50%
of full-body
repetitive actions.


294
00:15:56.088 --> 00:15:57.857 line:-1 position:50%
You can find out more
about this model


295
00:15:57,857 --> 00:16:00,827 line:-1
and potential use case
by checking out the sample code


296
00:16:00.827 --> 00:16:04.530 line:-1 position:50%
and the article linked
to this session.


297
00:16:04,530 --> 00:16:08,334 line:-1
So that's a quick overview
of what's new in Create ML.


298
00:16:08,334 --> 00:16:11,103 line:-1
Interactive evaluation
and live previews


299
00:16:11,103 --> 00:16:13,573 line:-1
in the Create ML app
lets you dive deeper


300
00:16:13.573 --> 00:16:16.475 line:-1 position:50%
into understanding
the models you train.


301
00:16:16.475 --> 00:16:20.079 line:-1 position:50%
The Create ML framework
adds tvOS support,


302
00:16:20,079 --> 00:16:23,115 line:-1
repetition counting,
and has expanded


303
00:16:23,115 --> 00:16:27,019 line:-1
to give you access to a rich
set of underlying components


304
00:16:27.019 --> 00:16:29.889 line:-1 position:50%
to help you build models
highly customized


305
00:16:29,889 --> 00:16:32,058 line:-1
to your app needs.


306
00:16:32.058 --> 00:16:33.092 line:-1 position:50%
Thank you,


307
00:16:33,092 --> 00:16:35,928 line:-1
and I hope you enjoyed all
these exciting new features,


308
00:16:35,928 --> 00:16:38,464 line:-1
and we can't wait to see
what you do with them!


309
00:16:38,464 --> 00:16:42,902 line:0 align:right size:2%
♪

