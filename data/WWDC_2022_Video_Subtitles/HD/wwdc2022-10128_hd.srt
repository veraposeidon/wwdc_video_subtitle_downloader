2
00:00:00.000 --> 00:00:03.003 line:-1 position:50%
♪ Mellow instrumental
hip-hop music ♪


3
00:00:03,003 --> 00:00:09,810 size:2% position:90% align:right
♪


4
00:00:09.810 --> 00:00:11.879 line:-1 position:50%
Hao Tang: Hi, my name is Hao.


5
00:00:11,879 --> 00:00:15,115 line:-1
I'm an engineer
on the Object Capture team.


6
00:00:15.115 --> 00:00:18.986 line:-1 position:50%
Today, my colleague Risa and I
will be showing you how to use


7
00:00:18.986 --> 00:00:21.989 line:-1 position:50%
the Object Capture API
and RealityKit


8
00:00:21.989 --> 00:00:25.325 line:-1 position:50%
to create 3D models
of real-world objects


9
00:00:25,325 --> 00:00:27,628 line:-1
and bring them into AR.


10
00:00:27,628 --> 00:00:29,396 line:-1
Let's get started.


11
00:00:29.396 --> 00:00:32.633 line:-1 position:50%
First, I'll give you a recap
of Object Capture,


12
00:00:32,633 --> 00:00:35,502 line:-1
which we launched
as a RealityKit API


13
00:00:35,502 --> 00:00:38,238 line:-1
on macOS last year.


14
00:00:38,238 --> 00:00:40,307 line:-1
Then, I'll introduce you


15
00:00:40,307 --> 00:00:43,310 line:-1
to a couple of camera
enhancements in ARKit,


16
00:00:43,310 --> 00:00:47,047 line:-1
which allow you to capture
high-res photos of your object


17
00:00:47.047 --> 00:00:48.582 line:-1 position:50%
and can help you
better integrate


18
00:00:48,582 --> 00:00:52,753 line:-1
Object Capture
into your AR applications.


19
00:00:52,753 --> 00:00:56,223 line:-1
After that, I will go through
the best practice guidelines


20
00:00:56,223 --> 00:00:58,792 line:-1
of Object Capture
so you can continue


21
00:00:58,792 --> 00:01:02,362 line:-1
to make the best
out of this technology.


22
00:01:02.362 --> 00:01:05.265 line:-1 position:50%
In the last section,
Risa will take you through


23
00:01:05,265 --> 00:01:09,436 line:-1
an end-to-end workflow with
Object Capture in RealityKit


24
00:01:09.436 --> 00:01:12.506 line:-1 position:50%
and demonstrate how
you can bring real-world objects


25
00:01:12,506 --> 00:01:15,609 line:-1
into an AR experience.


26
00:01:15.609 --> 00:01:19.246 line:-1 position:50%
Let's start with a quick recap
of Object Capture.


27
00:01:19.246 --> 00:01:22.316 line:-1 position:50%
Object Capture
is a computer vision technology


28
00:01:22.316 --> 00:01:25.018 line:-1 position:50%
that you can leverage
to easily turn images


29
00:01:25.018 --> 00:01:29.523 line:-1 position:50%
of real-world objects
into detailed 3D models.


30
00:01:29,523 --> 00:01:32,059 line:-1
You begin by taking photos
of your object


31
00:01:32,059 --> 00:01:37,030 line:-1
from various angles
with an iPhone, iPad, or DSLR.


32
00:01:37,030 --> 00:01:39,633 line:-1
Then, you copy
those photos to a Mac


33
00:01:39.633 --> 00:01:42.836 line:-1 position:50%
which supports Object Capture.


34
00:01:42,836 --> 00:01:45,138 line:-1
Using the Photogrammetry API,


35
00:01:45,138 --> 00:01:49,142 line:-1
RealityKit can transform
your photos into a 3D model


36
00:01:49.142 --> 00:01:51.878 line:-1 position:50%
in just a few minutes.


37
00:01:51.878 --> 00:01:55.182 line:-1 position:50%
The output model includes both
a geometric mesh


38
00:01:55,182 --> 00:01:58,585 line:-1
as well as various material
maps, including textures,


39
00:01:58.585 --> 00:02:02.522 line:-1 position:50%
that are automatically applied
to your model.


40
00:02:02,522 --> 00:02:05,492 line:0
For more details
of the Object Capture API,


41
00:02:05,492 --> 00:02:07,561 line:0
I would highly recommend
that you watch


42
00:02:07,561 --> 00:02:12,499 line:0
last year's WWDC session
on Object Capture.


43
00:02:12,499 --> 00:02:16,269 line:0
Many developers have created
amazing 3D capture apps


44
00:02:16,269 --> 00:02:21,241 line:0
using Object Capture:
Unity, Cinema4D, Qlone,


45
00:02:21,241 --> 00:02:25,078 position:50%
PolyCam, PhotoCatch,
just to name a few.


46
00:02:25,078 --> 00:02:28,382 line:-1
In addition to this,
we have beautiful-looking models


47
00:02:28,382 --> 00:02:31,351 line:-1
that were created
using this API.


48
00:02:31.351 --> 00:02:34.688 line:-1 position:50%
Here's a few models that
were created by Ethan Saadia


49
00:02:34,688 --> 00:02:36,957 line:-1
using the power
of Object Capture


50
00:02:36.957 --> 00:02:39.626 line:-1 position:50%
within the PhotoCatch app.


51
00:02:39,626 --> 00:02:43,597 line:-1
And our friend Mikko Haapoja
from Shopify also generated


52
00:02:43.597 --> 00:02:48.068 line:-1 position:50%
a bunch of great-looking
3D models using this API.


53
00:02:48,068 --> 00:02:50,704 line:-1
The detailed quality
of the output 3D models


54
00:02:50.704 --> 00:02:56.143 line:-1 position:50%
you get with Object Capture is
highly beneficial in e-commerce.


55
00:02:56.143 --> 00:02:58.412 line:-1 position:50%
Here's the GOAT app,
for example,


56
00:02:58,412 --> 00:03:02,115 line:-1
that lets you try on a variety
of shoes on your feet.


57
00:03:02,115 --> 00:03:04,351 line:-1
All of these shoe models
have been created


58
00:03:04,351 --> 00:03:07,921 line:-1
with the Object Capture API
which has been designed


59
00:03:07,921 --> 00:03:12,392 line:-1
to capture the finest level
of detail on them.


60
00:03:12.392 --> 00:03:15.195 line:-1 position:50%
This can go a long way
in helping you


61
00:03:15,195 --> 00:03:18,331 line:-1
with your purchase decision
on a product,


62
00:03:18,331 --> 00:03:22,702 line:-1
or even try out an accurate fit
for an object in your space.


63
00:03:22.702 --> 00:03:26.106 line:-1 position:50%
For example, the Plant Story app
lets you preview


64
00:03:26,106 --> 00:03:30,177 line:-1
real-looking 3D models
of various plants in your space,


65
00:03:30,177 --> 00:03:34,147 line:-1
all of which have been created
with Object Capture.


66
00:03:34,147 --> 00:03:36,650 line:-1
This can help you get a sense
of how much space


67
00:03:36,650 --> 00:03:38,819 line:-1
you may need for a plant,


68
00:03:38,819 --> 00:03:43,457 line:-1
or simply see them in your space
in realistic detail.


69
00:03:43,457 --> 00:03:45,525 line:-1
Speaking about realism,


70
00:03:45,525 --> 00:03:49,563 line:-1
were you able to spot
the real plant in this video?


71
00:03:49.563 --> 00:03:52.299 line:-1 position:50%
Yes, it's the one
in the white planter


72
00:03:52,299 --> 00:03:55,769 line:-1
on the left-most corner
of the table.


73
00:03:55,769 --> 00:03:58,305 line:-1
We are very thrilled
to see such a stunning


74
00:03:58.305 --> 00:04:00.974 line:-1 position:50%
and widespread use
of the Object Capture API


75
00:04:00.974 --> 00:04:04.111 line:-1 position:50%
since its launch in 2021.


76
00:04:04.111 --> 00:04:08.381 line:-1 position:50%
Now, let's talk about some
camera enhancements in ARKit,


77
00:04:08,381 --> 00:04:11,651 line:-1
which will greatly help
the quality of reconstruction


78
00:04:11,651 --> 00:04:14,087 line:-1
with Object Capture.


79
00:04:14,087 --> 00:04:16,389 line:-1
A great Object Capture
experience starts


80
00:04:16.389 --> 00:04:21.128 line:-1 position:50%
with taking good photos
of objects from all sides.


81
00:04:21,128 --> 00:04:24,764 line:-1
To this end, you can use
any high-resolution camera,


82
00:04:24,764 --> 00:04:26,833 line:-1
like the iPhone or iPad,


83
00:04:26.833 --> 00:04:31.071 line:-1 position:50%
or even a DSLR
or mirrorless camera.


84
00:04:31,071 --> 00:04:34,741 line:-1
If you use the Camera app
on your iPhone or iPad,


85
00:04:34,741 --> 00:04:37,410 line:-1
you can take high-quality
photos with depth


86
00:04:37,410 --> 00:04:41,081 line:-1
and gravity information which
lets the Object Capture API


87
00:04:41.081 --> 00:04:43.717 line:-1 position:50%
automatically recover
the real-world scale


88
00:04:43.717 --> 00:04:47.254 line:-1 position:50%
and orientation of the object.


89
00:04:47.254 --> 00:04:51.124 line:-1 position:50%
In addition to that,
if you use an iPhone or iPad,


90
00:04:51,124 --> 00:04:54,461 line:-1
you can take advantage
of ARKit's tracking capabilities


91
00:04:54,461 --> 00:04:58,598 line:-1
to overlay a 3D guidance UI
on top of the model


92
00:04:58.598 --> 00:05:03.203 line:-1 position:50%
to get good coverage
of the object from all sides.


93
00:05:03,203 --> 00:05:05,038 line:-1
Another important thing to note


94
00:05:05.038 --> 00:05:08.842 line:-1 position:50%
is that the higher the image
resolution from your capture,


95
00:05:08.842 --> 00:05:11.778 line:-1 position:50%
the better the quality
of the 3D model


96
00:05:11.778 --> 00:05:14.581 line:-1 position:50%
that Object Capture can produce.


97
00:05:14,581 --> 00:05:15,882 line:-1
To that end,


98
00:05:15.882 --> 00:05:19.719 line:-1 position:50%
with this year's ARKit release
we are introducing a brand-new


99
00:05:19.719 --> 00:05:23.423 line:-1 position:50%
high-resolution
background photos API.


100
00:05:23,423 --> 00:05:28,061 line:-1
This API lets you capture photos
at native camera resolution


101
00:05:28,061 --> 00:05:31,164 line:-1
while you are still running
an ARSession.


102
00:05:31.164 --> 00:05:36.002 line:-1 position:50%
It allows you to use your 3D
UI overlays on top of the object


103
00:05:36,002 --> 00:05:40,240 line:-1
while taking full advantage
of the camera sensor on device.


104
00:05:40,240 --> 00:05:44,044 line:-1
On an iPhone 13, that means
the full 12 megapixels


105
00:05:44,044 --> 00:05:47,547 line:-1
native resolution
of the Wide camera.


106
00:05:47,547 --> 00:05:50,250 line:-1
This API is nonintrusive.


107
00:05:50,250 --> 00:05:52,852 line:-1
It does not interrupt
the continuous video stream


108
00:05:52.852 --> 00:05:56.423 line:-1 position:50%
of the current ARSession,
so your app will continue


109
00:05:56,423 --> 00:06:01,061 line:-1
to provide a smooth
AR experience for your users.


110
00:06:01,061 --> 00:06:05,165 line:-1
In addition, ARKit makes
EXIF metadata available


111
00:06:05,165 --> 00:06:07,767 line:-1
in the photos,
which allows your app


112
00:06:07.767 --> 00:06:12.038 line:-1 position:50%
to read useful information
about white balance, exposure,


113
00:06:12.038 --> 00:06:16.910 line:-1 position:50%
and other settings that can be
valuable for post-processing.


114
00:06:16.910 --> 00:06:22.882 line:-1 position:50%
ARKit makes it extremely easy
to use this new API in your app.


115
00:06:22.882 --> 00:06:25.318 line:-1 position:50%
You can simply query
a video format


116
00:06:25.318 --> 00:06:27.954 line:-1 position:50%
that supports high-resolution
frame capturing


117
00:06:27,954 --> 00:06:33,059 line:-1
on ARWorldTrackingConfguration,
and if successful,


118
00:06:33,059 --> 00:06:37,897 line:-1
set the new video format
and run the ARSession.


119
00:06:37,897 --> 00:06:41,668 line:-1
When it comes to capturing
a high-res photo,


120
00:06:41,668 --> 00:06:44,137 line:-1
simply call ARSession's new


121
00:06:44,137 --> 00:06:47,574 line:-1
captureHighResolutionFrame API
function,


122
00:06:47.574 --> 00:06:50.310 line:-1 position:50%
which will return to you
a high-res photo


123
00:06:50.310 --> 00:06:53.480 line:-1 position:50%
via a completion handler
asynchronously.


124
00:06:53,480 --> 00:06:56,850 line:-1
It is that simple.


125
00:06:56.850 --> 00:06:59.686 line:-1 position:50%
We have also recognized
that there are use cases


126
00:06:59,686 --> 00:07:03,657 line:-1
where you may prefer manual
control over the camera settings


127
00:07:03.657 --> 00:07:07.661 line:-1 position:50%
such as focus, exposure,
or white balance.


128
00:07:07,661 --> 00:07:11,231 line:-1
So we are providing you
with a convenient way


129
00:07:11.231 --> 00:07:14.934 line:-1 position:50%
to access the underlying
AVCaptureDevice directly


130
00:07:14,934 --> 00:07:19,139 line:-1
and change its properties
for fine-grained camera control.


131
00:07:19,139 --> 00:07:22,776 line:-1
As shown in this code example,
simply call


132
00:07:22,776 --> 00:07:25,645 line:-1
configurableCaptureDevice
ForPrimaryCamera


133
00:07:25,645 --> 00:07:28,515 line:-1
on your
ARWorldTrackingConfiguration


134
00:07:28.515 --> 00:07:33.553 line:-1 position:50%
to get access to the underlying
AVCaptureDevice.


135
00:07:33,553 --> 00:07:36,056 line:0
For more details
on these enhancements,


136
00:07:36,056 --> 00:07:38,224 line:0
I highly recommend
you to check out


137
00:07:38,224 --> 00:07:44,097 line:0
the "Discover ARKit 6 session"
from this year's WWDC.


138
00:07:44,097 --> 00:07:47,500 line:-1
Now, let's go through
some best practice guidelines


139
00:07:47,500 --> 00:07:49,669 line:-1
with Object Capture.


140
00:07:49.669 --> 00:07:52.806 line:-1 position:50%
First things first;
we need to choose an object


141
00:07:52,806 --> 00:07:56,810 line:-1
with the right characteristics
for Object Capture.


142
00:07:56,810 --> 00:08:01,081 line:-1
A good object has
adequate texture on its surface.


143
00:08:01,081 --> 00:08:04,951 line:-1
If some regions of the object
are textureless or transparent,


144
00:08:04,951 --> 00:08:09,923 line:-1
the details in those regions
may not be reconstructed well.


145
00:08:09.923 --> 00:08:14.127 line:-1 position:50%
A good object should also be
free of glare and reflections.


146
00:08:14.127 --> 00:08:16.896 line:-1 position:50%
If the object does not have
a matte surface,


147
00:08:16.896 --> 00:08:19.399 line:-1 position:50%
you can try to reduce
the specular on it


148
00:08:19.399 --> 00:08:21.901 line:-1 position:50%
using diffuse lighting.


149
00:08:21,901 --> 00:08:24,070 line:-1
If you would like
to flip over the object


150
00:08:24,070 --> 00:08:25,872 line:-1
to capture its bottom,


151
00:08:25.872 --> 00:08:29.242 line:-1 position:50%
please ensure
that your object stays rigid.


152
00:08:29.242 --> 00:08:33.947 line:-1 position:50%
In other words, it should not
change its shape when flipped.


153
00:08:33,947 --> 00:08:37,884 line:-1
And lastly, a good object
can contain fine structure


154
00:08:37,884 --> 00:08:40,253 line:-1
to some degree,
but you will need to use


155
00:08:40,253 --> 00:08:43,223 line:-1
a high-resolution camera
and take close-up photos


156
00:08:43,223 --> 00:08:48,161 line:-1
to recover the fine detail
of the object.


157
00:08:48.161 --> 00:08:49.529 line:-1 position:50%
The next important thing


158
00:08:49.529 --> 00:08:52.932 line:-1 position:50%
is setting up an ideal
capture environment.


159
00:08:52,932 --> 00:08:56,269 line:-1
You will want to make sure
that your capture environment


160
00:08:56.269 --> 00:09:00.006 line:-1 position:50%
has good, even,
and diffuse lighting.


161
00:09:00,006 --> 00:09:03,176 line:-1
It is important to ensure
a stable background


162
00:09:03.176 --> 00:09:06.413 line:-1 position:50%
and have sufficient space
around the object.


163
00:09:06.413 --> 00:09:08.014 line:-1 position:50%
If your room is dark,


164
00:09:08.014 --> 00:09:11.918 line:-1 position:50%
you can make use
of a well-lit turntable.


165
00:09:11,918 --> 00:09:14,487 line:-1
Next, we'll look
at some guidelines


166
00:09:14,487 --> 00:09:18,691 line:-1
for capturing good photos
of your object, which in turn,


167
00:09:18.691 --> 00:09:22.061 line:-1 position:50%
will ensure that you get
a good quality 3D model


168
00:09:22,061 --> 00:09:24,431 line:-1
from Object Capture.


169
00:09:24,431 --> 00:09:28,067 line:-1
As an example, I'll show you
how my colleague Maunesh


170
00:09:28,067 --> 00:09:30,370 line:-1
used his iPhone
to capture the images


171
00:09:30,370 --> 00:09:32,939 line:-1
of a beautiful pirate ship
that was created


172
00:09:32,939 --> 00:09:37,911 line:-1
by our beloved ARKit engineer,
Christian Lipski.


173
00:09:37.911 --> 00:09:40.380 line:-1 position:50%
Maunesh begins
by placing the pirate ship


174
00:09:40.380 --> 00:09:43.516 line:-1 position:50%
in the middle of a clean table.


175
00:09:43,516 --> 00:09:47,921 line:-1
This makes the ship
clearly stand out in the photos.


176
00:09:47,921 --> 00:09:51,491 line:-1
He holds his iPhone steadily
with two hands.


177
00:09:51,491 --> 00:09:54,260 line:-1
As he circles
around the ship slowly,


178
00:09:54,260 --> 00:09:57,997 line:-1
he captures photos
at various heights.


179
00:09:57,997 --> 00:10:01,901 line:-1
He makes sure that the ship
is large enough in the center


180
00:10:01,901 --> 00:10:03,903 line:-1
of the camera's field of view


181
00:10:03,903 --> 00:10:07,874 line:-1
so that he can capture
the maximum amount of detail.


182
00:10:07,874 --> 00:10:10,310 line:-1
He also makes sure
that he always maintains


183
00:10:10,310 --> 00:10:15,882 line:-1
a high degree of overlap
between any two adjacent photos.


184
00:10:15.882 --> 00:10:18.384 line:-1 position:50%
After he takes
a good number of photos --


185
00:10:18.384 --> 00:10:23.423 line:-1 position:50%
about 80 in this case --
he flips the ship on its side,


186
00:10:23.423 --> 00:10:27.227 line:-1 position:50%
so that he can also
reconstruct its bottom.


187
00:10:27,227 --> 00:10:31,097 line:-1
He continues to capture
about 20 more photos of the ship


188
00:10:31,097 --> 00:10:34,334 line:-1
in a flipped orientation.


189
00:10:34,334 --> 00:10:37,270 line:-1
One thing to note is that
he is holding the iPhone


190
00:10:37.270 --> 00:10:39.172 line:-1 position:50%
in landscape mode.


191
00:10:39.172 --> 00:10:42.642 line:-1 position:50%
This is because
he is capturing a long object,


192
00:10:42.642 --> 00:10:45.278 line:-1 position:50%
and in this case,
the landscape mode helps him


193
00:10:45.278 --> 00:10:49.916 line:-1 position:50%
capture maximum amount of detail
of the object.


194
00:10:49.916 --> 00:10:53.286 line:-1 position:50%
However, he may need to use
the iPhone in portrait mode


195
00:10:53.286 --> 00:10:57.357 line:-1 position:50%
if he were to capture
a tall object instead.


196
00:10:59.359 --> 00:11:00.527 line:-1 position:50%
That's it!


197
00:11:00.527 --> 00:11:03.963 line:-1 position:50%
The final step in the process
is to copy those photos


198
00:11:03,963 --> 00:11:09,002 line:-1
onto a Mac and process them
using the Object Capture API.


199
00:11:09,002 --> 00:11:11,771 position:50%
You can choose from
four different detail levels,


200
00:11:11,771 --> 00:11:15,041 line:0
which are optimized
for different use cases.


201
00:11:15,041 --> 00:11:18,211 line:0
The reduced and medium detail
levels are optimized


202
00:11:18,211 --> 00:11:21,481 line:0
for use in web-based
and mobile experiences,


203
00:11:21,481 --> 00:11:25,218 position:50%
such as viewing 3D content
in AR QuickLook.


204
00:11:25,218 --> 00:11:28,121 position:50%
The reconstructed models
for those detail levels


205
00:11:28,121 --> 00:11:31,124 line:0
have fewer triangles
and material channels,


206
00:11:31,124 --> 00:11:34,294 line:0
thereby consuming
less memory.


207
00:11:34,294 --> 00:11:36,496 line:0
The full and raw detail levels


208
00:11:36,496 --> 00:11:39,432 position:50%
are intended for high-end
interactive use cases,


209
00:11:39,432 --> 00:11:44,203 line:0
such as in computer games
or post-production workflows.


210
00:11:44,203 --> 00:11:47,140 line:0
These models contain
the highest geometric detail


211
00:11:47,140 --> 00:11:50,176 line:0
and give you the flexibility
to choose between baked


212
00:11:50,176 --> 00:11:52,412 position:50%
and unbaked materials,


213
00:11:52,412 --> 00:11:55,882 position:50%
but they require more memory
to reconstruct.


214
00:11:55,882 --> 00:11:58,585 position:50%
It is important to select
the right output level


215
00:11:58,585 --> 00:12:00,954 line:0
depending on your use case.


216
00:12:00,954 --> 00:12:04,324 line:0
For our pirate ship, we chose
the medium detail level,


217
00:12:04,324 --> 00:12:09,896 line:0
which only took a few minutes
to process it on an M1 Mac.


218
00:12:09.896 --> 00:12:12.565 line:-1 position:50%
The output 3D model
looked so stunning


219
00:12:12,565 --> 00:12:15,268 line:-1
that we actually put together
an animated clip


220
00:12:15,268 --> 00:12:18,905 line:-1
of the pirate ship
sailing in high seas.


221
00:12:18.905 --> 00:12:22.208 line:-1 position:50%
And that's the power
of Object Capture for you!


222
00:12:22.208 --> 00:12:24.010 line:-1 position:50%
Ahoy!


223
00:12:24,010 --> 00:12:25,945 line:-1
Now I'll hand it off to Risa,


224
00:12:25,945 --> 00:12:28,681 line:-1
who will be walking you through
an end-to-end workflow


225
00:12:28.681 --> 00:12:31.517 line:-1 position:50%
with Object Capture
in RealityKit.


226
00:12:31,517 --> 00:12:33,186 line:-1
Risa Yoneyama: Thanks, Hao.


227
00:12:33,186 --> 00:12:37,056 line:-1
Now that we have gone over
the Object Capture API,


228
00:12:37,056 --> 00:12:41,194 line:-1
I am excited to go over an
end-to-end developer workflow,


229
00:12:41,194 --> 00:12:46,399 line:-1
to bring your real-life object
into AR using RealityKit.


230
00:12:46.399 --> 00:12:48.368 line:-1 position:50%
We'll walk through
each step in detail


231
00:12:48.368 --> 00:12:50.236 line:-1 position:50%
with an example workflow,


232
00:12:50.236 --> 00:12:54.007 line:-1 position:50%
so let's dive
straight into a demo.


233
00:12:54.007 --> 00:12:56.843 line:-1 position:50%
My colleague Zach
is an occasional woodworker


234
00:12:56.843 --> 00:13:00.780 line:-1 position:50%
and recently built six oversized
wooden chess pieces --


235
00:13:00,780 --> 00:13:02,949 line:-1
one for each unique piece.


236
00:13:02.949 --> 00:13:04.517 line:-1 position:50%
Looking at these chess pieces,


237
00:13:04,517 --> 00:13:08,621 line:-1
I'm inspired to create
an interactive AR chess game.


238
00:13:08,621 --> 00:13:10,790 line:-1
Previously,
you'd need a 3D modeler


239
00:13:10,790 --> 00:13:13,993 line:-1
and material specialist
to create high-quality 3D models


240
00:13:13,993 --> 00:13:15,862 line:-1
of real-world objects.


241
00:13:15,862 --> 00:13:18,398 line:-1
Now, with the
Object Capture API,


242
00:13:18.398 --> 00:13:21.367 line:-1 position:50%
we can simply capture
these chess pieces directly


243
00:13:21,367 --> 00:13:24,504 line:-1
and bring them
into augmented reality.


244
00:13:24,504 --> 00:13:27,006 line:-1
Let's start off
by capturing the rook.


245
00:13:27,006 --> 00:13:30,543 line:-1
My colleague Bryan will be using
this professional setup,


246
00:13:30,543 --> 00:13:33,179 line:-1
keeping in mind
the best practices we covered


247
00:13:33.179 --> 00:13:35.448 line:-1 position:50%
in the previous section.


248
00:13:35,448 --> 00:13:39,085 line:-1
In this case, Bryan is placing
the rook on this turntable


249
00:13:39,085 --> 00:13:41,821 line:-1
with some professional lighting
to help avoid harsh shadows


250
00:13:41.821 --> 00:13:44.123 line:-1 position:50%
in the final output.


251
00:13:44.123 --> 00:13:47.393 line:-1 position:50%
You can also use the iPhone
camera with a turntable,


252
00:13:47.393 --> 00:13:50.029 line:-1 position:50%
which provides you with
automatic scale estimation


253
00:13:50.029 --> 00:13:54.500 line:-1 position:50%
and gravity vector information
in your output USDZ.


254
00:13:54.500 --> 00:13:57.870 line:-1 position:50%
Please refer to the
Object Capture session from 2021


255
00:13:57.870 --> 00:14:00.306 line:-1 position:50%
for more details on this.


256
00:14:00.306 --> 00:14:03.142 line:-1 position:50%
Of course, if you do not have
an elaborate setup


257
00:14:03,142 --> 00:14:07,613 line:-1
like Bryan does here, you can
also simply hold your iOS device


258
00:14:07,613 --> 00:14:12,218 line:-1
and walk around your object
to capture the images.


259
00:14:12,218 --> 00:14:14,987 line:-1
Now that we have all the photos
of our rook piece,


260
00:14:14.987 --> 00:14:17.924 line:-1 position:50%
I'm going to transfer these
over to the Mac.


261
00:14:17.924 --> 00:14:19.292 line:-1 position:50%
I'll process these photos


262
00:14:19.292 --> 00:14:21.427 line:-1 position:50%
using the
PhotogrammetrySession API


263
00:14:21.427 --> 00:14:24.597 line:-1 position:50%
that was introduced in 2021.


264
00:14:24.597 --> 00:14:26.632 line:-1 position:50%
Per the best practice
guidelines,


265
00:14:26.632 --> 00:14:29.469 line:-1 position:50%
I'll use the reduced detail
level to reconstruct,


266
00:14:29.469 --> 00:14:33.239 line:-1 position:50%
as we want to make sure
our AR app performs well.


267
00:14:33.239 --> 00:14:38.911 line:-1 position:50%
The final output of the API
will be a USDZ file type model.


268
00:14:38,911 --> 00:14:40,913 line:-1
Here is our final output
of the rook chess piece


269
00:14:40.913 --> 00:14:43.616 line:-1 position:50%
I just reconstructed.


270
00:14:43.616 --> 00:14:46.319 line:-1 position:50%
To save us some time,
I've gone ahead and captured


271
00:14:46,319 --> 00:14:50,022 line:-1
the other five pieces
ahead of time.


272
00:14:50.022 --> 00:14:52.825 line:-1 position:50%
You may be wondering
how we will create a chess game


273
00:14:52,825 --> 00:14:56,262 line:-1
with only one color scheme
for the chess pieces.


274
00:14:56,262 --> 00:14:58,598 line:-1
Let's duplicate
our six unique pieces


275
00:14:58,598 --> 00:15:01,667 line:-1
and drag them
into Reality Converter.


276
00:15:01,667 --> 00:15:04,370 line:-1
I have inverted the colors
in the original texture


277
00:15:04,370 --> 00:15:08,808 line:-1
and replaced the duplicated set
with this new inverted texture.


278
00:15:08.808 --> 00:15:10.943 line:-1 position:50%
This way, we can have
a lighter version


279
00:15:10.943 --> 00:15:13.479 line:-1 position:50%
and a darker version
of the chess pieces,


280
00:15:13.479 --> 00:15:15.348 line:-1 position:50%
one for each player.


281
00:15:15.348 --> 00:15:16.783 line:-1 position:50%
I'll be exporting the models


282
00:15:16,783 --> 00:15:18,918 line:-1
with the compressed textures
option turned on


283
00:15:18.918 --> 00:15:20.987 line:-1 position:50%
in the Export menu.


284
00:15:20,987 --> 00:15:22,822 line:-1
This will help decrease
the memory footprint


285
00:15:22.822 --> 00:15:24.724 line:-1 position:50%
of the textures.


286
00:15:26,325 --> 00:15:28,795 line:-1
Now that we have
our full set of chess pieces,


287
00:15:28,795 --> 00:15:33,566 line:-1
we are ready to bring the models
into our Xcode project.


288
00:15:33,566 --> 00:15:35,802 line:-1
I've created a chessboard
using RealityKit


289
00:15:35,802 --> 00:15:38,738 line:-1
by scaling down
primitive cubes on the y-axis


290
00:15:38,738 --> 00:15:42,241 line:-1
and alternating the colors
between black and white.


291
00:15:42,241 --> 00:15:45,077 line:-1
Here are all the chess pieces
I reconstructed,


292
00:15:45.077 --> 00:15:47.246 line:-1 position:50%
laid out on the chessboard.


293
00:15:47,246 --> 00:15:48,881 line:-1
This is already exciting to see


294
00:15:48,881 --> 00:15:51,751 line:-1
our real-life objects
in our application,


295
00:15:51,751 --> 00:15:53,152 line:-1
but let's start adding
some features


296
00:15:53,152 --> 00:15:56,455 line:-1
to make it an actual
interactive game.


297
00:15:56.455 --> 00:15:58.090 line:-1 position:50%
Throughout
this part of the demo,


298
00:15:58,090 --> 00:16:01,160 line:-1
I would like to showcase several
different existing technologies,


299
00:16:01.160 --> 00:16:03.429 line:-1 position:50%
so we can provide examples
of how you might want


300
00:16:03,429 --> 00:16:08,034 line:-1
to combine the technologies to
accomplish your desired output.


301
00:16:08.034 --> 00:16:10.369 line:-1 position:50%
As we'll be going over
some practical use cases


302
00:16:10.369 --> 00:16:12.772 line:-1 position:50%
of advanced topics
in RealityKit,


303
00:16:12,772 --> 00:16:14,574 position:50%
I would recommend checking out


304
00:16:14,574 --> 00:16:16,709 position:50%
the RealityKit sessions
from 2021


305
00:16:16,709 --> 00:16:20,546 line:0
if you are not already
familiar with the APIs.


306
00:16:20.546 --> 00:16:23.349 line:-1 position:50%
I want to start by adding
a start-up animation


307
00:16:23.349 --> 00:16:26.352 line:-1 position:50%
when we first launch
the application.


308
00:16:26.352 --> 00:16:28.855 line:-1 position:50%
I am imagining an animation
where the checker tiles


309
00:16:28,855 --> 00:16:30,323 line:-1
slowly fall into place


310
00:16:30.323 --> 00:16:32.792 line:-1 position:50%
from slightly above
its final position,


311
00:16:32,792 --> 00:16:36,429 line:-1
all while the chess pieces
also translate in together.


312
00:16:36.429 --> 00:16:38.664 line:-1 position:50%
To replicate
this effect in code,


313
00:16:38.664 --> 00:16:41.400 line:-1 position:50%
all it takes is two steps.


314
00:16:41,400 --> 00:16:44,136 line:-1
The first step is to translate
both our entities


315
00:16:44.136 --> 00:16:46.172 line:-1 position:50%
up along the y-axis,


316
00:16:46.172 --> 00:16:50.009 line:-1 position:50%
while also uniformly
scaling down the chess piece.


317
00:16:50,009 --> 00:16:53,145 line:-1
The second step and final step
is to animate both entities


318
00:16:53,145 --> 00:16:56,315 line:-1
back to its original transform.


319
00:16:56,315 --> 00:16:59,352 line:-1
The code for this
is quite simple.


320
00:16:59,352 --> 00:17:03,289 line:-1
I'll start by iterating through
the checker tile entities.


321
00:17:03,289 --> 00:17:04,390 line:-1
For each entity,


322
00:17:04.390 --> 00:17:07.159 line:-1 position:50%
I'll save the current transform
of the checker tile


323
00:17:07.159 --> 00:17:10.763 line:-1 position:50%
as this will be the final
position it lands on.


324
00:17:10,763 --> 00:17:16,002 line:-1
Then, I'll move each square up
10 cm on the y-axis.


325
00:17:16,002 --> 00:17:18,104 line:-1
We can now take advantage
of the move function


326
00:17:18.104 --> 00:17:22.642 line:-1 position:50%
to animate this back
to our original transform.


327
00:17:22.642 --> 00:17:25.544 line:-1 position:50%
I also happen to know
that this border USDZ


328
00:17:25,544 --> 00:17:29,749 line:-1
that outlines the checkerboard
has a built-in animation.


329
00:17:29,749 --> 00:17:31,817 position:50%
We can use the playAnimation API


330
00:17:31,817 --> 00:17:35,454 line:0
to start the animation
simultaneously.


331
00:17:35,454 --> 00:17:38,357 position:50%
I've added the exact same
animation to the chess pieces


332
00:17:38,357 --> 00:17:42,495 line:0
but also modifying the scale
as they translate.


333
00:17:42.495 --> 00:17:43.729 line:-1 position:50%
And here we have it:


334
00:17:43,729 --> 00:17:47,934 line:-1
a simple startup animation
with just a few lines of code.


335
00:17:47,934 --> 00:17:50,970 line:-1
However, we won't actually
be able to play chess


336
00:17:50,970 --> 00:17:53,539 line:-1
without the ability
to move the chess pieces.


337
00:17:53,539 --> 00:17:55,708 line:-1
Let's work on that next.


338
00:17:55,708 --> 00:17:58,210 line:-1
Before we can start moving
the chess pieces,


339
00:17:58.210 --> 00:18:00.980 line:-1 position:50%
we'll need to be able
to select one.


340
00:18:00.980 --> 00:18:03.649 line:-1 position:50%
I've already added
a UITapGestureRecognizer


341
00:18:03.649 --> 00:18:05.651 line:-1 position:50%
to my ARView.


342
00:18:05,651 --> 00:18:08,220 line:-1
When the users taps
a specific location,


343
00:18:08,220 --> 00:18:10,990 line:-1
we will define a ray that starts
from the camera origin


344
00:18:10.990 --> 00:18:14.827 line:-1 position:50%
and goes through that 2D point.


345
00:18:14,827 --> 00:18:18,698 line:-1
We can then perform a raycast
with that ray into the 3D scene


346
00:18:18,698 --> 00:18:21,167 line:-1
to see if we hit any entities.


347
00:18:21.167 --> 00:18:24.403 line:-1 position:50%
I've specified my chess piece
collision group as a mask


348
00:18:24.403 --> 00:18:27.206 line:-1 position:50%
as I know I only want to be able
to select the chess pieces


349
00:18:27,206 --> 00:18:29,308 line:-1
in my scene.


350
00:18:29,308 --> 00:18:31,077 line:-1
Be mindful that
the raycast function


351
00:18:31,077 --> 00:18:33,212 line:-1
will ignore all entities
that do not have


352
00:18:33.212 --> 00:18:35.047 line:-1 position:50%
a CollisionComponent.


353
00:18:35,047 --> 00:18:39,719 line:0
If we do find a chess piece,
we can finally select it.


354
00:18:39,719 --> 00:18:41,754 position:50%
Now that we know
which piece is selected,


355
00:18:41,754 --> 00:18:43,122 line:0
I want to add an effect


356
00:18:43,122 --> 00:18:47,259 line:0
that will make the piece
look like it is glowing.


357
00:18:47.259 --> 00:18:50.062 line:-1 position:50%
We can leverage custom materials
to achieve this;


358
00:18:50,062 --> 00:18:52,999 line:-1
more specifically,
surface shaders.


359
00:18:52,999 --> 00:18:55,001 line:-1
Surface shaders allow you
to calculate


360
00:18:55,001 --> 00:18:58,170 line:-1
or specify material parameters
through Metal,


361
00:18:58.170 --> 00:19:01.240 line:-1 position:50%
which then gets called by
RealityKit's fragment shader


362
00:19:01.240 --> 00:19:03.809 line:-1 position:50%
once per each pixel.


363
00:19:03,809 --> 00:19:05,177 line:-1
We can write a surface shader


364
00:19:05.177 --> 00:19:08.014 line:-1 position:50%
that looks like
this fire effect in Metal.


365
00:19:08,014 --> 00:19:09,615 line:-1
Then apply a custom material,


366
00:19:09,615 --> 00:19:12,184 line:-1
with this surface shader
to our rectangular prism


367
00:19:12.184 --> 00:19:15.955 line:-1 position:50%
to have the shader affect
how our entity looks.


368
00:19:15,955 --> 00:19:19,859 line:-1
Let's write some code
to achieve our desired effect.


369
00:19:19,859 --> 00:19:22,228 line:-1
I've already added
a noise texture to the project


370
00:19:22.228 --> 00:19:24.530 line:-1 position:50%
to use in this surface shader.


371
00:19:24,530 --> 00:19:26,399 line:-1
We'll sample the texture twice,


372
00:19:26,399 --> 00:19:28,534 line:-1
once for the overall
shape of the effect


373
00:19:28.534 --> 00:19:30.603 line:-1 position:50%
and another for detail.


374
00:19:30.603 --> 00:19:33.606 line:-1 position:50%
We then take the RGB value
and remap it to look


375
00:19:33,606 --> 00:19:35,641 line:-1
just the way we want.


376
00:19:35,641 --> 00:19:38,144 line:-1
Then, with the processed value
we just extracted,


377
00:19:38,144 --> 00:19:40,946 line:-1
we'll calculate the opacity
of the sample point


378
00:19:40,946 --> 00:19:45,418 line:-1
by comparing its y-position
with the image value.


379
00:19:45,418 --> 00:19:47,053 line:0
To give the effect
some movement,


380
00:19:47,053 --> 00:19:49,188 line:0
we'll be moving through
the y-axis of the texture


381
00:19:49,188 --> 00:19:52,525 position:50%
as a function of time.


382
00:19:52,525 --> 00:19:55,194 line:-1
Additionally, we will also
use the facing angle


383
00:19:55.194 --> 00:19:57.296 line:-1 position:50%
of each sample point
in conjunction


384
00:19:57.296 --> 00:19:59.965 line:-1 position:50%
with the viewing direction
of the camera


385
00:19:59.965 --> 00:20:02.001 line:-1 position:50%
to fade the effect at the sides.


386
00:20:02,001 --> 00:20:04,503 line:-1
This will soften the edges
and hide the regular nature


387
00:20:04,503 --> 00:20:07,973 line:-1
of the underlying model.


388
00:20:07.973 --> 00:20:11.544 line:-1 position:50%
Finally, we'll set the color
and opacity we just calculated


389
00:20:11,544 --> 00:20:15,448 line:-1
using the surface
parameter functions.


390
00:20:15.448 --> 00:20:16.615 line:-1 position:50%
And here are the chess pieces


391
00:20:16,615 --> 00:20:19,018 line:-1
with the selection shader
applied to it.


392
00:20:19,018 --> 00:20:22,922 line:-1
They really do look like they
are glowing from the inside.


393
00:20:22,922 --> 00:20:24,390 line:-1
Now, if we combine that


394
00:20:24,390 --> 00:20:26,892 line:-1
with three separate
translation animations,


395
00:20:26,892 --> 00:20:30,663 line:-1
that will result in something
that looks like this.


396
00:20:30,663 --> 00:20:34,867 line:-1
With the functionality to move
chess pieces implemented,


397
00:20:34,867 --> 00:20:38,704 line:-1
we'll also be able to capture
the opponent's pieces.


398
00:20:38,704 --> 00:20:41,774 line:-1
Just like surface shaders,
geometry modifiers


399
00:20:41.774 --> 00:20:45.511 line:-1 position:50%
can be implemented
using custom materials.


400
00:20:45,511 --> 00:20:48,981 line:-1
They are a very powerful tool,
as you can change vertex data


401
00:20:48,981 --> 00:20:54,420 line:-1
such as position, normals,
texture coordinates, and more.


402
00:20:54.420 --> 00:20:57.523 line:-1 position:50%
Each of these Metal functions
will be called once per vertex


403
00:20:57.523 --> 00:21:00.526 line:-1 position:50%
by RealityKit's vertex shader.


404
00:21:00,526 --> 00:21:03,295 line:-1
These modifications
are purely transient


405
00:21:03,295 --> 00:21:05,598 line:-1
and do not affect
the vertex information


406
00:21:05.598 --> 00:21:08.667 line:-1 position:50%
of the actual entity.


407
00:21:08,667 --> 00:21:11,137 line:-1
I'm thinking we could add
a fun geometry modifier


408
00:21:11.137 --> 00:21:14.473 line:-1 position:50%
to squash the pieces
when they are captured.


409
00:21:14,473 --> 00:21:16,942 line:-1
I have this property
on my chess piece


410
00:21:16.942 --> 00:21:19.812 line:-1 position:50%
called capturedProgress
to represent the progress


411
00:21:19.812 --> 00:21:24.350 line:-1 position:50%
of the capturing animation
from 0 to 1.


412
00:21:24,350 --> 00:21:27,486 line:-1
Since capturing
is a user-initiated action,


413
00:21:27.486 --> 00:21:29.755 line:-1 position:50%
we somehow need to tell
the geometry modifier


414
00:21:29,755 --> 00:21:32,725 line:-1
when to start its animation.


415
00:21:32,725 --> 00:21:34,593 line:-1
The good thing is
you can do this


416
00:21:34.593 --> 00:21:38.097 line:-1 position:50%
by setting the custom property
on a customMaterial.


417
00:21:38,097 --> 00:21:42,735 line:-1
This allows data to be shared
between the CPU and the GPU.


418
00:21:42,735 --> 00:21:45,704 line:-1
We will specifically use
the custom value property here


419
00:21:45.704 --> 00:21:50.142 line:-1 position:50%
and pass the animation progress
to the geometry modifier.


420
00:21:50.142 --> 00:21:53.579 line:-1 position:50%
To extract the animation
progress from the Metal side,


421
00:21:53,579 --> 00:21:57,917 line:-1
we can use the custom parameter
on uniforms.


422
00:21:57.917 --> 00:22:00.186 line:-1 position:50%
Since I want to scale
the object vertically,


423
00:22:00,186 --> 00:22:02,621 line:-1
as if it is being squashed
by another piece,


424
00:22:02,621 --> 00:22:06,125 line:-1
we will set the scale axis
as the y-direction.


425
00:22:06,125 --> 00:22:08,360 line:-1
To add some complexity
to the animation,


426
00:22:08.360 --> 00:22:10.796 line:-1 position:50%
we will also change
the geometry in the x-axis


427
00:22:10.796 --> 00:22:13.265 line:-1 position:50%
to create a wave effect.


428
00:22:13,265 --> 00:22:15,601 line:0
The offset of the vertex
can be set using the


429
00:22:15,601 --> 00:22:19,271 position:50%
set_model_position_ offset
function.


430
00:22:19,271 --> 00:22:23,142 line:-1
Here is the final product
of our geometry modifier.


431
00:22:23.142 --> 00:22:26.278 line:-1 position:50%
You can see that it scales up
a bit before collapsing down,


432
00:22:26,278 --> 00:22:30,482 line:-1
while being stretched vertically
along the x-axis.


433
00:22:30.482 --> 00:22:32.885 line:-1 position:50%
As a chess novice myself,


434
00:22:32.885 --> 00:22:34.987 line:-1 position:50%
I thought it might be helpful
to add a feature


435
00:22:34.987 --> 00:22:37.389 line:-1 position:50%
to indicate where
your selected piece can move to


436
00:22:37.389 --> 00:22:40.292 line:-1 position:50%
to help me learn the game.


437
00:22:40.292 --> 00:22:43.329 line:-1 position:50%
Since the checker pieces
are each individual entities


438
00:22:43,329 --> 00:22:45,297 line:-1
with their own Model Component,


439
00:22:45,297 --> 00:22:48,634 line:-1
I can apply a pulsing effect
using a surface shader


440
00:22:48,634 --> 00:22:52,171 line:-1
to potential moves
to distinguish them from others.


441
00:22:52,171 --> 00:22:55,107 line:-1
Next, I'll add a post-processing
effect called "bloom"


442
00:22:55.107 --> 00:22:58.344 line:-1 position:50%
to accentuate
the effect even more.


443
00:22:58.344 --> 00:23:00.713 line:-1 position:50%
Again, we're using
the custom parameter here


444
00:23:00,713 --> 00:23:04,283 line:-1
we used in the surface shader
for the glow effect.


445
00:23:04.283 --> 00:23:07.853 line:-1 position:50%
In this case, we are passing in
a Boolean from the CPU side


446
00:23:07.853 --> 00:23:11.123 line:-1 position:50%
to our Metal surface shader.


447
00:23:11.123 --> 00:23:13.459 line:-1 position:50%
If this checker
is a possible move,


448
00:23:13,459 --> 00:23:16,629 line:-1
I want to add a pulsing effect
by changing the color.


449
00:23:16.629 --> 00:23:21.100 line:-1 position:50%
We'll specifically add the pulse
to the emissive color here.


450
00:23:21,100 --> 00:23:25,571 line:-1
Lastly, I'll add the bloom
effect to the entire view.


451
00:23:25.571 --> 00:23:28.440 line:-1 position:50%
Bloom is a post-processing
effect that produces


452
00:23:28.440 --> 00:23:32.344 line:-1 position:50%
feathers of light from
the borders of bright areas.


453
00:23:32,344 --> 00:23:35,147 line:-1
We can accomplish this effect
by taking advantage


454
00:23:35.147 --> 00:23:39.451 line:-1 position:50%
of the render callbacks property
on ARView.


455
00:23:39,451 --> 00:23:42,154 line:-1
We will write the bloom effect
using the already built-in


456
00:23:42,154 --> 00:23:45,758 line:-1
Metal performance shader
functions.


457
00:23:45,758 --> 00:23:49,094 line:-1
Next, we'll simply set the
renderCallbacks.postProcess


458
00:23:49,094 --> 00:23:52,498 line:-1
closure as our bloom function
we just defined.


459
00:23:52.498 --> 00:23:55.601 line:-1 position:50%
When we pulse our checkers,
we are pulsing to a white color


460
00:23:55,601 --> 00:23:57,536 line:-1
which will now be
further emphasized


461
00:23:57,536 --> 00:24:00,339 line:-1
with the bloom effect.


462
00:24:00,339 --> 00:24:03,142 position:50%
With the surface shader
and bloom effect together,


463
00:24:03,142 --> 00:24:08,480 position:50%
we can see exactly where
we can move our pieces to.


464
00:24:08.480 --> 00:24:11.216 line:-1 position:50%
Finally, let's combine
everything we have together


465
00:24:11.216 --> 00:24:13.619 line:-1 position:50%
to see our real-life
chess pieces come to life


466
00:24:13.619 --> 00:24:16.422 line:-1 position:50%
in our AR app.


467
00:24:16.422 --> 00:24:18.490 line:-1 position:50%
We can see how
all the features we added


468
00:24:18.490 --> 00:24:21.126 line:-1 position:50%
look in our environment.


469
00:24:21.126 --> 00:24:22.761 line:-1 position:50%
For your convenience
we have linked


470
00:24:22.761 --> 00:24:26.732 line:-1 position:50%
the Capture Chess sample project
to the session resources.


471
00:24:26,732 --> 00:24:28,901 line:-1
Please download it
and try it out for yourself


472
00:24:28,901 --> 00:24:31,236 line:-1
to see it in your environment.


473
00:24:31.236 --> 00:24:32.604 line:-1 position:50%
And it's that simple.


474
00:24:32.604 --> 00:24:36.041 line:-1 position:50%
From capture to reconstruction
of the oversized chess pieces,


475
00:24:36.041 --> 00:24:40.112 line:-1 position:50%
then into
our augmented reality app.


476
00:24:40.112 --> 00:24:43.082 line:-1 position:50%
We've covered a lot
in this session today


477
00:24:43,082 --> 00:24:46,418 line:-1
so let's summarize
some of the key points.


478
00:24:46,418 --> 00:24:50,255 line:-1
We first started off by
recapping the Object Capture API


479
00:24:50.255 --> 00:24:53.459 line:-1 position:50%
that we announced in 2021.


480
00:24:53,459 --> 00:24:56,362 line:-1
We then went over
a new API in ARKit


481
00:24:56,362 --> 00:24:58,997 line:-1
that enables
capturing photos on-demand


482
00:24:58.997 --> 00:25:03.802 line:-1 position:50%
at native camera resolution
during an active ARSession.


483
00:25:03,802 --> 00:25:07,706 line:-1
To help you get the most out of
the Object Capture technology,


484
00:25:07.706 --> 00:25:11.243 line:-1 position:50%
we listed types of objects that
are suited for reconstruction,


485
00:25:11,243 --> 00:25:14,747 line:-1
ideal environments
to get high-quality images,


486
00:25:14.747 --> 00:25:16.648 line:-1 position:50%
and the recommended
flow to follow


487
00:25:16,648 --> 00:25:19,885 line:-1
while capturing your object.


488
00:25:19.885 --> 00:25:21.787 line:-1 position:50%
For the latter part
of this session,


489
00:25:21.787 --> 00:25:25.591 line:-1 position:50%
we walked through an example
end-to-end developer workflow.


490
00:25:25.591 --> 00:25:28.494 line:-1 position:50%
We captured photos
of the oversized chess pieces


491
00:25:28.494 --> 00:25:32.431 line:-1 position:50%
and used the images as input
to the PhotogrammetrySession API


492
00:25:32.431 --> 00:25:35.167 line:-1 position:50%
to create 3D models of them.


493
00:25:35.167 --> 00:25:38.270 line:-1 position:50%
Then, we imported the models
into Reality Converter


494
00:25:38.270 --> 00:25:40.739 line:-1 position:50%
to replace some textures.


495
00:25:40.739 --> 00:25:43.575 line:-1 position:50%
And finally, we slowly
built up our chess game


496
00:25:43,575 --> 00:25:47,946 line:-1
to see our chess pieces
in action in AR.


497
00:25:47,946 --> 00:25:50,015 line:-1
And that's it
for our session today.


498
00:25:50,015 --> 00:25:51,817 line:-1
Thank you so much for watching.


499
00:25:51,817 --> 00:25:53,285 line:-1
Ahoy!


500
00:25:53,285 --> 00:25:57,556 line:0 position:90% align:right
♪

