2
00:00:00,501 --> 00:00:08,509 line:-1
â™ª â™ª


3
00:00:09.309 --> 00:00:11.778 line:-1 align:center
Christian: Hi, my name is Christian.


4
00:00:11.812 --> 00:00:14.214 line:-1 align:center
I'm an engineer on the ARKit team,


5
00:00:14,248 --> 00:00:18,452 line:-2
and I would like to welcome you
to our session, Discover ARKit 6.


6
00:00:18,485 --> 00:00:21,688 line:-2
You'll learn how to make use
of the latest advancements


7
00:00:21.722 --> 00:00:24.691 line:-1 align:center
in our Augmented Reality framework.


8
00:00:24.725 --> 00:00:28.996 line:-2 align:center
We are delighted to see what you have been
creating over the last several years


9
00:00:29.029 --> 00:00:30.497 line:-1 align:center
with ARKit.


10
00:00:30,531 --> 00:00:33,967 line:-2
We are seeing some amazing apps
in interior design,


11
00:00:34.001 --> 00:00:36.103 line:-1 align:center
travel, virtual exhibitions,


12
00:00:36.136 --> 00:00:38.372 line:-1 align:center
games, and so many others.


13
00:00:38.405 --> 00:00:42.009 line:-2 align:center
Our team here at Apple has
paid close attention to your feedback,


14
00:00:42,042 --> 00:00:45,546 line:-2
and we have incorporated a lot of it
into ARKit 6.


15
00:00:45,579 --> 00:00:46,647 line:-1
Let's have a look.


16
00:00:46,680 --> 00:00:51,618 line:-2
We are introducing a new 4K video mode
that lets you run the camera stream


17
00:00:51.652 --> 00:00:54.421 line:-1 align:center
in the highest image resolution yet.


18
00:00:54.454 --> 00:00:58.392 line:-2 align:center
After that, I'll talk about some
additional camera enhancements we made


19
00:00:58,425 --> 00:01:01,762 line:-2
that give you more control
of the video backdrop.


20
00:01:01,795 --> 00:01:05,566 line:-2
We also have updates
on the behavior of plane anchors,


21
00:01:05,599 --> 00:01:08,435 line:-1
additions to the Motion Capture API,


22
00:01:08,468 --> 00:01:12,739 line:-2
and finally share new cities
where location anchors will be supported.


23
00:01:14.441 --> 00:01:17.477 line:-1 align:center
Let's start with 4K video.


24
00:01:17,511 --> 00:01:20,347 line:-1
Over the course of the past several years,


25
00:01:20.380 --> 00:01:24.184 line:-2 align:center
we saw a lot of demand
for high resolution content,


26
00:01:24.218 --> 00:01:28.055 line:-2 align:center
especially those apps which leverage
the power of Augmented Reality


27
00:01:28.088 --> 00:01:32.492 line:-2 align:center
for filmmaking,
are ever hungry for more pixels.


28
00:01:32.526 --> 00:01:36.530 line:-2 align:center
Let me show you how images are captured
and processed for ARKit.


29
00:01:36,563 --> 00:01:39,933 line:-2
This is the camera module
of an iPhone 13 Pro.


30
00:01:39,967 --> 00:01:43,036 line:-1
If we open it up, we can see its setup.


31
00:01:43.070 --> 00:01:46.406 line:-2 align:center
Let us talk about the Wide
and the Ultrawide camera.


32
00:01:46.440 --> 00:01:50.844 line:-2 align:center
Both these cameras can be used
for different computer vision tasks,


33
00:01:50,878 --> 00:01:55,415 line:-2
such as world tracking,
motion capture, or person segmentation.


34
00:01:55.449 --> 00:01:58.719 line:-2 align:center
The wide camera
has a special place in our heart,


35
00:01:58.752 --> 00:02:02.489 line:-2 align:center
since it delivers the images
for the rendering backdrop.


36
00:02:02,523 --> 00:02:06,326 line:-2
It's important to understand
how images are processed for rendering,


37
00:02:06.360 --> 00:02:09.129 line:-1 align:center
so let me zoom in to the sensor level.


38
00:02:13.100 --> 00:02:17.838 line:-2 align:center
When capturing images for ARKit,
we use a large part of the image sensor.


39
00:02:17.871 --> 00:02:23.343 line:-2 align:center
To be more precise,
it's an area of 3840x2880 pixels


40
00:02:23,377 --> 00:02:25,546 line:-1
on this particular model.


41
00:02:25,579 --> 00:02:28,815 line:-2
After capture,
we use a process called binning.


42
00:02:28.849 --> 00:02:31.852 line:-1 align:center
It works as follows:


43
00:02:31.885 --> 00:02:36.123 line:-1 align:center
Binning takes a region of 2x2 pixels,


44
00:02:36.156 --> 00:02:38.525 line:-1 align:center
averages the pixel values,


45
00:02:38,559 --> 00:02:41,895 line:-1
and writes back a single pixel.


46
00:02:41.929 --> 00:02:44.731 line:-1 align:center
This has two significant advantages.


47
00:02:44.765 --> 00:02:48.535 line:-2 align:center
First, image dimensions are reduced
by a factor of two,


48
00:02:48.569 --> 00:02:53.240 line:-2 align:center
in this case,
it downscales to 1920x1440 pixels.


49
00:02:53.273 --> 00:02:58.579 line:-2 align:center
As a result of this, each frame consumes
way less memory and processing power.


50
00:02:58,612 --> 00:03:02,883 line:-2
This allows the device to run the camera
at up to 60 frames per second


51
00:03:02.916 --> 00:03:05.819 line:-1 align:center
and frees up resources for rendering.


52
00:03:05.853 --> 00:03:09.022 line:-2 align:center
Secondly,
this process offers an advantage


53
00:03:09.056 --> 00:03:10.724 line:-1 align:center
in low light environments,


54
00:03:10,757 --> 00:03:15,062 line:-2
where the averaging of pixel values
reduces the effects of sensor noise.


55
00:03:15.796 --> 00:03:21.869 line:-2 align:center
We end up with a camera stream
that provides an image at HD resolution


56
00:03:21.902 --> 00:03:24.972 line:-1 align:center
roughly every 17 milliseconds.


57
00:03:25.005 --> 00:03:29.042 line:-2 align:center
After using the current frame
for various computer vision tasks,


58
00:03:29.076 --> 00:03:33.347 line:-2 align:center
ARKit surfaces the current frame
for rendering.


59
00:03:33,380 --> 00:03:35,983 line:-2
In case you are writing
your own Metal renderer,


60
00:03:36.016 --> 00:03:41.088 line:-2 align:center
you have access to it via
ARSession's currentFrame.capturedImage.


61
00:03:42.623 --> 00:03:47.227 line:-2 align:center
If you are using RealityKit, the image
is automatically processed further


62
00:03:47.261 --> 00:03:49.129 line:-1 align:center
for use as a backdrop.


63
00:03:49.162 --> 00:03:55.302 line:-2 align:center
It is scaled on-device to match
the screen width of 2532 pixels


64
00:03:55,335 --> 00:04:00,374 line:-2
and is cropped to match
the display aspect ratio.


65
00:04:00,407 --> 00:04:05,379 line:-2
RealityKit performs the task of rendering
and compositing the virtual content,


66
00:04:05.412 --> 00:04:06.847 line:-1 align:center
like this pirate ship,


67
00:04:06,880 --> 00:04:10,817 line:-2
on top of the frame and displays
the final result on screen.


68
00:04:10.851 --> 00:04:13.453 line:-2 align:center
Now, with the power
of our latest hardware,


69
00:04:13,487 --> 00:04:17,891 line:-1
we enable full 4K video mode in ARKit.


70
00:04:17,925 --> 00:04:21,461 line:-2
Your app can now take advantage
of a higher resolution image


71
00:04:21,495 --> 00:04:27,701 line:-2
by skipping the binning step and directly
accessing it in full 4K resolution.


72
00:04:27,734 --> 00:04:34,241 line:-2
In 4K mode,
an image area of 3840x2160 pixels is used


73
00:04:34.274 --> 00:04:37.878 line:-2 align:center
and you can capture video
at 30 frames per second.


74
00:04:37,911 --> 00:04:41,515 line:-2
Apart from these changes, your app
will work the same way as before.


75
00:04:41.548 --> 00:04:44.685 line:-2 align:center
If you use RealityKit,
it performs scaling, cropping,


76
00:04:44.718 --> 00:04:46.420 line:-1 align:center
and rendering for you.


77
00:04:49.723 --> 00:04:54.528 line:-2 align:center
You can enable the 4K mode
using a few simple steps.


78
00:04:54,561 --> 00:04:56,964 line:-1
Let's see how that looks in code.


79
00:04:58.866 --> 00:05:02.236 line:-2 align:center
'ARConfiguration' has a new convenience
function


80
00:05:02,269 --> 00:05:08,675 line:-2
'recommendedVideoFormatFor4KResolution'
that returns a 4K video format


81
00:05:08,709 --> 00:05:11,812 line:-2
if that mode is supported
on your device.


82
00:05:11,845 --> 00:05:17,317 line:-2
If the device or configuration do not
support 4K, this function will return nil.


83
00:05:17.351 --> 00:05:20.854 line:-2 align:center
You can then assign this video format
to your configuration,


84
00:05:20.888 --> 00:05:24.291 line:-2 align:center
then you run your session
with that adjusted configuration.


85
00:05:25.826 --> 00:05:30.464 line:-2 align:center
The 4K video mode is available
on iPhone 11 and up


86
00:05:30.497 --> 00:05:34.034 line:-1 align:center
and on any iPad Pro with an M1 chip.


87
00:05:34.067 --> 00:05:40.807 line:-2 align:center
The resolution is 3840x2160 pixels
at 30 frames per second.


88
00:05:40.841 --> 00:05:43.544 line:-1 align:center
The aspect ratio is 16:9,


89
00:05:43.577 --> 00:05:47.748 line:-2 align:center
for iPad that means that images have to be
cropped at the sides


90
00:05:47,781 --> 00:05:52,286 line:-2
for full screen display and the final
render might look zoomed in.


91
00:05:53,453 --> 00:05:57,658 line:-2
When using ARKit,
especially in the new 4K resolution,


92
00:05:57,691 --> 00:06:01,728 line:-2
it's important to follow some
best practices for optimal results.


93
00:06:01.762 --> 00:06:04.531 line:-1 align:center
Do not hold on to an ARFrame for too long.


94
00:06:04,565 --> 00:06:08,402 line:-2
This might prevent the system
from freeing up memory,


95
00:06:08,435 --> 00:06:12,406 line:-2
which might further stop ARKit
from surfacing newer frames to you.


96
00:06:12,439 --> 00:06:15,876 line:-2
This will become visible through
frame drops in your rendering.


97
00:06:15.909 --> 00:06:20.714 line:-2 align:center
Ultimately, the ARCamera's tracking state
might fall back to limited.


98
00:06:20,747 --> 00:06:23,817 line:-2
Check for console warnings
to make sure you do not retain


99
00:06:23.851 --> 00:06:26.753 line:-1 align:center
too many images at any given time.


100
00:06:26.787 --> 00:06:32.693 line:-2 align:center
Also consider if the new 4K video format
is indeed the right option for your app.


101
00:06:32,726 --> 00:06:36,697 line:-2
Apps that benefit from high resolution
video are good candidates,


102
00:06:36.730 --> 00:06:40.868 line:-2 align:center
such as video, filmmaking,
and virtual production apps.


103
00:06:40,901 --> 00:06:45,205 line:-2
Dealing with higher resolution images
takes up additional system resources,


104
00:06:45.239 --> 00:06:49.009 line:-2 align:center
so for games and other apps
that rely on a high refresh rate,


105
00:06:49,042 --> 00:06:54,047 line:-2
we still suggest using full HD video
at 60 frames per second.


106
00:06:55.048 --> 00:06:58.685 line:-2 align:center
On top of the new 4K mode,
there are some additional enhancements


107
00:06:58.719 --> 00:07:03.090 line:-2 align:center
that allow you to get more control
over your camera.


108
00:07:03,123 --> 00:07:08,161 line:-2
I will start by introducing the hi-res
background photo API


109
00:07:08.195 --> 00:07:12.599 line:-1 align:center
and show how to enable the new HDR mode.


110
00:07:12.633 --> 00:07:15.836 line:-1 align:center
Further, I will demonstrate how to get access


111
00:07:15,869 --> 00:07:20,807 line:-2
to the underlying AVCaptureDevice
for more fine grained control


112
00:07:20,841 --> 00:07:24,678 line:-2
and show you how to read EXIF tags
in ARKit.


113
00:07:24,711 --> 00:07:29,283 line:-2
Let's jump into the new
hi-res background photo API.


114
00:07:30,317 --> 00:07:31,985 line:-1
While running an ARSession,


115
00:07:32,019 --> 00:07:35,923 line:-2
you still get access
to the video stream as usual.


116
00:07:35.956 --> 00:07:41.628 line:-2 align:center
In addition, ARKit lets you request
the capture of single photos on demand


117
00:07:41,662 --> 00:07:42,996 line:-1
in the background,


118
00:07:43,030 --> 00:07:46,133 line:-2
while the video stream is running
uninterrupted.


119
00:07:46.166 --> 00:07:50.571 line:-2 align:center
Those single photo frames take
full advantage of your camera sensor.


120
00:07:50,604 --> 00:07:55,843 line:-2
On my iPhone 13 that means
the full 12 megapixels of the wide camera.


121
00:07:55.876 --> 00:07:58.212 line:-1 align:center
When preparing for WWDC,


122
00:07:58.245 --> 00:08:01.548 line:-2 align:center
we at ARKit had a fun idea
for a Photography app


123
00:08:01.582 --> 00:08:06.153 line:-2 align:center
that highlights what this new API
can help you create.


124
00:08:06.186 --> 00:08:09.423 line:-2 align:center
In our example,
we take you back in time


125
00:08:09,456 --> 00:08:13,227 line:-2
to April 1st, 2016,
when the famous pirate flag


126
00:08:13.260 --> 00:08:16.430 line:-2 align:center
was flying over
the Apple Infinite Loop Campus.


127
00:08:16.463 --> 00:08:19.600 line:-2 align:center
I asked Tommy,
the original photographer,


128
00:08:19,633 --> 00:08:23,036 line:-2
where exactly he shot that photo
six years ago.


129
00:08:25,005 --> 00:08:29,376 line:-2
Based on this coordinate,
we can create a location anchor


130
00:08:29,409 --> 00:08:35,148 line:-2
that guides you to the exact same spot
where Tommy stood in April 2016,


131
00:08:35.182 --> 00:08:38.785 line:-1 align:center
as indicated by the big blue dot.


132
00:08:38.819 --> 00:08:42.956 line:-2 align:center
Upon reaching that spot,
it helps you frame that perfect picture


133
00:08:42.990 --> 00:08:45.292 line:-1 align:center
by showing a focus square.


134
00:08:45.325 --> 00:08:51.265 line:-2 align:center
Finally, the app lets your take a photo
by tapping the screen.


135
00:08:51.298 --> 00:08:54.434 line:-2 align:center
That photo can be taken
in native camera resolution


136
00:08:54.468 --> 00:08:56.737 line:-2 align:center
while the current ARKit session
is running,


137
00:08:56,770 --> 00:09:00,607 line:-2
without the need to spin up
another AVCapture session.


138
00:09:00.641 --> 00:09:05.345 line:-2 align:center
We're excited to see which ideas you have
that combine the power of AR


139
00:09:05.379 --> 00:09:06.613 line:-1 align:center
and photography.


140
00:09:06.647 --> 00:09:11.118 line:-2 align:center
Another use case that will greatly benefit
by this API


141
00:09:11,151 --> 00:09:14,688 line:-2
is the creation of 3D models
using Object Capture.


142
00:09:15.489 --> 00:09:19.893 line:-2 align:center
Object capture takes in photos
of a real world object,


143
00:09:19.927 --> 00:09:21.395 line:-1 align:center
like this running shoe,


144
00:09:21.428 --> 00:09:24.831 line:-2 align:center
and using our latest photogrammetry
algorithms,


145
00:09:24,865 --> 00:09:30,103 line:-2
it turns them into a 3D model
ready for deployment in your AR app.


146
00:09:30.137 --> 00:09:35.008 line:-2 align:center
With ARKit you can overlay a 3D UI
on top of a physical object


147
00:09:35,042 --> 00:09:37,277 line:-1
and provide better capture guidance.


148
00:09:37.311 --> 00:09:41.448 line:-2 align:center
And now with the new high resolution
background image API,


149
00:09:41,481 --> 00:09:44,418 line:-2
you can take higher-resolution photos
of the object


150
00:09:44,451 --> 00:09:47,754 line:-1
and create even more realistic 3D models.


151
00:09:47,788 --> 00:09:49,756 align:center
I'm a big fan of photogrammetry,


152
00:09:49,790 --> 00:09:53,126 align:center
so I'd highly recommend
that you check out this year's


153
00:09:53,160 --> 00:09:56,296 line:0
"Bring your world to augmented reality"
session.


154
00:09:56,330 --> 00:10:01,034 line:0
Let me show you how you can enable
high-resolution photo captures in code.


155
00:10:01.935 --> 00:10:07.574 line:-2 align:center
First, we check for a video format
that supports hiResCapture.


156
00:10:07.608 --> 00:10:09.510 line:-1 align:center
We can use the convenience function


157
00:10:09.543 --> 00:10:15.582 line:-2 align:center
'recommendedVideoFormatForHighResolution
FrameCapturing' for that.


158
00:10:15.616 --> 00:10:18.619 line:-2 align:center
After we make sure
that the format is supported,


159
00:10:18.652 --> 00:10:22.456 line:-2 align:center
we can set the new video format
and run the session.


160
00:10:22,489 --> 00:10:27,294 line:-2
We further have to tell ARKit
when to capture a hi-res image.


161
00:10:27.327 --> 00:10:29.062 line:-1 align:center
In our earlier example,


162
00:10:29,096 --> 00:10:32,733 line:-2
the capture of a photo is triggered
by a tap on the screen.


163
00:10:32.766 --> 00:10:36.436 line:-2 align:center
In your own application, you might want
to react to different events


164
00:10:36.470 --> 00:10:39.206 line:-2 align:center
that trigger high-resolution
frame captures.


165
00:10:39,239 --> 00:10:42,075 line:-1
It really depends on your use case.


166
00:10:42,109 --> 00:10:47,414 line:-2
The ARSession has a new function
called captureHighResolutionFrame.


167
00:10:47,447 --> 00:10:51,351 line:-2
Calling this function
triggers an out-of-band capture


168
00:10:51,385 --> 00:10:54,087 line:-1
of a high-resolution image.


169
00:10:54,121 --> 00:10:57,658 line:-2
You get access to an ARFrame
containing the high-resolution image


170
00:10:57.691 --> 00:11:00.227 line:-1 align:center
and all other frame properties


171
00:11:00,260 --> 00:11:03,163 line:-1
asynchronously in the completion handler.


172
00:11:03,197 --> 00:11:05,766 line:-2
You should check
if the frame capture was successful


173
00:11:05.799 --> 00:11:08.168 line:-1 align:center
before accessing its contents.


174
00:11:08.202 --> 00:11:11.672 line:-2 align:center
In this example
we store the frame to disk.


175
00:11:11.705 --> 00:11:15.209 line:-2 align:center
Also keep in mind our best practices
on image retention


176
00:11:15,242 --> 00:11:16,543 line:-1
that I mentioned earlier,


177
00:11:16,577 --> 00:11:22,616 line:-2
especially since these images use
the full resolution of the image sensor.


178
00:11:22,649 --> 00:11:26,386 line:-1
Next, let's talk about HDR.


179
00:11:26,420 --> 00:11:29,389 line:-2
High Dynamic Range captures
a wider range of colors


180
00:11:29.423 --> 00:11:31.792 line:-1 align:center
and maps those to your display.


181
00:11:31.825 --> 00:11:35.896 line:-2 align:center
This is most visible in environments
with high contrast.


182
00:11:35,929 --> 00:11:38,599 line:-1
Here's a good example from my backyard.


183
00:11:38,632 --> 00:11:41,668 line:-1
This scene features both very dark areasâ€“


184
00:11:41,702 --> 00:11:43,470 line:-1
for example, on the wooden fenceâ€“


185
00:11:43,504 --> 00:11:47,541 line:-2
and some very bright areas
like the clouds in the sky.


186
00:11:47.574 --> 00:11:50.377 line:-2 align:center
When turning on the HDR mode,
as on the right,


187
00:11:50.410 --> 00:11:52.613 line:-1 align:center
you can see that details in these regions,


188
00:11:52,646 --> 00:11:58,051 line:0
like the fluffiness in the clouds,
are preserved much better in HDR.


189
00:11:58,085 --> 00:12:01,321 line:0
Let's see how HDR is turned on in code.


190
00:12:01,355 --> 00:12:05,325 line:-2
You can query any video format
if it supports HDR


191
00:12:05,359 --> 00:12:09,162 line:-2
through its
'isVideoHDRSupported' property.


192
00:12:09,196 --> 00:12:13,700 line:-2
Currently, only non-binned video formats
support HDR.


193
00:12:13.734 --> 00:12:18.939 line:-2 align:center
If HDR is supported, set videoHDRAllowed
in the config to true


194
00:12:18.972 --> 00:12:22.309 line:-2 align:center
and run your session
with that configuration.


195
00:12:22.342 --> 00:12:25.712 line:-2 align:center
Turning on HDR
will have a performance impact,


196
00:12:25.746 --> 00:12:29.283 line:-2 align:center
so make sure to only use it
when there is a need for it.


197
00:12:29,316 --> 00:12:31,919 line:-2
In use cases where you prefer
manual control


198
00:12:31.952 --> 00:12:35.489 line:-2 align:center
over settings such as exposure
or white balance,


199
00:12:35.522 --> 00:12:40.227 line:-2 align:center
there is now convenient way
to directly access an AVCaptureDevice


200
00:12:40.260 --> 00:12:42.996 line:-1 align:center
and change any of its settings.


201
00:12:43.030 --> 00:12:44.498 line:-1 align:center
In our code example,


202
00:12:44,531 --> 00:12:48,702 line:-2
call 'configurableCaptureDevice
ForPrimaryCamera'


203
00:12:48,735 --> 00:12:54,308 line:-2
of your configuration to get access
to the underlying 'AVCaptureDevice'.


204
00:12:54.341 --> 00:12:58.779 line:-2 align:center
Use this capability to create custom looks
for your ARKit app,


205
00:12:58,812 --> 00:13:03,083 line:-2
but keep in mind that the image is
not only used as a rendering backdrop,


206
00:13:03,116 --> 00:13:07,321 line:-2
but is also actively used by ARKit
to analyze the scene.


207
00:13:07,354 --> 00:13:11,725 line:-2
So any changes like strong overexposure
might have a negative effect


208
00:13:11,758 --> 00:13:14,595 line:-1
on the output quality of ARKit.


209
00:13:14.628 --> 00:13:19.566 line:-2 align:center
You can also perform some advanced
operations, like triggering focus events.


210
00:13:19,600 --> 00:13:23,437 line:-2
For more information on how to configure
AVCaptureSessions,


211
00:13:23.470 --> 00:13:29.009 line:-2 align:center
please refer to the AVCapture
documentation on developer.apple.com.


212
00:13:29,042 --> 00:13:33,313 line:-2
Finally, ARKit exposes EXIF tags
to your app.


213
00:13:33.347 --> 00:13:36.984 line:-1 align:center
They are now available with every ARFrame.


214
00:13:37,017 --> 00:13:40,420 line:-2
EXIF tags contain useful information
about white balance,


215
00:13:40,454 --> 00:13:45,259 line:-2
exposure, and other settings
that can be valuable for post-processing.


216
00:13:45,292 --> 00:13:49,062 line:-2
That concludes all updates
on the image capture pipeline.


217
00:13:49.096 --> 00:13:51.932 line:-2 align:center
Let's see which changes we have
for Plane Anchors.


218
00:13:53,200 --> 00:13:58,805 line:-2
Plane anchors have been a popular feature
since the very first version of ARKit.


219
00:13:58,839 --> 00:14:03,577 line:-2
Many of you expressed the need to have
a cleaner separation of plane anchors


220
00:14:03,610 --> 00:14:05,879 line:-1
and the underlying plane geometry.


221
00:14:05.913 --> 00:14:08.348 line:-1 align:center
For that reason, we are announcing updates


222
00:14:08.382 --> 00:14:12.786 line:-2 align:center
on the behavior of the plane anchor
and the geometry of the plane.


223
00:14:12.819 --> 00:14:17.925 line:-2 align:center
This is an example of a typical
plane anchor in iOS 15.


224
00:14:17,958 --> 00:14:20,961 line:-2
At the beginning of the AR session,
it fits the plane


225
00:14:20,994 --> 00:14:24,198 line:-2
to this well-textured notebook
on the table.


226
00:14:24.231 --> 00:14:27.301 line:-2 align:center
When running the session,
the plane is gradually updated


227
00:14:27.334 --> 00:14:31.238 line:-2 align:center
to account for new parts of the table
that come into view.


228
00:14:31,271 --> 00:14:33,740 line:-1
Every time the plane geometry is updated,


229
00:14:33,774 --> 00:14:36,243 line:-1
the anchor rotation is updated as well


230
00:14:36.276 --> 00:14:39.213 line:-2 align:center
to reflect the new orientation
of the plane.


231
00:14:39.246 --> 00:14:44.218 line:-2 align:center
With iOS 16, we introduce a cleaner
separation between plane anchors


232
00:14:44.251 --> 00:14:45.986 line:-1 align:center
and their plane geometry.


233
00:14:47,154 --> 00:14:52,659 line:-2
Plane anchor and geometry updates
are now fully decoupled.


234
00:14:52,693 --> 00:14:56,230 line:-2
While the plane is extending
and updating its geometry


235
00:14:56.263 --> 00:14:58.465 line:-1 align:center
as the full table comes into view,


236
00:14:58.498 --> 00:15:02.236 line:-2 align:center
the anchor rotation itself
remains constant.


237
00:15:06,807 --> 00:15:09,943 line:-2
When contrasting with the old behavior
on the left hand side,


238
00:15:09.977 --> 00:15:13.680 line:-2 align:center
you can see that the plane anchor
in iOS 16 has stayed


239
00:15:13.714 --> 00:15:16.850 line:-2 align:center
at the same orientation,
aligned to the notebook,


240
00:15:16,884 --> 00:15:19,653 line:-1
throughout the whole AR Session.


241
00:15:21.421 --> 00:15:24.224 line:-1 align:center
All information on plane geometry


242
00:15:24,258 --> 00:15:28,529 line:-2
is now contained in a class
called ARPlaneExtent.


243
00:15:28.562 --> 00:15:33.800 line:-2 align:center
Rotation updates are no longer expressed
through rotating the plane anchor itself.


244
00:15:33.834 --> 00:15:39.339 line:-2 align:center
Instead, ARPlaneExtent contains
a new property, rotationOnYAxis,


245
00:15:39,373 --> 00:15:42,176 line:-1
that represents the angle of rotation.


246
00:15:42.209 --> 00:15:44.444 line:-1 align:center
In addition to this new property,


247
00:15:44.478 --> 00:15:48.348 line:-2 align:center
planes are fully defined
by width and height,


248
00:15:48.382 --> 00:15:52.252 line:-2 align:center
as well as the center coordinate
of the PlaneAnchor.


249
00:15:52.286 --> 00:15:56.423 line:-2 align:center
Let me show you how to create this
plane visualization in code.


250
00:15:58.525 --> 00:16:02.396 line:-2 align:center
First, we generate an entity
based on a plane mesh


251
00:16:02,429 --> 00:16:06,500 line:-2
according to the specified
width and height.


252
00:16:06.533 --> 00:16:11.672 line:-2 align:center
Then we set the entities transform
according to the rotation on y axis


253
00:16:11.705 --> 00:16:16.176 line:-2 align:center
and also offset it by the value
of the center property.


254
00:16:16.210 --> 00:16:21.081 line:-2 align:center
Every time the plane is updated, we have
to account for the fact that width,


255
00:16:21.114 --> 00:16:26.787 line:-2 align:center
height, and center coordinate and
the new rotationOnYAxis might change.


256
00:16:26,820 --> 00:16:31,391 line:-2
To make use of this new behavior,
set your deployment target to iOS 16


257
00:16:31.425 --> 00:16:34.194 line:-1 align:center
in your Xcode settings.


258
00:16:34.228 --> 00:16:37.097 line:-1 align:center
The next update is on MotionCapture,


259
00:16:37.130 --> 00:16:42.202 line:-2 align:center
our machine learning masterminds worked
hard to make further improvements.


260
00:16:42,236 --> 00:16:44,338 line:-1
There is a whole suite of updates,


261
00:16:44.371 --> 00:16:49.176 line:-2 align:center
both for the 2D skeleton,
as well as for the 3D joints.


262
00:16:49.209 --> 00:16:52.946 line:-2 align:center
For the 2D skeleton
we are tracking two new joints:


263
00:16:52.980 --> 00:16:55.449 line:-1 align:center
the left and the right ear.


264
00:16:55.482 --> 00:16:59.086 line:-2 align:center
We also improved
the overall pose detection.


265
00:16:59,119 --> 00:17:02,856 line:-2
On iPhone 12 and up,
as well as on the latest iPad Pro


266
00:17:02.890 --> 00:17:05.325 line:-1 align:center
and iPad Air models with the M1 chip,


267
00:17:05.359 --> 00:17:09.096 line:-2 align:center
the 3D skeleton, as shown in red,
has been improved.


268
00:17:09,129 --> 00:17:14,535 line:-2
You will experience less jitter
and overall more temporal consistency.


269
00:17:14.568 --> 00:17:18.472 line:-2 align:center
Tracking is also more stable
if parts of the person are occluded


270
00:17:18.505 --> 00:17:21.308 line:-1 align:center
or when walking up close to the camera.


271
00:17:21,341 --> 00:17:26,180 line:-2
To make use of the improved MotionCapture,
set your deployment target to iOS 16


272
00:17:26.213 --> 00:17:29.249 line:-1 align:center
in your Xcode settings.


273
00:17:29.283 --> 00:17:33.820 line:-2 align:center
Next, I would also like to announce
new cities and countries


274
00:17:33,854 --> 00:17:35,989 line:-1
where LocationAnchors will be supported.


275
00:17:36.023 --> 00:17:40.060 line:-2 align:center
As a small reminder,
Apple Maps uses the LocationAnchor API


276
00:17:40.093 --> 00:17:42.496 line:-2 align:center
to power its pedestrian walking
instructions.


277
00:17:42,529 --> 00:17:47,167 line:0
In this example you can see that it can
lead you through the streets of London,


278
00:17:47,201 --> 00:17:50,938 align:center
thanks to the power of LocationAnchors.


279
00:17:50,971 --> 00:17:54,041 line:-2
LocationAnchors are already available
in a growing number of cities


280
00:17:54,074 --> 00:17:57,311 line:-1
in the United States and in London, UK.


281
00:17:57.344 --> 00:18:01.415 line:-2 align:center
Starting today, they will be available
in the Canadian cities of Vancouver,


282
00:18:01.448 --> 00:18:03.483 line:-1 align:center
Toronto, and Montreal.


283
00:18:03.517 --> 00:18:06.086 line:-1 align:center
We are also enabling them in Singapore,


284
00:18:06,119 --> 00:18:10,157 line:-2
and in seven metropolitan areas in Japan,
including Tokyo.


285
00:18:10,190 --> 00:18:14,294 line:-2
As well as in Melbourne and Sydney,
Australia.


286
00:18:14.328 --> 00:18:17.431 line:-2 align:center
Later this year,
we will make them available in


287
00:18:17,464 --> 00:18:19,233 line:-1
Auckland, New Zealand,


288
00:18:19.266 --> 00:18:22.970 line:-2 align:center
Tel Aviv, Israel,
and Paris, France


289
00:18:23,003 --> 00:18:26,073 line:-2
If you are interested to know
if LocationAnchors are supported


290
00:18:26.106 --> 00:18:27.941 line:-1 align:center
at a particular coordinate,


291
00:18:27,975 --> 00:18:33,146 line:-2
just use the checkAvailability method
of ARGeoTrackingConfiguration.


292
00:18:33,981 --> 00:18:37,284 line:-1
And those were all the updates to ARKit 6.


293
00:18:37.317 --> 00:18:43.223 line:-2 align:center
To summarize, I presented how to run ARKit
in the new 4K video format.


294
00:18:43,257 --> 00:18:47,427 line:-2
For advanced use cases,
I demonstrated how to enable HDR


295
00:18:47.461 --> 00:18:51.698 line:-2 align:center
or get manual control
over the AVCaptureDevice.


296
00:18:51,732 --> 00:18:54,134 line:-1
For even more pixel hungry applications,


297
00:18:54.168 --> 00:18:59.173 line:-2 align:center
I demonstrated how to get high resolution
photos from an ARKit session.


298
00:18:59.206 --> 00:19:01.942 line:-2 align:center
We talked about the new behavior
of Plane Anchors,


299
00:19:01.975 --> 00:19:03.977 line:-1 align:center
and I presented the new ear joints


300
00:19:04,011 --> 00:19:07,080 line:-1
and other improvements in MotionCapture.


301
00:19:07,114 --> 00:19:10,284 line:-2
You also got to know
in which countries LocationAnchors


302
00:19:10,317 --> 00:19:12,986 line:-1
will be available later this year.


303
00:19:14.321 --> 00:19:15.656 line:-1 align:center
Thanks for tuning in.


304
00:19:15,689 --> 00:19:20,093 line:-1
Have a great WWDC 2022!

