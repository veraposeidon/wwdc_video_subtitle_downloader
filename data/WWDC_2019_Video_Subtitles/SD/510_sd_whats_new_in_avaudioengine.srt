1
00:00:01,516 --> 00:00:04,500
[ Music ]


2
00:00:07,796 --> 00:00:09,296
>> Hello, and welcome to our


3
00:00:09,296 --> 00:00:11,706
session about audio API updates.


4
00:00:12,116 --> 00:00:14,116
My name is Peter Vasil, and I am


5
00:00:14,116 --> 00:00:15,656
a software engineer in the Core


6
00:00:15,656 --> 00:00:16,276
Audio team.


7
00:00:18,426 --> 00:00:20,066
Let's start with what's new in


8
00:00:20,066 --> 00:00:21,186
AVAudioEngine.


9
00:00:24,206 --> 00:00:25,226
We have added a couple of


10
00:00:25,226 --> 00:00:26,976
enhancements and new APIs to


11
00:00:26,976 --> 00:00:27,996
AVAudioEngine.


12
00:00:28,946 --> 00:00:30,446
We now have a voice processing


13
00:00:30,446 --> 00:00:30,946
support.


14
00:00:31,946 --> 00:00:33,486
We have added two new nodes,


15
00:00:33,726 --> 00:00:35,346
AVAudioSourceNode and


16
00:00:35,346 --> 00:00:37,646
AVAudioSinkNode, and we have


17
00:00:37,646 --> 00:00:38,826
made some improvements to


18
00:00:38,826 --> 00:00:40,256
spatial audio rendering.


19
00:00:41,616 --> 00:00:43,076
Now, let's dive into the


20
00:00:45,976 --> 00:00:46,516
details.


21
00:00:46,516 --> 00:00:48,236
AVAudioEngine now has a voice


22
00:00:48,236 --> 00:00:49,156
processing mode.


23
00:00:49,726 --> 00:00:51,916
The main use case for the mode


24
00:00:51,916 --> 00:00:53,256
is echo cancellation and


25
00:00:53,256 --> 00:00:54,926
voice-over IP applications.


26
00:00:55,956 --> 00:00:56,836
What does this mean?


27
00:00:57,836 --> 00:00:59,346
When enabled, extra signal


28
00:00:59,346 --> 00:01:00,826
processing is applied on the


29
00:01:00,826 --> 00:01:03,286
incoming audio, and any audio


30
00:01:03,286 --> 00:01:04,676
that is coming from the device


31
00:01:04,676 --> 00:01:06,046
is taken out.


32
00:01:06,816 --> 00:01:09,136
This requires that both input


33
00:01:09,136 --> 00:01:10,506
and output nodes are in the


34
00:01:10,506 --> 00:01:11,686
voice processing mode.


35
00:01:13,126 --> 00:01:15,236
Therefore, when enabling the


36
00:01:15,236 --> 00:01:16,966
mode on either of the I/O nodes,


37
00:01:17,536 --> 00:01:19,556
the engine takes care that both


38
00:01:19,556 --> 00:01:21,406
I/O nodes exist and that they


39
00:01:21,406 --> 00:01:22,506
are switched to the voice


40
00:01:22,506 --> 00:01:23,336
processing mode.


41
00:01:24,966 --> 00:01:26,296
Voice processing is only


42
00:01:26,296 --> 00:01:27,886
available when rendering to an


43
00:01:27,886 --> 00:01:29,906
audio device, not a manual


44
00:01:29,906 --> 00:01:30,746
rendering mode.


45
00:01:34,326 --> 00:01:35,966
To enable or disable voice


46
00:01:35,966 --> 00:01:38,456
processing, we can use set voice


47
00:01:38,496 --> 00:01:40,616
processing enabled on either the


48
00:01:40,616 --> 00:01:42,066
input or output node.


49
00:01:43,406 --> 00:01:44,826
Voice processing cannot be


50
00:01:44,826 --> 00:01:47,046
enabled dynamically, which means


51
00:01:47,106 --> 00:01:48,586
the engine needs to be in a stop


52
00:01:48,586 --> 00:01:50,466
state when enabling the mode.


53
00:01:50,466 --> 00:01:54,296
The AV Echo Touch Sample Code


54
00:01:54,296 --> 00:01:56,726
project demonstrates how to use


55
00:01:56,726 --> 00:01:57,826
voice processing with


56
00:01:57,826 --> 00:01:59,396
AVAudioEngine in detail.


57
00:01:59,846 --> 00:02:03,616
Let's look at the new nodes in


58
00:02:03,616 --> 00:02:06,376
AVAudioEngine, AVAudioSourceNode


59
00:02:06,376 --> 00:02:07,766
and AVAudioSinkNode.


60
00:02:08,955 --> 00:02:10,826
Both nodes wrap a user-defined


61
00:02:10,826 --> 00:02:13,006
blog that allows apps to send or


62
00:02:13,006 --> 00:02:14,006
receive audio from


63
00:02:14,006 --> 00:02:15,006
AVAudioEngine.


64
00:02:16,176 --> 00:02:17,646
When rendering to an audio


65
00:02:17,646 --> 00:02:20,056
device, the block operates under


66
00:02:20,056 --> 00:02:21,476
real-time constraints, which


67
00:02:21,476 --> 00:02:22,796
means that within the block


68
00:02:22,796 --> 00:02:24,156
there shouldn't be any blocking


69
00:02:24,156 --> 00:02:26,106
calls like memory allocations,


70
00:02:26,566 --> 00:02:28,066
call to lib dispatch, or


71
00:02:28,066 --> 00:02:28,946
blocking on a mutex.


72
00:02:32,936 --> 00:02:35,176
With AVAudioSourceNode, we pass


73
00:02:35,176 --> 00:02:36,566
or render block to the node,


74
00:02:36,566 --> 00:02:38,236
which sends audio data to its


75
00:02:38,236 --> 00:02:38,736
output.


76
00:02:40,066 --> 00:02:41,626
This makes it very easy to


77
00:02:41,626 --> 00:02:43,446
create generated nodes without


78
00:02:43,446 --> 00:02:45,406
having to implement a full audio


79
00:02:45,406 --> 00:02:47,106
unit and wrap it with AVAudio


80
00:02:47,106 --> 00:02:47,486
unit.


81
00:02:49,046 --> 00:02:51,306
The node can be used in both


82
00:02:51,306 --> 00:02:52,936
real time and manual rendering


83
00:02:52,936 --> 00:02:53,246
mode.


84
00:02:54,476 --> 00:02:56,726
AVAudioSourceNode support linear


85
00:02:56,726 --> 00:02:59,316
PCM conversions such as sample


86
00:02:59,316 --> 00:03:01,056
rate or bit depth conversions


87
00:03:01,616 --> 00:03:04,996
and has one output but no input.


88
00:03:09,436 --> 00:03:11,476
This short code snippet shows


89
00:03:11,476 --> 00:03:13,366
how to use AVAudioSourceNode.


90
00:03:14,056 --> 00:03:16,096
As we can see, the block is


91
00:03:16,096 --> 00:03:18,126
passed as an initializer


92
00:03:18,126 --> 00:03:19,986
argument, and after creating the


93
00:03:19,986 --> 00:03:21,896
node, it can be connected just


94
00:03:21,896 --> 00:03:22,906
like any other node.


95
00:03:23,936 --> 00:03:25,676
A more detailed example can be


96
00:03:25,676 --> 00:03:27,306
found in our Signal Generator


97
00:03:27,306 --> 00:03:28,536
Sample Code project.


98
00:03:32,356 --> 00:03:34,166
Let's look at AVAudioSinkNode.


99
00:03:34,866 --> 00:03:37,156
AVAudioSinkNode is a symmetrical


100
00:03:37,156 --> 00:03:37,876
counterpart of


101
00:03:37,876 --> 00:03:39,256
AVAudioSourceNode.


102
00:03:40,086 --> 00:03:41,916
It wraps a user-defined block


103
00:03:41,966 --> 00:03:43,636
that receives the input audio


104
00:03:43,636 --> 00:03:45,086
from the node chain that is


105
00:03:45,086 --> 00:03:46,446
connected to its input.


106
00:03:47,516 --> 00:03:49,796
AVAudioSinkNode is restricted to


107
00:03:49,796 --> 00:03:50,776
the input chain.


108
00:03:51,176 --> 00:03:52,746
In other words, it must be


109
00:03:52,746 --> 00:03:54,056
connected downstream of the


110
00:03:54,056 --> 00:03:54,796
input node.


111
00:03:56,076 --> 00:03:57,496
It does not support format


112
00:03:57,496 --> 00:03:59,306
conversions, and the format


113
00:03:59,306 --> 00:04:00,916
within the block has to be the


114
00:04:00,916 --> 00:04:02,336
same as the hardware input


115
00:04:02,336 --> 00:04:02,836
format.


116
00:04:04,236 --> 00:04:06,436
The node can be useful for


117
00:04:06,436 --> 00:04:09,086
voice-over IP application when


118
00:04:09,086 --> 00:04:10,756
the input needs to be processed


119
00:04:10,756 --> 00:04:12,596
in real time, in which case


120
00:04:12,596 --> 00:04:14,256
installing a regular tap would


121
00:04:14,256 --> 00:04:15,936
not be sufficient because the


122
00:04:15,936 --> 00:04:17,755
tap doesn't operate in a


123
00:04:17,755 --> 00:04:18,815
real-time context.


124
00:04:21,076 --> 00:04:22,746
Here is a code snippet


125
00:04:22,746 --> 00:04:24,636
demonstrating how to create an


126
00:04:24,636 --> 00:04:25,826
AVAudioSinkNode.


127
00:04:26,466 --> 00:04:28,086
It is quite similar to


128
00:04:28,086 --> 00:04:29,206
AVAudioSourceNode.


129
00:04:29,976 --> 00:04:32,096
The main steps to note here are


130
00:04:32,096 --> 00:04:33,606
to initialize the node with a


131
00:04:33,606 --> 00:04:35,836
blog, attach it to the engine,


132
00:04:36,146 --> 00:04:37,676
and connect it to a node


133
00:04:37,676 --> 00:04:39,266
downstream of the input node.


134
00:04:42,996 --> 00:04:44,266
Now let's see the spatial


135
00:04:44,266 --> 00:04:45,576
rendering improvements.


136
00:04:46,666 --> 00:04:48,426
We have introduced an automatic


137
00:04:48,426 --> 00:04:51,256
spatial rendering algorithm, and


138
00:04:51,256 --> 00:04:53,486
AVAudioPlayerNode now supports


139
00:04:53,486 --> 00:04:55,636
spatialization of multichannel


140
00:04:55,636 --> 00:04:56,546
audio content.


141
00:05:00,716 --> 00:05:02,076
With the automatic spatial


142
00:05:02,076 --> 00:05:03,806
rendering algorithm, the most


143
00:05:03,806 --> 00:05:05,446
appropriate spatialization


144
00:05:05,446 --> 00:05:06,936
algorithm is selected for the


145
00:05:06,936 --> 00:05:07,786
current route.


146
00:05:08,626 --> 00:05:10,576
This means developers don't need


147
00:05:10,576 --> 00:05:12,396
to figure out what algorithms


148
00:05:12,396 --> 00:05:14,066
are suitable for headphones or


149
00:05:14,066 --> 00:05:14,786
different speaker


150
00:05:14,786 --> 00:05:15,816
configurations.


151
00:05:16,896 --> 00:05:18,846
This adds near-field and in-head


152
00:05:18,846 --> 00:05:20,856
rendering for headphones and


153
00:05:20,856 --> 00:05:22,426
virtual surround for built-in


154
00:05:22,426 --> 00:05:24,546
speakers is available starting


155
00:05:24,546 --> 00:05:26,466
with iOS devices and laptops


156
00:05:26,466 --> 00:05:28,646
from 2018 and newer.


157
00:05:32,096 --> 00:05:34,026
Here we see the new API in the


158
00:05:34,026 --> 00:05:36,126
AVAudio3DMixing protocol.


159
00:05:36,746 --> 00:05:39,656
The AVAudio3DMixing rendering


160
00:05:39,656 --> 00:05:42,076
algorithm enum has a new entry,


161
00:05:42,476 --> 00:05:43,006
auto.


162
00:05:44,056 --> 00:05:45,926
Additionally, we can specify the


163
00:05:45,926 --> 00:05:47,966
output type with the output type


164
00:05:47,966 --> 00:05:48,576
property.


165
00:05:49,076 --> 00:05:52,346
With the property set to auto,


166
00:05:52,636 --> 00:05:54,146
the output type can be


167
00:05:54,146 --> 00:05:56,346
automatically detected in


168
00:05:56,346 --> 00:05:58,266
real-time mode but not in manual


169
00:05:58,266 --> 00:05:59,076
rendering mode.


170
00:06:03,056 --> 00:06:05,116
With the ability to spatialize


171
00:06:05,116 --> 00:06:07,546
multichannel streams, we support


172
00:06:07,546 --> 00:06:09,316
point-source and ambience bed


173
00:06:09,316 --> 00:06:09,916
rendering.


174
00:06:10,816 --> 00:06:12,476
We also support channel-based


175
00:06:12,476 --> 00:06:14,066
formats and higher-order


176
00:06:14,066 --> 00:06:15,576
Ambisonics up to the third


177
00:06:15,576 --> 00:06:15,996
order.


178
00:06:19,616 --> 00:06:20,786
We have added two new


179
00:06:20,786 --> 00:06:22,706
spatialization properties to the


180
00:06:22,706 --> 00:06:25,946
AVAudio3DMixing protocol, source


181
00:06:25,946 --> 00:06:27,606
mode and pointSource and head


182
00:06:27,606 --> 00:06:27,996
mode.


183
00:06:29,936 --> 00:06:32,366
SpatializeIfMono is legacy


184
00:06:32,366 --> 00:06:33,056
behavior.


185
00:06:33,246 --> 00:06:35,416
This is the same as bypass for


186
00:06:35,416 --> 00:06:37,546
any multichannel stream, which


187
00:06:37,546 --> 00:06:39,596
means a pass through or downmix


188
00:06:39,596 --> 00:06:40,806
to the output format.


189
00:06:41,906 --> 00:06:44,016
With pointSource, the audio is


190
00:06:44,016 --> 00:06:45,826
sum to mono and render at the


191
00:06:45,826 --> 00:06:47,366
location of the player node.


192
00:06:47,446 --> 00:06:50,096
And with ambienceBed, the audio


193
00:06:50,096 --> 00:06:52,246
is anchored to the 3D world and


194
00:06:52,246 --> 00:06:53,596
is rotatable with the player


195
00:06:53,596 --> 00:06:55,506
node's position relative to the


196
00:06:55,506 --> 00:06:56,716
listener orientation.


197
00:06:59,326 --> 00:07:00,856
Here we see an example of


198
00:07:00,856 --> 00:07:02,616
ambienceBed source mode with


199
00:07:02,616 --> 00:07:04,376
automatic rendering algorithm.


200
00:07:05,476 --> 00:07:07,496
After setting the properties, it


201
00:07:07,496 --> 00:07:09,156
is important to make sure the


202
00:07:09,156 --> 00:07:10,666
format that is used for the


203
00:07:10,666 --> 00:07:12,426
connection between player node


204
00:07:12,606 --> 00:07:13,836
and the environment node


205
00:07:14,106 --> 00:07:15,406
contains the multichannel


206
00:07:15,406 --> 00:07:15,936
layout.


207
00:07:19,176 --> 00:07:21,546
Now let's talk about what's new


208
00:07:21,546 --> 00:07:22,606
in AVAudioSession.


209
00:07:25,316 --> 00:07:27,906
AVAudioSessionPromptStyle is a


210
00:07:27,906 --> 00:07:30,576
hint to apps that play voice


211
00:07:30,616 --> 00:07:32,366
prompts in order to modify the


212
00:07:32,366 --> 00:07:34,076
style of the played prompt.


213
00:07:35,036 --> 00:07:37,596
For example, if Siri is speaking


214
00:07:37,596 --> 00:07:39,116
or a phone call is ongoing,


215
00:07:39,506 --> 00:07:41,116
verbal navigation prompts is a


216
00:07:41,116 --> 00:07:42,756
confusing user experience.


217
00:07:43,696 --> 00:07:45,366
We also don't want Siri to


218
00:07:45,366 --> 00:07:47,046
record a navigation prompt.


219
00:07:47,946 --> 00:07:49,526
Navigation apps, for example,


220
00:07:49,526 --> 00:07:51,236
are encouraged to pay attention


221
00:07:51,236 --> 00:07:53,016
to prompt style changes and


222
00:07:53,016 --> 00:07:54,486
modify the prompts for better


223
00:07:54,486 --> 00:07:55,566
user experience.


224
00:07:56,276 --> 00:07:57,746
We have three prompt styles,


225
00:07:57,916 --> 00:08:00,066
none, short, and normal.


226
00:08:00,756 --> 00:08:02,676
We can now indicate to disable


227
00:08:02,676 --> 00:08:04,446
prompts completely, play


228
00:08:04,446 --> 00:08:06,496
shortened prompts, or play the


229
00:08:06,496 --> 00:08:07,446
regular prompts.


230
00:08:10,026 --> 00:08:11,126
Let's look at other


231
00:08:11,126 --> 00:08:12,946
AVAudioSession enhancements.


232
00:08:14,176 --> 00:08:15,766
The default policy is to mute


233
00:08:15,766 --> 00:08:17,406
haptics and system sounds when


234
00:08:17,406 --> 00:08:18,936
audio recording is active.


235
00:08:19,836 --> 00:08:21,766
A new property, allow haptics


236
00:08:21,766 --> 00:08:23,076
and system sounds during


237
00:08:23,076 --> 00:08:25,436
recording, allows system sounds


238
00:08:25,826 --> 00:08:27,186
and haptics to play while the


239
00:08:27,186 --> 00:08:28,836
session is actively using an


240
00:08:28,836 --> 00:08:29,566
audio input.


241
00:08:30,366 --> 00:08:32,126
It can be set using the


242
00:08:32,336 --> 00:08:33,466
setter set allow haptics


243
00:08:33,466 --> 00:08:34,736
and system sounds during


244
00:08:34,736 --> 00:08:35,376
recording.


245
00:08:37,976 --> 00:08:40,096
For more information, please


246
00:08:40,096 --> 00:08:41,846
visit the developer website.


247
00:08:43,196 --> 00:08:44,936
Thank you for your attention.

