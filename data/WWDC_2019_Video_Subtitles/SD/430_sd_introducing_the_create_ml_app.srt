1
00:00:01,516 --> 00:00:04,500
[ Music ]


2
00:00:08,516 --> 00:00:13,146
[ Applause ]


3
00:00:13,646 --> 00:00:15,286
>> This year, our Create ML


4
00:00:15,286 --> 00:00:17,276
release has new models and a


5
00:00:17,276 --> 00:00:18,416
whole new workflow.


6
00:00:19,646 --> 00:00:21,156
Every workflow starts with


7
00:00:21,156 --> 00:00:21,526
input.


8
00:00:22,166 --> 00:00:23,946
The devices that we develop for,


9
00:00:24,136 --> 00:00:26,106
use, and love, are rich with


10
00:00:26,106 --> 00:00:27,196
information from different


11
00:00:27,196 --> 00:00:29,326
sensors such as a camera, the


12
00:00:29,326 --> 00:00:30,946
microphone, the keyboard,


13
00:00:31,296 --> 00:00:33,236
Accelerometer, even Gyroscope.


14
00:00:34,036 --> 00:00:35,436
And all of these types of input


15
00:00:35,716 --> 00:00:37,406
can be used so you can train


16
00:00:37,406 --> 00:00:38,906
machine learning models and make


17
00:00:38,906 --> 00:00:40,656
your apps more personalized and


18
00:00:40,656 --> 00:00:41,346
more intelligent.


19
00:00:42,756 --> 00:00:44,876
Last year, we supported three of


20
00:00:44,876 --> 00:00:47,136
these types of input; images,


21
00:00:47,436 --> 00:00:48,946
text, and tabular data.


22
00:00:50,086 --> 00:00:51,836
This year, we're increasing the


23
00:00:51,906 --> 00:00:53,446
set of available domains from


24
00:00:53,506 --> 00:00:54,736
three to five.


25
00:00:54,736 --> 00:00:57,146
And now, introducing Activity


26
00:00:57,326 --> 00:00:57,876
and Sound.


27
00:00:58,676 --> 00:01:00,096
We're also expanding the breadth


28
00:01:00,156 --> 00:01:01,886
of available models within all


29
00:01:02,736 --> 00:01:03,776
of them.


30
00:01:03,986 --> 00:01:05,626
And all of this is being brought


31
00:01:05,866 --> 00:01:07,036
into a new medium.


32
00:01:07,656 --> 00:01:09,386
We call it Create ML app.


33
00:01:10,426 --> 00:01:12,416
It all starts with identifying


34
00:01:12,416 --> 00:01:13,006
your domain.


35
00:01:14,266 --> 00:01:15,436
And once you filter by your


36
00:01:15,436 --> 00:01:16,936
input, you can see all of the


37
00:01:16,936 --> 00:01:18,366
available model types you can


38
00:01:18,366 --> 00:01:18,836
create.


39
00:01:20,946 --> 00:01:22,286
Create ML then breaks down the


40
00:01:22,286 --> 00:01:23,966
task of creating machine


41
00:01:23,966 --> 00:01:25,556
learning model into three simple


42
00:01:25,556 --> 00:01:28,486
phases; input, training, and


43
00:01:29,336 --> 00:01:29,486
output.


44
00:01:30,156 --> 00:01:32,056
This new environment changes the


45
00:01:32,056 --> 00:01:33,726
way you interact with machine


46
00:01:33,726 --> 00:01:34,746
learning on the system.


47
00:01:35,316 --> 00:01:37,696
The app then displays an


48
00:01:37,696 --> 00:01:39,476
overview of your data and a rich


49
00:01:39,476 --> 00:01:41,306
set of analytics as it trains.


50
00:01:42,006 --> 00:01:43,156
You can visualize your model's


51
00:01:43,246 --> 00:01:44,466
progress in an easy to


52
00:01:44,466 --> 00:01:46,386
understand graphical view that


53
00:01:46,386 --> 00:01:47,586
displays the accuracy of your


54
00:01:47,586 --> 00:01:49,156
model across iterations.


55
00:01:49,666 --> 00:01:52,296
You can also see a breakdown of


56
00:01:52,296 --> 00:01:53,836
the precision and recall values


57
00:01:53,886 --> 00:01:55,396
for each class your model was


58
00:01:55,396 --> 00:01:55,906
trained on.


59
00:01:56,646 --> 00:01:58,276
And the table is interactive so


60
00:01:58,736 --> 00:02:00,316
you can filter by class or by


61
00:02:00,316 --> 00:02:02,336
percentage to better understand


62
00:02:02,336 --> 00:02:03,436
your model's performance.


63
00:02:04,096 --> 00:02:07,136
The process of testing is as


64
00:02:07,196 --> 00:02:08,586
simple as dragging and dropping


65
00:02:08,586 --> 00:02:09,045
in new data.


66
00:02:10,175 --> 00:02:11,366
You can have the ability to


67
00:02:11,366 --> 00:02:13,306
train and retest just by


68
00:02:13,306 --> 00:02:14,316
clicking the Test button.


69
00:02:16,006 --> 00:02:17,436
And what's really unique about


70
00:02:17,436 --> 00:02:18,866
Create ML is you can easily


71
00:02:18,866 --> 00:02:20,516
preview trained models in the


72
00:02:20,516 --> 00:02:21,166
Output tab.


73
00:02:21,936 --> 00:02:23,156
This new feature allows you to


74
00:02:23,256 --> 00:02:24,776
see exactly how your model will


75
00:02:24,826 --> 00:02:26,606
predict without having to


76
00:02:26,606 --> 00:02:27,976
incorporate your models into


77
00:02:27,976 --> 00:02:28,206
your apps.


78
00:02:29,256 --> 00:02:30,676
This means no more waiting to


79
00:02:30,676 --> 00:02:31,286
deploy them.


80
00:02:31,896 --> 00:02:33,056
You can do this directly in


81
00:02:33,056 --> 00:02:34,846
Create ML, saving you time to


82
00:02:34,846 --> 00:02:36,186
perfect your models instead.


83
00:02:36,796 --> 00:02:39,516
The Preview section is also


84
00:02:39,516 --> 00:02:41,296
custom built for every template,


85
00:02:41,686 --> 00:02:43,266
ensuring a complete end-to-end


86
00:02:43,266 --> 00:02:44,776
experience for every task.


87
00:02:46,246 --> 00:02:47,606
But what better way to see this


88
00:02:47,996 --> 00:02:49,206
than to show it to you live?


89
00:02:51,126 --> 00:02:51,726
Let's take a look.


90
00:02:52,516 --> 00:02:57,606
[ Applause ]


91
00:02:58,106 --> 00:02:59,746
Now, over in Xcode, I've been


92
00:02:59,746 --> 00:03:01,336
working on a flower classifier


93
00:03:01,796 --> 00:03:02,896
app to help me identify


94
00:03:02,896 --> 00:03:04,296
different types of flowers.


95
00:03:05,046 --> 00:03:06,406
And I've been using a model that


96
00:03:06,406 --> 00:03:07,496
I downloaded from the Model


97
00:03:07,496 --> 00:03:09,696
Gallery called Resnet50.


98
00:03:10,096 --> 00:03:11,576
And this is a well-known image


99
00:03:11,576 --> 00:03:13,146
classifier model that's been


100
00:03:13,146 --> 00:03:14,896
trained to recognize 1,000


101
00:03:14,896 --> 00:03:15,726
different classes.


102
00:03:16,956 --> 00:03:18,186
But this model is taking up


103
00:03:18,226 --> 00:03:19,736
about 100 megabytes of my app.


104
00:03:20,746 --> 00:03:22,076
And we can see when I actually


105
00:03:22,076 --> 00:03:24,386
try it on different images it


106
00:03:25,456 --> 00:03:27,496
knows that this Hibiscus is a


107
00:03:27,496 --> 00:03:29,196
flower, but it doesn't know the


108
00:03:29,196 --> 00:03:29,826
exact type.


109
00:03:30,306 --> 00:03:32,856
So, it doesn't quite suit my


110
00:03:33,386 --> 00:03:33,516
needs.


111
00:03:33,756 --> 00:03:35,866
Now, what I can do is from Xcode


112
00:03:37,386 --> 00:03:39,386
I can open Developer Tools and


113
00:03:39,386 --> 00:03:41,216
launch Create ML.


114
00:03:42,696 --> 00:03:44,876
This then prompts me to create a


115
00:03:44,876 --> 00:03:45,506
new document.


116
00:03:45,506 --> 00:03:48,506
And we can see I'm launched into


117
00:03:48,506 --> 00:03:50,296
the Template View where I can


118
00:03:50,356 --> 00:03:52,386
see all the available models we


119
00:03:53,006 --> 00:03:53,926
can create.


120
00:03:54,116 --> 00:03:55,276
Since I'm working with images,


121
00:03:55,646 --> 00:03:57,416
I'll filter by image and select


122
00:03:57,746 --> 00:03:58,746
the Image Classifier.


123
00:04:00,026 --> 00:04:00,896
We can then name this.


124
00:04:05,366 --> 00:04:07,276
And then, pick the place to save


125
00:04:07,276 --> 00:04:08,516
it so we can come back to it


126
00:04:08,516 --> 00:04:08,816
later.


127
00:04:09,426 --> 00:04:12,226
And then, launch into the New


128
00:04:12,626 --> 00:04:13,286
App view.


129
00:04:14,036 --> 00:04:16,346
And you can see that I'm, I'm


130
00:04:16,346 --> 00:04:18,435
first prompted to drag in input


131
00:04:18,435 --> 00:04:19,166
as training data.


132
00:04:19,166 --> 00:04:21,356
And if I progress through some


133
00:04:21,356 --> 00:04:22,786
of the other tabs, they're not


134
00:04:22,786 --> 00:04:24,416
unlocked yet because I haven't


135
00:04:24,416 --> 00:04:25,256
gone through the flow.


136
00:04:26,516 --> 00:04:27,756
So, let's try this sequentially.


137
00:04:28,416 --> 00:04:31,906
On my desktop, I set aside some


138
00:04:31,906 --> 00:04:33,116
images of different types of


139
00:04:33,116 --> 00:04:33,566
flowers.


140
00:04:34,396 --> 00:04:36,306
And you can see, I have some


141
00:04:36,306 --> 00:04:40,266
hibiscus, some passionflower,


142
00:04:40,266 --> 00:04:43,836
and then even some roses,


143
00:04:45,316 --> 00:04:46,306
dahlias, and daisies.


144
00:04:47,756 --> 00:04:48,876
I could take this folder and


145
00:04:48,876 --> 00:04:51,136
drag it in and immediately see


146
00:04:51,136 --> 00:04:53,136
that I have 65 different images


147
00:04:53,256 --> 00:04:54,686
contained within it and they're


148
00:04:54,686 --> 00:04:59,706
across five different classes.


149
00:04:59,816 --> 00:05:01,376
Now, since we have our input


150
00:05:01,446 --> 00:05:03,076
data, I can hit the Run button


151
00:05:03,356 --> 00:05:04,836
and automatically this model


152
00:05:04,836 --> 00:05:05,666
begins training.


153
00:05:06,456 --> 00:05:07,816
It first starts by extracting


154
00:05:07,816 --> 00:05:09,046
features from the images.


155
00:05:09,556 --> 00:05:10,616
And then, we can see the


156
00:05:10,616 --> 00:05:12,416
progress as training begins.


157
00:05:13,796 --> 00:05:15,216
I can see a breakdown of how the


158
00:05:15,216 --> 00:05:16,446
model's performing on this data.


159
00:05:17,116 --> 00:05:18,546
But what I'd really like to do


160
00:05:18,546 --> 00:05:20,206
is see how the model performs on


161
00:05:20,206 --> 00:05:21,776
new data that it hasn't seen.


162
00:05:22,256 --> 00:05:23,496
So, I'll navigate to the Testing


163
00:05:23,496 --> 00:05:25,836
tab and I'll drag in these new


164
00:05:25,836 --> 00:05:27,886
flowers that I've set aside and


165
00:05:28,476 --> 00:05:29,266
hit Test.


166
00:05:34,296 --> 00:05:35,686
Now, what I'd really like to do


167
00:05:35,686 --> 00:05:36,886
is take a look at the trained


168
00:05:36,886 --> 00:05:38,136
model in the Output tab.


169
00:05:38,136 --> 00:05:40,816
And we can see here I have a


170
00:05:40,816 --> 00:05:42,996
flower classifier that's 66


171
00:05:43,066 --> 00:05:43,586
kilobytes.


172
00:05:44,326 --> 00:05:46,886
Now, to actually preview this,


173
00:05:47,106 --> 00:05:49,006
I've taken some other photos and


174
00:05:49,006 --> 00:05:50,416
perhaps this hibiscus that


175
00:05:50,806 --> 00:05:52,046
wasn't working before with


176
00:05:52,106 --> 00:05:52,516
Resnet.


177
00:05:53,766 --> 00:05:55,466
And I can see now, this model


178
00:05:55,466 --> 00:05:57,006
can correctly predict exactly


179
00:05:57,006 --> 00:05:57,506
what it is.


180
00:05:58,106 --> 00:05:59,366
And I can see other predictions


181
00:05:59,366 --> 00:06:00,476
the model has made and


182
00:06:00,476 --> 00:06:02,106
confidence values for each one.


183
00:06:02,356 --> 00:06:05,376
I can even take a full folder


184
00:06:05,376 --> 00:06:09,006
and drag them in and debug any


185
00:06:09,006 --> 00:06:10,276
image that this model has


186
00:06:10,276 --> 00:06:10,876
predicted on.


187
00:06:12,356 --> 00:06:13,896
Now, once I'm satisfied, I can


188
00:06:13,896 --> 00:06:15,656
take this model and drag it out.


189
00:06:20,196 --> 00:06:21,546
And then, reintegrate that into


190
00:06:21,616 --> 00:06:21,836
my app.


191
00:06:23,246 --> 00:06:24,856
But what's more, is you can also


192
00:06:24,856 --> 00:06:26,736
leverage the power of Continuity


193
00:06:26,736 --> 00:06:28,186
Camera in Create ML.


194
00:06:29,106 --> 00:06:31,196
And from this, what I can do is


195
00:06:31,196 --> 00:06:33,936
I can import from my phone which


196
00:06:33,936 --> 00:06:34,226
is attached.


197
00:06:34,826 --> 00:06:37,106
And I can try to take a photo of


198
00:06:37,656 --> 00:06:39,596
this flower that I have here on


199
00:06:39,596 --> 00:06:41,376
stage, and we can see how it


200
00:06:41,376 --> 00:06:41,626
does.


201
00:06:42,146 --> 00:06:44,526
And it actually turns out okay.


202
00:06:46,516 --> 00:06:52,586
[ Applause ]


203
00:06:53,086 --> 00:06:54,106
Now, if you're not happy with


204
00:06:54,106 --> 00:06:55,866
your performance or if you'd


205
00:06:55,866 --> 00:06:56,886
just like to run some more


206
00:06:56,886 --> 00:06:58,226
experiments, there's a Plus


207
00:06:58,326 --> 00:06:59,206
button here, as well.


208
00:06:59,706 --> 00:07:00,906
And what you can do is you can


209
00:07:00,976 --> 00:07:03,076
select more training data.


210
00:07:03,256 --> 00:07:04,516
You can toggle how our


211
00:07:04,516 --> 00:07:06,226
validation data is specified and


212
00:07:06,846 --> 00:07:08,616
even your testing data, as well.


213
00:07:10,116 --> 00:07:11,476
This time, I might want to tweak


214
00:07:11,526 --> 00:07:12,496
some augmentations.


215
00:07:13,236 --> 00:07:14,286
And then, I can hit Run to


216
00:07:14,286 --> 00:07:14,706
train.


217
00:07:16,096 --> 00:07:17,896
And that's a look at the new


218
00:07:17,896 --> 00:07:19,466
workflow in Create ML.


219
00:07:20,016 --> 00:07:21,066
Let's go back to the slides.


220
00:07:22,516 --> 00:07:24,736
[ Applause ]


221
00:07:25,236 --> 00:07:27,656
So, you've seen Create ML gives


222
00:07:27,656 --> 00:07:29,376
you a whole new way to train


223
00:07:29,376 --> 00:07:30,476
your custom machine learning


224
00:07:30,476 --> 00:07:32,276
models on the Mac, with a


225
00:07:32,276 --> 00:07:33,506
beautiful look and feel.


226
00:07:34,296 --> 00:07:35,826
And with additions like metrics


227
00:07:35,876 --> 00:07:37,756
visualization, live progress,


228
00:07:37,966 --> 00:07:40,016
and interactive preview, Create


229
00:07:40,016 --> 00:07:42,306
ML app sets the bar for a great


230
00:07:42,306 --> 00:07:43,666
model training experience.


231
00:07:45,006 --> 00:07:46,746
In the demo, we walked through


232
00:07:46,986 --> 00:07:48,476
just one model that you can


233
00:07:48,476 --> 00:07:49,556
create with Create ML.


234
00:07:50,146 --> 00:07:51,396
But this release, we're


235
00:07:51,396 --> 00:07:52,436
introducing nine.


236
00:07:53,306 --> 00:07:54,816
So, let's take a high-level tour


237
00:07:54,876 --> 00:07:56,196
of all of the models you can


238
00:07:56,196 --> 00:07:58,176
create and some examples of


239
00:07:58,236 --> 00:07:59,646
sample apps.


240
00:08:00,766 --> 00:08:02,066
Starting with the image domain,


241
00:08:02,396 --> 00:08:04,186
we have the Image Classifier and


242
00:08:04,186 --> 00:08:04,996
Object Detector.


243
00:08:06,436 --> 00:08:08,176
An Image Classifier can be used


244
00:08:08,176 --> 00:08:10,076
for categorizing images based on


245
00:08:10,076 --> 00:08:10,646
their contents.


246
00:08:11,166 --> 00:08:12,706
For example, the Art Style


247
00:08:12,706 --> 00:08:14,736
identifier uses a custom Image


248
00:08:14,736 --> 00:08:16,496
Classifier to determine the most


249
00:08:16,556 --> 00:08:18,086
likely movement of a piece.


250
00:08:18,966 --> 00:08:20,226
It then separately provides an


251
00:08:20,226 --> 00:08:22,436
overview of notable artists to


252
00:08:22,436 --> 00:08:23,916
complete the app experience.


253
00:08:26,636 --> 00:08:27,856
In Create ML, the Image


254
00:08:27,936 --> 00:08:29,826
Classifier leverages core Apple


255
00:08:29,906 --> 00:08:31,286
technology by performing


256
00:08:31,286 --> 00:08:32,986
transfer learning on top of the


257
00:08:32,986 --> 00:08:34,216
vision feature print model


258
00:08:34,506 --> 00:08:35,525
already in the OS.


259
00:08:36,145 --> 00:08:37,696
This allows you to benefit from


260
00:08:37,746 --> 00:08:39,385
faster training times and a


261
00:08:39,385 --> 00:08:43,006
reduced model size in your app.


262
00:08:43,436 --> 00:08:44,766
Also, you have the option to


263
00:08:44,766 --> 00:08:46,746
train with augmentation to make


264
00:08:46,746 --> 00:08:48,326
your models more robust to


265
00:08:48,366 --> 00:08:49,206
unseen input.


266
00:08:50,336 --> 00:08:51,996
If you instead want to identify


267
00:08:52,106 --> 00:08:53,796
multiple objects within an image


268
00:08:53,796 --> 00:08:55,716
instead of one single one, you


269
00:08:55,716 --> 00:08:57,126
might want to create an Object


270
00:08:57,126 --> 00:08:57,626
Detector.


271
00:08:58,976 --> 00:09:00,696
Object Detectors can be used for


272
00:09:00,726 --> 00:09:02,376
localizing and recognizing


273
00:09:02,376 --> 00:09:03,876
contents within an image.


274
00:09:04,866 --> 00:09:06,336
For example, these can be


275
00:09:06,396 --> 00:09:07,886
trained to detect one or more


276
00:09:07,886 --> 00:09:10,246
classes such as specific playing


277
00:09:10,246 --> 00:09:12,196
cards or the exact suits


278
00:09:12,316 --> 00:09:13,096
contained on them.


279
00:09:14,626 --> 00:09:16,096
The Object Detector is a deep


280
00:09:16,096 --> 00:09:17,476
learning-based model and


281
00:09:17,476 --> 00:09:19,636
performs data augmentation to


282
00:09:19,696 --> 00:09:20,786
make it more robust.


283
00:09:21,286 --> 00:09:23,036
And it does this entirely on


284
00:09:23,466 --> 00:09:25,806
your Mac's GPU.


285
00:09:26,126 --> 00:09:27,976
Our next domain is Sound.


286
00:09:29,186 --> 00:09:30,696
Within Sound, we have a new


287
00:09:30,696 --> 00:09:31,746
model called the Sound


288
00:09:31,746 --> 00:09:32,356
Classifier.


289
00:09:33,816 --> 00:09:35,156
This model allows you to


290
00:09:35,156 --> 00:09:36,886
determine the most dominant


291
00:09:36,956 --> 00:09:38,506
sound within an audio stream.


292
00:09:40,206 --> 00:09:41,796
Since audio data is time series


293
00:09:41,866 --> 00:09:43,486
based, you could differentiate


294
00:09:43,556 --> 00:09:45,246
between the start and end points


295
00:09:45,246 --> 00:09:46,926
of different sounds such as when


296
00:09:46,926 --> 00:09:48,496
the guitar solo ends and the


297
00:09:48,496 --> 00:09:49,486
crowd goes wild.


298
00:09:51,656 --> 00:09:53,016
This model leverages transfer


299
00:09:53,016 --> 00:09:54,326
learning so you can also


300
00:09:54,326 --> 00:09:55,646
experience faster training


301
00:09:55,696 --> 00:09:55,946
times.


302
00:09:56,916 --> 00:09:58,376
And we also understand that


303
00:09:58,376 --> 00:10:00,066
optimizing performance across


304
00:10:00,186 --> 00:10:01,546
complex applications is


305
00:10:01,576 --> 00:10:02,146
challenging.


306
00:10:02,676 --> 00:10:03,586
Which is why we want to


307
00:10:03,586 --> 00:10:05,486
emphasize that these models are


308
00:10:05,566 --> 00:10:06,986
lightweight and run on the


309
00:10:06,986 --> 00:10:09,736
Neural Engine, making them ideal


310
00:10:09,736 --> 00:10:11,566
for real-time applications on


311
00:10:11,636 --> 00:10:12,276
any device.


312
00:10:12,996 --> 00:10:16,986
Our third domain is Activity.


313
00:10:17,586 --> 00:10:19,466
And within Activity, we have the


314
00:10:19,576 --> 00:10:20,916
Activity Classifier for the


315
00:10:20,916 --> 00:10:21,436
first time.


316
00:10:22,826 --> 00:10:24,966
This model also operates on time


317
00:10:25,046 --> 00:10:25,736
series-based data.


318
00:10:25,846 --> 00:10:28,596
And Activity Classifiers can be


319
00:10:28,596 --> 00:10:30,236
trained to categorize contents


320
00:10:30,236 --> 00:10:32,396
of motion data from a variety of


321
00:10:32,396 --> 00:10:33,396
sensors such as the


322
00:10:33,396 --> 00:10:35,326
Accelerometer and Gyroscope.


323
00:10:37,036 --> 00:10:37,936
These models are deep


324
00:10:37,996 --> 00:10:39,536
learning-based and train on the


325
00:10:39,536 --> 00:10:40,006
GPU.


326
00:10:40,496 --> 00:10:41,976
And they result in small model


327
00:10:42,036 --> 00:10:43,866
sizes that are also ideal for


328
00:10:43,866 --> 00:10:45,436
deployment on any device.


329
00:10:47,166 --> 00:10:49,046
Our second to last input is


330
00:10:49,046 --> 00:10:49,216
Text.


331
00:10:50,166 --> 00:10:52,356
Within Text, there are two model


332
00:10:52,356 --> 00:10:54,426
types available; the Text


333
00:10:54,486 --> 00:10:56,376
Classifier and the Word Tagger.


334
00:10:58,456 --> 00:11:00,256
Text classification can be used


335
00:11:00,256 --> 00:11:02,516
to label sentences, paragraphs,


336
00:11:02,516 --> 00:11:04,516
or even entire articles based on


337
00:11:04,516 --> 00:11:05,106
their contents.


338
00:11:05,906 --> 00:11:07,246
You can train these for custom


339
00:11:07,246 --> 00:11:08,746
topic identification or


340
00:11:08,746 --> 00:11:09,926
categorization tasks.


341
00:11:11,476 --> 00:11:12,566
In Create ML, there are a


342
00:11:12,566 --> 00:11:14,026
variety of different algorithms


343
00:11:14,026 --> 00:11:15,696
for you to try and even a new


344
00:11:15,696 --> 00:11:17,456
transfer learning option this


345
00:11:17,986 --> 00:11:18,096
year.


346
00:11:18,896 --> 00:11:21,166
The Word Tagger is slightly more


347
00:11:21,166 --> 00:11:21,616
nuanced.


348
00:11:22,586 --> 00:11:24,266
It's ideal for labeling tokens


349
00:11:24,466 --> 00:11:26,176
or words of interest in text.


350
00:11:27,186 --> 00:11:28,706
General purpose examples of this


351
00:11:28,976 --> 00:11:30,876
are things like tagging


352
00:11:30,876 --> 00:11:32,426
different parts of speech or


353
00:11:32,426 --> 00:11:33,846
recognizing named entities,


354
00:11:34,246 --> 00:11:35,346
though you could customize your


355
00:11:35,346 --> 00:11:36,976
own to do things like tag


356
00:11:37,056 --> 00:11:37,486
cheeses.


357
00:11:38,356 --> 00:11:39,876
With a Cheese Tagger, you could


358
00:11:39,876 --> 00:11:41,306
be sure to identify different


359
00:11:41,306 --> 00:11:43,046
flavor notes from any cheese


360
00:11:43,086 --> 00:11:43,646
description.


361
00:11:44,196 --> 00:11:47,816
Our last domain is the most


362
00:11:47,816 --> 00:11:49,846
general of all five; Tabular


363
00:11:49,846 --> 00:11:50,016
Data.


364
00:11:51,076 --> 00:11:52,516
And within this, we have three


365
00:11:52,516 --> 00:11:54,286
model types; the Tabular


366
00:11:54,676 --> 00:11:57,386
Classifier, Tabular Regressor,


367
00:11:58,046 --> 00:11:59,046
and Recommender.


368
00:11:59,716 --> 00:12:01,696
Classifiers are for categorizing


369
00:12:01,776 --> 00:12:03,446
samples based on their features


370
00:12:03,446 --> 00:12:03,966
of interest.


371
00:12:04,676 --> 00:12:06,216
And features can be a variety of


372
00:12:06,216 --> 00:12:07,516
different types such as


373
00:12:07,516 --> 00:12:10,286
integers, doubles, strings, so


374
00:12:10,286 --> 00:12:11,466
long as your target is a


375
00:12:11,466 --> 00:12:12,436
discrete value.


376
00:12:14,216 --> 00:12:15,376
These allow you to do things


377
00:12:15,426 --> 00:12:16,996
like determine if a seat is


378
00:12:17,036 --> 00:12:18,836
comfortable or not based on a


379
00:12:18,836 --> 00:12:20,236
particular person's height and


380
00:12:20,236 --> 00:12:21,966
weight and specific properties


381
00:12:22,006 --> 00:12:23,466
of the seat such as the amount


382
00:12:23,466 --> 00:12:24,036
of leg room.


383
00:12:25,476 --> 00:12:26,716
What's unique about the Tabular


384
00:12:26,766 --> 00:12:28,736
Classifier is it extracts away


385
00:12:28,956 --> 00:12:30,306
the underlying algorithm for


386
00:12:30,306 --> 00:12:30,536
you.


387
00:12:30,916 --> 00:12:32,796
And identifies the best multiple


388
00:12:32,796 --> 00:12:34,136
classifiers for your data.


389
00:12:35,766 --> 00:12:37,156
If you instead want a model that


390
00:12:37,156 --> 00:12:38,656
will predict a numeric value,


391
00:12:38,776 --> 00:12:40,936
such as a rating or a score, you


392
00:12:40,936 --> 00:12:42,306
may instead want to use the


393
00:12:42,306 --> 00:12:43,256
Tabular Regressor.


394
00:12:44,516 --> 00:12:46,166
This model quantifies samples


395
00:12:46,296 --> 00:12:47,216
based on their defining


396
00:12:47,216 --> 00:12:47,696
features.


397
00:12:47,786 --> 00:12:49,176
So, you could train one to


398
00:12:49,206 --> 00:12:50,566
estimate the price of a house


399
00:12:51,036 --> 00:12:52,956
based on its location and number


400
00:12:52,956 --> 00:12:54,316
of bedrooms, bathrooms, and


401
00:12:54,316 --> 00:12:55,126
parking spaces.


402
00:12:56,556 --> 00:12:57,956
Like the Classifier, the


403
00:12:57,956 --> 00:12:59,546
Regressor also automatically


404
00:12:59,546 --> 00:13:01,386
detects the best of multiple


405
00:13:01,386 --> 00:13:02,336
regressors for your data.


406
00:13:03,176 --> 00:13:03,866
Though, you still have the


407
00:13:03,866 --> 00:13:06,146
flexibility to choose a specific


408
00:13:06,256 --> 00:13:08,436
boosted or decision tree, random


409
00:13:08,506 --> 00:13:10,356
forest, or linear regressor, if


410
00:13:10,356 --> 00:13:11,426
you like.


411
00:13:12,026 --> 00:13:14,056
And our last model is the


412
00:13:14,056 --> 00:13:16,036
Recommender which allows you to


413
00:13:16,036 --> 00:13:17,996
recommend content based on user


414
00:13:17,996 --> 00:13:18,536
behavior.


415
00:13:19,626 --> 00:13:20,866
The Recommender can be trained


416
00:13:20,866 --> 00:13:23,306
on user-item interactions with


417
00:13:23,306 --> 00:13:24,276
or without ratings.


418
00:13:24,576 --> 00:13:26,206
And it's able to be deployed on


419
00:13:26,206 --> 00:13:28,586
device, saving you the hassle of


420
00:13:28,736 --> 00:13:30,896
setting up the server.


421
00:13:31,506 --> 00:13:33,376
As we saw, Create ML comes with


422
00:13:33,446 --> 00:13:35,456
great features to help you set


423
00:13:35,456 --> 00:13:36,356
up your machine learning


424
00:13:36,356 --> 00:13:38,616
experiments, use native support


425
00:13:38,666 --> 00:13:40,726
for data visualization, metrics,


426
00:13:40,856 --> 00:13:41,596
and performance.


427
00:13:42,336 --> 00:13:43,796
And the machine learning models


428
00:13:43,796 --> 00:13:45,606
you train can easily be saved


429
00:13:45,606 --> 00:13:46,906
and shared with members of your


430
00:13:47,016 --> 00:13:47,286
team.


431
00:13:48,536 --> 00:13:50,366
Of course, all of this leverages


432
00:13:50,406 --> 00:13:52,076
the power and efficiency of


433
00:13:52,106 --> 00:13:53,216
training on your Mac.


434
00:13:55,206 --> 00:13:56,866
This new medium augments other


435
00:13:56,866 --> 00:13:58,266
ways you have available to you


436
00:13:58,546 --> 00:13:59,566
to create machine learning


437
00:13:59,566 --> 00:14:01,166
models such as in Swift


438
00:14:01,236 --> 00:14:02,976
Playgrounds, Swift Scripts, or


439
00:14:03,056 --> 00:14:04,556
Swift Frepple [phonetic], Xcode


440
00:14:04,556 --> 00:14:04,856
Playground.


441
00:14:05,716 --> 00:14:07,276
But allows you to do so without


442
00:14:07,276 --> 00:14:09,486
writing a single line of code.


443
00:14:10,456 --> 00:14:12,166
We believe this brings machine


444
00:14:12,166 --> 00:14:13,706
learning to everyone.


445
00:14:15,376 --> 00:14:17,446
To summarize, in Create ML this


446
00:14:17,516 --> 00:14:19,876
year, you have new models, nine


447
00:14:19,936 --> 00:14:21,536
templates, and a whole new


448
00:14:21,536 --> 00:14:21,946
workflow.


449
00:14:22,516 --> 00:14:28,500
[ Applause ]

