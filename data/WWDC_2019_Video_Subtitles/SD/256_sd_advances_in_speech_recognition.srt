1
00:00:00,506 --> 00:00:05,916
[ Music ]


2
00:00:06,416 --> 00:00:08,846
>> Hi. I'm Neha Agrawal, and I'm


3
00:00:08,846 --> 00:00:10,516
a software engineer working on


4
00:00:10,516 --> 00:00:11,426
speech recognition.


5
00:00:12,426 --> 00:00:14,776
In 2016, we introduced the


6
00:00:14,776 --> 00:00:16,436
Speech Recognition framework for


7
00:00:16,686 --> 00:00:18,756
developers to solve their speech


8
00:00:18,756 --> 00:00:19,686
recognition needs.


9
00:00:20,326 --> 00:00:22,096
For anyone who is new to this


10
00:00:22,096 --> 00:00:24,096
framework, I highly recommend


11
00:00:24,316 --> 00:00:25,876
watching this Speech Recognition


12
00:00:25,876 --> 00:00:28,166
API session by my colleague


13
00:00:28,316 --> 00:00:29,246
Henry Mason.


14
00:00:31,066 --> 00:00:32,695
In this video, we're going to


15
00:00:32,695 --> 00:00:35,106
discuss exciting new advances in


16
00:00:35,106 --> 00:00:35,426
the APIs.


17
00:00:35,426 --> 00:00:36,906
Let's get started.


18
00:00:39,216 --> 00:00:40,596
Speech recognition is now


19
00:00:40,596 --> 00:00:42,206
supported for macOS.


20
00:00:43,036 --> 00:00:44,706
The support is available for


21
00:00:44,706 --> 00:00:47,376
both AppKit and iPad apps on


22
00:00:47,376 --> 00:00:47,716
Mac.


23
00:00:48,886 --> 00:00:51,536
Just like iOS, over 50 languages


24
00:00:51,536 --> 00:00:52,266
are supported.


25
00:00:53,816 --> 00:00:55,756
You need approval from your


26
00:00:55,756 --> 00:00:57,856
users to access the microphone


27
00:00:57,976 --> 00:00:59,616
and record their speech, and


28
00:01:00,406 --> 00:01:01,736
they also need to have Siri


29
00:01:01,736 --> 00:01:02,246
enabled.


30
00:01:02,876 --> 00:01:05,596
In addition to supporting speech


31
00:01:05,596 --> 00:01:08,366
recognition on macOS, we are now


32
00:01:08,366 --> 00:01:10,056
allowing developers to run


33
00:01:10,056 --> 00:01:12,026
recognition on-device for


34
00:01:12,026 --> 00:01:13,936
privacy sensitive applications.


35
00:01:14,646 --> 00:01:17,876
With on-device support, your


36
00:01:17,876 --> 00:01:19,746
user's data will not be sent to


37
00:01:19,746 --> 00:01:20,586
Apple servers.


38
00:01:22,096 --> 00:01:24,156
Your app no longer needs to rely


39
00:01:24,446 --> 00:01:27,136
on a network connection, and


40
00:01:27,136 --> 00:01:28,626
cellular data will not be


41
00:01:28,626 --> 00:01:29,196
consumed.


42
00:01:31,216 --> 00:01:33,556
However, there are tradeoffs to


43
00:01:33,556 --> 00:01:34,026
consider.


44
00:01:34,736 --> 00:01:37,426
Accuracy is good on-device, but


45
00:01:37,426 --> 00:01:39,536
you may find it is better on


46
00:01:39,536 --> 00:01:40,996
server due to a continuous


47
00:01:40,996 --> 00:01:41,416
learning.


48
00:01:41,666 --> 00:01:43,896
A server-based recognition


49
00:01:43,896 --> 00:01:46,246
support has limits on number of


50
00:01:46,246 --> 00:01:48,196
requests and audio duration.


51
00:01:48,976 --> 00:01:50,496
With on-device recognition,


52
00:01:50,876 --> 00:01:52,436
these limits do not apply.


53
00:01:53,726 --> 00:01:54,776
The number of languages


54
00:01:54,776 --> 00:01:57,256
supported on server are more


55
00:01:57,256 --> 00:01:58,536
than on-device.


56
00:01:59,846 --> 00:02:02,126
Also, if server isn't available,


57
00:02:02,126 --> 00:02:04,426
our server mode automatically


58
00:02:04,426 --> 00:02:06,376
falls back on on-device


59
00:02:06,376 --> 00:02:08,276
recognition if it is supported.


60
00:02:09,156 --> 00:02:11,736
All iPhones and iPads with Apple


61
00:02:12,156 --> 00:02:13,196
A9 or later processors are


62
00:02:13,196 --> 00:02:15,156
supported, and all Mac devices


63
00:02:15,156 --> 00:02:15,746
are supported.


64
00:02:16,776 --> 00:02:18,086
There are over 10 languages


65
00:02:18,086 --> 00:02:19,246
supported for on-device


66
00:02:19,246 --> 00:02:19,856
recognition.


67
00:02:20,426 --> 00:02:23,746
Now, let's look at how to enable


68
00:02:23,976 --> 00:02:25,876
on-device recognition in code.


69
00:02:26,536 --> 00:02:29,016
To recognize pre-recorded audio,


70
00:02:29,386 --> 00:02:30,986
we first create an


71
00:02:30,986 --> 00:02:33,066
SFSpeechRecognizer object and


72
00:02:33,066 --> 00:02:35,096
check for availability of speech


73
00:02:35,096 --> 00:02:36,856
recognition on that object.


74
00:02:39,206 --> 00:02:40,346
If speech recognition is


75
00:02:40,346 --> 00:02:42,516
available, we can create a


76
00:02:42,516 --> 00:02:44,376
recognition request with the


77
00:02:44,376 --> 00:02:46,366
audio file URL and start


78
00:02:46,366 --> 00:02:47,026
recognition.


79
00:02:49,676 --> 00:02:51,896
Now, in order to use on-device


80
00:02:51,896 --> 00:02:53,616
recognition, you need to first


81
00:02:53,616 --> 00:02:55,416
check if on-device recognition


82
00:02:55,416 --> 00:02:57,396
is supported and then set


83
00:02:57,606 --> 00:02:59,446
requiresOnDeviceRecognition


84
00:02:59,446 --> 00:03:01,396
property on the request object.


85
00:03:03,136 --> 00:03:04,586
Now that we have looked at this


86
00:03:04,586 --> 00:03:06,296
in code, let's talk about the


87
00:03:06,296 --> 00:03:07,006
results you get.


88
00:03:07,466 --> 00:03:11,466
Since iOS 10 in speech


89
00:03:11,466 --> 00:03:13,016
recognition results, we have


90
00:03:13,016 --> 00:03:14,616
provided transcriptions,


91
00:03:14,966 --> 00:03:16,486
alternative interpretations,


92
00:03:16,786 --> 00:03:18,456
confidence levels and timing


93
00:03:18,456 --> 00:03:19,096
information.


94
00:03:20,636 --> 00:03:22,146
We're making a few more


95
00:03:22,146 --> 00:03:23,616
additions to the speech


96
00:03:23,616 --> 00:03:24,556
recognition results.


97
00:03:26,776 --> 00:03:29,186
Speaking rate measures how fast


98
00:03:29,186 --> 00:03:31,016
a person speaks in words per


99
00:03:31,016 --> 00:03:31,396
minute.


100
00:03:33,366 --> 00:03:35,006
Average pause duration measures


101
00:03:35,276 --> 00:03:36,556
the average length of pause


102
00:03:36,556 --> 00:03:37,336
between words.


103
00:03:37,906 --> 00:03:41,086
And voice analytics features


104
00:03:41,306 --> 00:03:43,196
include various measures of


105
00:03:43,196 --> 00:03:44,566
vocal characteristics.


106
00:03:46,116 --> 00:03:47,906
Now, voice analytics gives


107
00:03:47,906 --> 00:03:49,416
insight into four features.


108
00:03:50,186 --> 00:03:52,216
Jitter measures how pitch varies


109
00:03:52,216 --> 00:03:52,726
in audio.


110
00:03:53,446 --> 00:03:55,296
With voice analytics, you can


111
00:03:55,296 --> 00:03:57,066
now understand the amount of


112
00:03:57,066 --> 00:03:59,066
jitter in speech expressed as a


113
00:03:59,066 --> 00:03:59,816
percentage.


114
00:04:01,236 --> 00:04:02,926
Shimmer measures how amplitude


115
00:04:02,926 --> 00:04:04,886
varies in audio, and with voice


116
00:04:04,886 --> 00:04:06,706
analytics, you can understand


117
00:04:06,706 --> 00:04:10,336
shimmer in speech expressed in


118
00:04:11,536 --> 00:04:11,946
decibels.


119
00:04:12,096 --> 00:04:13,376
Let's listen to some audio


120
00:04:13,376 --> 00:04:14,466
samples to understand what


121
00:04:14,466 --> 00:04:16,166
speech with high jitter and


122
00:04:16,166 --> 00:04:17,125
shimmer sounds like.


123
00:04:17,606 --> 00:04:19,526
First, let's hear audio with


124
00:04:19,526 --> 00:04:20,276
normal speech.


125
00:04:20,866 --> 00:04:21,546
>> Apple.


126
00:04:23,276 --> 00:04:24,756
>> Now, audio with perturbed


127
00:04:24,756 --> 00:04:25,236
speech.


128
00:04:25,956 --> 00:04:26,846
>> Apple.


129
00:04:27,926 --> 00:04:29,176
>> Next feature is pitch.


130
00:04:29,966 --> 00:04:31,976
Pitch measures the highness and


131
00:04:31,976 --> 00:04:33,286
lowness of the tone.


132
00:04:33,656 --> 00:04:35,476
Often, women and children have


133
00:04:35,476 --> 00:04:36,266
higher pitch.


134
00:04:37,496 --> 00:04:39,426
And voicing is used to identify


135
00:04:39,776 --> 00:04:41,766
voiced regions in speech.


136
00:04:42,316 --> 00:04:44,956
The voice analytics features are


137
00:04:44,956 --> 00:04:46,516
specific to an individual, and


138
00:04:46,516 --> 00:04:49,036
they can vary with time and


139
00:04:49,036 --> 00:04:49,926
circumstances.


140
00:04:50,636 --> 00:04:52,506
For example, if the person is


141
00:04:52,506 --> 00:04:54,876
tired, these features will be


142
00:04:54,876 --> 00:04:56,616
different than when they're not.


143
00:04:57,466 --> 00:04:59,346
Also, depending on who the


144
00:04:59,346 --> 00:05:00,996
person is talking to, these


145
00:05:00,996 --> 00:05:01,976
features may vary.


146
00:05:04,416 --> 00:05:06,556
These new results are part of


147
00:05:06,556 --> 00:05:08,436
the SF transcription object and


148
00:05:08,436 --> 00:05:10,016
will be available periodically.


149
00:05:10,556 --> 00:05:12,776
We will have them at the end


150
00:05:12,986 --> 00:05:14,586
when the isFinal flag is sent,


151
00:05:14,996 --> 00:05:16,246
but we could also see them


152
00:05:16,246 --> 00:05:16,586
before.


153
00:05:17,306 --> 00:05:19,806
You can access speakingRate and


154
00:05:19,806 --> 00:05:21,796
averagePauseDuration as shown.


155
00:05:23,736 --> 00:05:26,566
To access voice analytics, you


156
00:05:26,566 --> 00:05:28,446
would have to access the SF


157
00:05:28,446 --> 00:05:30,346
transcription segment object,


158
00:05:30,586 --> 00:05:32,256
and then you can access it as


159
00:05:32,256 --> 00:05:32,846
shown here.


160
00:05:34,636 --> 00:05:37,006
To summarize, we have made three


161
00:05:37,006 --> 00:05:37,846
key advances.


162
00:05:38,506 --> 00:05:40,326
You can now build apps on macOS


163
00:05:40,656 --> 00:05:42,366
using speech recognition APIs.


164
00:05:43,546 --> 00:05:45,066
Speech recognition can be run


165
00:05:45,066 --> 00:05:47,196
on-device in a privacy-friendly


166
00:05:47,196 --> 00:05:47,606
manner.


167
00:05:48,386 --> 00:05:50,696
And you now have access to voice


168
00:05:50,696 --> 00:05:52,686
analytics features for getting


169
00:05:52,686 --> 00:05:54,076
insight into vocal


170
00:05:54,076 --> 00:05:55,136
characteristics.


171
00:05:57,176 --> 00:05:59,486
For more information, check out


172
00:05:59,486 --> 00:06:01,006
the session's web page and


173
00:06:01,006 --> 00:06:01,976
thanks for watching.

