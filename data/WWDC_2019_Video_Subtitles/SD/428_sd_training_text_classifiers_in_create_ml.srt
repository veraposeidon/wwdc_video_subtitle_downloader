1
00:00:00,506 --> 00:00:04,500
[ Music ]


2
00:00:07,516 --> 00:00:14,026
[ Applause ]


3
00:00:14,526 --> 00:00:15,626
>> Hello, everyone.


4
00:00:15,836 --> 00:00:16,516
Good afternoon.


5
00:00:17,316 --> 00:00:18,456
Welcome to the session.


6
00:00:19,796 --> 00:00:20,836
My name is Tao.


7
00:00:21,246 --> 00:00:22,446
I'm from Core ML Team.


8
00:00:23,276 --> 00:00:25,016
Today we're super excited to


9
00:00:25,016 --> 00:00:26,916
talk about a few new features we


10
00:00:26,916 --> 00:00:28,676
added to Create ML this year.


11
00:00:29,016 --> 00:00:30,136
In What's New in Machine


12
00:00:30,136 --> 00:00:31,536
Learning Session, you were


13
00:00:31,536 --> 00:00:33,286
introduced to the brand-new


14
00:00:33,336 --> 00:00:34,986
Create ML app.


15
00:00:34,986 --> 00:00:36,336
It's a great new tool designed


16
00:00:36,336 --> 00:00:38,226
by Apple to guide you through


17
00:00:38,226 --> 00:00:40,146
the essential steps of training


18
00:00:40,146 --> 00:00:41,206
of machine learning models.


19
00:00:42,226 --> 00:00:43,806
We believe this makes your


20
00:00:43,806 --> 00:00:46,016
machine learning workflow easy


21
00:00:46,016 --> 00:00:46,756
and approachable.


22
00:00:48,206 --> 00:00:49,366
Now, let's start with Text


23
00:00:49,366 --> 00:00:49,976
Classification.


24
00:00:52,546 --> 00:00:53,956
What is Text Classification?


25
00:00:54,536 --> 00:00:55,966
It's a machine learning task


26
00:00:56,346 --> 00:00:58,796
that classifies input text to a


27
00:00:58,886 --> 00:01:00,446
set of predefined labels.


28
00:01:03,136 --> 00:01:04,566
You can use it for sentiment


29
00:01:04,566 --> 00:01:07,626
analysis, like classifying text


30
00:01:07,626 --> 00:01:09,936
as positive or negative.


31
00:01:11,396 --> 00:01:12,756
Or doing spam detection.


32
00:01:12,756 --> 00:01:16,096
Or more complicated things like


33
00:01:16,386 --> 00:01:18,596
topic analysis, classifying text


34
00:01:18,596 --> 00:01:21,786
as food, politics, or science.


35
00:01:23,146 --> 00:01:24,556
Now, Text Classification has


36
00:01:24,556 --> 00:01:25,976
been supported since last year,


37
00:01:26,516 --> 00:01:28,296
but this year we're adding the


38
00:01:28,296 --> 00:01:30,076
support for the state of the art


39
00:01:30,076 --> 00:01:30,776
transfer learning.


40
00:01:31,636 --> 00:01:33,156
Today, I'm going to give you a


41
00:01:33,156 --> 00:01:35,206
concrete example of how you can


42
00:01:35,206 --> 00:01:37,346
train a Text Classifier using


43
00:01:37,346 --> 00:01:38,046
Transfer Learning.


44
00:01:39,446 --> 00:01:41,336
To train such a model, the first


45
00:01:41,336 --> 00:01:42,566
thing you'll want to do is


46
00:01:42,886 --> 00:01:44,616
collect some training data.


47
00:01:46,336 --> 00:01:48,386
Once you have the data, you can


48
00:01:48,386 --> 00:01:50,066
organize in an easy way.


49
00:01:51,116 --> 00:01:53,676
I have sports, entertainment and


50
00:01:53,676 --> 00:01:54,056
nature.


51
00:01:55,166 --> 00:01:56,996
Under each folder, I have a few


52
00:01:56,996 --> 00:01:57,626
text files.


53
00:01:58,236 --> 00:02:00,316
And each one of them is a single


54
00:02:00,316 --> 00:02:02,996
training example, and its label


55
00:02:03,146 --> 00:02:04,996
is simply the name of the folder


56
00:02:04,996 --> 00:02:05,406
they are in.


57
00:02:05,946 --> 00:02:07,786
And that's it.


58
00:02:07,786 --> 00:02:08,806
That's all you need to do with


59
00:02:08,806 --> 00:02:09,186
the data.


60
00:02:10,156 --> 00:02:11,636
I'll give you a quick demo to


61
00:02:11,636 --> 00:02:12,576
show how you can do this.


62
00:02:12,776 --> 00:02:15,606
On my desktop, I have a training


63
00:02:15,606 --> 00:02:15,956
data folder.


64
00:02:20,386 --> 00:02:21,456
So, I decided to have a little


65
00:02:21,456 --> 00:02:22,026
bit of fun.


66
00:02:22,716 --> 00:02:24,356
Instead of using plain text as


67
00:02:24,356 --> 00:02:26,546
the label, I used a few emojis.


68
00:02:27,426 --> 00:02:29,116
For example, for entertainment I


69
00:02:29,116 --> 00:02:30,306
use a camcorder.


70
00:02:31,106 --> 00:02:33,216
For sport, I'm using an American


71
00:02:33,216 --> 00:02:33,836
football.


72
00:02:35,196 --> 00:02:36,836
For nature, I'm using this cute


73
00:02:36,836 --> 00:02:39,486
little tent besides a great pine


74
00:02:40,856 --> 00:02:40,966
tree.


75
00:02:41,186 --> 00:02:42,536
You notice there is also this


76
00:02:42,656 --> 00:02:43,306
other folder.


77
00:02:44,186 --> 00:02:45,686
This is the training data that I


78
00:02:45,686 --> 00:02:46,936
actually don't want.


79
00:02:46,936 --> 00:02:49,466
I want my model to learn such


80
00:02:49,466 --> 00:02:51,326
that anything that's not one of


81
00:02:51,326 --> 00:02:53,416
the three intended class, I want


82
00:02:53,416 --> 00:02:55,756
my model to classify them into


83
00:02:56,726 --> 00:02:58,516
this class.


84
00:02:58,686 --> 00:03:00,286
So, let's take a look at a few


85
00:03:00,286 --> 00:03:00,936
examples here.


86
00:03:01,766 --> 00:03:05,186
For example if you read this


87
00:03:05,186 --> 00:03:06,056
sentence, there's something


88
00:03:06,056 --> 00:03:07,586
about writer and IMDB.


89
00:03:07,586 --> 00:03:09,026
It's clearly something related


90
00:03:09,026 --> 00:03:09,806
to entertainment.


91
00:03:13,006 --> 00:03:15,066
If I go into other folder, this


92
00:03:15,926 --> 00:03:19,086
is not one of the three intended


93
00:03:19,856 --> 00:03:20,006
class.


94
00:03:24,536 --> 00:03:25,546
That's about data.


95
00:03:25,796 --> 00:03:32,446
Now, I'll go to Create ML app.


96
00:03:34,436 --> 00:03:36,806
To do that, I go to Developer


97
00:03:36,806 --> 00:03:39,356
Tools and find the Create ML.


98
00:03:42,116 --> 00:03:43,256
But I'm going to do a new


99
00:03:43,256 --> 00:03:48,336
document and go to text.


100
00:03:48,496 --> 00:03:49,496
I'll name it like that.


101
00:03:50,736 --> 00:03:53,906
Create. So, I'm sure you have


102
00:03:53,906 --> 00:03:56,476
seen this user interface in the


103
00:03:56,476 --> 00:03:58,096
earlier session, Object


104
00:03:58,096 --> 00:03:58,776
Connection and


105
00:03:58,846 --> 00:03:59,916
Subclassification.


106
00:04:00,226 --> 00:04:01,466
So, I'm just going to drag my


107
00:04:01,466 --> 00:04:02,826
training data in directly here.


108
00:04:03,446 --> 00:04:05,956
So, it gives you some feedback


109
00:04:05,956 --> 00:04:06,926
about your training data.


110
00:04:07,366 --> 00:04:08,606
But what's new about Text


111
00:04:08,606 --> 00:04:10,306
Classifier is this particular


112
00:04:10,306 --> 00:04:11,236
parameter section.


113
00:04:11,866 --> 00:04:15,026
So, for today's demo, I'm going


114
00:04:15,026 --> 00:04:16,296
to select Transfer Learning.


115
00:04:17,736 --> 00:04:19,065
If we take a look at it, the


116
00:04:19,065 --> 00:04:20,596
first two algorithms actually


117
00:04:20,596 --> 00:04:21,995
have been supported since last


118
00:04:21,995 --> 00:04:22,136
year.


119
00:04:22,776 --> 00:04:23,826
And this year we're adding


120
00:04:23,826 --> 00:04:24,606
Transfer Learning.


121
00:04:25,096 --> 00:04:27,086
And for the demo I'm going to


122
00:04:27,086 --> 00:04:28,546
use this feature extractor


123
00:04:28,546 --> 00:04:29,826
called Dynamic Embedding.


124
00:04:30,156 --> 00:04:32,496
I'll go into the detail about


125
00:04:32,496 --> 00:04:33,946
what is Transfer Learning a bit


126
00:04:33,946 --> 00:04:35,936
later after the demo, but all


127
00:04:35,936 --> 00:04:37,846
you need to know now is Transfer


128
00:04:37,846 --> 00:04:39,256
Learning with Dynamic Embedding


129
00:04:39,676 --> 00:04:41,686
is actually an algorithm that


130
00:04:41,686 --> 00:04:43,096
pays attention to the semantic


131
00:04:43,096 --> 00:04:45,446
meaning of your input text.


132
00:04:47,036 --> 00:04:48,216
I'll start training.


133
00:04:49,346 --> 00:04:50,506
So, in general, Transfer


134
00:04:50,506 --> 00:04:52,326
Learning takes a bit longer to


135
00:04:52,326 --> 00:04:52,726
train.


136
00:04:53,516 --> 00:04:54,716
For this particular data set,


137
00:04:55,176 --> 00:04:57,416
it'll take about five minutes on


138
00:04:57,416 --> 00:04:58,316
this particular machine.


139
00:04:59,376 --> 00:05:01,196
So, I'm not going to wait.


140
00:05:02,666 --> 00:05:04,636
Instead, I have my pre-picked


141
00:05:04,966 --> 00:05:07,116
solution here that's trained on


142
00:05:07,116 --> 00:05:08,386
exactly the same data.


143
00:05:08,956 --> 00:05:12,286
Once the model has been trained,


144
00:05:12,286 --> 00:05:14,996
the accuracy test gives you a


145
00:05:14,996 --> 00:05:16,846
good summary about how your


146
00:05:16,846 --> 00:05:18,786
model performs on different


147
00:05:18,786 --> 00:05:21,266
data, broken down into different


148
00:05:21,266 --> 00:05:21,676
classes.


149
00:05:22,666 --> 00:05:24,216
It looks my model has done a


150
00:05:24,216 --> 00:05:26,246
good job on training validation


151
00:05:26,246 --> 00:05:26,836
and testing data.


152
00:05:27,486 --> 00:05:30,446
So, I will directly jump to the


153
00:05:30,446 --> 00:05:31,196
output tab.


154
00:05:31,946 --> 00:05:34,566
This preview pane gives you some


155
00:05:34,636 --> 00:05:37,116
summary about the model as well


156
00:05:37,116 --> 00:05:38,906
as a few different ways for you


157
00:05:38,906 --> 00:05:40,506
to do some quick experiments.


158
00:05:41,286 --> 00:05:42,836
For example, if you go to the


159
00:05:42,836 --> 00:05:44,576
lower right-hand side corner,


160
00:05:45,246 --> 00:05:47,526
you can directly add File to do


161
00:05:47,526 --> 00:05:50,166
a quick test.


162
00:05:50,336 --> 00:05:56,016
Or you can track a folder that


163
00:05:56,016 --> 00:05:57,756
the model will be able to make


164
00:05:57,756 --> 00:05:59,496
prediction of all the text file


165
00:05:59,526 --> 00:06:00,406
within that folder.


166
00:06:01,256 --> 00:06:02,696
The model actually will use the


167
00:06:02,696 --> 00:06:04,856
entire body of the text in each


168
00:06:04,856 --> 00:06:06,276
file to make a single


169
00:06:06,276 --> 00:06:06,776
prediction.


170
00:06:07,306 --> 00:06:10,336
But there is another way for you


171
00:06:10,336 --> 00:06:12,416
to do quick experiment which is


172
00:06:12,826 --> 00:06:13,626
manually typing.


173
00:06:16,446 --> 00:06:19,356
So in this particular text input


174
00:06:19,506 --> 00:06:22,066
section, when you, when I type


175
00:06:22,376 --> 00:06:25,566
each space, or if I stop typing


176
00:06:25,616 --> 00:06:27,406
for a little while, the model


177
00:06:27,406 --> 00:06:28,436
will make a prediction.


178
00:06:29,186 --> 00:06:30,966
So, let's see how that works.


179
00:06:33,136 --> 00:06:35,336
What a comeback win.


180
00:06:36,076 --> 00:06:40,886
Sport. Let's try something


181
00:06:40,926 --> 00:06:41,546
different.


182
00:06:42,896 --> 00:06:46,796
The season finale adds a twist


183
00:06:47,486 --> 00:06:48,966
to the plot.


184
00:06:49,456 --> 00:06:52,076
Which seems about right.


185
00:06:52,386 --> 00:06:52,966
Entertainment.


186
00:06:53,516 --> 00:06:56,826
[ Applause ]


187
00:06:57,326 --> 00:06:58,516
I actually also want to try


188
00:06:58,516 --> 00:07:00,086
something more recent and more


189
00:07:00,086 --> 00:07:00,566
relevant.


190
00:07:01,006 --> 00:07:03,166
This just came to me last night.


191
00:07:04,266 --> 00:07:14,356
The Raptors are on top of the


192
00:07:15,616 --> 00:07:15,976
mountain.


193
00:07:18,316 --> 00:07:18,796
Nature [laughter].


194
00:07:20,476 --> 00:07:21,856
Well, if I switch context.


195
00:07:26,016 --> 00:07:27,096
[ Applause ]


196
00:07:27,096 --> 00:07:27,946
It predicts sport.


197
00:07:28,516 --> 00:07:32,926
[ Applause ]


198
00:07:33,426 --> 00:07:35,206
So, I'm pretty happy with the


199
00:07:35,206 --> 00:07:35,966
model performance.


200
00:07:36,766 --> 00:07:38,276
Now I'm ready to deploy.


201
00:07:38,556 --> 00:07:40,186
So, I just simply drag it out


202
00:07:40,536 --> 00:07:42,086
and I can put it on my iOS


203
00:07:42,146 --> 00:07:42,626
devices.


204
00:07:51,556 --> 00:07:53,186
That's how you can train a Text


205
00:07:53,186 --> 00:07:54,876
Classifier using Transfer


206
00:07:54,876 --> 00:07:55,146
Learning.


207
00:07:56,366 --> 00:07:58,286
But you might want to ask what


208
00:07:58,286 --> 00:07:59,856
is Transfer Learning?


209
00:08:02,196 --> 00:08:03,896
Transfer Learning is a powerful


210
00:08:03,896 --> 00:08:05,736
machine learning technique where


211
00:08:05,736 --> 00:08:07,526
a model trained on a huge amount


212
00:08:07,526 --> 00:08:09,516
of data for one particular task


213
00:08:10,086 --> 00:08:11,936
can be repurposed for another


214
00:08:11,936 --> 00:08:15,226
task so that you, as developers,


215
00:08:15,226 --> 00:08:17,226
only need to prepare limited


216
00:08:17,226 --> 00:08:19,486
amount of data and still get


217
00:08:19,486 --> 00:08:20,786
your customized machine learning


218
00:08:20,786 --> 00:08:21,256
model.


219
00:08:21,706 --> 00:08:25,816
Create ML actually uses Transfer


220
00:08:25,816 --> 00:08:26,646
Learning for image


221
00:08:26,646 --> 00:08:27,866
classification today.


222
00:08:28,326 --> 00:08:30,206
And now we're bringing it to


223
00:08:31,166 --> 00:08:31,536
text.


224
00:08:32,426 --> 00:08:34,296
Well, to train a good Transfer


225
00:08:34,296 --> 00:08:36,866
Learning model for text, the


226
00:08:36,866 --> 00:08:37,796
problem is a little bit


227
00:08:37,796 --> 00:08:38,256
different.


228
00:08:39,176 --> 00:08:40,796
If you read this sentence, "I


229
00:08:41,056 --> 00:08:43,856
was able to park my car near the


230
00:08:43,856 --> 00:08:44,806
park entrance."


231
00:08:46,736 --> 00:08:48,936
For a model that's trained with


232
00:08:49,506 --> 00:08:51,776
conventional technique or study


233
00:08:51,776 --> 00:08:54,726
embedding, these two parts will


234
00:08:54,726 --> 00:08:57,586
look exactly the same.


235
00:08:57,766 --> 00:08:59,386
But for a model trained with


236
00:08:59,386 --> 00:09:01,036
Transfer Learning with Dynamic


237
00:09:01,036 --> 00:09:03,706
Embedding, because it pays


238
00:09:03,706 --> 00:09:04,916
attention to the semantic


239
00:09:04,916 --> 00:09:06,716
meaning of the overall context,


240
00:09:07,406 --> 00:09:09,826
it is able to figure out these


241
00:09:09,826 --> 00:09:11,216
two parts actually mean


242
00:09:11,216 --> 00:09:12,666
different things.


243
00:09:16,136 --> 00:09:18,206
To train such a good model, you


244
00:09:18,206 --> 00:09:19,586
need to do it on many texts.


245
00:09:20,056 --> 00:09:21,586
That's exactly what we did.


246
00:09:22,566 --> 00:09:26,716
We trained on billions of text


247
00:09:26,876 --> 00:09:28,096
and shipped that pretrained


248
00:09:28,096 --> 00:09:29,586
model to your mobile devices.


249
00:09:30,066 --> 00:09:31,956
And more importantly, we


250
00:09:31,956 --> 00:09:34,446
optimized its performance so


251
00:09:34,446 --> 00:09:38,316
that you only need to prepare


252
00:09:38,466 --> 00:09:40,126
your limited amount of raw text,


253
00:09:40,626 --> 00:09:43,686
send it in to Create ML app.


254
00:09:44,006 --> 00:09:46,286
Underneath it, it'll interact


255
00:09:46,286 --> 00:09:47,736
with the model that's already


256
00:09:47,736 --> 00:09:50,956
part of your OS and gives your


257
00:09:50,956 --> 00:09:52,816
customized text classifier.


258
00:09:55,696 --> 00:09:57,236
And you can deploy the same


259
00:09:57,236 --> 00:09:59,116
model on your iOS devices


260
00:09:59,436 --> 00:10:01,386
seamlessly because the


261
00:10:01,386 --> 00:10:03,116
pretrained model is already


262
00:10:03,116 --> 00:10:06,166
there for you to use.


263
00:10:06,476 --> 00:10:09,216
Now, that's the workflow to use


264
00:10:09,216 --> 00:10:11,016
the Create ML app to train your


265
00:10:11,016 --> 00:10:12,116
Text Classifier.


266
00:10:13,216 --> 00:10:14,816
If you're also interested in


267
00:10:15,056 --> 00:10:17,396
writing code, it's also very


268
00:10:17,396 --> 00:10:17,706
easy.


269
00:10:18,816 --> 00:10:20,106
To use the Transfer Learning


270
00:10:20,106 --> 00:10:22,136
with Dynamic Embedding, the only


271
00:10:22,136 --> 00:10:23,496
thing you need to specify is


272
00:10:23,496 --> 00:10:24,816
this model parameter.


273
00:10:25,616 --> 00:10:27,096
The rest of the code is exactly


274
00:10:27,096 --> 00:10:27,976
the same as last year.


275
00:10:32,986 --> 00:10:35,246
Now, I've shown you how to train


276
00:10:35,246 --> 00:10:37,756
Text Classifier, but I'd like to


277
00:10:37,756 --> 00:10:39,866
give you a few simple tips to


278
00:10:39,866 --> 00:10:41,906
get the most out of your Text


279
00:10:41,906 --> 00:10:42,476
Classifier.


280
00:10:45,086 --> 00:10:47,876
Now, choose an algorithm which


281
00:10:47,876 --> 00:10:49,206
suits your use case.


282
00:10:50,296 --> 00:10:51,836
Transfer Learning is only one of


283
00:10:51,836 --> 00:10:53,966
the three algorithms that Text


284
00:10:53,966 --> 00:10:55,256
Classifier supports.


285
00:10:57,656 --> 00:10:58,726
Different algorithms have


286
00:10:58,806 --> 00:10:59,556
different tradeoffs.


287
00:11:00,676 --> 00:11:02,236
To find out which one fits your


288
00:11:02,236 --> 00:11:04,596
use case best, please go to the


289
00:11:04,596 --> 00:11:05,926
Natural Language session that


290
00:11:05,926 --> 00:11:10,156
happens after this.


291
00:11:10,346 --> 00:11:11,816
Provide balanced classes.


292
00:11:12,196 --> 00:11:13,256
This is very important.


293
00:11:14,376 --> 00:11:15,686
In the particular example that I


294
00:11:15,686 --> 00:11:17,606
showed you, because each text


295
00:11:17,606 --> 00:11:19,146
file is a single training


296
00:11:19,146 --> 00:11:19,756
example.


297
00:11:20,526 --> 00:11:22,076
So, I roughly kept the same


298
00:11:22,076 --> 00:11:24,146
amount of text files in each of


299
00:11:24,146 --> 00:11:24,646
the folders.


300
00:11:28,086 --> 00:11:29,126
Data consistency.


301
00:11:29,626 --> 00:11:31,256
If you expect your Text


302
00:11:31,256 --> 00:11:33,226
Classifier to mostly work on


303
00:11:33,226 --> 00:11:35,876
short sentences, like I do, your


304
00:11:35,876 --> 00:11:37,336
training data should be mostly


305
00:11:37,336 --> 00:11:39,026
consisting of such examples.


306
00:11:39,906 --> 00:11:42,876
If you expect your Text


307
00:11:42,876 --> 00:11:44,196
Classifier to work on short


308
00:11:44,196 --> 00:11:47,076
words, paragraphs, or even an


309
00:11:47,076 --> 00:11:49,866
entire article, you also want to


310
00:11:49,866 --> 00:11:51,236
make sure your training data


311
00:11:51,236 --> 00:11:52,626
cover these cases as well.


312
00:11:53,516 --> 00:11:58,506
[ Applause ]

