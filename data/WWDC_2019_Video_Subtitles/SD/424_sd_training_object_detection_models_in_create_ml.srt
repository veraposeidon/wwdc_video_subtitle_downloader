1
00:00:00,506 --> 00:00:05,500
[ Music ]


2
00:00:09,516 --> 00:00:16,096
[ Applause ]


3
00:00:16,596 --> 00:00:17,216
>> Good morning.


4
00:00:18,406 --> 00:00:21,606
I'm Alex Brown, an Engineer in


5
00:00:21,606 --> 00:00:22,146
Core ML.


6
00:00:23,206 --> 00:00:24,736
And today, we are going to


7
00:00:24,736 --> 00:00:26,816
present Create ML for Object


8
00:00:26,816 --> 00:00:27,366
Detection.


9
00:00:27,786 --> 00:00:30,726
In the What's New in Machine


10
00:00:30,726 --> 00:00:32,235
Learning session, you were


11
00:00:32,235 --> 00:00:34,666
introduced to the new Create ML


12
00:00:34,936 --> 00:00:35,003
app.


13
00:00:36,076 --> 00:00:37,206
It provides a really


14
00:00:37,206 --> 00:00:39,296
approachable way to build custom


15
00:00:39,296 --> 00:00:40,786
machine learning models to add


16
00:00:41,286 --> 00:00:42,466
to your applications.


17
00:00:43,496 --> 00:00:45,906
In this session, we're going to


18
00:00:45,906 --> 00:00:47,756
dig a little deeper into two


19
00:00:47,756 --> 00:00:49,086
specific templates.


20
00:00:49,886 --> 00:00:51,796
Object detection, which works


21
00:00:51,796 --> 00:00:53,606
with images, and sound


22
00:00:53,606 --> 00:00:54,456
classification.


23
00:00:55,056 --> 00:00:59,456
Let's get started with object


24
00:00:59,456 --> 00:01:00,046
detection.


25
00:01:02,506 --> 00:01:05,506
Object detection enables your


26
00:01:05,506 --> 00:01:07,316
application to identify


27
00:01:07,316 --> 00:01:09,076
real-world objects captured by


28
00:01:09,076 --> 00:01:10,856
your device's camera, and


29
00:01:10,856 --> 00:01:13,226
respond based on their presence,


30
00:01:13,806 --> 00:01:16,246
position, and relationship.


31
00:01:17,116 --> 00:01:19,406
You can download object


32
00:01:19,406 --> 00:01:21,026
detectors from the web which


33
00:01:21,026 --> 00:01:22,176
know the difference between


34
00:01:22,176 --> 00:01:23,756
broad categories of objects.


35
00:01:25,386 --> 00:01:27,086
But by training a custom machine


36
00:01:27,086 --> 00:01:29,046
learning model on your own data,


37
00:01:29,636 --> 00:01:31,166
you can teach your application


38
00:01:31,166 --> 00:01:32,506
about the subtle differences


39
00:01:33,046 --> 00:01:35,306
between individual animals, hand


40
00:01:35,306 --> 00:01:38,146
gestures, street signs, or game


41
00:01:38,146 --> 00:01:38,816
tokens.


42
00:01:39,396 --> 00:01:43,056
If you've used machine learning


43
00:01:43,316 --> 00:01:45,086
with Apple before, you may


44
00:01:45,086 --> 00:01:47,036
already be familiar with image


45
00:01:47,036 --> 00:01:47,936
classification.


46
00:01:49,456 --> 00:01:51,896
With image classification, you


47
00:01:51,896 --> 00:01:53,636
build a model which can provide


48
00:01:53,636 --> 00:01:55,596
a single simple description of


49
00:01:55,596 --> 00:01:56,146
an image.


50
00:01:57,656 --> 00:01:59,626
This image we might describe as


51
00:02:00,166 --> 00:02:02,976
outdoors or park, or for a


52
00:02:02,976 --> 00:02:05,476
particular application, dog.


53
00:02:08,056 --> 00:02:10,346
But what if we're interested in


54
00:02:10,346 --> 00:02:11,526
more than one object in the


55
00:02:11,526 --> 00:02:11,936
scene?


56
00:02:12,306 --> 00:02:16,286
In this case, object detection


57
00:02:16,466 --> 00:02:18,086
can come to the rescue.


58
00:02:18,586 --> 00:02:20,616
It can identify multiple objects


59
00:02:20,826 --> 00:02:22,596
within your photograph, and


60
00:02:22,596 --> 00:02:25,456
provide the location, size, and


61
00:02:25,456 --> 00:02:26,726
label for each one.


62
00:02:27,646 --> 00:02:29,966
This can enable your application


63
00:02:29,966 --> 00:02:31,806
to do more sophisticated things


64
00:02:32,096 --> 00:02:34,436
using your camera, but in order


65
00:02:34,436 --> 00:02:36,136
to do that, we need to go into


66
00:02:36,136 --> 00:02:37,776
more detail when teaching the


67
00:02:37,776 --> 00:02:39,676
model about your images.


68
00:02:41,756 --> 00:02:45,296
To train an object detector, you


69
00:02:45,296 --> 00:02:47,796
need to annotate each image with


70
00:02:47,796 --> 00:02:49,326
labeled regions that you would


71
00:02:49,326 --> 00:02:50,836
like the model to recognize.


72
00:02:51,606 --> 00:02:53,786
The bounding box for your


73
00:02:53,786 --> 00:02:56,266
annotated objects starting at


74
00:02:56,266 --> 00:02:57,576
the center of each object of


75
00:02:57,576 --> 00:03:00,116
interest and having a size,


76
00:03:00,206 --> 00:03:03,066
height, and width, this is


77
00:03:03,156 --> 00:03:05,376
measured in pixels from the top


78
00:03:05,376 --> 00:03:07,306
left-hand corner of your image


79
00:03:08,136 --> 00:03:11,066
to the center of each object of


80
00:03:11,956 --> 00:03:12,436
interest.


81
00:03:12,886 --> 00:03:14,806
You bundle together all of these


82
00:03:14,806 --> 00:03:17,736
annotations, label, position,


83
00:03:17,736 --> 00:03:20,356
and size, in a JSON file in the


84
00:03:20,356 --> 00:03:21,226
following format.


85
00:03:21,946 --> 00:03:26,986
You can download tools from the


86
00:03:26,986 --> 00:03:29,176
web to help you build these, but


87
00:03:29,466 --> 00:03:31,016
make sure they use the same


88
00:03:31,016 --> 00:03:33,206
coordinate system the Create ML


89
00:03:34,506 --> 00:03:35,646
app expects.


90
00:03:35,966 --> 00:03:37,216
Once you've assembled your


91
00:03:37,256 --> 00:03:40,256
annotations, simply drop them


92
00:03:40,256 --> 00:03:41,716
into the same folder as the


93
00:03:41,776 --> 00:03:44,446
images they describe, and that's


94
00:03:44,446 --> 00:03:44,686
it.


95
00:03:45,896 --> 00:03:50,176
Your training data is ready.


96
00:03:50,336 --> 00:03:52,576
So now we know how to create


97
00:03:52,576 --> 00:03:53,886
training data for object


98
00:03:53,886 --> 00:03:54,436
detection.


99
00:03:55,176 --> 00:03:56,656
Let's consider a real case.


100
00:03:58,266 --> 00:03:59,736
My colleague, Scott, has got a


101
00:03:59,736 --> 00:04:01,876
great idea for building a math


102
00:04:01,876 --> 00:04:03,786
game that is really engaging for


103
00:04:03,786 --> 00:04:06,676
kids, and uses real-world dice


104
00:04:07,066 --> 00:04:08,376
to provide the questions.


105
00:04:10,116 --> 00:04:11,346
You can hear more about this


106
00:04:11,346 --> 00:04:13,546
application in session 228,


107
00:04:14,046 --> 00:04:16,616
Creating Great Apps Using Core


108
00:04:16,616 --> 00:04:18,685
ML and AR Kit.


109
00:04:19,236 --> 00:04:21,106
So, Scott asked me to help build


110
00:04:21,106 --> 00:04:23,436
a model for his game, and I


111
00:04:23,436 --> 00:04:25,576
suggested using Apple's Create


112
00:04:25,576 --> 00:04:27,716
ML application to train an


113
00:04:27,716 --> 00:04:28,546
object detector.


114
00:04:29,136 --> 00:04:33,316
Scott has already sent me the


115
00:04:33,316 --> 00:04:34,036
training data.


116
00:04:35,346 --> 00:04:36,706
He took a bunch of images of


117
00:04:36,736 --> 00:04:38,816
dice from different angles and


118
00:04:38,816 --> 00:04:39,776
with different values on the


119
00:04:39,776 --> 00:04:41,976
top, and he's annotated them,


120
00:04:42,406 --> 00:04:44,636
drawing bounding boxes around


121
00:04:44,636 --> 00:04:47,056
the top face and adding a label,


122
00:04:47,056 --> 00:04:48,766
counting the number of pips on


123
00:04:50,016 --> 00:04:51,816
each dice.


124
00:04:52,476 --> 00:04:54,066
So, now we've got our data


125
00:04:54,066 --> 00:04:54,336
ready.


126
00:04:54,906 --> 00:04:56,266
Let's take a look at how we can


127
00:04:56,266 --> 00:04:57,866
use the Create ML application to


128
00:04:57,866 --> 00:04:58,566
build our model.


129
00:05:07,056 --> 00:05:10,146
So first of all, let's just


130
00:05:10,146 --> 00:05:10,796
check the data.


131
00:05:12,326 --> 00:05:13,646
You can see we've put all of our


132
00:05:13,646 --> 00:05:18,766
images in a folder, and each one


133
00:05:18,856 --> 00:05:22,236
contains multiple dice, and


134
00:05:23,286 --> 00:05:24,416
we've gathered together the


135
00:05:24,416 --> 00:05:26,176
annotations in a single JSON


136
00:05:26,176 --> 00:05:26,486
file.


137
00:05:28,276 --> 00:05:30,626
So now, I'll open the Create ML


138
00:05:30,626 --> 00:05:31,286
application.


139
00:05:31,836 --> 00:05:33,786
I can do this from inside X


140
00:05:33,786 --> 00:05:35,766
code's menu, or I can just use


141
00:05:35,766 --> 00:05:36,286
Spotlight.


142
00:05:40,696 --> 00:05:42,106
When the Create ML application


143
00:05:42,106 --> 00:05:44,226
opens, it gives us the option to


144
00:05:44,226 --> 00:05:45,446
access documents we already


145
00:05:45,446 --> 00:05:45,976
created.


146
00:05:46,586 --> 00:05:50,666
Here, we want a new project.


147
00:05:50,756 --> 00:05:52,376
First, you'll see the template


148
00:05:52,376 --> 00:05:54,076
picker, which give you a


149
00:05:54,076 --> 00:05:55,586
collection of machine learning


150
00:05:55,586 --> 00:05:57,056
model types to select from.


151
00:05:57,646 --> 00:05:59,756
In this case, we want an image


152
00:06:00,006 --> 00:06:01,596
object detector.


153
00:06:04,476 --> 00:06:06,156
I give it a name, so we can


154
00:06:06,156 --> 00:06:08,116
identify it later on, and fill


155
00:06:08,116 --> 00:06:09,246
in a few details.


156
00:06:15,666 --> 00:06:17,976
Here, you can see the main


157
00:06:17,976 --> 00:06:20,196
window with the training view on


158
00:06:20,196 --> 00:06:20,956
the right-hand side.


159
00:06:20,956 --> 00:06:22,706
It has already selected the


160
00:06:22,706 --> 00:06:24,516
input tab, ready for our


161
00:06:24,516 --> 00:06:25,196
training data.


162
00:06:25,926 --> 00:06:27,816
I can drag that straight into


163
00:06:27,816 --> 00:06:30,606
the training data well.


164
00:06:31,166 --> 00:06:32,676
Even before training the model,


165
00:06:33,266 --> 00:06:34,686
the application takes a look at


166
00:06:34,686 --> 00:06:36,416
the data, and checks it's in the


167
00:06:36,416 --> 00:06:38,566
right format, contains images


168
00:06:38,656 --> 00:06:40,236
rather than sound, for instance,


169
00:06:40,506 --> 00:06:41,886
and has a JSON file, which


170
00:06:41,886 --> 00:06:43,626
correctly describes them.


171
00:06:43,926 --> 00:06:45,536
It also provides some initial


172
00:06:45,536 --> 00:06:46,376
statistics.


173
00:06:46,916 --> 00:06:48,226
Here, we can see we have around


174
00:06:48,226 --> 00:06:51,526
1,000 images, and there are six


175
00:06:51,526 --> 00:06:54,236
classes, six, for the six sides


176
00:06:54,236 --> 00:06:55,476
of a six-sided dice.


177
00:06:56,556 --> 00:06:57,356
That's perfect.


178
00:06:59,576 --> 00:07:00,716
We can do some other things on


179
00:07:00,716 --> 00:07:01,296
this screen.


180
00:07:01,446 --> 00:07:03,006
For instance, we can supply


181
00:07:03,006 --> 00:07:04,786
testing data, to allow us to


182
00:07:04,786 --> 00:07:06,226
compare the performance of two


183
00:07:06,226 --> 00:07:07,036
different models.


184
00:07:07,686 --> 00:07:09,816
Also, we can set some advanced


185
00:07:09,816 --> 00:07:11,276
parameters, tuning the way the


186
00:07:11,276 --> 00:07:12,216
model trains.


187
00:07:12,716 --> 00:07:13,956
But we don't need to worry about


188
00:07:13,956 --> 00:07:15,266
any of that right now, we're


189
00:07:15,266 --> 00:07:16,296
actually ready to train.


190
00:07:17,466 --> 00:07:19,036
Let's hit the play button, and


191
00:07:19,036 --> 00:07:19,856
see what happens.


192
00:07:21,616 --> 00:07:22,976
Training has begun.


193
00:07:23,826 --> 00:07:25,546
It takes us instantly to the


194
00:07:25,546 --> 00:07:28,086
Training tab, where we can see


195
00:07:28,086 --> 00:07:29,216
the progress of the model


196
00:07:29,216 --> 00:07:29,706
training.


197
00:07:30,006 --> 00:07:32,316
This is a graph of loss.


198
00:07:32,506 --> 00:07:34,426
Loss decreases as the model gets


199
00:07:34,426 --> 00:07:35,136
better and better.


200
00:07:35,486 --> 00:07:36,936
So we should see this converge


201
00:07:37,076 --> 00:07:41,226
down to the bottom of the graph.


202
00:07:42,016 --> 00:07:43,906
Object detection takes a lot


203
00:07:43,906 --> 00:07:45,136
longer to train than image


204
00:07:45,136 --> 00:07:45,896
classification.


205
00:07:46,506 --> 00:07:47,776
I estimate this is probably


206
00:07:47,776 --> 00:07:49,336
going to take an hour or more.


207
00:07:49,726 --> 00:07:51,466
We don't want to wait for that,


208
00:07:51,466 --> 00:07:53,236
so I've already trained a model


209
00:07:53,346 --> 00:07:53,976
using this data.


210
00:08:03,496 --> 00:08:05,486
Here we are, and I can jump to


211
00:08:05,486 --> 00:08:06,966
the same training tab that we


212
00:08:06,966 --> 00:08:07,636
just looked at.


213
00:08:08,706 --> 00:08:10,396
You can see that the loss has


214
00:08:10,396 --> 00:08:11,996
neatly declined, showing the


215
00:08:11,996 --> 00:08:13,106
performance of the model has


216
00:08:13,106 --> 00:08:14,706
really increased over the time


217
00:08:14,706 --> 00:08:15,466
it took to train.


218
00:08:16,506 --> 00:08:17,636
There's a couple of other things


219
00:08:17,636 --> 00:08:18,416
that you should really have a


220
00:08:18,416 --> 00:08:19,546
look at on this screen.


221
00:08:20,416 --> 00:08:22,546
First of all, the overall


222
00:08:22,546 --> 00:08:23,336
performance.


223
00:08:23,686 --> 00:08:25,396
Ninety-two percent, which is a


224
00:08:25,396 --> 00:08:26,606
really great number for an


225
00:08:26,606 --> 00:08:27,436
object detector.


226
00:08:29,116 --> 00:08:30,746
We also want to have a look and


227
00:08:30,746 --> 00:08:32,456
check that we have consistent


228
00:08:32,456 --> 00:08:33,946
performance across all of the


229
00:08:33,946 --> 00:08:34,676
classes.


230
00:08:35,746 --> 00:08:38,446
The classes, 1 to 6, each here


231
00:08:38,546 --> 00:08:41,015
has 90% or more, and they're


232
00:08:41,015 --> 00:08:42,056
about the same value.


233
00:08:42,645 --> 00:08:45,036
This is important because it


234
00:08:45,036 --> 00:08:46,096
shows that it is performing


235
00:08:46,096 --> 00:08:47,486
equally well on the six sides of


236
00:08:47,486 --> 00:08:48,076
the dice.


237
00:08:48,806 --> 00:08:50,086
For a game of dice, where


238
00:08:50,086 --> 00:08:51,826
fairness is important, that's


239
00:08:51,826 --> 00:08:52,586
pretty important.


240
00:08:53,136 --> 00:08:57,796
So, the model has told us


241
00:08:57,946 --> 00:08:59,396
mathematically that it's pretty


242
00:08:59,396 --> 00:09:00,696
good, but how do we get


243
00:09:00,696 --> 00:09:01,886
confidence that it's going to


244
00:09:01,886 --> 00:09:03,446
work for our cases?


245
00:09:04,316 --> 00:09:06,266
Well, we can use the output tab.


246
00:09:07,816 --> 00:09:09,416
Scott sent me a test image to


247
00:09:09,416 --> 00:09:11,106
try out before I send the model


248
00:09:11,106 --> 00:09:12,746
back to him, so let's drag that


249
00:09:12,746 --> 00:09:12,976
in now.


250
00:09:20,036 --> 00:09:21,256
That's looking pretty great.


251
00:09:21,896 --> 00:09:22,766
You can see that it is


252
00:09:22,766 --> 00:09:24,546
identified, the five dice in the


253
00:09:24,546 --> 00:09:24,966
scene.


254
00:09:25,196 --> 00:09:27,146
It has correctly drawn the box


255
00:09:27,146 --> 00:09:29,746
around their top faces, and by


256
00:09:29,746 --> 00:09:34,526
clicking through, 6, 1, 5, we


257
00:09:34,526 --> 00:09:36,386
can see each label, and the


258
00:09:36,386 --> 00:09:37,546
confidence is assigned.


259
00:09:39,456 --> 00:09:41,086
That's performing really well.


260
00:09:41,786 --> 00:09:43,726
So, if I was building my own


261
00:09:44,556 --> 00:09:46,436
app, I could go ahead and drag


262
00:09:46,466 --> 00:09:47,756
the model that has been produced


263
00:09:48,136 --> 00:09:49,456
and use it within Xcode.


264
00:09:50,316 --> 00:09:51,926
I think Scott is probably


265
00:09:51,926 --> 00:09:53,196
waiting for this model to build


266
00:09:53,196 --> 00:09:53,976
his application.


267
00:09:55,306 --> 00:09:57,396
But before we go there, there's


268
00:09:57,396 --> 00:09:58,336
something I want to try.


269
00:10:00,556 --> 00:10:01,816
While I was preparing for this


270
00:10:01,846 --> 00:10:03,936
demo, playing with dice, and a


271
00:10:03,936 --> 00:10:06,146
camera, and my computer, my son,


272
00:10:06,146 --> 00:10:07,886
who is 9, came over and asked


273
00:10:07,886 --> 00:10:09,116
what I was doing.


274
00:10:10,276 --> 00:10:11,826
Once I'd explained it, he got


275
00:10:11,826 --> 00:10:13,226
pretty excited, and already


276
00:10:13,226 --> 00:10:14,586
started coming up with an idea


277
00:10:14,586 --> 00:10:17,056
for a game which had animals,


278
00:10:17,056 --> 00:10:18,446
bears, and bats, and they


279
00:10:18,686 --> 00:10:20,456
cooperate to collect bolts to


280
00:10:20,456 --> 00:10:21,226
build a space ship.


281
00:10:21,476 --> 00:10:23,586
And they use dice, colored dice,


282
00:10:23,586 --> 00:10:24,836
to level up for each different


283
00:10:24,836 --> 00:10:25,436
kind of monster.


284
00:10:26,946 --> 00:10:28,716
So we got his dice, and I


285
00:10:28,716 --> 00:10:30,506
decided to try them with Scott's


286
00:10:30,506 --> 00:10:30,786
model.


287
00:10:31,236 --> 00:10:33,806
So the dice he's using are a


288
00:10:33,806 --> 00:10:34,636
little bit different.


289
00:10:35,206 --> 00:10:36,506
They're role-playing dice,


290
00:10:36,896 --> 00:10:40,556
so let's see how the model


291
00:10:40,556 --> 00:10:41,196
performs.


292
00:10:42,126 --> 00:10:43,816
Using the Max Continuity Camera


293
00:10:43,816 --> 00:10:46,336
feature, I can import an image


294
00:10:47,316 --> 00:10:49,036
directly from my phone.


295
00:10:49,436 --> 00:10:50,546
This is really great because it


296
00:10:50,596 --> 00:10:52,186
means it's using the same glass,


297
00:10:52,296 --> 00:10:53,536
the same camera that your


298
00:10:53,536 --> 00:10:54,736
application will use.


299
00:10:57,176 --> 00:10:59,286
I take the photo and click Use


300
00:10:59,286 --> 00:10:59,796
Photo.


301
00:11:00,346 --> 00:11:04,716
And it's instantly analyzed it.


302
00:11:04,876 --> 00:11:06,276
So let's take a moment to have a


303
00:11:06,376 --> 00:11:07,556
look at what is going on here.


304
00:11:08,216 --> 00:11:11,876
It has correctly spotted the two


305
00:11:12,026 --> 00:11:15,376
six-sided dice with pips, and it


306
00:11:15,376 --> 00:11:18,056
has given them the right labels.


307
00:11:18,476 --> 00:11:20,966
It has ignored most of the other


308
00:11:20,966 --> 00:11:23,306
dice in the picture, except for


309
00:11:23,306 --> 00:11:24,246
a couple over here.


310
00:11:28,156 --> 00:11:29,596
It has given those the wrong


311
00:11:29,596 --> 00:11:30,206
numbers.


312
00:11:30,436 --> 00:11:31,986
So why is this?


313
00:11:32,336 --> 00:11:34,806
The problem here is a difference


314
00:11:34,806 --> 00:11:35,726
in expectation.


315
00:11:36,596 --> 00:11:37,896
Scott knows the dice that are


316
00:11:37,896 --> 00:11:39,726
going to be used are six-sided


317
00:11:39,806 --> 00:11:41,036
white dice with pips.


318
00:11:41,686 --> 00:11:43,226
My son's idea of dice is quite


319
00:11:43,226 --> 00:11:43,636
different.


320
00:11:44,006 --> 00:11:44,956
They're colored.


321
00:11:44,956 --> 00:11:46,406
They don't just have six sides.


322
00:11:47,266 --> 00:11:49,246
So how might we address this in


323
00:11:49,246 --> 00:11:50,006
our application?


324
00:11:51,006 --> 00:11:52,926
Well, either we can insist on


325
00:11:52,926 --> 00:11:54,206
using the dice that maybe are


326
00:11:54,206 --> 00:11:56,316
supplied with the game in the


327
00:11:56,316 --> 00:11:58,806
classroom, or we can train the


328
00:11:58,806 --> 00:12:00,536
model with these dice.


329
00:12:00,836 --> 00:12:02,016
There are two ways we can


330
00:12:02,016 --> 00:12:02,766
approach this.


331
00:12:03,366 --> 00:12:05,166
Either we can decide that only


332
00:12:05,166 --> 00:12:06,726
the six-sided dice with pips are


333
00:12:06,726 --> 00:12:08,556
valid, but we want to exclude


334
00:12:08,556 --> 00:12:11,026
the other dice, in which case,


335
00:12:11,276 --> 00:12:13,096
we just need to take photographs


336
00:12:13,096 --> 00:12:14,666
containing both kinds of dice,


337
00:12:15,326 --> 00:12:16,836
and just label the six-sided


338
00:12:16,836 --> 00:12:17,286
ones.


339
00:12:18,246 --> 00:12:20,466
Or if we were building a bear


340
00:12:20,776 --> 00:12:23,516
and bat game, we might like to


341
00:12:23,516 --> 00:12:25,096
add the other kinds of dice into


342
00:12:25,096 --> 00:12:26,546
our model, and label those too,


343
00:12:27,386 --> 00:12:28,916
either just using their numbers


344
00:12:29,236 --> 00:12:30,946
or adding extra labels to


345
00:12:30,946 --> 00:12:32,076
distinguish the colors.


346
00:12:32,806 --> 00:12:35,576
Red 6, black 4, etc.


347
00:12:38,466 --> 00:12:40,626
So let's send this model on to


348
00:12:40,626 --> 00:12:42,656
Scott, so he can build his demo.


349
00:12:43,266 --> 00:12:45,556
I can use the Share button to


350
00:12:45,556 --> 00:12:47,000
simply mail the model.


351
00:12:54,226 --> 00:12:55,176
And there we have it.


352
00:12:57,516 --> 00:13:01,500
[ Applause ]


353
00:13:07,256 --> 00:13:08,396
>> So, we've seen how you can


354
00:13:08,396 --> 00:13:10,696
use the Create ML application to


355
00:13:10,696 --> 00:13:12,726
train your object detector on


356
00:13:12,726 --> 00:13:13,776
training data that you've


357
00:13:13,776 --> 00:13:14,336
collected.


358
00:13:14,746 --> 00:13:16,526
There are some things I'd like


359
00:13:16,526 --> 00:13:17,896
you to consider when building


360
00:13:17,896 --> 00:13:18,726
that training data.


361
00:13:19,626 --> 00:13:21,496
Firstly, you should have a


362
00:13:21,496 --> 00:13:23,376
balanced number of images with


363
00:13:23,376 --> 00:13:25,116
annotations for each class.


364
00:13:26,416 --> 00:13:28,266
This tells the algorithm that


365
00:13:28,266 --> 00:13:29,646
you consider each of these to be


366
00:13:29,646 --> 00:13:31,276
equally important, and we can


367
00:13:31,276 --> 00:13:32,556
build a model which performs


368
00:13:32,556 --> 00:13:35,106
equally well on all of the


369
00:13:35,146 --> 00:13:35,746
classes.


370
00:13:37,456 --> 00:13:39,196
Secondly, you are going to need


371
00:13:39,196 --> 00:13:40,096
a bunch of images.


372
00:13:40,266 --> 00:13:42,036
I recommend you start with 30


373
00:13:42,036 --> 00:13:44,206
images with annotations for each


374
00:13:44,246 --> 00:13:45,346
class you want the model to


375
00:13:45,346 --> 00:13:47,546
recognize, and increase that


376
00:13:47,546 --> 00:13:49,256
number if you find performance


377
00:13:49,256 --> 00:13:51,086
isn't good enough, or if your


378
00:13:51,086 --> 00:13:52,236
subjects are particularly


379
00:13:52,236 --> 00:13:52,906
complicated.


380
00:13:53,186 --> 00:13:54,196
For instance, they look


381
00:13:54,196 --> 00:13:56,000
different on different sides.


382
00:13:59,376 --> 00:14:00,566
What about the issue we


383
00:14:00,566 --> 00:14:01,626
encountered with the different


384
00:14:01,626 --> 00:14:02,376
colored dice?


385
00:14:02,946 --> 00:14:04,716
Well, that's not the only way


386
00:14:04,716 --> 00:14:05,626
pictures might differ.


387
00:14:06,696 --> 00:14:09,036
We recommend you consider how


388
00:14:09,036 --> 00:14:10,406
the application will be used in


389
00:14:10,406 --> 00:14:11,086
the real world.


390
00:14:11,776 --> 00:14:13,696
Your users may not have studio


391
00:14:13,696 --> 00:14:15,656
lighting, standard dice, and a


392
00:14:15,656 --> 00:14:16,956
beautiful wooden desk to work


393
00:14:16,956 --> 00:14:17,126
with.


394
00:14:18,176 --> 00:14:20,486
Perhaps ask your friends to


395
00:14:20,486 --> 00:14:21,956
collect additional data in


396
00:14:21,956 --> 00:14:23,896
different scenarios, such as


397
00:14:24,226 --> 00:14:26,296
indoor lighting, outdoors in the


398
00:14:26,296 --> 00:14:28,826
sun, different backgrounds, and


399
00:14:28,906 --> 00:14:30,406
add in different objects that


400
00:14:30,406 --> 00:14:31,956
you aren't using for your model.


401
00:14:32,796 --> 00:14:34,336
This helps the model generalize


402
00:14:34,336 --> 00:14:34,856
really well.


403
00:14:39,046 --> 00:14:40,146
Something that may be surprising


404
00:14:40,146 --> 00:14:42,326
to you, if you've used an image


405
00:14:42,326 --> 00:14:44,376
classifier before, is that one


406
00:14:44,376 --> 00:14:45,156
label is enough.


407
00:14:46,316 --> 00:14:48,186
This is because by explaining a


408
00:14:48,186 --> 00:14:49,686
part of your image that is a


409
00:14:49,686 --> 00:14:51,676
dog, you're also saying that the


410
00:14:51,676 --> 00:14:53,516
rest of it isn't, and the model


411
00:14:53,516 --> 00:14:54,416
trains accordingly.


412
00:14:55,506 --> 00:14:57,506
So, for example, if you were


413
00:14:57,506 --> 00:14:59,156
building an application to count


414
00:14:59,156 --> 00:15:00,576
the number of pickle jars in


415
00:15:00,576 --> 00:15:02,366
your fridge, you don't need to


416
00:15:02,366 --> 00:15:03,166
label all of the other


417
00:15:03,166 --> 00:15:03,816
condiments.


418
00:15:03,986 --> 00:15:05,476
It automatically infers that


419
00:15:05,476 --> 00:15:06,616
they're not pickle jars.


420
00:15:08,656 --> 00:15:12,646
Once you've built your model,


421
00:15:12,646 --> 00:15:14,616
and you want to add the


422
00:15:14,616 --> 00:15:15,716
functionality into your


423
00:15:15,716 --> 00:15:18,326
application, we recommend you


424
00:15:18,326 --> 00:15:19,416
use the vision framework.


425
00:15:20,216 --> 00:15:21,926
The vision framework can


426
00:15:21,926 --> 00:15:24,016
seamlessly integrate live camera


427
00:15:24,396 --> 00:15:26,566
as well as video into your model


428
00:15:26,566 --> 00:15:27,000
flow.


429
00:15:29,346 --> 00:15:30,996
And that's all there is to


430
00:15:30,996 --> 00:15:32,446
training object detectors.


431
00:15:33,516 --> 00:15:39,960
[ Applause ]

