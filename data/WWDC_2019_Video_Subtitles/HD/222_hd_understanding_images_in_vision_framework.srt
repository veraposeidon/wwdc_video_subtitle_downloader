1
00:00:00,506 --> 00:00:04,500
[ Music ]


2
00:00:07,516 --> 00:00:14,196
[ Applause ]


3
00:00:14,696 --> 00:00:15,336
>> Good morning.


4
00:00:15,676 --> 00:00:16,976
My name is Brittany Weinert, and


5
00:00:16,976 --> 00:00:17,946
I'm a software engineer on the


6
00:00:17,946 --> 00:00:18,866
Vision Framework Team.


7
00:00:19,566 --> 00:00:20,596
This year the Vision Team has a


8
00:00:20,596 --> 00:00:22,086
lot of exciting new updates that


9
00:00:22,086 --> 00:00:23,096
we think you're all going to


10
00:00:23,096 --> 00:00:23,316
love.


11
00:00:23,916 --> 00:00:24,846
Because we have so much new


12
00:00:24,846 --> 00:00:26,076
stuff to cover, we're going to


13
00:00:26,076 --> 00:00:27,106
dive right into the new


14
00:00:27,106 --> 00:00:27,516
features.


15
00:00:27,876 --> 00:00:29,256
If you're completely new to


16
00:00:29,256 --> 00:00:30,706
Vision, don't worry.


17
00:00:30,706 --> 00:00:31,466
You should still be able to


18
00:00:31,466 --> 00:00:33,096
follow along, and our hope is


19
00:00:33,096 --> 00:00:34,216
that the new capabilities that


20
00:00:34,216 --> 00:00:35,956
we introduce today will motivate


21
00:00:35,956 --> 00:00:37,366
you to learn about Vision and to


22
00:00:37,366 --> 00:00:39,606
use it in your apps.


23
00:00:39,836 --> 00:00:40,906
Today well be covering four


24
00:00:40,906 --> 00:00:44,206
completely new topics, saliency,


25
00:00:44,416 --> 00:00:46,066
image classification, Image


26
00:00:46,066 --> 00:00:47,556
Similarity, and face quality.


27
00:00:47,556 --> 00:00:49,456
We also have some technology


28
00:00:49,456 --> 00:00:50,796
upgrades for the Object Tracker


29
00:00:50,796 --> 00:00:52,826
and Face Landmarks as well as


30
00:00:52,826 --> 00:00:54,666
new detectors and improved Core


31
00:00:54,666 --> 00:00:55,196
ML support.


32
00:00:55,196 --> 00:00:58,486
Today, I'm going to be talking


33
00:00:58,486 --> 00:00:59,276
about saliency.


34
00:00:59,736 --> 00:01:00,836
Let's start with a definition.


35
00:01:01,386 --> 00:01:02,806
I'm about to show you a photo,


36
00:01:02,806 --> 00:01:06,426
and I want you to pay attention


37
00:01:06,426 --> 00:01:07,586
to where your eyes are first


38
00:01:07,586 --> 00:01:08,036
drawn.


39
00:01:08,526 --> 00:01:13,046
When you first saw this photo of


40
00:01:13,046 --> 00:01:14,126
the three puffins sitting on a


41
00:01:14,126 --> 00:01:15,696
cliff, did you notice what stood


42
00:01:15,696 --> 00:01:16,366
out to you first?


43
00:01:17,326 --> 00:01:19,956
According to our models, most of


44
00:01:19,956 --> 00:01:21,226
you looked at the puffins faces


45
00:01:21,226 --> 00:01:21,476
first.


46
00:01:22,436 --> 00:01:23,556
This is saliency.


47
00:01:24,006 --> 00:01:26,366
There are two types of saliency,


48
00:01:26,766 --> 00:01:28,156
attention based and objectness


49
00:01:28,216 --> 00:01:28,566
based.


50
00:01:29,086 --> 00:01:30,976
The overlay that you saw on the


51
00:01:30,976 --> 00:01:32,566
puffin image just now called the


52
00:01:32,566 --> 00:01:34,226
heatmap was generated by


53
00:01:34,226 --> 00:01:35,686
attention based saliency.


54
00:01:36,146 --> 00:01:37,216
But before we get into more


55
00:01:37,216 --> 00:01:38,556
visual examples, I want to go


56
00:01:38,556 --> 00:01:39,696
over the basics of each


57
00:01:39,696 --> 00:01:40,246
algorithm.


58
00:01:41,776 --> 00:01:45,186
Attention based saliency is a


59
00:01:45,186 --> 00:01:47,786
human aspected saliency, and by


60
00:01:47,786 --> 00:01:49,436
this, I mean that the attention


61
00:01:49,436 --> 00:01:51,006
based saliency models were


62
00:01:51,006 --> 00:01:53,566
generated by where people looked


63
00:01:53,906 --> 00:01:55,006
when they were shown a series of


64
00:01:55,006 --> 00:01:55,446
images.


65
00:01:56,326 --> 00:01:57,646
This means that the heatmap


66
00:01:57,646 --> 00:02:00,026
reflects and highlights where


67
00:02:00,026 --> 00:02:00,966
people first look when they're


68
00:02:00,966 --> 00:02:01,646
shown an image.


69
00:02:02,676 --> 00:02:04,556
Objectness based saliency on the


70
00:02:04,556 --> 00:02:06,006
other hand was trained on


71
00:02:06,056 --> 00:02:07,976
subject segmentation in an image


72
00:02:08,515 --> 00:02:10,286
with the goal to highlight the


73
00:02:10,286 --> 00:02:12,086
foreground objects or the


74
00:02:12,086 --> 00:02:13,176
subjects of an image.


75
00:02:13,766 --> 00:02:15,996
So, in the heatmap, the subjects


76
00:02:15,996 --> 00:02:17,196
or foreground objects should be


77
00:02:17,196 --> 00:02:17,656
highlighted.


78
00:02:18,226 --> 00:02:19,916
Let's look at some examples now.


79
00:02:20,496 --> 00:02:23,566
So, here are the puffins from


80
00:02:23,566 --> 00:02:23,946
earlier.


81
00:02:24,636 --> 00:02:26,956
Here's the attention based


82
00:02:26,956 --> 00:02:28,436
heatmap overlaid on the image,


83
00:02:29,446 --> 00:02:30,916
and here's the objectness based


84
00:02:32,316 --> 00:02:33,046
heatmap.


85
00:02:33,046 --> 00:02:34,806
As I said, people tend to look


86
00:02:34,806 --> 00:02:36,056
at the puffins' faces first, so


87
00:02:36,346 --> 00:02:37,686
the area around the puffins'


88
00:02:37,686 --> 00:02:38,996
heads is very salient for the


89
00:02:38,996 --> 00:02:39,956
attention based heatmap.


90
00:02:40,896 --> 00:02:42,286
For objectness, we're just


91
00:02:42,286 --> 00:02:43,676
trying to pick up the subjects,


92
00:02:43,676 --> 00:02:45,246
and in this case, it's the three


93
00:02:45,246 --> 00:02:45,636
puffins.


94
00:02:45,786 --> 00:02:46,846
So, all the puffins are


95
00:02:46,846 --> 00:02:47,266
highlighted.


96
00:02:48,486 --> 00:02:50,206
Let's look at how saliency works


97
00:02:50,206 --> 00:02:51,206
with images of people.


98
00:02:51,746 --> 00:02:56,556
For attention based saliency,


99
00:02:57,046 --> 00:02:58,656
the areas around peoples' faces


100
00:02:58,656 --> 00:02:59,926
tend to be the most salient,


101
00:03:00,536 --> 00:03:02,146
unsurprisingly because we tend


102
00:03:02,146 --> 00:03:04,146
to look at people's faces first.


103
00:03:04,846 --> 00:03:06,616
For objectness based saliency,


104
00:03:06,616 --> 00:03:08,196
if the person is the subject of


105
00:03:08,196 --> 00:03:09,646
the image, the entire person


106
00:03:09,646 --> 00:03:10,386
should be highlighted.


107
00:03:12,596 --> 00:03:14,896
So, attention based saliency


108
00:03:14,896 --> 00:03:16,266
though is the more complicated


109
00:03:16,266 --> 00:03:17,846
of the two saliencies, I'd say,


110
00:03:18,436 --> 00:03:19,926
because it is determined by a


111
00:03:19,926 --> 00:03:21,386
number of very human factors.


112
00:03:22,226 --> 00:03:23,846
And the number, the main factors


113
00:03:23,846 --> 00:03:25,126
that determine attention based


114
00:03:25,126 --> 00:03:26,236
saliency and what's salient or


115
00:03:26,236 --> 00:03:28,426
not, is contrast, faces,


116
00:03:28,916 --> 00:03:31,046
subjects, horizons, and light.


117
00:03:32,416 --> 00:03:33,666
But interestingly enough, it can


118
00:03:33,666 --> 00:03:35,516
also be affected by perceived


119
00:03:35,516 --> 00:03:36,026
motion.


120
00:03:36,556 --> 00:03:39,816
In this example, the umbrella


121
00:03:39,816 --> 00:03:42,436
colors really pop, so the area


122
00:03:42,436 --> 00:03:43,716
around the umbrella is salient,


123
00:03:44,026 --> 00:03:45,636
but the road is also salient


124
00:03:46,006 --> 00:03:47,666
because our eyes try to track


125
00:03:47,666 --> 00:03:48,796
where the umbrella is headed.


126
00:03:50,706 --> 00:03:52,216
For objectness based saliency,


127
00:03:52,216 --> 00:03:53,406
we just pick up on the umbrella


128
00:03:55,016 --> 00:03:55,096
guy.


129
00:03:55,316 --> 00:03:56,876
So, I could do this all day and


130
00:03:56,876 --> 00:03:58,456
show you more examples, but


131
00:03:58,456 --> 00:03:59,456
honestly, the best way to


132
00:03:59,456 --> 00:04:00,966
understand saliency is to try it


133
00:04:00,966 --> 00:04:01,766
out for yourself.


134
00:04:02,476 --> 00:04:03,776
I encourage everybody to


135
00:04:03,776 --> 00:04:05,726
download the Saliency app and


136
00:04:05,726 --> 00:04:06,656
try it on their own photo


137
00:04:06,656 --> 00:04:07,136
libraries.


138
00:04:07,796 --> 00:04:10,536
So, let's get into what's


139
00:04:10,536 --> 00:04:12,236
returned from the saliency


140
00:04:12,236 --> 00:04:15,726
request, mainly the heatmap.


141
00:04:16,055 --> 00:04:17,375
So, the images that I've been


142
00:04:17,375 --> 00:04:19,596
showing to you up until now, the


143
00:04:19,596 --> 00:04:22,356
heatmap has been scaled,


144
00:04:22,356 --> 00:04:25,996
overlaid, and colorized and put


145
00:04:25,996 --> 00:04:27,536
onto the image, but in


146
00:04:27,536 --> 00:04:29,656
actuality, the heatmap is a very


147
00:04:29,656 --> 00:04:32,206
small CV pixel buffer that's


148
00:04:32,206 --> 00:04:34,186
made up of Floats in the range


149
00:04:34,186 --> 00:04:37,246
of 0 to 1, 0 designating


150
00:04:37,526 --> 00:04:39,356
nonsalient and 1 being most


151
00:04:39,356 --> 00:04:39,746
salient.


152
00:04:40,256 --> 00:04:44,066
And there's extra code that


153
00:04:44,066 --> 00:04:45,206
you'd have to do to get the


154
00:04:45,206 --> 00:04:46,526
exact same effect like you see


155
00:04:46,526 --> 00:04:46,746
here.


156
00:04:47,526 --> 00:04:48,896
But let's go into how to


157
00:04:48,946 --> 00:04:50,926
formulate a request at the very


158
00:04:50,926 --> 00:04:51,716
basic level.


159
00:04:53,256 --> 00:04:56,686
Okay. So, first we start out


160
00:04:56,686 --> 00:04:58,776
with a VNImageRequestHandler to


161
00:04:58,776 --> 00:05:00,206
handle a single image.


162
00:05:01,266 --> 00:05:03,126
Next, you choose the algorithm


163
00:05:03,126 --> 00:05:04,346
that you want to run, in this


164
00:05:04,346 --> 00:05:06,516
case, AttentionBasedSaliency,


165
00:05:06,566 --> 00:05:09,256
and set the revision if you


166
00:05:09,256 --> 00:05:10,586
always want to be using the same


167
00:05:10,586 --> 00:05:10,976
algorithm.


168
00:05:12,976 --> 00:05:14,896
Next, you call perform request,


169
00:05:15,196 --> 00:05:17,466
like you usually would, and if


170
00:05:17,466 --> 00:05:19,476
it's successful, the results


171
00:05:19,476 --> 00:05:20,996
property on the request should


172
00:05:20,996 --> 00:05:22,456
be populated with a


173
00:05:22,456 --> 00:05:24,266
VNSaliencyImageObservation.


174
00:05:25,326 --> 00:05:28,396
To access the heatmap, you call


175
00:05:28,396 --> 00:05:30,086
the pixelBuffer property on the


176
00:05:30,086 --> 00:05:32,906
VNSaliencyImageObservation like


177
00:05:35,256 --> 00:05:35,356
so.


178
00:05:35,596 --> 00:05:37,516
If you wanted to do objectness


179
00:05:37,516 --> 00:05:39,316
based saliency, all you would


180
00:05:39,316 --> 00:05:41,096
have to do is change the request


181
00:05:41,246 --> 00:05:43,786
name and the revision to be


182
00:05:43,786 --> 00:05:44,246
objectness.


183
00:05:45,426 --> 00:05:46,676
So, for attention, it's


184
00:05:46,736 --> 00:05:48,206
VNGenerateAttentionBased


185
00:05:48,206 --> 00:05:50,106
SaliencyImageRequest and for


186
00:05:50,106 --> 00:05:50,836
objectness, it's


187
00:05:50,836 --> 00:05:52,386
VNGenerateObjectnessBased


188
00:05:52,386 --> 00:05:53,076
SaliencyRequest.


189
00:05:53,796 --> 00:05:56,856
So, let's get into another tool


190
00:05:56,856 --> 00:05:58,226
other than at heatmap, the


191
00:05:58,226 --> 00:05:58,856
bounding box.


192
00:05:59,476 --> 00:06:03,196
The bounding boxes encapsulate


193
00:06:03,196 --> 00:06:04,536
all the salient regions in an


194
00:06:04,536 --> 00:06:04,796
image.


195
00:06:05,156 --> 00:06:06,726
For attention based saliency,


196
00:06:06,726 --> 00:06:08,006
you should always have one


197
00:06:08,006 --> 00:06:09,866
bounding box, and for objectness


198
00:06:09,866 --> 00:06:11,116
based saliency, you can have up


199
00:06:11,116 --> 00:06:12,616
to three bounding boxes.


200
00:06:13,726 --> 00:06:15,826
The bounding boxes are in


201
00:06:15,826 --> 00:06:17,336
normalized coordinate space with


202
00:06:17,336 --> 00:06:18,546
respect to the image, the


203
00:06:18,546 --> 00:06:21,726
original image, and the lower


204
00:06:21,726 --> 00:06:23,316
left-hand corner is the origin


205
00:06:23,316 --> 00:06:25,066
point, much like bounding boxes


206
00:06:25,066 --> 00:06:26,826
returned by other algorithms in


207
00:06:26,826 --> 00:06:27,186
Vision.


208
00:06:27,956 --> 00:06:30,716
So, I wrote up a small method to


209
00:06:30,716 --> 00:06:32,266
show how to access the bounding


210
00:06:32,266 --> 00:06:33,146
boxes and use them.


211
00:06:33,916 --> 00:06:35,346
Here we have a


212
00:06:35,346 --> 00:06:37,386
VNSaliencyImageObservation, and


213
00:06:37,826 --> 00:06:40,156
all you have to do is access the


214
00:06:40,156 --> 00:06:41,706
salientObjects property on that


215
00:06:41,706 --> 00:06:43,876
observation, and you should get


216
00:06:44,036 --> 00:06:46,456
a list of bounding boxes, and


217
00:06:46,456 --> 00:06:48,296
you can access them like so.


218
00:06:48,296 --> 00:06:50,566
Okay. So, now that you know how


219
00:06:50,566 --> 00:06:53,136
to formulate a request and now


220
00:06:53,136 --> 00:06:54,906
that you know what saliency is,


221
00:06:55,686 --> 00:06:57,306
let's get into some of the use


222
00:06:57,306 --> 00:06:57,736
cases.


223
00:06:58,346 --> 00:07:02,606
First, for a bit of fun, you can


224
00:07:02,816 --> 00:07:05,816
use saliency as a graphical mask


225
00:07:06,076 --> 00:07:07,056
to edit your photos with.


226
00:07:07,056 --> 00:07:09,496
So, here you have the heatmaps.


227
00:07:10,216 --> 00:07:14,306
On the left-hand side, I've


228
00:07:14,306 --> 00:07:15,886
desaturated all the nonsalient


229
00:07:15,886 --> 00:07:17,716
regions, and on the right-hand


230
00:07:17,716 --> 00:07:19,416
side, I've added a Gaussian blur


231
00:07:19,416 --> 00:07:20,636
to all the nonsalient regions.


232
00:07:21,006 --> 00:07:22,336
It really makes the subjects


233
00:07:22,336 --> 00:07:22,576
pop.


234
00:07:25,536 --> 00:07:27,246
Another use case of saliency is


235
00:07:27,246 --> 00:07:28,396
you can enhance your photo


236
00:07:28,396 --> 00:07:29,156
viewing experience.


237
00:07:30,106 --> 00:07:31,666
So, let's say that you're at


238
00:07:31,666 --> 00:07:32,036
home.


239
00:07:32,036 --> 00:07:33,846
You're sitting on the couch, and


240
00:07:33,946 --> 00:07:35,236
either your TV or your computer


241
00:07:35,236 --> 00:07:38,216
has gone into standby mode, and


242
00:07:38,216 --> 00:07:39,066
it's going through your photo


243
00:07:39,066 --> 00:07:39,906
library.


244
00:07:40,336 --> 00:07:41,706
A lot of times, these


245
00:07:41,706 --> 00:07:44,446
photo-showing algorithms can be


246
00:07:44,446 --> 00:07:45,306
a little bit awkward.


247
00:07:45,306 --> 00:07:47,006
They zoom into seemingly random


248
00:07:47,006 --> 00:07:50,506
parts of the image, and it's not


249
00:07:50,506 --> 00:07:51,346
always what you expect.


250
00:07:52,086 --> 00:07:53,546
But with saliency, you always


251
00:07:53,546 --> 00:07:56,026
know where the subjects are, so


252
00:07:56,026 --> 00:07:57,036
you can get a more


253
00:07:57,136 --> 00:07:59,366
documentary-like effect like


254
00:08:02,476 --> 00:08:02,576
this.


255
00:08:02,766 --> 00:08:04,616
Finally, saliency works really


256
00:08:04,616 --> 00:08:05,656
great with other vision


257
00:08:05,656 --> 00:08:06,206
algorithms.


258
00:08:07,486 --> 00:08:09,246
Let's say we have an image, and


259
00:08:09,246 --> 00:08:11,236
we want to classify the objects


260
00:08:11,236 --> 00:08:11,806
in the image.


261
00:08:12,966 --> 00:08:14,426
We can run objectness based


262
00:08:14,426 --> 00:08:16,226
saliency to pick up on the


263
00:08:16,226 --> 00:08:19,196
objects in the image, crop the


264
00:08:19,196 --> 00:08:21,266
image to the bounding boxes


265
00:08:21,266 --> 00:08:22,456
returned by objectness based


266
00:08:22,456 --> 00:08:25,006
saliency, and run these crops


267
00:08:25,366 --> 00:08:26,816
through the algorithm through a


268
00:08:26,886 --> 00:08:28,736
image classification algorithm


269
00:08:29,106 --> 00:08:31,286
to find out what the objects


270
00:08:31,286 --> 00:08:31,536
are.


271
00:08:32,316 --> 00:08:33,996
So, not only do you know where


272
00:08:34,285 --> 00:08:35,576
they are in the image because of


273
00:08:35,576 --> 00:08:36,885
the bounding boxes, but it


274
00:08:36,885 --> 00:08:39,905
allows you the hone in on what


275
00:08:39,905 --> 00:08:42,035
the objects are by just picking


276
00:08:42,035 --> 00:08:43,366
out the crops that have those


277
00:08:43,366 --> 00:08:44,976
objects in it.


278
00:08:45,286 --> 00:08:46,756
Now, you can already classify


279
00:08:46,756 --> 00:08:48,996
things with Core ML, but this


280
00:08:48,996 --> 00:08:50,606
year, Vision has new image


281
00:08:50,606 --> 00:08:52,296
classification technique that


282
00:08:52,296 --> 00:08:54,126
Rohan will now present to you.


283
00:08:55,516 --> 00:09:02,736
[ Applause ]


284
00:09:03,236 --> 00:09:04,696
>> Good morning.


285
00:09:05,136 --> 00:09:06,806
My name is Rohan Chandra, and


286
00:09:06,806 --> 00:09:08,176
I'm a researcher on the Vision


287
00:09:08,176 --> 00:09:08,476
Team.


288
00:09:09,266 --> 00:09:10,846
Today, I'm going to be talking


289
00:09:10,846 --> 00:09:12,106
about some of the new image


290
00:09:12,106 --> 00:09:13,476
classification requests we're


291
00:09:13,476 --> 00:09:14,926
introducing to the Vision API


292
00:09:15,126 --> 00:09:15,606
this year.


293
00:09:16,806 --> 00:09:18,856
Now, image classification as a


294
00:09:18,856 --> 00:09:20,626
task is fundamentally meant to


295
00:09:20,626 --> 00:09:22,096
answer the question, what are


296
00:09:22,096 --> 00:09:23,406
the objects that appear in my


297
00:09:23,406 --> 00:09:23,916
image.


298
00:09:25,066 --> 00:09:26,546
Many of you will already be


299
00:09:26,546 --> 00:09:27,386
familiar with image


300
00:09:27,386 --> 00:09:28,206
classification.


301
00:09:28,626 --> 00:09:30,146
You may have used Create ML or


302
00:09:30,146 --> 00:09:31,776
Core ML to train your own


303
00:09:31,776 --> 00:09:33,306
classification networks on your


304
00:09:33,356 --> 00:09:35,366
own data as we showed in the


305
00:09:35,366 --> 00:09:36,846
Vision with Core ML talk last


306
00:09:36,846 --> 00:09:37,046
year.


307
00:09:38,156 --> 00:09:39,306
Others of you may have been


308
00:09:39,356 --> 00:09:40,456
interested in image


309
00:09:40,456 --> 00:09:41,636
classification but felt you


310
00:09:41,636 --> 00:09:43,246
lacked the resources or the


311
00:09:43,246 --> 00:09:44,696
expertise to develop your own


312
00:09:44,696 --> 00:09:45,116
networks.


313
00:09:45,896 --> 00:09:48,716
In practice, developing a


314
00:09:48,716 --> 00:09:50,026
large-scale classification


315
00:09:50,026 --> 00:09:51,576
network from scratch can take


316
00:09:51,676 --> 00:09:53,076
millions of images to annotate,


317
00:09:53,596 --> 00:09:55,246
thousands of hours to train, and


318
00:09:55,246 --> 00:09:56,406
very specialized domain


319
00:09:56,406 --> 00:09:57,566
expertise to develop.


320
00:09:58,736 --> 00:10:00,606
We here at Apple have already


321
00:10:00,606 --> 00:10:02,296
gone through this process, and


322
00:10:02,336 --> 00:10:03,646
so we wanted to share our


323
00:10:03,646 --> 00:10:05,206
large-scale, on-device


324
00:10:05,256 --> 00:10:06,706
classification network with you


325
00:10:07,176 --> 00:10:08,206
so that you can leverage this


326
00:10:08,206 --> 00:10:09,936
technology without needing to


327
00:10:09,936 --> 00:10:11,396
invest a huge amount of time or


328
00:10:11,396 --> 00:10:12,816
resources into developing it


329
00:10:12,816 --> 00:10:13,306
yourself.


330
00:10:14,296 --> 00:10:16,116
We've also strived to put tools


331
00:10:16,116 --> 00:10:17,346
in the API to help you


332
00:10:17,346 --> 00:10:19,216
contextualize and understand the


333
00:10:19,216 --> 00:10:20,646
results in a way that makes


334
00:10:20,646 --> 00:10:21,806
sense for your application.


335
00:10:22,986 --> 00:10:24,116
Now, the network we're talking


336
00:10:24,116 --> 00:10:25,796
about exposing here is in fact


337
00:10:25,846 --> 00:10:27,326
the same network we ourselves


338
00:10:27,326 --> 00:10:28,686
use to power the photo search


339
00:10:28,686 --> 00:10:29,306
experience.


340
00:10:30,096 --> 00:10:31,136
This is a network we've


341
00:10:31,136 --> 00:10:32,646
developed specifically to run


342
00:10:32,646 --> 00:10:34,256
efficiently on device without


343
00:10:34,256 --> 00:10:35,516
requiring any service side


344
00:10:35,576 --> 00:10:36,236
processing.


345
00:10:36,956 --> 00:10:38,446
We've also developed it to


346
00:10:38,446 --> 00:10:39,746
identify over a thousand


347
00:10:39,746 --> 00:10:41,136
different categories of objects.


348
00:10:42,516 --> 00:10:44,396
Now, it's also important to note


349
00:10:44,516 --> 00:10:45,776
that this is a multi-label


350
00:10:45,776 --> 00:10:47,876
network capable of identifying


351
00:10:48,236 --> 00:10:49,936
multiple objects in a single


352
00:10:49,936 --> 00:10:51,986
image, in contrast to more


353
00:10:51,986 --> 00:10:53,976
typical mono-label networks that


354
00:10:53,976 --> 00:10:55,496
try to focus on identifying a


355
00:10:55,496 --> 00:10:57,666
single large central object in


356
00:10:57,666 --> 00:10:58,226
an image.


357
00:10:59,586 --> 00:11:01,076
Now, as I talk about this new


358
00:11:01,076 --> 00:11:03,226
classification API, I think one


359
00:11:03,226 --> 00:11:04,186
of the first questions that


360
00:11:04,186 --> 00:11:05,786
comes to mind is what are the


361
00:11:05,786 --> 00:11:06,856
objects it can actually


362
00:11:06,856 --> 00:11:07,426
identify?


363
00:11:08,336 --> 00:11:09,916
Well, the set of objects that a


364
00:11:09,916 --> 00:11:11,536
classifier can predict is known


365
00:11:11,536 --> 00:11:12,426
as the taxonomy.


366
00:11:13,436 --> 00:11:15,106
The taxonomy has a hierarchical


367
00:11:15,106 --> 00:11:16,456
structure with directional


368
00:11:16,456 --> 00:11:17,936
relationships between classes.


369
00:11:19,006 --> 00:11:20,606
These relationships are based


370
00:11:20,606 --> 00:11:22,226
upon shared semantic meaning.


371
00:11:22,916 --> 00:11:24,866
For instance, a class like dog


372
00:11:24,966 --> 00:11:26,436
might have children like Beagle,


373
00:11:26,616 --> 00:11:28,176
Poodle, Husky, and other


374
00:11:28,176 --> 00:11:29,156
sub-breeds of dogs.


375
00:11:30,256 --> 00:11:31,866
In this sense, a parent class


376
00:11:31,896 --> 00:11:33,226
tends to be more general while


377
00:11:33,226 --> 00:11:34,866
child classes are more specific


378
00:11:34,866 --> 00:11:36,106
instances of their parent.


379
00:11:37,046 --> 00:11:38,466
You can of course see the entire


380
00:11:38,466 --> 00:11:39,816
taxonomy using


381
00:11:40,006 --> 00:11:40,926
ImageRequest.known


382
00:11:40,926 --> 00:11:41,756
Classifications.


383
00:11:43,136 --> 00:11:44,416
Now, when we constructed the


384
00:11:44,416 --> 00:11:46,276
taxonomy, we had a few specific


385
00:11:46,276 --> 00:11:47,226
rules that we applied.


386
00:11:48,656 --> 00:11:49,816
The first is that the classes


387
00:11:49,856 --> 00:11:51,516
must be visually identifiable.


388
00:11:52,836 --> 00:11:54,456
That is, we avoid more abstract


389
00:11:54,456 --> 00:11:55,756
concepts like holiday or


390
00:11:55,756 --> 00:11:56,306
festival.


391
00:11:57,426 --> 00:11:59,196
We also avoid any classes that


392
00:11:59,196 --> 00:11:59,876
might be considered


393
00:11:59,876 --> 00:12:01,746
controversial or offensive as


394
00:12:01,746 --> 00:12:03,066
well as those to do with proper


395
00:12:03,066 --> 00:12:04,866
names, nouns, excuse me,


396
00:12:04,866 --> 00:12:06,256
adjectives, or basic shapes.


397
00:12:07,346 --> 00:12:09,266
Finally, we omit occupations,


398
00:12:09,526 --> 00:12:10,686
and this might seem odd at


399
00:12:10,686 --> 00:12:11,076
first.


400
00:12:11,716 --> 00:12:12,856
But consider the range of


401
00:12:12,856 --> 00:12:14,266
answers you'd get if we asked


402
00:12:14,266 --> 00:12:15,226
something like what does an


403
00:12:15,226 --> 00:12:16,216
engineer look like.


404
00:12:16,556 --> 00:12:18,496
There probably isn't a single


405
00:12:18,496 --> 00:12:19,546
concise description you could


406
00:12:19,546 --> 00:12:20,856
give that would apply to every


407
00:12:20,856 --> 00:12:22,416
engineer aside from sleep


408
00:12:22,416 --> 00:12:23,716
deprived and usually glued to a


409
00:12:23,716 --> 00:12:24,476
computer screen.


410
00:12:25,556 --> 00:12:26,646
Let's take a look at the code


411
00:12:26,646 --> 00:12:27,816
you need to use in order to


412
00:12:27,816 --> 00:12:28,706
classify an image.


413
00:12:28,706 --> 00:12:31,636
So, as usual, you form an


414
00:12:31,636 --> 00:12:32,896
ImageRequestHandler to your


415
00:12:32,896 --> 00:12:33,526
source image.


416
00:12:34,196 --> 00:12:35,026
You then perform the


417
00:12:35,026 --> 00:12:36,836
VNClassifyImageRequest and


418
00:12:36,836 --> 00:12:38,066
retrieve your observations.


419
00:12:38,746 --> 00:12:40,036
Now, in this case, you actually


420
00:12:40,036 --> 00:12:41,406
get an array of observations,


421
00:12:41,696 --> 00:12:42,976
one for every class in the


422
00:12:42,976 --> 00:12:44,976
taxonomy and its associated


423
00:12:44,976 --> 00:12:45,456
confidence.


424
00:12:46,366 --> 00:12:47,876
In a mono-label problem, you'd


425
00:12:47,876 --> 00:12:48,946
probably expect that these


426
00:12:48,946 --> 00:12:50,906
probabilities sum up to 1, but


427
00:12:50,906 --> 00:12:51,896
this is a multi-label


428
00:12:51,936 --> 00:12:53,876
classification network, and each


429
00:12:53,876 --> 00:12:55,376
prediction is an independent


430
00:12:55,376 --> 00:12:56,756
confidence associated with a


431
00:12:56,756 --> 00:12:57,416
particular class.


432
00:12:58,416 --> 00:13:00,096
As such, they won't sum to 1,


433
00:13:00,406 --> 00:13:01,466
and they're meant to be compared


434
00:13:01,466 --> 00:13:02,956
within the same class, not


435
00:13:02,956 --> 00:13:04,256
across different classes.


436
00:13:04,496 --> 00:13:06,196
So we can't simply take the max


437
00:13:06,196 --> 00:13:07,486
amongst them in order to


438
00:13:07,486 --> 00:13:08,816
determine our final prediction.


439
00:13:09,696 --> 00:13:11,166
You might be wondering then, how


440
00:13:11,166 --> 00:13:12,806
do I deal with so many classes


441
00:13:12,856 --> 00:13:13,756
and so many numbers.


442
00:13:14,516 --> 00:13:15,836
Well, there are a few key tools


443
00:13:15,836 --> 00:13:17,066
in the API that we've


444
00:13:17,066 --> 00:13:18,186
implemented to help you make


445
00:13:18,256 --> 00:13:19,086
sense of the result.


446
00:13:20,376 --> 00:13:22,026
Now, in order to talk about


447
00:13:22,086 --> 00:13:23,916
these tools in the API, we first


448
00:13:23,916 --> 00:13:25,586
need to define some basic terms.


449
00:13:26,266 --> 00:13:28,716
The first is when you get a


450
00:13:28,716 --> 00:13:30,576
confidence for a class, we


451
00:13:30,576 --> 00:13:31,936
typically compare that to a


452
00:13:31,936 --> 00:13:33,606
class-specific threshold, which


453
00:13:33,606 --> 00:13:34,866
we refer to as an operating


454
00:13:34,866 --> 00:13:35,186
point.


455
00:13:35,976 --> 00:13:37,976
If the class confidence is above


456
00:13:37,976 --> 00:13:39,466
the threshold, then we say that


457
00:13:39,466 --> 00:13:40,796
class is present in the image.


458
00:13:41,266 --> 00:13:42,996
If the class confidence is below


459
00:13:42,996 --> 00:13:44,516
the class threshold, then we say


460
00:13:44,516 --> 00:13:46,316
that object is not present in


461
00:13:46,316 --> 00:13:46,756
the image.


462
00:13:47,656 --> 00:13:49,316
In this sense, we want to pick


463
00:13:49,316 --> 00:13:50,866
thresholds such that objects


464
00:13:50,866 --> 00:13:52,346
with the target class typically


465
00:13:52,346 --> 00:13:53,456
have a confidence higher than


466
00:13:53,456 --> 00:13:55,646
the threshold, and images


467
00:13:55,736 --> 00:13:56,886
without the target class


468
00:13:57,026 --> 00:13:58,556
typically have a score lower


469
00:13:58,556 --> 00:13:59,406
than the threshold.


470
00:14:00,376 --> 00:14:02,216
However, machine learning is not


471
00:14:02,216 --> 00:14:03,866
infallible, and there will be


472
00:14:03,866 --> 00:14:05,636
instances where the network is


473
00:14:05,636 --> 00:14:07,136
unsure and the confidence is


474
00:14:07,136 --> 00:14:08,276
proportionally lower.


475
00:14:09,056 --> 00:14:10,496
This can happen when objects are


476
00:14:10,536 --> 00:14:12,156
office gated, appear in odd


477
00:14:12,156 --> 00:14:14,006
lighting or at odd angles, for


478
00:14:14,006 --> 00:14:14,506
instance.


479
00:14:15,176 --> 00:14:15,866
So how do we pick our


480
00:14:15,866 --> 00:14:16,426
thresholds?


481
00:14:17,596 --> 00:14:18,306
Well, there are essentially


482
00:14:18,436 --> 00:14:19,756
three different regimes we can


483
00:14:19,756 --> 00:14:20,926
be in depending on our choice of


484
00:14:20,926 --> 00:14:22,266
threshold that yield three


485
00:14:22,266 --> 00:14:23,326
different kinds of searches.


486
00:14:24,416 --> 00:14:25,426
To make this a little more


487
00:14:25,426 --> 00:14:26,816
concrete, let's say I have a


488
00:14:26,876 --> 00:14:28,696
library of images for which I've


489
00:14:28,806 --> 00:14:30,346
already performed classification


490
00:14:30,386 --> 00:14:31,246
and stored the results.


491
00:14:32,026 --> 00:14:33,296
Let's say in this particular


492
00:14:33,296 --> 00:14:35,016
case I'm looking for images of


493
00:14:35,016 --> 00:14:35,866
motorcycles.


494
00:14:36,726 --> 00:14:37,626
Now, I want to pick my


495
00:14:37,626 --> 00:14:39,466
thresholds such that images with


496
00:14:39,466 --> 00:14:40,776
motorcycles typically have a


497
00:14:40,776 --> 00:14:41,826
confidence higher than this


498
00:14:41,876 --> 00:14:43,906
threshold and images without


499
00:14:43,906 --> 00:14:45,306
motorcycles typically have a


500
00:14:45,306 --> 00:14:46,946
score lower than this threshold.


501
00:14:47,596 --> 00:14:49,186
So, what happens if I just pick


502
00:14:49,186 --> 00:14:50,006
a low threshold.


503
00:14:50,826 --> 00:14:52,286
As you can see behind me, when I


504
00:14:52,286 --> 00:14:54,246
apply this low threshold, I do


505
00:14:54,246 --> 00:14:55,356
in fact get my motorcycle


506
00:14:55,356 --> 00:14:56,926
images, but I'm also getting


507
00:14:56,926 --> 00:14:58,696
these images of mopeds in the


508
00:14:58,696 --> 00:14:59,246
bottom right.


509
00:14:59,246 --> 00:15:01,106
And if my users are motorcycle


510
00:15:01,106 --> 00:15:02,106
enthusiasts, they might be a


511
00:15:02,106 --> 00:15:03,386
little annoyed with that result.


512
00:15:04,516 --> 00:15:06,186
When we talk about a search that


513
00:15:06,186 --> 00:15:07,806
tries to maximize the percentage


514
00:15:07,806 --> 00:15:09,346
of the target class retrieved


515
00:15:09,346 --> 00:15:11,156
amongst the entire library, and


516
00:15:11,246 --> 00:15:12,656
isn't as concerned with these


517
00:15:12,656 --> 00:15:14,196
missed predictions where we say


518
00:15:14,196 --> 00:15:15,596
the motorcycle is present when


519
00:15:15,596 --> 00:15:16,266
it actually isn't.


520
00:15:16,656 --> 00:15:18,036
We are typically talking about a


521
00:15:18,036 --> 00:15:19,076
high recall search.


522
00:15:20,156 --> 00:15:22,236
Now, I could maximize recall by


523
00:15:22,236 --> 00:15:23,806
simply returning as many images


524
00:15:23,806 --> 00:15:25,086
as possible, but I would get a


525
00:15:25,176 --> 00:15:26,526
huge number of these false


526
00:15:26,526 --> 00:15:27,516
predictions where I say my


527
00:15:27,516 --> 00:15:28,806
target class is present when it


528
00:15:28,806 --> 00:15:30,436
actually isn't, and so we need


529
00:15:30,436 --> 00:15:31,666
to find a more balanced point of


530
00:15:31,666 --> 00:15:32,676
recall to operate at.


531
00:15:33,586 --> 00:15:34,956
Let's take a look at how I need


532
00:15:34,956 --> 00:15:36,596
to change my code in order to


533
00:15:36,596 --> 00:15:38,256
perform this high recall search.


534
00:15:39,716 --> 00:15:41,566
So, here I have the same code


535
00:15:41,566 --> 00:15:43,466
snippet as before, but this time


536
00:15:43,606 --> 00:15:45,516
I'm performing a filtering with


537
00:15:45,516 --> 00:15:47,206
hasMinimumPrecision and a


538
00:15:47,206 --> 00:15:48,666
specific recall value.


539
00:15:49,496 --> 00:15:51,526
For each observation in my array


540
00:15:51,526 --> 00:15:53,646
of observations, the filter only


541
00:15:53,646 --> 00:15:55,166
retains it if the confidence


542
00:15:55,166 --> 00:15:56,336
associated with the class


543
00:15:56,656 --> 00:15:57,946
achieves the level of recall


544
00:15:57,946 --> 00:15:58,896
that I specified.


545
00:15:59,646 --> 00:16:01,526
Now, the actual operating point


546
00:16:01,526 --> 00:16:02,856
needed to determine this is


547
00:16:02,856 --> 00:16:04,196
going to be different for every


548
00:16:04,196 --> 00:16:06,106
class, and it's something we've


549
00:16:06,106 --> 00:16:07,756
determined based on our internal


550
00:16:07,756 --> 00:16:08,986
tests of how the network


551
00:16:08,986 --> 00:16:10,476
performs on every class in the


552
00:16:10,476 --> 00:16:11,116
taxonomy.


553
00:16:12,086 --> 00:16:13,736
However, the filter handles this


554
00:16:13,736 --> 00:16:14,696
for you automatically.


555
00:16:15,026 --> 00:16:16,756
All you need to do is specify


556
00:16:16,756 --> 00:16:18,016
the level of recall you want to


557
00:16:18,016 --> 00:16:18,696
operate at.


558
00:16:19,736 --> 00:16:20,686
So, we talked about a high


559
00:16:20,686 --> 00:16:22,426
recall search here, but what if


560
00:16:22,426 --> 00:16:24,196
I have an application that can't


561
00:16:24,196 --> 00:16:25,646
tolerate these false predictions


562
00:16:25,646 --> 00:16:26,786
where I'm saying motorcycles are


563
00:16:26,786 --> 00:16:27,696
present when they're not.


564
00:16:28,106 --> 00:16:29,746
That is, I want to be absolutely


565
00:16:29,746 --> 00:16:31,456
sure that the images I retrieve


566
00:16:31,626 --> 00:16:32,566
actually do contain a


567
00:16:32,566 --> 00:16:33,246
motorcycle.


568
00:16:34,026 --> 00:16:35,326
Well, let's come back to our


569
00:16:35,326 --> 00:16:36,956
library of images then and see


570
00:16:36,956 --> 00:16:38,236
what would happen if we applied


571
00:16:38,266 --> 00:16:39,186
the higher threshold.


572
00:16:39,956 --> 00:16:41,406
As you can see behind me, when I


573
00:16:41,406 --> 00:16:43,186
apply my high threshold, I do in


574
00:16:43,186 --> 00:16:44,776
fact only get motorcycle images,


575
00:16:45,106 --> 00:16:46,506
but I get far fewer images


576
00:16:46,506 --> 00:16:47,166
overall.


577
00:16:48,536 --> 00:16:50,176
When we talk about a search that


578
00:16:50,176 --> 00:16:51,816
tries to maximize the percentage


579
00:16:51,876 --> 00:16:53,506
of the target class amongst the


580
00:16:53,506 --> 00:16:55,586
retrieved images and isn't as


581
00:16:55,586 --> 00:16:57,146
concerned with overlooking some


582
00:16:57,146 --> 00:16:58,486
of the more ambiguous images


583
00:16:58,536 --> 00:16:59,696
that actually do contain the


584
00:16:59,696 --> 00:17:01,216
target class, we are typically


585
00:17:01,216 --> 00:17:03,296
talking about a high precision


586
00:17:03,296 --> 00:17:03,736
search.


587
00:17:04,445 --> 00:17:06,296
Again, like with high recall, we


588
00:17:06,296 --> 00:17:07,316
need to find a more balanced


589
00:17:07,316 --> 00:17:08,656
operating point where I have an


590
00:17:08,656 --> 00:17:10,435
acceptable likelihood about my


591
00:17:10,435 --> 00:17:11,486
target class appearing in my


592
00:17:11,486 --> 00:17:12,886
results, but I'm not getting too


593
00:17:12,986 --> 00:17:13,756
few images.


594
00:17:14,816 --> 00:17:16,116
So, let's take a look at how I


595
00:17:16,116 --> 00:17:17,816
need to modify my code in order


596
00:17:17,816 --> 00:17:19,175
to perform this high precision


597
00:17:19,175 --> 00:17:19,586
search.


598
00:17:20,175 --> 00:17:22,546
So here's the same code snippet,


599
00:17:22,715 --> 00:17:24,215
but this time my filtering is


600
00:17:24,215 --> 00:17:26,366
done with hasMinimumRecall and a


601
00:17:26,366 --> 00:17:27,935
precision value I've specified.


602
00:17:28,806 --> 00:17:30,636
Again, I only retain the


603
00:17:30,636 --> 00:17:32,186
observation if the confidence


604
00:17:32,186 --> 00:17:33,786
associated with it achieves the


605
00:17:33,786 --> 00:17:34,736
level of precision that I


606
00:17:34,736 --> 00:17:35,406
specified.


607
00:17:36,166 --> 00:17:37,546
The actual threshold needed for


608
00:17:37,546 --> 00:17:38,806
this is going to be different


609
00:17:38,806 --> 00:17:40,286
for every class, but the filter


610
00:17:40,286 --> 00:17:41,646
handles that for me


611
00:17:41,646 --> 00:17:42,256
automatically.


612
00:17:42,626 --> 00:17:44,056
All I need to do is tell it the


613
00:17:44,056 --> 00:17:45,026
level of precision I want to


614
00:17:45,026 --> 00:17:45,616
operate at.


615
00:17:46,936 --> 00:17:48,576
So we've talked about two


616
00:17:48,576 --> 00:17:49,846
different extremes here, one of


617
00:17:49,906 --> 00:17:51,236
high recall and one of high


618
00:17:51,236 --> 00:17:53,516
precision, but in practice, it


619
00:17:53,516 --> 00:17:55,216
can be better to find a balanced


620
00:17:55,416 --> 00:17:57,076
tradeoff between the two.


621
00:17:58,096 --> 00:17:59,496
So, let's see how we can go


622
00:17:59,496 --> 00:18:00,896
about doing that, and in order


623
00:18:00,896 --> 00:18:01,966
to understand what's happening,


624
00:18:02,246 --> 00:18:03,266
I first need to introduce


625
00:18:03,396 --> 00:18:04,836
something known as the precision


626
00:18:04,836 --> 00:18:05,646
and recall curve.


627
00:18:06,346 --> 00:18:08,976
So, in practice, there is a


628
00:18:08,976 --> 00:18:10,406
tradeoff to be made where


629
00:18:10,406 --> 00:18:11,986
increasing one of precision and


630
00:18:11,986 --> 00:18:13,846
recall can lead to a decrease in


631
00:18:13,846 --> 00:18:14,196
the other.


632
00:18:14,646 --> 00:18:16,376
I can represent this tradeoff as


633
00:18:16,376 --> 00:18:17,956
a graph, where for each


634
00:18:18,026 --> 00:18:19,586
operating point I can compute


635
00:18:19,586 --> 00:18:20,936
the corresponding precision and


636
00:18:20,936 --> 00:18:21,336
recall.


637
00:18:22,016 --> 00:18:23,476
For instance, at the operating


638
00:18:23,506 --> 00:18:25,156
point at where I achieve a


639
00:18:25,156 --> 00:18:27,116
recall of 0.7, I find that I get


640
00:18:27,116 --> 00:18:28,456
a corresponding precision of


641
00:18:28,456 --> 00:18:29,436
0.74.


642
00:18:29,436 --> 00:18:31,886
I can compute this for a


643
00:18:31,886 --> 00:18:33,486
multitude of operating points in


644
00:18:33,486 --> 00:18:35,016
order to form my full curve.


645
00:18:36,246 --> 00:18:37,956
As I said before, I want to find


646
00:18:37,956 --> 00:18:39,846
a balance point along this curve


647
00:18:40,056 --> 00:18:41,056
that achieves the level of


648
00:18:41,056 --> 00:18:42,286
recall and precision that makes


649
00:18:42,286 --> 00:18:43,536
sense for my application.


650
00:18:44,486 --> 00:18:45,726
So let's see how I need to


651
00:18:45,756 --> 00:18:47,366
change my code in order to


652
00:18:47,366 --> 00:18:48,636
accomplish it and how the


653
00:18:48,636 --> 00:18:50,376
precision and recall curve plays


654
00:18:51,106 --> 00:18:52,146
into that.


655
00:18:52,286 --> 00:18:54,276
So here I have a filtering with


656
00:18:54,276 --> 00:18:55,896
hasMinimumPrecision where I'm


657
00:18:55,896 --> 00:18:57,546
specifying the minimum precision


658
00:18:57,546 --> 00:18:57,976
and a recall value.


659
00:18:58,416 --> 00:19:00,746
When I specify a


660
00:19:00,746 --> 00:19:02,486
MinimumPrecision, I'm actually


661
00:19:02,486 --> 00:19:04,286
selecting an area along the


662
00:19:04,286 --> 00:19:05,566
graph that I want to operate


663
00:19:05,566 --> 00:19:05,976
within.


664
00:19:06,866 --> 00:19:08,236
When I select a recall point


665
00:19:08,286 --> 00:19:10,226
with forRecall, I'm choosing a


666
00:19:10,296 --> 00:19:11,896
point along the curve that will


667
00:19:11,896 --> 00:19:13,006
be my operating point.


668
00:19:13,876 --> 00:19:15,516
Now, if the operating point is


669
00:19:15,576 --> 00:19:16,666
in the valid region that I


670
00:19:16,666 --> 00:19:18,166
selected, then that is the


671
00:19:18,166 --> 00:19:19,616
threshold that the filter will


672
00:19:19,616 --> 00:19:20,916
apply when looking at that


673
00:19:20,916 --> 00:19:21,626
particular class.


674
00:19:22,586 --> 00:19:24,076
If the operating point is not in


675
00:19:24,076 --> 00:19:25,636
the valid region, then there is


676
00:19:25,636 --> 00:19:27,046
no operating point that meets


677
00:19:27,046 --> 00:19:28,536
the constraints I stated, and


678
00:19:28,536 --> 00:19:29,606
the class will always be


679
00:19:29,606 --> 00:19:30,816
filtered out of my results.


680
00:19:31,856 --> 00:19:33,556
In this sense, all you need to


681
00:19:33,556 --> 00:19:35,166
do is provide the level of


682
00:19:35,166 --> 00:19:36,476
precision and recall that you


683
00:19:36,476 --> 00:19:37,686
want to operate at, and the


684
00:19:37,686 --> 00:19:38,626
filter will determine the


685
00:19:38,626 --> 00:19:39,916
necessary thresholds for you


686
00:19:40,076 --> 00:19:40,796
automatically.


687
00:19:41,386 --> 00:19:44,906
So, to summarize, the


688
00:19:44,906 --> 00:19:46,226
observation I get back when


689
00:19:46,226 --> 00:19:47,656
performing image classification


690
00:19:47,986 --> 00:19:49,106
is actually an array of


691
00:19:49,106 --> 00:19:50,656
observations, one for every


692
00:19:50,656 --> 00:19:51,736
class in the taxonomy.


693
00:19:52,876 --> 00:19:54,106
Because this is a multi-label


694
00:19:54,206 --> 00:19:55,566
problem, the confidences will


695
00:19:55,566 --> 00:19:56,456
not sum to 1.


696
00:19:57,166 --> 00:19:58,716
Instead, we have independent


697
00:19:58,716 --> 00:20:00,376
confidence values, one for every


698
00:20:00,376 --> 00:20:02,616
class between 0 to 1, and we


699
00:20:02,616 --> 00:20:04,096
need to understand precision and


700
00:20:04,096 --> 00:20:05,656
recall and how they apply to our


701
00:20:05,656 --> 00:20:07,676
specific use case in order to


702
00:20:07,676 --> 00:20:08,606
apply a filtering with


703
00:20:08,606 --> 00:20:10,226
hasMinimumPrecision or


704
00:20:10,226 --> 00:20:11,856
hasMinimumRecall that makes


705
00:20:11,856 --> 00:20:13,166
sense for our application.


706
00:20:13,606 --> 00:20:15,846
So, that concludes the portion


707
00:20:16,146 --> 00:20:17,496
on image classification.


708
00:20:17,986 --> 00:20:19,416
I'd like to switch gears and


709
00:20:19,416 --> 00:20:20,676
talk about a related topic,


710
00:20:21,226 --> 00:20:22,866
Image -- excuse me.


711
00:20:23,176 --> 00:20:23,976
Image Similarity.


712
00:20:26,216 --> 00:20:27,216
When we talk about Image


713
00:20:27,216 --> 00:20:29,076
Similarity, what we really mean


714
00:20:29,076 --> 00:20:30,406
is a method to describe the


715
00:20:30,406 --> 00:20:32,476
content of an image and another


716
00:20:32,476 --> 00:20:34,286
method to compare those


717
00:20:34,316 --> 00:20:34,956
descriptions.


718
00:20:36,116 --> 00:20:38,106
The most basic way in which I


719
00:20:38,106 --> 00:20:39,676
can describe the contents of an


720
00:20:39,676 --> 00:20:41,436
image is using the source pixels


721
00:20:41,436 --> 00:20:41,986
themselves.


722
00:20:43,536 --> 00:20:45,286
That is, I can search for other


723
00:20:45,286 --> 00:20:47,076
images that have close to or


724
00:20:47,076 --> 00:20:49,196
exactly the same pixel values


725
00:20:49,256 --> 00:20:50,076
and retrieve them.


726
00:20:51,146 --> 00:20:52,136
If I did a search in this


727
00:20:52,136 --> 00:20:54,046
fashion, however, it's extremely


728
00:20:54,046 --> 00:20:55,886
fragile, and it's easily fooled


729
00:20:55,986 --> 00:20:57,646
by small changes like rotations


730
00:20:57,916 --> 00:20:59,466
or lighting augmentations that


731
00:20:59,466 --> 00:21:00,656
drastically change the pixel


732
00:21:00,656 --> 00:21:02,256
values but not the semantic


733
00:21:02,256 --> 00:21:03,376
content in the image.


734
00:21:04,266 --> 00:21:05,536
What I really want is a more


735
00:21:05,536 --> 00:21:07,246
high-level description of what


736
00:21:07,246 --> 00:21:08,836
the content of the image is,


737
00:21:08,836 --> 00:21:09,926
perhaps something like natural


738
00:21:09,926 --> 00:21:10,426
language.


739
00:21:10,936 --> 00:21:13,126
I could make use of the image


740
00:21:13,126 --> 00:21:14,696
classification API I was


741
00:21:14,696 --> 00:21:16,426
describing previously in order


742
00:21:16,426 --> 00:21:17,636
to extract a set of words that


743
00:21:17,636 --> 00:21:18,626
describe my image.


744
00:21:19,446 --> 00:21:20,936
I could then retrieve other


745
00:21:20,936 --> 00:21:22,426
images with a similar set of


746
00:21:22,426 --> 00:21:23,316
classifications.


747
00:21:23,756 --> 00:21:25,106
I might even combine this with


748
00:21:25,106 --> 00:21:26,256
something like word vectors to


749
00:21:26,326 --> 00:21:27,716
account for similar but not


750
00:21:27,716 --> 00:21:29,386
exactly matching words like cat


751
00:21:29,386 --> 00:21:30,356
and kitten.


752
00:21:30,696 --> 00:21:31,896
Well, if I performed a search


753
00:21:31,896 --> 00:21:33,556
like this, I might get similar


754
00:21:33,556 --> 00:21:35,046
objects in a very general sense,


755
00:21:35,446 --> 00:21:36,406
but the way in which those


756
00:21:36,406 --> 00:21:37,556
objects appear and the


757
00:21:37,556 --> 00:21:39,066
relationships between them could


758
00:21:39,066 --> 00:21:40,026
be very different.


759
00:21:40,966 --> 00:21:43,036
As well, I would be limited by


760
00:21:43,036 --> 00:21:44,586
the taxonomy of my classifier.


761
00:21:45,386 --> 00:21:46,736
That is, any object that


762
00:21:46,736 --> 00:21:48,426
appeared in my image that wasn't


763
00:21:48,426 --> 00:21:49,756
in my classification networks


764
00:21:49,756 --> 00:21:51,686
taxonomy couldn't be expressed


765
00:21:51,786 --> 00:21:52,876
in a search like this.


766
00:21:54,216 --> 00:21:55,486
What I really want is a


767
00:21:55,486 --> 00:21:56,966
high-level description of the


768
00:21:56,996 --> 00:21:58,176
objects that appear in the image


769
00:21:58,386 --> 00:21:59,856
that isn't fixated on the exact


770
00:21:59,856 --> 00:22:01,096
pixel values but still cares


771
00:22:01,096 --> 00:22:01,556
about them.


772
00:22:02,256 --> 00:22:04,006
I also want this to apply to any


773
00:22:04,006 --> 00:22:05,896
natural image and not just those


774
00:22:05,896 --> 00:22:07,266
within a specific taxonomy.


775
00:22:07,746 --> 00:22:09,946
As it turns out, this kind of


776
00:22:09,946 --> 00:22:11,756
representation learning is


777
00:22:11,756 --> 00:22:12,676
something that's naturally


778
00:22:12,676 --> 00:22:14,016
engendered in our classification


779
00:22:14,016 --> 00:22:15,296
network as part of its training


780
00:22:15,296 --> 00:22:15,786
process.


781
00:22:16,786 --> 00:22:18,736
The upper layers of the network


782
00:22:18,976 --> 00:22:20,356
contain all of the salient


783
00:22:20,356 --> 00:22:22,166
information necessary to perform


784
00:22:22,166 --> 00:22:23,686
classification while discarding


785
00:22:23,756 --> 00:22:25,466
any redundant or unnecessary


786
00:22:25,466 --> 00:22:26,726
information that doesn't aid it


787
00:22:26,726 --> 00:22:28,336
in that task.


788
00:22:28,386 --> 00:22:29,596
We can make use of these upper


789
00:22:29,596 --> 00:22:31,136
layers then to act as our


790
00:22:31,136 --> 00:22:32,456
feature descriptor, and it's


791
00:22:32,456 --> 00:22:33,516
something we refer to as the


792
00:22:33,516 --> 00:22:34,156
feature print.


793
00:22:35,196 --> 00:22:36,706
Now, the feature print is a


794
00:22:36,706 --> 00:22:37,946
vector that describes the


795
00:22:37,946 --> 00:22:39,666
content of the image that isn't


796
00:22:39,666 --> 00:22:40,696
constrained to a particular


797
00:22:40,696 --> 00:22:42,086
taxonomy, even the one that the


798
00:22:42,086 --> 00:22:43,146
classification network was


799
00:22:43,146 --> 00:22:43,636
trained on.


800
00:22:43,896 --> 00:22:45,106
It simply leverages what the


801
00:22:45,106 --> 00:22:46,486
network has learned about images


802
00:22:46,486 --> 00:22:47,736
during its training process.


803
00:22:48,816 --> 00:22:50,296
If we look at these pairs of


804
00:22:50,296 --> 00:22:51,696
images, we can compare how


805
00:22:51,696 --> 00:22:52,786
similar their feature prints


806
00:22:52,786 --> 00:22:54,236
are, and the smaller the value


807
00:22:54,236 --> 00:22:55,486
is, the more similar the two


808
00:22:55,486 --> 00:22:57,296
images are in a semantic sense.


809
00:22:58,046 --> 00:22:59,316
We can see that even though the


810
00:22:59,316 --> 00:23:00,556
two images of the cats are


811
00:23:00,556 --> 00:23:02,026
visually dissimilar, they have a


812
00:23:02,026 --> 00:23:03,506
much more similar feature print


813
00:23:03,746 --> 00:23:05,526
than the visually similar pairs


814
00:23:05,596 --> 00:23:06,636
of different animals.


815
00:23:07,136 --> 00:23:09,416
To make this a little more


816
00:23:09,416 --> 00:23:10,646
concrete, let's go through a


817
00:23:10,646 --> 00:23:11,686
specific example.


818
00:23:12,396 --> 00:23:13,476
Let's say I have the source


819
00:23:13,476 --> 00:23:15,186
image on screen, and I want to


820
00:23:15,186 --> 00:23:16,706
find other semantically similar


821
00:23:16,706 --> 00:23:17,476
images to it.


822
00:23:18,336 --> 00:23:19,656
I'm going to take a library of


823
00:23:19,656 --> 00:23:21,196
images and compute the feature


824
00:23:21,196 --> 00:23:22,896
print for each image and then


825
00:23:22,896 --> 00:23:24,476
retrieve those images with the


826
00:23:24,476 --> 00:23:26,296
most similar feature print to my


827
00:23:26,296 --> 00:23:26,986
source image.


828
00:23:27,746 --> 00:23:29,136
When I do it for this image of


829
00:23:29,136 --> 00:23:29,926
the gentleman in the coffee


830
00:23:29,926 --> 00:23:31,876
shop, I find I get other images


831
00:23:31,926 --> 00:23:33,176
of people in coffee shop and


832
00:23:33,176 --> 00:23:33,946
restaurant settings.


833
00:23:34,886 --> 00:23:36,266
If I focus on a crop of the


834
00:23:36,266 --> 00:23:38,246
newspaper, however, I get other


835
00:23:38,246 --> 00:23:39,586
images of newspapers.


836
00:23:40,246 --> 00:23:42,156
And if I focus on the teapot, I


837
00:23:42,236 --> 00:23:43,906
get other images of teapots.


838
00:23:45,326 --> 00:23:46,616
I'd like to now invite the


839
00:23:46,616 --> 00:23:48,616
Vision Team onstage to help me


840
00:23:48,616 --> 00:23:50,116
with a quick demonstration to


841
00:23:50,116 --> 00:23:51,546
expand a little more on how


842
00:23:51,546 --> 00:23:52,646
Image Similarity works.


843
00:23:54,516 --> 00:23:58,166
[ Applause ]


844
00:23:58,666 --> 00:23:59,466
>> Hello everyone.


845
00:23:59,886 --> 00:24:00,846
My name is Brett, and we have a


846
00:24:00,846 --> 00:24:02,046
really fun way to demonstrate


847
00:24:02,046 --> 00:24:03,546
Image Similarity for you today.


848
00:24:03,546 --> 00:24:05,286
We have very creatively called


849
00:24:05,286 --> 00:24:06,846
it the Image Similarity game.


850
00:24:07,876 --> 00:24:09,086
And here is how you play.


851
00:24:09,676 --> 00:24:11,066
You draw something on a piece of


852
00:24:11,066 --> 00:24:14,026
paper, then ask a few friends to


853
00:24:14,026 --> 00:24:15,166
re-create your original as close


854
00:24:15,166 --> 00:24:15,726
as possible.


855
00:24:16,296 --> 00:24:17,596
So I will start by drawing the


856
00:24:17,596 --> 00:24:17,976
original.


857
00:24:30,096 --> 00:24:33,496
Okay. Tap continue to scan it in


858
00:24:33,496 --> 00:24:33,976
as my original.


859
00:24:42,046 --> 00:24:42,976
And then save.


860
00:24:44,526 --> 00:24:46,456
Now, my team will act as


861
00:24:46,456 --> 00:24:47,886
contestants, and they will draw


862
00:24:48,156 --> 00:24:48,976
this as best as they can.


863
00:24:54,266 --> 00:24:55,206
Now while they're drawing, I


864
00:24:55,206 --> 00:24:57,316
should tell you that this sample


865
00:24:57,316 --> 00:24:58,476
app is currently available to


866
00:24:58,536 --> 00:25:00,576
you now on the developer


867
00:25:00,576 --> 00:25:04,356
documentation website as sample


868
00:25:04,356 --> 00:25:05,986
code, and also, we are using the


869
00:25:05,986 --> 00:25:07,586
Vision kit document scanner to


870
00:25:07,586 --> 00:25:08,886
scan in our drawings, and you


871
00:25:08,886 --> 00:25:09,966
can learn more about that at our


872
00:25:09,966 --> 00:25:11,226
text recognition session.


873
00:25:12,706 --> 00:25:15,076
Let's them give a few more


874
00:25:16,636 --> 00:25:16,886
seconds.


875
00:25:16,966 --> 00:25:19,896
Five, four, three, okay, I guess


876
00:25:19,926 --> 00:25:20,186
they're done.


877
00:25:20,266 --> 00:25:22,186
Okay. Let's bring them up and


878
00:25:22,186 --> 00:25:24,266
start scanning them in.


879
00:25:24,996 --> 00:25:26,256
Contestant number one.


880
00:25:31,046 --> 00:25:31,576
Pretty good [applause].


881
00:25:32,756 --> 00:25:33,406
That might be a winner.


882
00:25:33,406 --> 00:25:35,256
Let's see contestant number two.


883
00:25:38,296 --> 00:25:39,786
Still pretty good.


884
00:25:40,096 --> 00:25:40,506
Nicely done.


885
00:25:41,256 --> 00:25:43,256
[ Applause ]


886
00:25:43,496 --> 00:25:44,706
Contestant number three please.


887
00:25:48,056 --> 00:25:50,056
[ Laughter and Applause ]


888
00:25:50,096 --> 00:25:50,976
I think that's pretty good.


889
00:25:51,016 --> 00:25:52,586
[ Applause ]


890
00:25:52,586 --> 00:25:53,696
And contestant number four.


891
00:25:57,046 --> 00:25:58,136
Well, I don't know about that,


892
00:25:58,196 --> 00:26:00,836
but we'll see how it goes.


893
00:26:01,151 --> 00:26:03,151
[ Applause ]


894
00:26:03,286 --> 00:26:03,836
All right.


895
00:26:03,836 --> 00:26:07,006
So let's save those, and we find


896
00:26:07,006 --> 00:26:08,286
out that the winner is


897
00:26:08,286 --> 00:26:09,636
contestant number one.


898
00:26:09,636 --> 00:26:10,446
Congratulations.


899
00:26:11,016 --> 00:26:12,736
[ Applause ]


900
00:26:12,736 --> 00:26:14,716
Now I can swipe over, and we can


901
00:26:14,796 --> 00:26:16,076
see that the faces are more


902
00:26:16,076 --> 00:26:17,656
semantically similar that way.


903
00:26:18,336 --> 00:26:19,996
They are closer to the original


904
00:26:20,096 --> 00:26:21,376
while the tree is semantically


905
00:26:21,376 --> 00:26:22,416
different, it was much further


906
00:26:22,416 --> 00:26:22,686
away.


907
00:26:23,336 --> 00:26:24,426
And that is the Image Similarity


908
00:26:24,426 --> 00:26:25,376
game, and background check to


909
00:26:25,376 --> 00:26:25,726
Rohan.


910
00:26:26,516 --> 00:26:31,776
[ Applause ]


911
00:26:32,276 --> 00:26:32,876
>> Thanks everyone.


912
00:26:33,476 --> 00:26:34,736
I want to take a quick look at a


913
00:26:34,736 --> 00:26:35,846
snippet from that demo


914
00:26:35,846 --> 00:26:37,196
application to show how we


915
00:26:37,196 --> 00:26:37,946
determined the winning


916
00:26:37,946 --> 00:26:38,546
contestant.


917
00:26:39,686 --> 00:26:41,906
So here I have the portion of


918
00:26:41,906 --> 00:26:43,506
the code that compares each of


919
00:26:43,506 --> 00:26:45,286
the contestant's drawings


920
00:26:45,396 --> 00:26:46,796
feature print to Brett's


921
00:26:46,796 --> 00:26:47,666
drawing's feature print.


922
00:26:48,326 --> 00:26:49,006
Now, I extracted the


923
00:26:49,006 --> 00:26:50,276
contestant's feature print with


924
00:26:50,276 --> 00:26:51,396
a function we have defined in


925
00:26:51,396 --> 00:26:52,566
the application called


926
00:26:52,566 --> 00:26:54,466
featureprintObservationForImage.


927
00:26:55,186 --> 00:26:56,956
Once I have each feature print,


928
00:26:57,226 --> 00:26:58,666
I then need to determine how


929
00:26:58,666 --> 00:27:00,056
similar it was to the original


930
00:27:00,056 --> 00:27:01,846
drawing, and I can do that using


931
00:27:01,846 --> 00:27:03,246
computeDistance, which returns


932
00:27:03,246 --> 00:27:04,576
me a floating-point value.


933
00:27:05,166 --> 00:27:05,826
Now, the smaller the


934
00:27:05,826 --> 00:27:07,206
floating-point value, the more


935
00:27:07,206 --> 00:27:08,646
similar the two images are.


936
00:27:09,236 --> 00:27:10,456
And so, once I've determined


937
00:27:10,456 --> 00:27:11,636
this for every contestant, I


938
00:27:11,636 --> 00:27:13,116
simply need to sort them in


939
00:27:13,116 --> 00:27:14,276
order to determine the winner.


940
00:27:15,336 --> 00:27:17,006
Well, this concludes the portion


941
00:27:17,156 --> 00:27:18,156
on Image Similarity.


942
00:27:18,486 --> 00:27:19,536
I'd now like to hand the mic


943
00:27:19,536 --> 00:27:20,816
over to Sergey to talk about


944
00:27:20,816 --> 00:27:21,866
some of the changes coming to


945
00:27:21,866 --> 00:27:22,836
Face Technologies.


946
00:27:23,516 --> 00:27:28,500
[ Applause ]


947
00:27:33,056 --> 00:27:33,876
>> Good morning everybody.


948
00:27:34,196 --> 00:27:35,226
My name is Sergey Kamensky.


949
00:27:35,226 --> 00:27:36,196
I'm a software engineer on the


950
00:27:36,196 --> 00:27:36,926
Vision Framework Team.


951
00:27:37,356 --> 00:27:38,456
I'm excited to share with you


952
00:27:38,456 --> 00:27:39,786
today even more new features


953
00:27:39,876 --> 00:27:40,926
coming to the Framework this


954
00:27:40,926 --> 00:27:41,096
year.


955
00:27:41,096 --> 00:27:43,286
Let's talk about Face Technology


956
00:27:43,286 --> 00:27:43,606
first.


957
00:27:44,206 --> 00:27:45,956
Remember, two years ago when we


958
00:27:45,956 --> 00:27:47,836
introduced Vision Framework, we


959
00:27:47,836 --> 00:27:49,366
also talked about Face Landmark


960
00:27:49,416 --> 00:27:49,806
detector.


961
00:27:50,266 --> 00:27:51,596
This year, we're coming with a


962
00:27:51,596 --> 00:27:52,796
new revision for this algorithm.


963
00:27:53,176 --> 00:27:54,806
So, what are the changes?


964
00:27:55,916 --> 00:27:57,786
Well, first, we now have


965
00:27:57,926 --> 00:27:59,616
76-point cancellation, and this


966
00:27:59,616 --> 00:28:01,426
is versus 65-point cancellation


967
00:28:01,426 --> 00:28:02,166
as we had before.


968
00:28:02,166 --> 00:28:04,116
The 76-point cancellation gives


969
00:28:04,116 --> 00:28:05,146
us a greater density to


970
00:28:05,146 --> 00:28:06,276
represent different face


971
00:28:06,276 --> 00:28:06,686
regions.


972
00:28:07,556 --> 00:28:09,556
Second, we now report confidence


973
00:28:09,556 --> 00:28:11,306
score per landmark point, and


974
00:28:11,306 --> 00:28:12,886
this is versus a single average


975
00:28:12,886 --> 00:28:14,446
confidence score, as we reported


976
00:28:14,446 --> 00:28:14,836
before.


977
00:28:14,836 --> 00:28:16,646
But the biggest improvement


978
00:28:16,646 --> 00:28:18,126
comes in the pupil detection.


979
00:28:18,706 --> 00:28:19,996
As you can see, the image on the


980
00:28:19,996 --> 00:28:21,296
right-hand side has pupils


981
00:28:21,296 --> 00:28:22,406
detected with much better


982
00:28:22,566 --> 00:28:23,066
accuracy.


983
00:28:23,516 --> 00:28:25,886
Let's take a look at the client


984
00:28:25,886 --> 00:28:26,416
code sample.


985
00:28:27,986 --> 00:28:29,676
This code snippet will repeat


986
00:28:29,676 --> 00:28:31,056
throughout the presentation so


987
00:28:31,056 --> 00:28:32,386
the first time we're going to go


988
00:28:32,386 --> 00:28:33,206
line by line.


989
00:28:33,496 --> 00:28:35,516
Also, I use for [inaudible] in


990
00:28:35,516 --> 00:28:36,246
my samples.


991
00:28:36,246 --> 00:28:37,946
If this is just to simplify the


992
00:28:37,946 --> 00:28:39,376
slides, when you develop your


993
00:28:39,376 --> 00:28:40,736
apps, you probably should use


994
00:28:40,786 --> 00:28:42,276
proper error handling to avoid


995
00:28:42,276 --> 00:28:43,516
unwanted boundary conditions.


996
00:28:44,256 --> 00:28:45,156
Let's get back to the sample.


997
00:28:46,276 --> 00:28:47,276
In order to get your facial


998
00:28:47,276 --> 00:28:48,866
landmarks, first you need to


999
00:28:48,866 --> 00:28:49,416
create a


1000
00:28:49,416 --> 00:28:50,716
DetectFaceLandmarksRequest.


1001
00:28:51,296 --> 00:28:52,536
Then, you need to create


1002
00:28:52,536 --> 00:28:54,036
ImageRequestHandler, passing the


1003
00:28:54,036 --> 00:28:56,096
image into it the image that


1004
00:28:56,096 --> 00:28:58,346
needs to be processed, and then


1005
00:28:58,626 --> 00:28:59,626
you need to use that request


1006
00:28:59,626 --> 00:29:00,776
handler to process your request.


1007
00:29:01,426 --> 00:29:03,136
Finally, you need to look at the


1008
00:29:03,136 --> 00:29:03,606
results.


1009
00:29:04,386 --> 00:29:05,446
The results for everything that


1010
00:29:05,446 --> 00:29:06,736
this human face related in


1011
00:29:06,736 --> 00:29:08,156
Vision Framework will come in


1012
00:29:08,196 --> 00:29:09,946
forms of face observations.


1013
00:29:10,506 --> 00:29:12,006
Face observation derives some


1014
00:29:12,006 --> 00:29:13,486
detected object observation.


1015
00:29:13,856 --> 00:29:15,006
It inherits bounding box


1016
00:29:15,046 --> 00:29:16,396
property, and it also adds


1017
00:29:16,396 --> 00:29:17,766
several other properties on its


1018
00:29:17,766 --> 00:29:19,886
level to describe human face.


1019
00:29:20,766 --> 00:29:21,806
This time we'll be interested in


1020
00:29:21,806 --> 00:29:22,636
the landmarks property.


1021
00:29:23,136 --> 00:29:24,366
The landmarks property is of


1022
00:29:24,426 --> 00:29:25,976
FaceLandmarks2D class.


1023
00:29:26,176 --> 00:29:28,166
FaceLandmarks2D class consists


1024
00:29:28,416 --> 00:29:29,896
of the confidence score.


1025
00:29:30,086 --> 00:29:31,356
This is the average single


1026
00:29:31,356 --> 00:29:32,476
average confidence score for the


1027
00:29:32,476 --> 00:29:34,716
entire set and multiple face


1028
00:29:34,716 --> 00:29:37,296
regions where each face region


1029
00:29:37,296 --> 00:29:38,196
is represented by


1030
00:29:38,196 --> 00:29:40,176
FaceLandmarksRegion2D class.


1031
00:29:40,636 --> 00:29:41,856
Let's take a closer look at the


1032
00:29:41,856 --> 00:29:44,536
properties of this class.


1033
00:29:44,716 --> 00:29:46,166
First is pointCount.


1034
00:29:46,666 --> 00:29:48,156
PointCount will tell you how


1035
00:29:48,156 --> 00:29:49,546
many points represent a


1036
00:29:49,546 --> 00:29:50,756
particular face region.


1037
00:29:50,996 --> 00:29:52,256
This property will [inaudible] a


1038
00:29:52,256 --> 00:29:53,616
different value depending how


1039
00:29:53,616 --> 00:29:55,366
you configure your request, with


1040
00:29:55,366 --> 00:29:56,936
65-point cancellation or


1041
00:29:56,936 --> 00:29:58,376
76-point cancellation.


1042
00:29:59,646 --> 00:30:01,146
The normalizedPoints property


1043
00:30:01,916 --> 00:30:03,876
will represent the actual


1044
00:30:03,876 --> 00:30:05,596
landmarks point, and the


1045
00:30:05,596 --> 00:30:07,326
precisionEstimatesPerPoint will


1046
00:30:07,326 --> 00:30:08,916
represent the actual confidence


1047
00:30:08,916 --> 00:30:10,416
score for teach landmark point.


1048
00:30:11,456 --> 00:30:12,386
Let's take a look at the codes


1049
00:30:12,386 --> 00:30:12,666
needed.


1050
00:30:12,666 --> 00:30:14,496
This is the same code snippet as


1051
00:30:14,496 --> 00:30:16,106
in the previous slide, but now


1052
00:30:16,106 --> 00:30:17,056
we're going to look at it from a


1053
00:30:17,056 --> 00:30:18,196
slightly different perspective.


1054
00:30:18,576 --> 00:30:20,266
We want to see how revisioning


1055
00:30:20,266 --> 00:30:22,296
of the algorithm works in Vision


1056
00:30:22,296 --> 00:30:22,696
Framework.


1057
00:30:23,446 --> 00:30:25,056
If you take this code snippet


1058
00:30:25,056 --> 00:30:26,276
and recompile it with the last


1059
00:30:26,276 --> 00:30:28,076
[inaudible], what you will get


1060
00:30:28,076 --> 00:30:30,086
is that the request object will


1061
00:30:30,086 --> 00:30:31,806
be configured as follows: the


1062
00:30:31,806 --> 00:30:33,196
revision property will be set to


1063
00:30:33,196 --> 00:30:34,786
revision number 2, and the


1064
00:30:34,786 --> 00:30:36,136
cancellation property will be


1065
00:30:36,136 --> 00:30:37,426
set to cancellation of 65


1066
00:30:37,426 --> 00:30:37,816
points.


1067
00:30:38,396 --> 00:30:39,056
Technically, we didn't have


1068
00:30:39,056 --> 00:30:40,286
cancellation property last year,


1069
00:30:40,286 --> 00:30:41,456
but if we did, we could have set


1070
00:30:41,456 --> 00:30:42,616
it to a single value only.


1071
00:30:43,426 --> 00:30:45,726
Now, if on the other hand you


1072
00:30:45,726 --> 00:30:47,246
take the same code snippet and


1073
00:30:47,246 --> 00:30:49,136
recompile it with the current


1074
00:30:49,686 --> 00:30:50,336
[inaudible], what you will get


1075
00:30:50,336 --> 00:30:51,856
is that the revision property


1076
00:30:51,856 --> 00:30:52,846
will be set to revision number


1077
00:30:52,846 --> 00:30:55,056
3, and the cancellation property


1078
00:30:55,056 --> 00:30:56,726
will be set to cancellation 76


1079
00:30:56,726 --> 00:30:57,076
points.


1080
00:30:58,626 --> 00:30:59,706
This actually represents the


1081
00:30:59,706 --> 00:31:00,846
philosophy of how Vision


1082
00:31:00,846 --> 00:31:02,606
Framework handles revisions of


1083
00:31:02,606 --> 00:31:04,006
algorithms by default.


1084
00:31:04,096 --> 00:31:05,766
If you don't specify a revision,


1085
00:31:05,766 --> 00:31:07,716
what we will do is, we will give


1086
00:31:07,716 --> 00:31:09,366
the latest supported by the SDK


1087
00:31:09,366 --> 00:31:11,436
your code is compiled and linked


1088
00:31:11,436 --> 00:31:11,916
against.


1089
00:31:12,116 --> 00:31:14,066
Of course, we'll always


1090
00:31:14,066 --> 00:31:14,856
recommend to set those


1091
00:31:14,856 --> 00:31:15,836
properties explicitly.


1092
00:31:16,116 --> 00:31:17,106
This is just to guarantee


1093
00:31:17,106 --> 00:31:18,296
deterministic behavior in the


1094
00:31:18,296 --> 00:31:18,656
future.


1095
00:31:19,386 --> 00:31:22,266
Let's take a new metric that we


1096
00:31:22,266 --> 00:31:23,556
developed this year, Face


1097
00:31:23,556 --> 00:31:24,286
Capture Quality.


1098
00:31:24,786 --> 00:31:25,686
There are two images on the


1099
00:31:25,686 --> 00:31:25,946
screen.


1100
00:31:26,296 --> 00:31:27,416
You can clearly see that one


1101
00:31:27,416 --> 00:31:28,536
image was captured with better


1102
00:31:28,536 --> 00:31:29,436
lighting and focusing


1103
00:31:29,436 --> 00:31:29,996
conditions.


1104
00:31:30,846 --> 00:31:32,016
We wanted to develop the metric


1105
00:31:32,016 --> 00:31:33,376
that looks at the image as a


1106
00:31:33,376 --> 00:31:35,016
whole and gives you one score


1107
00:31:35,016 --> 00:31:36,796
back saying how bad or good the


1108
00:31:36,796 --> 00:31:37,966
capture quality was.


1109
00:31:37,966 --> 00:31:40,366
As a result, we came up with a


1110
00:31:40,366 --> 00:31:41,596
Face Capture Quality metric.


1111
00:31:42,466 --> 00:31:43,656
We trained our models for this


1112
00:31:43,656 --> 00:31:45,026
metric in such a way so they


1113
00:31:45,026 --> 00:31:46,876
tend to score lower if the image


1114
00:31:46,876 --> 00:31:48,456
was captured with low light or


1115
00:31:48,456 --> 00:31:50,206
bad focus, or for example, if a


1116
00:31:50,236 --> 00:31:51,936
person had negative expressions.


1117
00:31:52,896 --> 00:31:54,316
If we run this metric on these


1118
00:31:54,346 --> 00:31:55,626
two images, we will get our


1119
00:31:55,626 --> 00:31:56,206
scores back.


1120
00:31:57,036 --> 00:31:57,876
These are floating-point


1121
00:31:57,876 --> 00:31:58,316
numbers.


1122
00:31:58,636 --> 00:31:59,636
You can compare them against


1123
00:31:59,636 --> 00:32:00,776
each other, and you can say that


1124
00:32:00,776 --> 00:32:02,856
the image that scored higher is


1125
00:32:02,856 --> 00:32:04,056
the image that was captured with


1126
00:32:04,056 --> 00:32:04,716
better quality.


1127
00:32:05,346 --> 00:32:07,466
Let's take a look at the code


1128
00:32:07,466 --> 00:32:08,136
sample.


1129
00:32:09,606 --> 00:32:10,756
This is very similar to what we


1130
00:32:10,756 --> 00:32:11,986
saw just a couple of slides ago,


1131
00:32:12,196 --> 00:32:13,416
with the differences being in


1132
00:32:13,416 --> 00:32:15,596
the request type and the


1133
00:32:15,596 --> 00:32:16,136
results.


1134
00:32:16,846 --> 00:32:18,526
Since we still with C1 faces,


1135
00:32:18,736 --> 00:32:19,556
we're going to get our face


1136
00:32:19,556 --> 00:32:20,826
observation back, but now we're


1137
00:32:20,826 --> 00:32:21,686
going to look at a different


1138
00:32:21,686 --> 00:32:22,426
property of the face


1139
00:32:22,426 --> 00:32:23,926
observation, Face Capture


1140
00:32:23,926 --> 00:32:24,626
Quality property.


1141
00:32:24,876 --> 00:32:27,546
Let's take a look at the broader


1142
00:32:27,546 --> 00:32:27,946
example.


1143
00:32:28,616 --> 00:32:29,646
Let's say I have a sequence of


1144
00:32:29,646 --> 00:32:30,586
images that could have been


1145
00:32:30,586 --> 00:32:31,976
obtained by using the burst mode


1146
00:32:31,976 --> 00:32:33,346
on the selfie camera or in the


1147
00:32:33,346 --> 00:32:34,316
photo burst, for example.


1148
00:32:34,626 --> 00:32:35,776
And you will ask yourself a


1149
00:32:35,776 --> 00:32:36,166
question.


1150
00:32:36,426 --> 00:32:37,816
Which image was captured with


1151
00:32:37,816 --> 00:32:38,566
the best quality?


1152
00:32:39,686 --> 00:32:40,966
What you can do now, you can run


1153
00:32:40,966 --> 00:32:42,166
our algorithm on each image,


1154
00:32:42,506 --> 00:32:45,366
assign scores, rank them, and


1155
00:32:45,366 --> 00:32:46,466
the image that apps on the most


1156
00:32:46,466 --> 00:32:47,876
light is the image that was


1157
00:32:47,876 --> 00:32:50,896
captured with the best quality.


1158
00:32:50,966 --> 00:32:52,436
Let's try to understand how we


1159
00:32:52,436 --> 00:32:54,026
can interpret the results that


1160
00:32:54,026 --> 00:32:55,166
are coming from the Face Capture


1161
00:32:55,196 --> 00:32:55,856
Quality metric.


1162
00:32:56,586 --> 00:32:58,206
I have two sequences of images


1163
00:32:58,356 --> 00:32:58,886
on the slide.


1164
00:32:59,426 --> 00:33:00,726
Each sequence is of the same


1165
00:33:00,726 --> 00:33:02,146
person, and each sequence is


1166
00:33:02,146 --> 00:33:03,456
represented by the images that


1167
00:33:03,456 --> 00:33:05,286
scores lowest and the highest in


1168
00:33:05,286 --> 00:33:06,346
the sequence with respect to


1169
00:33:06,346 --> 00:33:07,216
Face Capture Quality.


1170
00:33:08,116 --> 00:33:09,076
What can we say about these


1171
00:33:09,076 --> 00:33:09,496
ranges?


1172
00:33:10,816 --> 00:33:12,356
Well, there is some overlapping


1173
00:33:12,356 --> 00:33:13,696
region, but there are some also


1174
00:33:13,696 --> 00:33:15,006
regions that belong to one and


1175
00:33:15,006 --> 00:33:16,336
don't belong to the other.


1176
00:33:16,516 --> 00:33:18,216
If you had yet another sequence,


1177
00:33:18,536 --> 00:33:19,306
it could have happened that


1178
00:33:19,306 --> 00:33:20,536
there was no overlapping region


1179
00:33:20,536 --> 00:33:20,926
at all.


1180
00:33:21,856 --> 00:33:22,976
The point I'm trying to make


1181
00:33:22,976 --> 00:33:24,686
here is that the Face Capture


1182
00:33:24,686 --> 00:33:26,146
Quality should not be compared


1183
00:33:26,146 --> 00:33:26,906
against a threshold.


1184
00:33:28,126 --> 00:33:29,466
In this particular example, if I


1185
00:33:29,466 --> 00:33:32,096
picked 0.52, I would have missed


1186
00:33:32,326 --> 00:33:33,876
all the images on the left, and


1187
00:33:33,876 --> 00:33:36,556
I would pretty much can get any


1188
00:33:36,556 --> 00:33:37,406
image that's just past the


1189
00:33:37,406 --> 00:33:38,626
midpoint on the right.


1190
00:33:39,996 --> 00:33:41,286
But then what is Face Capture


1191
00:33:41,346 --> 00:33:41,676
Quality?


1192
00:33:42,706 --> 00:33:44,246
We define Face Capture Quality


1193
00:33:44,246 --> 00:33:46,286
is a comparative or ranking


1194
00:33:46,326 --> 00:33:47,766
measure of the same subject.


1195
00:33:48,186 --> 00:33:49,756
Now, comparative and same are


1196
00:33:49,756 --> 00:33:51,086
the key words in this sentence.


1197
00:33:51,526 --> 00:33:53,216
If you're thinking, cool, I have


1198
00:33:53,216 --> 00:33:54,476
this great new metric, I'm going


1199
00:33:54,476 --> 00:33:55,606
to develop my beauty contest


1200
00:33:55,606 --> 00:33:55,726
app.


1201
00:33:56,946 --> 00:33:58,126
Probably not a good idea.


1202
00:33:58,606 --> 00:33:59,636
In a beauty contest app, you


1203
00:33:59,636 --> 00:34:01,296
would have to compare faces of


1204
00:34:01,296 --> 00:34:02,806
different people, and that's not


1205
00:34:02,806 --> 00:34:03,996
what this metric was developed


1206
00:34:03,996 --> 00:34:04,626
and designed for.


1207
00:34:06,266 --> 00:34:07,696
And that's Face Technology.


1208
00:34:09,295 --> 00:34:10,076
Let's take a look at the new


1209
00:34:10,076 --> 00:34:11,146
detectors we're adding this


1210
00:34:11,146 --> 00:34:11,335
year.


1211
00:34:12,896 --> 00:34:15,466
We're introducing Human Detector


1212
00:34:15,466 --> 00:34:16,726
that detects human upper body


1213
00:34:16,726 --> 00:34:18,076
that consists of human head and


1214
00:34:18,076 --> 00:34:20,386
torso and also a pet detector,


1215
00:34:20,795 --> 00:34:22,326
an Animal Detector that detects


1216
00:34:22,696 --> 00:34:23,406
cats and dogs.


1217
00:34:23,735 --> 00:34:24,755
The Animal Detector gives you


1218
00:34:24,755 --> 00:34:26,166
bounding box back, and in


1219
00:34:26,166 --> 00:34:27,286
addition to bounding boxes it


1220
00:34:27,286 --> 00:34:28,636
gives you also a label saying


1221
00:34:28,866 --> 00:34:30,235
which animal was detected.


1222
00:34:31,795 --> 00:34:32,746
Let's take a look at the client


1223
00:34:32,746 --> 00:34:33,226
code sample.


1224
00:34:35,956 --> 00:34:37,916
Two snippets, one for Human


1225
00:34:37,916 --> 00:34:39,366
Detector, one for Animal


1226
00:34:39,366 --> 00:34:39,815
Detector.


1227
00:34:40,326 --> 00:34:41,386
Very similar to what we had


1228
00:34:41,386 --> 00:34:41,835
before.


1229
00:34:42,016 --> 00:34:43,646
Again, the differences are in


1230
00:34:43,646 --> 00:34:44,596
the request types that you


1231
00:34:44,596 --> 00:34:46,386
create and in the results.


1232
00:34:47,186 --> 00:34:49,525
Now, for Human Detector, all we


1233
00:34:49,826 --> 00:34:51,275
care about is the bounding box.


1234
00:34:51,886 --> 00:34:53,166
So, we use for that


1235
00:34:53,306 --> 00:34:54,606
DetectedObjectObservation.


1236
00:34:55,726 --> 00:34:56,706
For the Animal Detector on the


1237
00:34:56,706 --> 00:34:57,706
other hand, we also need the


1238
00:34:57,706 --> 00:34:58,986
label, so we use


1239
00:34:59,676 --> 00:35:01,206
RecognizedObjectObservation that


1240
00:35:01,206 --> 00:35:02,496
derives from detected object


1241
00:35:02,496 --> 00:35:03,076
observation.


1242
00:35:03,186 --> 00:35:04,536
It inherits bounding box, but it


1243
00:35:04,536 --> 00:35:06,736
also adds a label property on


1244
00:35:06,806 --> 00:35:07,296
the [inaudible].


1245
00:35:07,806 --> 00:35:10,486
And that's new detectors.


1246
00:35:11,246 --> 00:35:12,456
Let's take a look at what's new


1247
00:35:12,456 --> 00:35:13,336
in tracking this year.


1248
00:35:14,216 --> 00:35:15,126
We're coming up with a new


1249
00:35:15,126 --> 00:35:16,556
revision for the Tracker.


1250
00:35:16,556 --> 00:35:17,996
The changes are, we have


1251
00:35:17,996 --> 00:35:19,516
improvements in the bounding


1252
00:35:19,516 --> 00:35:20,396
boxes expansion area.


1253
00:35:21,266 --> 00:35:22,386
We can now handle better


1254
00:35:22,386 --> 00:35:22,976
occlusions.


1255
00:35:23,536 --> 00:35:25,716
We are machine learning based


1256
00:35:25,716 --> 00:35:26,176
this time.


1257
00:35:26,886 --> 00:35:28,086
And we can run with low power


1258
00:35:28,086 --> 00:35:29,046
consumption on multiple


1259
00:35:29,046 --> 00:35:29,476
[inaudible] devices.


1260
00:35:29,476 --> 00:35:32,516
Let's take a look at a sample.


1261
00:35:32,956 --> 00:35:35,056
I have a mini video clip where a


1262
00:35:35,056 --> 00:35:36,446
man is running in the forest,


1263
00:35:36,606 --> 00:35:38,126
and he appears sometimes behind


1264
00:35:38,126 --> 00:35:38,646
the trees.


1265
00:35:38,976 --> 00:35:40,126
As you can see, the tracker is


1266
00:35:40,126 --> 00:35:41,606
able to successfully recapture


1267
00:35:41,606 --> 00:35:42,926
the tracked object and keep


1268
00:35:42,926 --> 00:35:43,726
going with the tracking


1269
00:35:43,726 --> 00:35:44,186
sequence.


1270
00:35:46,016 --> 00:35:47,046
[ Applause ]


1271
00:35:47,046 --> 00:35:47,486
Thank you.


1272
00:35:48,516 --> 00:35:51,976
[ Applause ]


1273
00:35:52,476 --> 00:35:53,756
Let's take a look at the client


1274
00:35:53,756 --> 00:35:54,256
code sample.


1275
00:35:54,676 --> 00:35:56,046
This is exactly the same snippet


1276
00:35:56,046 --> 00:35:56,996
that we showed last year.


1277
00:35:57,256 --> 00:35:58,306
It represents probably the


1278
00:35:58,306 --> 00:35:59,416
simplest tracking sequence you


1279
00:35:59,416 --> 00:35:59,946
can imagine.


1280
00:36:00,166 --> 00:36:01,106
It tracks your object of


1281
00:36:01,106 --> 00:36:02,336
interest for five consecutive


1282
00:36:02,336 --> 00:36:02,786
frames.


1283
00:36:03,986 --> 00:36:05,356
I want to go line-by-line, but I


1284
00:36:05,356 --> 00:36:06,916
want to emphasize two points


1285
00:36:06,916 --> 00:36:07,116
here.


1286
00:36:07,486 --> 00:36:09,116
First is we use our


1287
00:36:09,116 --> 00:36:10,036
SequenceRequestHandler.


1288
00:36:11,066 --> 00:36:12,046
That is as opposite to


1289
00:36:12,046 --> 00:36:13,226
ImageRequestHandler as we have


1290
00:36:13,226 --> 00:36:14,226
used so far throughout the


1291
00:36:14,226 --> 00:36:14,816
presentation.


1292
00:36:15,336 --> 00:36:16,616
SequenceRequestHandler is used


1293
00:36:16,616 --> 00:36:17,986
in Vision when you work with a


1294
00:36:17,986 --> 00:36:19,216
sequence of frames and you need


1295
00:36:19,216 --> 00:36:20,426
to cache some information from


1296
00:36:20,426 --> 00:36:21,496
frame to frame to frame.


1297
00:36:22,826 --> 00:36:24,356
Second point is when you


1298
00:36:24,356 --> 00:36:25,106
implement your tracking


1299
00:36:25,106 --> 00:36:26,836
sequence, you need to get your


1300
00:36:26,836 --> 00:36:28,356
results from iteration number n


1301
00:36:28,356 --> 00:36:30,026
and feed it as an input to a


1302
00:36:30,026 --> 00:36:31,276
duration number n plus 1.


1303
00:36:31,976 --> 00:36:35,216
Of course, if you recompiled


1304
00:36:35,216 --> 00:36:36,106
this quote with the current


1305
00:36:36,106 --> 00:36:37,646
[inaudible] SDK, the revision of


1306
00:36:37,646 --> 00:36:38,846
the request will be set to


1307
00:36:38,846 --> 00:36:40,316
revision number 2 by default.


1308
00:36:40,496 --> 00:36:41,836
But we also recommend to set it


1309
00:36:41,836 --> 00:36:42,426
explicitly.


1310
00:36:42,966 --> 00:36:45,106
And that's the tracking.


1311
00:36:46,136 --> 00:36:47,376
Let's take a look at the news


1312
00:36:47,376 --> 00:36:49,696
with respect to Vision and Core


1313
00:36:49,696 --> 00:36:50,396
ML integration.


1314
00:36:51,146 --> 00:36:52,766
Last year, we presented


1315
00:36:52,766 --> 00:36:53,836
integration with Vision and Core


1316
00:36:53,836 --> 00:36:55,496
ML, and we showed how you can


1317
00:36:55,496 --> 00:36:57,066
run Core ML models through


1318
00:36:57,066 --> 00:36:57,596
Vision API.


1319
00:36:57,596 --> 00:36:59,776
The advantage of doing that was


1320
00:36:59,776 --> 00:37:01,706
that you can use 1 over 5


1321
00:37:01,816 --> 00:37:03,236
different overloads of the image


1322
00:37:03,236 --> 00:37:04,916
request handler to translate the


1323
00:37:04,916 --> 00:37:06,266
image that you have in your hand


1324
00:37:06,586 --> 00:37:08,976
to the image type, size, and


1325
00:37:08,976 --> 00:37:10,416
color scheme that the Core ML


1326
00:37:10,416 --> 00:37:11,266
model requires.


1327
00:37:12,246 --> 00:37:13,256
We will run the inference for


1328
00:37:13,256 --> 00:37:15,016
you, and we'll pack the outputs


1329
00:37:15,016 --> 00:37:16,436
or results coming from Core ML


1330
00:37:16,436 --> 00:37:17,886
model into Vision observations.


1331
00:37:20,716 --> 00:37:22,426
Now, if you have a different


1332
00:37:22,426 --> 00:37:23,696
task in mind, for example, if


1333
00:37:23,696 --> 00:37:24,646
you want to do image style


1334
00:37:24,646 --> 00:37:26,066
transfer, you need to have at


1335
00:37:26,066 --> 00:37:27,416
least two images, the image


1336
00:37:27,416 --> 00:37:29,056
content and the image style.


1337
00:37:29,256 --> 00:37:30,356
You may also need to have some


1338
00:37:30,356 --> 00:37:31,816
mixed ratio saying how much of a


1339
00:37:31,926 --> 00:37:33,386
style needs to be applied on the


1340
00:37:33,386 --> 00:37:33,826
content.


1341
00:37:34,306 --> 00:37:35,506
So, I have three parameters now.


1342
00:37:36,826 --> 00:37:37,886
Well, this year we're going to


1343
00:37:37,886 --> 00:37:39,666
introduce API where we can use


1344
00:37:39,666 --> 00:37:41,716
multiple inputs through Vision


1345
00:37:41,896 --> 00:37:43,476
to Core ML, and that's including


1346
00:37:43,476 --> 00:37:44,426
multi-image inputs.


1347
00:37:44,426 --> 00:37:47,696
Also, on the output section,


1348
00:37:48,186 --> 00:37:49,346
this sample shows only one


1349
00:37:49,346 --> 00:37:49,686
output.


1350
00:37:49,686 --> 00:37:50,616
But, for example, if you had


1351
00:37:50,616 --> 00:37:52,116
more than one, especially if you


1352
00:37:52,116 --> 00:37:53,376
have more than one of the same


1353
00:37:53,376 --> 00:37:55,256
type, it's hard to distinguish


1354
00:37:55,256 --> 00:37:56,356
them when they come in forms of


1355
00:37:56,356 --> 00:37:57,946
observation later on.


1356
00:37:58,416 --> 00:37:59,616
So, what we do this year, we


1357
00:37:59,616 --> 00:38:00,646
introduce a new field in the


1358
00:38:00,646 --> 00:38:02,616
observation that maps exactly to


1359
00:38:02,616 --> 00:38:04,376
the name that shows up here in


1360
00:38:04,376 --> 00:38:05,056
the output section.


1361
00:38:06,216 --> 00:38:07,696
Let's take a look at the inputs


1362
00:38:07,696 --> 00:38:08,316
and outputs.


1363
00:38:08,316 --> 00:38:09,316
We will use them in the next


1364
00:38:09,316 --> 00:38:09,576
slide.


1365
00:38:12,936 --> 00:38:14,136
This is the code snippet that


1366
00:38:14,176 --> 00:38:16,816
represents how to use Core ML


1367
00:38:16,956 --> 00:38:17,396
through Vision.


1368
00:38:18,676 --> 00:38:20,236
The highlighted sections show


1369
00:38:20,446 --> 00:38:21,256
what's new this year.


1370
00:38:21,716 --> 00:38:22,796
Let's keep them for now, and


1371
00:38:22,796 --> 00:38:23,896
we'll go over the code, and


1372
00:38:23,896 --> 00:38:25,316
we'll return to them later.


1373
00:38:26,156 --> 00:38:27,466
In order to run Core ML through


1374
00:38:27,466 --> 00:38:29,446
Vision, first you need to log


1375
00:38:29,446 --> 00:38:30,236
your Core ML model.


1376
00:38:31,266 --> 00:38:32,926
Then, you need to create Vision


1377
00:38:32,926 --> 00:38:34,956
CoreMLmodel wrapper around it.


1378
00:38:35,726 --> 00:38:37,476
Then, you need to create Vision


1379
00:38:37,476 --> 00:38:39,346
CoreMLRequest and pass in that


1380
00:38:39,346 --> 00:38:39,676
wrapper.


1381
00:38:41,266 --> 00:38:42,326
Then you create


1382
00:38:42,556 --> 00:38:44,136
ImageRequestHandler, you process


1383
00:38:44,136 --> 00:38:45,446
your request, and you look at


1384
00:38:45,446 --> 00:38:46,086
the results.


1385
00:38:47,386 --> 00:38:49,596
Now, with the new API that we


1386
00:38:49,596 --> 00:38:51,596
added this year, that only image


1387
00:38:51,596 --> 00:38:53,116
that you could use last year is


1388
00:38:53,116 --> 00:38:54,986
the default or the main image is


1389
00:38:54,986 --> 00:38:56,276
the image that is passing to


1390
00:38:56,476 --> 00:38:58,046
ImageRequestHandler, but that's


1391
00:38:58,046 --> 00:38:59,526
also the image whose name needs


1392
00:38:59,526 --> 00:39:01,126
to be assigned to input feature


1393
00:39:01,506 --> 00:39:03,456
name field of the CoreMLModel


1394
00:39:03,456 --> 00:39:03,796
wrapper.


1395
00:39:05,026 --> 00:39:06,886
All other parameters whether


1396
00:39:06,886 --> 00:39:08,646
images or not will have to be


1397
00:39:08,716 --> 00:39:10,406
passed through feature provider


1398
00:39:10,446 --> 00:39:11,686
property of the CoreMLModel


1399
00:39:11,686 --> 00:39:12,016
wrapper.


1400
00:39:12,376 --> 00:39:14,036
As you can see, image style and


1401
00:39:14,036 --> 00:39:15,436
mixed ratio are passed in that


1402
00:39:15,436 --> 00:39:15,666
way.


1403
00:39:16,956 --> 00:39:18,336
Finally, when you look at the


1404
00:39:18,336 --> 00:39:19,506
results, you can look at the


1405
00:39:19,786 --> 00:39:21,386
feature name property of the


1406
00:39:21,386 --> 00:39:22,646
observation that comes out, and


1407
00:39:22,646 --> 00:39:24,186
you can compare it in this case


1408
00:39:24,186 --> 00:39:25,246
against image result.


1409
00:39:25,506 --> 00:39:26,656
That's exactly the name that


1410
00:39:26,656 --> 00:39:27,706
appears in the output section of


1411
00:39:27,756 --> 00:39:29,066
Core ML, and that way you can


1412
00:39:29,096 --> 00:39:30,006
process your results


1413
00:39:30,146 --> 00:39:30,666
accordingly.


1414
00:39:32,636 --> 00:39:33,626
This slide actually concludes


1415
00:39:33,626 --> 00:39:34,666
our presentation for today.


1416
00:39:34,966 --> 00:39:36,076
For more information you can


1417
00:39:36,076 --> 00:39:37,136
refer to the links on the slide.


1418
00:39:37,466 --> 00:39:39,276
Thank you, and have a great rest


1419
00:39:39,276 --> 00:39:39,976
of your WWDC.


1420
00:39:40,016 --> 00:39:42,000
[ Applause ]

