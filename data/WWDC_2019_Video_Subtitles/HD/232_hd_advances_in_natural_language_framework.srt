1
00:00:00,506 --> 00:00:04,500
[ Music ]


2
00:00:07,516 --> 00:00:11,286
[ Applause ]


3
00:00:11,786 --> 00:00:12,636
>> Hello and good afternoon


4
00:00:12,636 --> 00:00:13,076
everyone.


5
00:00:13,546 --> 00:00:14,736
Welcome to our session on


6
00:00:14,736 --> 00:00:15,976
Natural Language Processing.


7
00:00:16,566 --> 00:00:18,266
I'm Vivek, and I'll be jointly


8
00:00:18,266 --> 00:00:19,656
presenting this session with my


9
00:00:19,656 --> 00:00:20,806
colleague, Doug Davidson.


10
00:00:21,646 --> 00:00:23,086
Let's get started.


11
00:00:23,716 --> 00:00:26,076
As you know, text is ubiquitous.


12
00:00:26,836 --> 00:00:27,796
You see it everywhere.


13
00:00:28,436 --> 00:00:29,826
If you think of how users


14
00:00:29,826 --> 00:00:31,256
interact with text in apps,


15
00:00:31,906 --> 00:00:33,286
there are two primary modes in


16
00:00:33,286 --> 00:00:34,796
which they interact.


17
00:00:34,796 --> 00:00:36,376
One, is through Natural Language


18
00:00:36,456 --> 00:00:38,996
input, wherein the user is


19
00:00:39,036 --> 00:00:41,036
writing text or generating text


20
00:00:41,266 --> 00:00:42,296
within the application.


21
00:00:43,176 --> 00:00:44,326
For instance, the user may be


22
00:00:44,326 --> 00:00:46,136
typing text on the keyboard


23
00:00:46,136 --> 00:00:48,266
inside the app.


24
00:00:48,526 --> 00:00:49,996
Examples of apps are, for


25
00:00:49,996 --> 00:00:51,506
example, messages where you're


26
00:00:51,506 --> 00:00:53,566
writing text and sharing it with


27
00:00:53,566 --> 00:00:55,456
other people, notes, or any


28
00:00:55,456 --> 00:00:56,956
productivity app where you're


29
00:00:56,956 --> 00:00:58,156
writing text as part of the


30
00:00:58,156 --> 00:00:58,776
application.


31
00:01:00,246 --> 00:01:01,136
The other sort of user


32
00:01:01,136 --> 00:01:03,126
interaction with text in apps is


33
00:01:03,126 --> 00:01:05,626
through Natural Language output


34
00:01:06,046 --> 00:01:07,696
wherein the app presents the


35
00:01:07,696 --> 00:01:09,126
text content to the user, and


36
00:01:09,286 --> 00:01:11,176
the user is consuming or reading


37
00:01:11,176 --> 00:01:11,706
this text.


38
00:01:12,836 --> 00:01:14,256
If you think of an application,


39
00:01:14,436 --> 00:01:17,346
like Apple News, the information


40
00:01:17,346 --> 00:01:18,466
or text is presented to the


41
00:01:18,466 --> 00:01:20,106
user, and the user is reading


42
00:01:20,106 --> 00:01:20,796
this information.


43
00:01:21,666 --> 00:01:24,116
So, both in cases of text input


44
00:01:24,226 --> 00:01:26,686
and text output, in order to


45
00:01:26,686 --> 00:01:28,366
extract actionable intelligence


46
00:01:28,546 --> 00:01:30,346
out of raw text, Natural


47
00:01:30,346 --> 00:01:31,686
Language processing is really


48
00:01:31,686 --> 00:01:32,146
important.


49
00:01:32,146 --> 00:01:34,816
And last year, we introduced the


50
00:01:34,816 --> 00:01:36,086
Natural Language Framework.


51
00:01:36,796 --> 00:01:38,236
The Natural Language Framework


52
00:01:38,406 --> 00:01:41,016
is the NLP workhorse for all


53
00:01:41,016 --> 00:01:42,346
things across all Apple


54
00:01:42,346 --> 00:01:42,796
platforms.


55
00:01:43,406 --> 00:01:44,476
So, we provide several


56
00:01:44,546 --> 00:01:46,256
fundamental NLP building blocks


57
00:01:46,696 --> 00:01:48,276
such as language identification,


58
00:01:48,276 --> 00:01:49,796
tokenization, part of speech


59
00:01:49,796 --> 00:01:51,666
tagging, and so on, and we


60
00:01:51,666 --> 00:01:53,036
present these functionalities


61
00:01:53,036 --> 00:01:54,846
and provide this across several


62
00:01:54,846 --> 00:01:55,796
different languages.


63
00:01:55,796 --> 00:01:58,456
And we do this by seamlessly


64
00:01:58,456 --> 00:02:00,156
blending linguistics and machine


65
00:02:00,156 --> 00:02:01,516
learning so that you can just


66
00:02:01,516 --> 00:02:03,356
focus on building your apps by


67
00:02:03,356 --> 00:02:05,526
using these APIs, and we do all


68
00:02:05,526 --> 00:02:07,066
of the heavy lifting under the


69
00:02:07,616 --> 00:02:07,706
hood.


70
00:02:08,336 --> 00:02:09,955
Now, if you step back and look


71
00:02:09,955 --> 00:02:11,306
at all of these functionalities,


72
00:02:11,536 --> 00:02:13,466
actually if you look at most NLP


73
00:02:13,466 --> 00:02:14,936
functionalities, they can be


74
00:02:14,936 --> 00:02:16,676
broken down into two broad


75
00:02:17,006 --> 00:02:19,176
categories of tasks.


76
00:02:19,176 --> 00:02:20,936
One is text classification.


77
00:02:21,066 --> 00:02:22,796
And the objective in text


78
00:02:22,796 --> 00:02:24,866
classification is given a piece


79
00:02:24,866 --> 00:02:26,286
of text, and this text can


80
00:02:26,286 --> 00:02:28,266
either be a sentence, can be a


81
00:02:28,266 --> 00:02:30,256
paragraph, or a document, you


82
00:02:30,256 --> 00:02:31,566
would like to assign labels to


83
00:02:31,566 --> 00:02:33,336
this piece of text, and these


84
00:02:33,336 --> 00:02:35,096
labels can be sentiment labels,


85
00:02:35,096 --> 00:02:36,486
topic labels, or any labels that


86
00:02:36,486 --> 00:02:37,096
you want to assign.


87
00:02:38,426 --> 00:02:40,036
The other category of tasks by


88
00:02:40,036 --> 00:02:41,696
NLP is called word tagging.


89
00:02:41,696 --> 00:02:43,576
And the task here or the


90
00:02:43,576 --> 00:02:45,176
objective here is given a


91
00:02:45,176 --> 00:02:46,756
sequence of words or what we


92
00:02:46,756 --> 00:02:48,606
call is tokens, we would like to


93
00:02:48,606 --> 00:02:50,796
assign a label to every token in


94
00:02:50,796 --> 00:02:51,456
this sequence.


95
00:02:51,656 --> 00:02:54,366
And this year, we have exciting


96
00:02:54,366 --> 00:02:55,986
new APIs in both text


97
00:02:55,986 --> 00:02:57,476
classification as well as word


98
00:02:57,476 --> 00:02:57,776
tagging.


99
00:02:57,776 --> 00:02:59,646
Let's start off with the first


100
00:02:59,646 --> 00:03:00,976
one, which is sentiment


101
00:03:00,976 --> 00:03:01,616
analysis.


102
00:03:02,356 --> 00:03:04,016
Sentiment analysis is a text


103
00:03:04,016 --> 00:03:05,666
classification API, this is a


104
00:03:05,666 --> 00:03:07,946
new API, and it works this way.


105
00:03:08,536 --> 00:03:09,766
What you do is you bring your


106
00:03:09,766 --> 00:03:11,496
text, and you pass your text to


107
00:03:11,496 --> 00:03:14,016
this API, and the API analyzes


108
00:03:14,046 --> 00:03:15,816
the text and gives you out a


109
00:03:15,816 --> 00:03:16,656
sentiment score.


110
00:03:17,466 --> 00:03:18,666
Now this sentiment score


111
00:03:18,786 --> 00:03:20,536
captures the degree of sentiment


112
00:03:20,536 --> 00:03:21,686
that is contained in your text.


113
00:03:22,786 --> 00:03:24,106
You provide a sentiment score


114
00:03:24,106 --> 00:03:26,626
from -1 to +1, which indicates


115
00:03:26,626 --> 00:03:27,516
the degree of sentiment.


116
00:03:28,216 --> 00:03:29,516
For instance, if you have -1, it


117
00:03:29,516 --> 00:03:31,396
indicates a very strong negative


118
00:03:31,396 --> 00:03:33,256
sentiment, and +1 indicates a


119
00:03:33,256 --> 00:03:34,336
very positive sentiment.


120
00:03:34,886 --> 00:03:36,056
So, essentially we provide the


121
00:03:36,056 --> 00:03:37,506
score and let you calibrate the


122
00:03:37,506 --> 00:03:38,846
score for your application.


123
00:03:39,036 --> 00:03:41,356
As an example, if you had a


124
00:03:41,356 --> 00:03:42,836
sentence such as we had a fun


125
00:03:42,836 --> 00:03:44,386
time in Hawaii with the family,


126
00:03:44,586 --> 00:03:45,946
the API might give you a score


127
00:03:45,946 --> 00:03:48,166
of 0.8, which shows that this


128
00:03:48,166 --> 00:03:50,476
sentence is a positive sentence.


129
00:03:51,616 --> 00:03:52,756
In contrast, if you had a


130
00:03:52,796 --> 00:03:54,266
sentence such as we had a not so


131
00:03:54,266 --> 00:03:55,656
fun time in Hawaii because mom


132
00:03:55,656 --> 00:03:57,166
twisted her ankle, well that's


133
00:03:57,166 --> 00:03:59,156
not positive, so you get a score


134
00:03:59,156 --> 00:04:00,956
of minus 0.8, and you can


135
00:04:00,956 --> 00:04:02,446
calibrate that to be a negative


136
00:04:02,446 --> 00:04:02,836
sentiment.


137
00:04:04,126 --> 00:04:05,466
This is great; how do you use


138
00:04:05,466 --> 00:04:05,576
it?


139
00:04:06,376 --> 00:04:07,676
It's really simple to use.


140
00:04:08,006 --> 00:04:09,646
So those of you who are used to


141
00:04:09,646 --> 00:04:11,036
using NaturalLanguage, this is


142
00:04:11,036 --> 00:04:11,886
extremely easy.


143
00:04:12,416 --> 00:04:13,736
You import NaturalLanguage.


144
00:04:14,236 --> 00:04:15,496
You create an instance of


145
00:04:15,536 --> 00:04:17,766
NLTagger and all that you do now


146
00:04:17,836 --> 00:04:19,646
is specify a new tag scheme.


147
00:04:19,786 --> 00:04:21,676
And the new tag scheme is called


148
00:04:21,676 --> 00:04:22,456
sentiment score.


149
00:04:23,266 --> 00:04:25,116
Once you do this, you attach the


150
00:04:25,116 --> 00:04:26,466
string that you want to analyze


151
00:04:26,466 --> 00:04:28,256
to the tagger, and you simply


152
00:04:28,256 --> 00:04:29,576
ask for the sentiment score


153
00:04:29,906 --> 00:04:31,666
either at the sentence level or


154
00:04:31,666 --> 00:04:32,446
the paragraph level.


155
00:04:33,476 --> 00:04:34,996
Now let's see this in action.


156
00:04:36,316 --> 00:04:37,576
So what we have here is a


157
00:04:37,576 --> 00:04:38,516
hypothetical app.


158
00:04:38,876 --> 00:04:40,106
It's a cheese application.


159
00:04:40,596 --> 00:04:42,766
And as part of this application,


160
00:04:42,766 --> 00:04:44,246
users can do a bunch of things.


161
00:04:44,536 --> 00:04:45,726
They can write notes about


162
00:04:45,726 --> 00:04:46,136
cheese.


163
00:04:46,416 --> 00:04:47,946
They can write reviews, express


164
00:04:47,946 --> 00:04:49,016
their opinions about different


165
00:04:49,016 --> 00:04:49,756
kinds of cheese.


166
00:04:50,176 --> 00:04:51,496
So, even though this application


167
00:04:51,496 --> 00:04:53,156
is about cheese, there's nothing


168
00:04:53,156 --> 00:04:53,886
cheesy about it.


169
00:04:53,886 --> 00:04:55,436
It really deals with the finer


170
00:04:55,436 --> 00:04:56,276
points of cheese.


171
00:04:56,656 --> 00:04:57,846
And what I'm going to show you


172
00:04:57,846 --> 00:05:00,646
here is a user writing a review,


173
00:05:01,066 --> 00:05:03,006
and as the user is writing the


174
00:05:03,006 --> 00:05:05,036
review, the text gets passed to


175
00:05:05,036 --> 00:05:06,286
the sentiment classification


176
00:05:06,286 --> 00:05:09,246
API, we get a score, and we


177
00:05:09,316 --> 00:05:10,746
color the text based on the


178
00:05:10,746 --> 00:05:11,416
sentiment score.


179
00:05:11,726 --> 00:05:13,646
So, let's see, if you were to


180
00:05:13,646 --> 00:05:15,496
type something like fantastic


181
00:05:16,336 --> 00:05:19,016
taste, really delicious, you can


182
00:05:19,016 --> 00:05:19,926
see this is a positive


183
00:05:19,926 --> 00:05:20,386
sentiment.


184
00:05:21,796 --> 00:05:24,886
In contrast, if you said great


185
00:05:24,886 --> 00:05:28,306
at first but a horrible


186
00:05:28,306 --> 00:05:30,296
aftertaste, you see that this is


187
00:05:30,296 --> 00:05:32,006
a negative sentiment, right.


188
00:05:32,276 --> 00:05:33,936
And what you also realize here


189
00:05:33,936 --> 00:05:35,726
is all of this can be happening


190
00:05:35,726 --> 00:05:36,386
in real time.


191
00:05:36,746 --> 00:05:38,046
That's because the API is


192
00:05:38,046 --> 00:05:39,156
extremely performing.


193
00:05:39,556 --> 00:05:41,126
It uses a Neural Network model


194
00:05:41,126 --> 00:05:43,206
underneath, and it's hardware


195
00:05:43,206 --> 00:05:44,516
activated across all Apple


196
00:05:44,516 --> 00:05:46,336
platforms, so essentially, you


197
00:05:46,336 --> 00:05:47,616
can do this in real time.


198
00:05:48,756 --> 00:05:49,846
And we support the sentiment


199
00:05:49,846 --> 00:05:51,936
analysis API in seven different


200
00:05:51,936 --> 00:05:53,966
languages, English, French,


201
00:05:54,016 --> 00:05:55,596
Italian, German, Spanish,


202
00:05:55,636 --> 00:05:57,176
Portuguese, and simplified


203
00:05:57,176 --> 00:05:57,646
Chinese.


204
00:05:58,176 --> 00:05:58,916
I think you're really going to


205
00:05:58,916 --> 00:05:59,436
like this.


206
00:06:00,516 --> 00:06:06,546
[ Applause ]


207
00:06:07,046 --> 00:06:08,126
And, of course, all of this is


208
00:06:08,126 --> 00:06:09,656
happening completely on device,


209
00:06:09,656 --> 00:06:11,026
and the user data never has to


210
00:06:11,026 --> 00:06:11,536
leave the device.


211
00:06:11,896 --> 00:06:13,216
We bring all that power on


212
00:06:13,216 --> 00:06:13,786
device to you.


213
00:06:14,756 --> 00:06:16,306
I like to just spend a brief


214
00:06:16,306 --> 00:06:17,926
moment on language assets.


215
00:06:18,296 --> 00:06:19,746
As I mentioned, the NLP


216
00:06:19,746 --> 00:06:21,246
functionalities are quite


217
00:06:21,896 --> 00:06:23,476
diverse, and we provide this in


218
00:06:23,476 --> 00:06:24,646
several different languages.


219
00:06:25,176 --> 00:06:26,186
Now, for users of our


220
00:06:26,186 --> 00:06:28,006
applications, we make sure that


221
00:06:28,006 --> 00:06:29,986
they always have the assets in


222
00:06:29,986 --> 00:06:31,136
the language they're interested


223
00:06:31,136 --> 00:06:31,286
in.


224
00:06:31,856 --> 00:06:33,316
But for you, for development


225
00:06:33,316 --> 00:06:34,686
purposes, you might be


226
00:06:34,686 --> 00:06:36,546
interested in getting assets on


227
00:06:36,546 --> 00:06:36,846
demand.


228
00:06:36,846 --> 00:06:38,266
This is in fact a very common


229
00:06:38,266 --> 00:06:39,286
request that we've heard from


230
00:06:39,286 --> 00:06:40,716
several of you, and we're


231
00:06:40,716 --> 00:06:42,746
introducing a new convenience


232
00:06:42,746 --> 00:06:44,236
API called Request Assets.


233
00:06:44,686 --> 00:06:46,076
So, you can trigger off a


234
00:06:46,076 --> 00:06:48,336
download for a particular asset


235
00:06:48,576 --> 00:06:49,216
on demand.


236
00:06:49,436 --> 00:06:50,896
You just specify the language


237
00:06:50,896 --> 00:06:51,836
and the tag scheme that you're


238
00:06:51,836 --> 00:06:53,306
interested in, and we'll fork


239
00:06:53,306 --> 00:06:54,076
off a download in the


240
00:06:54,076 --> 00:06:55,186
background, and the next


241
00:06:55,276 --> 00:06:56,476
opportune moment you're going to


242
00:06:56,476 --> 00:06:57,736
get the assets on your device.


243
00:06:57,736 --> 00:06:59,376
So, this is really going to help


244
00:06:59,376 --> 00:07:00,226
you with development and


245
00:07:00,226 --> 00:07:01,866
increase your productivity as


246
00:07:01,866 --> 00:07:03,476
you're building your apps.


247
00:07:05,156 --> 00:07:06,366
So, we talked about text


248
00:07:06,366 --> 00:07:07,226
classification.


249
00:07:07,226 --> 00:07:08,616
Now let's shift our attention to


250
00:07:08,616 --> 00:07:09,856
Word Tagging.


251
00:07:10,956 --> 00:07:12,486
To just refresh your memory,


252
00:07:12,486 --> 00:07:14,616
Word Tagging is a task where


253
00:07:14,616 --> 00:07:16,116
given a sequence of tokens we'd


254
00:07:16,116 --> 00:07:17,576
like to assign a label to every


255
00:07:17,576 --> 00:07:18,896
single token in the sequence.


256
00:07:19,086 --> 00:07:21,776
As an example here, we could


257
00:07:21,856 --> 00:07:23,056
assign a bunch of tokens


258
00:07:23,056 --> 00:07:24,246
different labels.


259
00:07:24,376 --> 00:07:25,546
Timothy is a person name.


260
00:07:25,546 --> 00:07:27,326
Switzerland is a location, and


261
00:07:27,326 --> 00:07:28,736
we have a bunch of nouns here in


262
00:07:28,736 --> 00:07:29,366
this sentence.


263
00:07:30,466 --> 00:07:31,226
Now, this is great.


264
00:07:31,226 --> 00:07:32,736
If you're just looking to do


265
00:07:32,736 --> 00:07:34,556
named entity recognition using


266
00:07:34,556 --> 00:07:36,346
our APIs or part of speech


267
00:07:36,346 --> 00:07:37,976
tagging using our APIs, this is


268
00:07:37,976 --> 00:07:39,616
fine, but there are several


269
00:07:39,616 --> 00:07:41,006
instances where you want to do


270
00:07:41,006 --> 00:07:42,386
something that's more customized


271
00:07:42,386 --> 00:07:43,096
to your task.


272
00:07:43,826 --> 00:07:44,736
You don't want to know just


273
00:07:44,736 --> 00:07:46,456
Gruyere cheese are two nouns,


274
00:07:46,816 --> 00:07:48,296
but what you want to do is you


275
00:07:48,296 --> 00:07:49,256
want to know that it's Swiss


276
00:07:49,256 --> 00:07:49,626
cheese.


277
00:07:49,736 --> 00:07:50,426
Of course, we are building a


278
00:07:50,426 --> 00:07:52,106
cheese application, you want to


279
00:07:52,106 --> 00:07:53,136
get this information out.


280
00:07:53,856 --> 00:07:55,626
But, the default tagger doesn't


281
00:07:55,626 --> 00:07:56,696
have any information about


282
00:07:56,756 --> 00:07:57,966
cheese, so how are we going to


283
00:07:57,966 --> 00:07:58,846
provide this information?


284
00:07:59,446 --> 00:08:00,926
So, we have a new functionality


285
00:08:01,336 --> 00:08:02,526
in Natural Language Framework


286
00:08:02,526 --> 00:08:04,366
that we call a Text Catalog.


287
00:08:05,646 --> 00:08:07,326
A Text Catalog is very simple.


288
00:08:07,866 --> 00:08:09,446
What you do is you provide your


289
00:08:09,446 --> 00:08:11,446
custom list, and this can be a


290
00:08:11,446 --> 00:08:13,036
very large list of entities.


291
00:08:13,276 --> 00:08:14,546
For each of the entities in your


292
00:08:14,546 --> 00:08:15,666
list, you have a label.


293
00:08:16,556 --> 00:08:18,476
In practice, these lists can be


294
00:08:18,476 --> 00:08:20,026
millions or even like, you know,


295
00:08:20,026 --> 00:08:21,046
a couple of hundred millions.


296
00:08:21,856 --> 00:08:23,416
What you do is you pass this


297
00:08:23,676 --> 00:08:25,646
sort of a dictionary into Create


298
00:08:25,646 --> 00:08:27,596
ML, create an instance of


299
00:08:27,596 --> 00:08:29,316
MLGazetteer, and Gazetteer is


300
00:08:29,316 --> 00:08:30,746
just a terminology that we use


301
00:08:31,026 --> 00:08:32,196
interchangeably with Text


302
00:08:32,196 --> 00:08:34,015
Catalog, and what you get as an


303
00:08:34,015 --> 00:08:35,436
output is a Text Catalog.


304
00:08:35,785 --> 00:08:37,145
Now, this is an extremely


305
00:08:37,216 --> 00:08:39,006
compressed and efficient form of


306
00:08:39,006 --> 00:08:40,066
the input dictionary that you


307
00:08:40,066 --> 00:08:40,456
provided.


308
00:08:41,015 --> 00:08:43,736
It's very simple to use.


309
00:08:43,856 --> 00:08:45,056
What you do is you provide this


310
00:08:45,056 --> 00:08:45,486
dictionary.


311
00:08:45,486 --> 00:08:46,956
As I mentioned, we can't show


312
00:08:46,956 --> 00:08:48,066
your million entries here.


313
00:08:48,066 --> 00:08:49,166
We're just showing as an example


314
00:08:49,166 --> 00:08:50,546
a few entries, but this can be


315
00:08:50,546 --> 00:08:52,086
an extremely large dictionary.


316
00:08:53,406 --> 00:08:54,916
Once you do that, you can create


317
00:08:54,916 --> 00:08:56,946
an instance of MLGazetteer, pass


318
00:08:56,946 --> 00:08:58,846
the dictionary, and you write it


319
00:08:58,846 --> 00:08:59,326
out to disc.


320
00:08:59,776 --> 00:09:01,026
It looks really innocuous.


321
00:09:01,026 --> 00:09:02,386
You might be thinking, I'm just


322
00:09:02,386 --> 00:09:03,386
writing a dictionary to disc.


323
00:09:03,386 --> 00:09:04,236
What are you doing here?


324
00:09:05,176 --> 00:09:06,866
Something magical happens when


325
00:09:06,866 --> 00:09:07,896
you make the right call.


326
00:09:08,516 --> 00:09:10,536
Create ML calls Natural Language


327
00:09:10,596 --> 00:09:12,246
under the hood, and Natural


328
00:09:12,246 --> 00:09:13,916
Language takes this very large


329
00:09:13,956 --> 00:09:15,566
dictionary and compresses it


330
00:09:15,706 --> 00:09:17,306
into a bloom filter, which is an


331
00:09:17,306 --> 00:09:18,286
extremely compact


332
00:09:18,286 --> 00:09:19,946
representation, and what you get


333
00:09:19,946 --> 00:09:21,586
as an output is a Text Catalog.


334
00:09:22,426 --> 00:09:24,046
In fact, we've used this to


335
00:09:24,046 --> 00:09:25,146
create effect internally.


336
00:09:25,146 --> 00:09:27,466
We've been able to compress


337
00:09:27,876 --> 00:09:29,166
almost all the person,


338
00:09:29,166 --> 00:09:30,986
organization, and location names


339
00:09:30,986 --> 00:09:32,536
in Wikipedia, which is almost


340
00:09:32,536 --> 00:09:33,916
two and a half million names,


341
00:09:34,306 --> 00:09:35,726
into two megabytes on disc.


342
00:09:36,136 --> 00:09:39,206
Sort of implicitly you've been


343
00:09:39,206 --> 00:09:40,136
using this model.


344
00:09:40,356 --> 00:09:41,466
When you call the named entity


345
00:09:41,466 --> 00:09:42,476
recognition API in


346
00:09:42,476 --> 00:09:44,306
NaturalLanguage, in conjunction


347
00:09:44,306 --> 00:09:45,386
with the statistical model,


348
00:09:45,386 --> 00:09:47,146
you're using this bloom filter


349
00:09:47,146 --> 00:09:48,636
and Gazetteer and now we are


350
00:09:48,636 --> 00:09:51,816
bringing that power to you.


351
00:09:51,896 --> 00:09:53,906
Once you create a Gazetteer or a


352
00:09:53,906 --> 00:09:55,726
Text Catalog, using it is


353
00:09:55,726 --> 00:09:57,276
extremely easy.


354
00:09:58,116 --> 00:09:59,666
You create an instance of


355
00:09:59,696 --> 00:10:01,376
MLGazetteer by specifying the


356
00:10:01,376 --> 00:10:03,576
path to the Text Catalog that


357
00:10:03,576 --> 00:10:06,616
you just wrote out to disc.


358
00:10:06,616 --> 00:10:08,036
You can work with your favorite


359
00:10:08,036 --> 00:10:08,706
tag scheme here.


360
00:10:08,706 --> 00:10:09,826
It can be lexical class.


361
00:10:09,826 --> 00:10:11,246
It can be name type, any tag


362
00:10:11,246 --> 00:10:12,836
scheme, and you can simply


363
00:10:12,836 --> 00:10:14,286
attach your Gazetteer to this


364
00:10:14,286 --> 00:10:14,756
tag scheme.


365
00:10:15,636 --> 00:10:17,696
Once you do this, every time you


366
00:10:17,696 --> 00:10:19,456
have a piece of text, this


367
00:10:19,456 --> 00:10:20,976
customized Gazetteer is going to


368
00:10:20,976 --> 00:10:22,736
override the default tags that


369
00:10:22,736 --> 00:10:23,916
NaturalLanguage provides.


370
00:10:25,246 --> 00:10:26,886
Consequently, you can customize


371
00:10:26,886 --> 00:10:27,526
your application.


372
00:10:28,646 --> 00:10:29,456
Now, if you go back to the


373
00:10:29,486 --> 00:10:30,876
cheese application, and if you


374
00:10:30,876 --> 00:10:32,626
have a sentence such as lighter


375
00:10:32,626 --> 00:10:34,196
than Camembert or Vacherin, you


376
00:10:34,196 --> 00:10:36,796
can use your Text Catalog for


377
00:10:36,846 --> 00:10:39,956
cheese and identify that one is


378
00:10:39,956 --> 00:10:41,116
a French cheese, and the other


379
00:10:41,116 --> 00:10:42,596
is a Swiss cheese, and you can


380
00:10:42,596 --> 00:10:44,076
perhaps hyperlink it and create


381
00:10:44,076 --> 00:10:45,586
a much more cooler application


382
00:10:45,586 --> 00:10:46,116
out of this.


383
00:10:46,586 --> 00:10:49,306
So that's one way to use Text


384
00:10:49,306 --> 00:10:51,686
Catalog in a word tagger in


385
00:10:51,686 --> 00:10:52,726
NaturalLanguage for this


386
00:10:52,726 --> 00:10:53,066
release.


387
00:10:53,626 --> 00:10:56,386
So we've talked about text


388
00:10:56,386 --> 00:10:57,246
classification.


389
00:10:57,246 --> 00:10:58,676
We've talked about word tagging.


390
00:10:59,356 --> 00:11:01,086
But the field of NLP has moved


391
00:11:01,086 --> 00:11:02,846
significantly in the past few


392
00:11:02,846 --> 00:11:04,676
years, and there have been the


393
00:11:04,676 --> 00:11:06,036
without catalysts for this


394
00:11:06,126 --> 00:11:06,586
change.


395
00:11:07,436 --> 00:11:08,916
One is the notion of Word


396
00:11:08,916 --> 00:11:10,876
Embeddings, and Word Embeddings


397
00:11:10,946 --> 00:11:12,006
are nothing but vector


398
00:11:12,006 --> 00:11:13,206
representation of words.


399
00:11:13,206 --> 00:11:15,876
And the other one is the use of


400
00:11:15,876 --> 00:11:17,986
Neural Networks in NLP.


401
00:11:19,056 --> 00:11:21,056
We are delighted to tell you


402
00:11:21,386 --> 00:11:22,576
that we are bringing both these


403
00:11:22,576 --> 00:11:24,056
things to your apps in


404
00:11:24,056 --> 00:11:25,366
NaturalLanguage this year.


405
00:11:25,946 --> 00:11:28,446
So, let's start off with Word


406
00:11:28,446 --> 00:11:28,956
Embeddings.


407
00:11:29,436 --> 00:11:30,166
Thank you.


408
00:11:31,596 --> 00:11:33,606
Before we jump or dive into Word


409
00:11:33,606 --> 00:11:34,996
Embeddings, I'd like to spend a


410
00:11:34,996 --> 00:11:36,426
couple of slides talking about


411
00:11:36,426 --> 00:11:37,726
what an embedding is.


412
00:11:37,726 --> 00:11:40,336
At a conceptual level, embedding


413
00:11:40,336 --> 00:11:41,896
is nothing but a mapping from a


414
00:11:41,896 --> 00:11:43,946
discrete set of objects into a


415
00:11:43,946 --> 00:11:44,726
continuous vector


416
00:11:44,726 --> 00:11:45,376
representation.


417
00:11:46,046 --> 00:11:47,186
So, you have these bunch of


418
00:11:47,186 --> 00:11:48,026
discrete objects.


419
00:11:48,466 --> 00:11:50,356
Each object in this set can be


420
00:11:50,356 --> 00:11:51,816
represented by some sort of a


421
00:11:51,816 --> 00:11:52,536
finite vector.


422
00:11:52,536 --> 00:11:54,176
In this example, we're showing


423
00:11:54,176 --> 00:11:55,466
it with a 3-dimensional vector.


424
00:11:56,146 --> 00:11:57,096
Three dimensions because it's


425
00:11:57,146 --> 00:11:59,236
easy to plot and visualize, but


426
00:11:59,236 --> 00:12:01,176
in reality, these vectors can be


427
00:12:01,176 --> 00:12:02,476
of arbitrary dimensions.


428
00:12:02,786 --> 00:12:04,556
You can have 100 dimensions, 300


429
00:12:04,556 --> 00:12:05,966
dimensions, or in some cases


430
00:12:06,266 --> 00:12:07,656
even 1000 dimensional vector.


431
00:12:08,756 --> 00:12:10,146
Now, the neat property about


432
00:12:10,146 --> 00:12:11,926
these embeddings is that when


433
00:12:11,926 --> 00:12:13,326
you plot these embeddings,


434
00:12:14,176 --> 00:12:15,456
objects that are similar


435
00:12:15,556 --> 00:12:16,896
semantically are clustered


436
00:12:16,896 --> 00:12:17,316
together.


437
00:12:18,446 --> 00:12:19,976
So, in this example, if you had


438
00:12:19,976 --> 00:12:21,306
to look at the paint can and the


439
00:12:21,306 --> 00:12:22,826
paint roller, they are clustered


440
00:12:22,826 --> 00:12:23,246
together.


441
00:12:24,376 --> 00:12:25,716
Or, if you had to look at the


442
00:12:25,716 --> 00:12:27,166
sneakers and the high heels,


443
00:12:27,376 --> 00:12:28,276
they are clustered together.


444
00:12:28,716 --> 00:12:30,206
So, this is a very neat property


445
00:12:30,206 --> 00:12:30,896
of embeddings.


446
00:12:31,096 --> 00:12:33,086
And this property of embeddings


447
00:12:33,086 --> 00:12:34,806
is not only proof of words but


448
00:12:34,806 --> 00:12:36,046
actually across several


449
00:12:36,046 --> 00:12:37,126
different modalities.


450
00:12:37,646 --> 00:12:38,576
You can think of image


451
00:12:38,576 --> 00:12:39,066
embeddings.


452
00:12:39,166 --> 00:12:40,826
When you take an image and pass


453
00:12:40,826 --> 00:12:42,876
it through a VGG network or any


454
00:12:42,876 --> 00:12:43,946
sort of a convolution Neural


455
00:12:43,946 --> 00:12:45,456
Network, the feature that you


456
00:12:45,456 --> 00:12:47,266
get as an output is nothing but


457
00:12:47,266 --> 00:12:48,046
an image embedding.


458
00:12:48,986 --> 00:12:49,836
Similarly, you can have


459
00:12:49,836 --> 00:12:51,696
embeddings for words, for


460
00:12:51,696 --> 00:12:54,016
phrases, and when you work with


461
00:12:54,016 --> 00:12:55,676
recommendation systems where


462
00:12:55,676 --> 00:12:57,136
you're working with song titles


463
00:12:57,136 --> 00:12:58,656
or product names, they are


464
00:12:58,656 --> 00:13:00,076
represented by using a vector.


465
00:13:00,526 --> 00:13:01,456
So, they are nothing but just


466
00:13:01,506 --> 00:13:02,066
embeddings.


467
00:13:02,926 --> 00:13:04,326
So, in summary, embedding is


468
00:13:04,326 --> 00:13:06,506
nothing but a mapping from a


469
00:13:06,506 --> 00:13:08,376
string into a continuous


470
00:13:08,376 --> 00:13:09,996
sequence of numbers or a vector


471
00:13:09,996 --> 00:13:10,556
of numbers.


472
00:13:11,076 --> 00:13:15,026
We've actually used these


473
00:13:15,066 --> 00:13:16,836
embeddings very successfully in


474
00:13:16,836 --> 00:13:18,656
iOS 12, and let me tell you how


475
00:13:18,656 --> 00:13:19,836
we use this in Photos.


476
00:13:21,226 --> 00:13:23,236
In Photos search, when you type


477
00:13:23,316 --> 00:13:24,426
a particular term that you're


478
00:13:24,426 --> 00:13:26,366
looking for, maybe pictures of a


479
00:13:26,416 --> 00:13:28,506
thunderstorm, what we do


480
00:13:28,506 --> 00:13:29,936
underneath the hood is all the


481
00:13:29,936 --> 00:13:31,756
images in your photo library are


482
00:13:31,756 --> 00:13:33,086
indexed by using a convolution


483
00:13:33,086 --> 00:13:33,626
Neural Network.


484
00:13:33,626 --> 00:13:35,106
And the output of the


485
00:13:35,106 --> 00:13:36,466
convolution Neural Network is


486
00:13:36,466 --> 00:13:37,696
fixed to some certain number of


487
00:13:37,696 --> 00:13:39,566
classes, perhaps to 1000 classes


488
00:13:39,566 --> 00:13:40,556
or 2000 classes.


489
00:13:41,426 --> 00:13:42,406
Now, if your convolution Neural


490
00:13:42,406 --> 00:13:43,666
Network doesn't know what


491
00:13:43,666 --> 00:13:45,506
thunderstorm is, you will never


492
00:13:45,506 --> 00:13:46,716
find the pictures that were


493
00:13:46,716 --> 00:13:48,476
indexed because they didn't have


494
00:13:48,476 --> 00:13:50,396
the term thunderstorm, but with


495
00:13:50,396 --> 00:13:52,466
the power of Word Embeddings, we


496
00:13:52,466 --> 00:13:53,646
know that thunderstorm is


497
00:13:53,646 --> 00:13:55,076
actually related to sky and


498
00:13:55,076 --> 00:13:56,986
cloudy, and those are labels


499
00:13:57,876 --> 00:13:58,936
that your convolution Neural


500
00:13:58,936 --> 00:13:59,996
Network understands.


501
00:14:00,386 --> 00:14:02,266
So, by doing this, in iOS 12,


502
00:14:02,266 --> 00:14:04,366
you're able to enable fuzzy


503
00:14:04,366 --> 00:14:06,416
search in Photos search by using


504
00:14:06,416 --> 00:14:07,076
Word Embeddings.


505
00:14:07,706 --> 00:14:09,396
So, as a consequence of this,


506
00:14:09,666 --> 00:14:11,676
you can find the images through


507
00:14:11,676 --> 00:14:12,876
the power of Word Embeddings.


508
00:14:12,876 --> 00:14:14,006
In fact, it can be applied to


509
00:14:14,006 --> 00:14:15,216
any search application.


510
00:14:15,466 --> 00:14:16,716
If you want to do fuzzy search


511
00:14:16,716 --> 00:14:18,226
and you have a string, you can


512
00:14:18,226 --> 00:14:19,426
use the Word Embedding to get


513
00:14:19,426 --> 00:14:20,756
neighbors related to that


514
00:14:20,756 --> 00:14:21,946
original word.


515
00:14:22,656 --> 00:14:24,826
Having said that, what can you


516
00:14:24,826 --> 00:14:25,846
do with an embedding?


517
00:14:26,676 --> 00:14:27,696
There are four primary


518
00:14:27,696 --> 00:14:29,066
operations that you can do with


519
00:14:29,066 --> 00:14:29,716
Word Embeddings.


520
00:14:30,556 --> 00:14:32,486
One is, given a word, you can


521
00:14:32,716 --> 00:14:33,926
obviously get the vector for


522
00:14:33,926 --> 00:14:34,466
that word.


523
00:14:35,576 --> 00:14:37,486
Given two words, you can find


524
00:14:37,486 --> 00:14:38,716
the distance between two words


525
00:14:39,116 --> 00:14:40,356
because for each of those words,


526
00:14:40,356 --> 00:14:41,156
you can look at the


527
00:14:41,156 --> 00:14:42,356
corresponding vectors.


528
00:14:42,616 --> 00:14:44,446
So, if I say dog and cat and ask


529
00:14:44,446 --> 00:14:45,576
for the distance, I'm going to


530
00:14:45,576 --> 00:14:46,816
get a distance, and that


531
00:14:46,816 --> 00:14:47,866
distance is going to be pretty


532
00:14:47,866 --> 00:14:48,996
close to each other.


533
00:14:49,886 --> 00:14:51,976
If I say dog and a boot, those


534
00:14:51,976 --> 00:14:53,706
are fairly distant in the


535
00:14:53,706 --> 00:14:55,246
semantic space, and you're going


536
00:14:55,246 --> 00:14:56,426
to get something that's much


537
00:14:56,606 --> 00:14:57,366
higher distance.


538
00:14:58,546 --> 00:14:59,696
The third thing that you can do


539
00:14:59,696 --> 00:15:01,086
is get the nearest neighbors for


540
00:15:01,086 --> 00:15:02,916
a word, and this probably is by


541
00:15:02,916 --> 00:15:04,676
far the most popular way of


542
00:15:04,676 --> 00:15:06,106
using word embeddings, and the


543
00:15:06,106 --> 00:15:07,516
Photos search application that I


544
00:15:07,516 --> 00:15:08,886
just showed you was doing


545
00:15:08,886 --> 00:15:10,236
exactly that.


546
00:15:10,236 --> 00:15:11,736
Given a word, you're looking for


547
00:15:11,736 --> 00:15:12,936
nearest neighbors of a word.


548
00:15:12,936 --> 00:15:15,836
Last but not the least is you


549
00:15:15,836 --> 00:15:17,056
can also get the nearest


550
00:15:17,246 --> 00:15:19,376
neighbors for a vector, so let's


551
00:15:19,376 --> 00:15:20,776
assume that you have a sentence,


552
00:15:20,836 --> 00:15:22,116
and you have multiple words in


553
00:15:22,116 --> 00:15:23,726
the sentence, and for each of


554
00:15:23,726 --> 00:15:25,176
the words in the sentence, you


555
00:15:25,176 --> 00:15:26,276
can get the word embedding, you


556
00:15:26,326 --> 00:15:27,516
can sum it up.


557
00:15:27,516 --> 00:15:28,886
So what you get is a new vector,


558
00:15:28,886 --> 00:15:31,036
and given that vector, you can


559
00:15:31,036 --> 00:15:32,466
ask for all the words that are


560
00:15:32,466 --> 00:15:33,266
close to that vector.


561
00:15:33,266 --> 00:15:35,046
That's a neat way of using Word


562
00:15:35,046 --> 00:15:35,576
Embeddings too.


563
00:15:35,576 --> 00:15:38,186
So a lot of stuff about Word


564
00:15:38,186 --> 00:15:39,396
Embeddings, but the most


565
00:15:39,396 --> 00:15:40,476
important thing is we are


566
00:15:40,476 --> 00:15:42,436
providing this easy for you to


567
00:15:42,436 --> 00:15:43,786
use on the OS.


568
00:15:44,076 --> 00:15:45,326
So, we're delighted to tell you


569
00:15:45,456 --> 00:15:46,906
that these Word Embeddings come


570
00:15:46,906 --> 00:15:48,396
on the OS in seven different


571
00:15:48,396 --> 00:15:50,206
languages for you to use, and


572
00:15:50,206 --> 00:15:51,426
all of the functionalities I


573
00:15:51,456 --> 00:15:53,366
just mentioned, you can use it


574
00:15:53,496 --> 00:15:54,946
with one or two lines of code.


575
00:15:55,386 --> 00:15:56,686
So, we're supporting it in seven


576
00:15:56,686 --> 00:15:58,406
languages from English, Spanish,


577
00:15:58,406 --> 00:15:59,686
French, Italian, German,


578
00:15:59,766 --> 00:16:01,226
Portuguese, and simplified


579
00:16:01,226 --> 00:16:01,706
Chinese.


580
00:16:02,986 --> 00:16:04,146
Now, this is great.


581
00:16:04,146 --> 00:16:05,546
The OS embeddings are generally


582
00:16:05,626 --> 00:16:07,536
framed on general corpora, large


583
00:16:07,536 --> 00:16:09,016
amounts of text, billions and


584
00:16:09,016 --> 00:16:09,866
billions of words.


585
00:16:10,406 --> 00:16:11,936
So, they have a general notion


586
00:16:12,056 --> 00:16:14,126
of what a relationship with a


587
00:16:14,126 --> 00:16:15,156
particular word is.


588
00:16:15,876 --> 00:16:17,226
But many a time, you want to do


589
00:16:17,226 --> 00:16:18,216
something that's even more


590
00:16:18,296 --> 00:16:18,716
custom.


591
00:16:19,846 --> 00:16:21,016
So, perhaps you're working with


592
00:16:21,216 --> 00:16:22,366
different sort of domains,


593
00:16:22,926 --> 00:16:24,206
something in the medical domain


594
00:16:24,206 --> 00:16:25,566
or the legal domain or the


595
00:16:25,566 --> 00:16:26,316
financial domain.


596
00:16:27,046 --> 00:16:28,286
So, if your domain is very


597
00:16:28,286 --> 00:16:30,316
different, and the vocabulary of


598
00:16:30,316 --> 00:16:31,916
words that you want to use in


599
00:16:31,916 --> 00:16:33,076
your application is extremely


600
00:16:33,076 --> 00:16:34,806
different, or maybe you just


601
00:16:34,806 --> 00:16:36,076
want to train a word embedding


602
00:16:36,076 --> 00:16:37,426
for a language that's not


603
00:16:37,426 --> 00:16:39,746
supported on the OS, how do you


604
00:16:39,746 --> 00:16:40,886
do that?


605
00:16:40,886 --> 00:16:41,966
We have a provision for that


606
00:16:42,076 --> 00:16:42,466
too.


607
00:16:43,366 --> 00:16:45,096
You can use and bring custom


608
00:16:45,096 --> 00:16:45,786
word embeddings.


609
00:16:46,506 --> 00:16:47,246
So, those of you who are


610
00:16:47,246 --> 00:16:48,466
familiar with word embeddings


611
00:16:48,466 --> 00:16:50,166
and have seen this field evolve,


612
00:16:50,166 --> 00:16:51,856
there are many third-party tools


613
00:16:51,856 --> 00:16:53,576
to train your own embedding such


614
00:16:53,576 --> 00:16:55,866
as word2vec, GloVe, fasttext.


615
00:16:56,366 --> 00:16:57,906
So, you can bring your own text


616
00:16:58,306 --> 00:16:59,666
or you can even use a Custom


617
00:16:59,666 --> 00:17:01,726
Neural Network that you train


618
00:17:01,726 --> 00:17:01,793
in Keras TensorFlow or PyTorch.


619
00:17:01,793 --> 00:17:04,756
So, go from raw data, you can


620
00:17:04,756 --> 00:17:06,756
build your own embeddings, or


621
00:17:06,756 --> 00:17:07,935
you can go to any one of these


622
00:17:07,935 --> 00:17:09,256
websites and download their


623
00:17:09,256 --> 00:17:10,526
pretrained word embeddings.


624
00:17:11,205 --> 00:17:13,106
Now, the challenge there is when


625
00:17:13,106 --> 00:17:14,185
you download any of these


626
00:17:14,185 --> 00:17:15,425
embeddings, they are very, very


627
00:17:15,425 --> 00:17:15,866
large.


628
00:17:16,256 --> 00:17:17,336
They're 1 gigabyte or 2


629
00:17:17,336 --> 00:17:18,306
gigabytes in size.


630
00:17:18,695 --> 00:17:19,826
But you want to use it in your


631
00:17:19,826 --> 00:17:20,896
app in a very compact and


632
00:17:20,896 --> 00:17:22,945
efficient way, and we do just


633
00:17:23,006 --> 00:17:23,266
that.


634
00:17:23,266 --> 00:17:25,336
When you bring these embeddings


635
00:17:25,606 --> 00:17:26,915
from third-party applications


636
00:17:26,915 --> 00:17:28,406
and they're really large, we


637
00:17:28,406 --> 00:17:30,076
automatically compress them into


638
00:17:30,076 --> 00:17:32,296
a very compact format, and once


639
00:17:32,296 --> 00:17:33,576
you have this compact format,


640
00:17:33,746 --> 00:17:35,446
you can use it just like how you


641
00:17:35,446 --> 00:17:36,716
use the OS embeddings.


642
00:17:37,436 --> 00:17:38,666
But to tell you how you use


643
00:17:38,666 --> 00:17:40,206
these embeddings, both the OS as


644
00:17:40,206 --> 00:17:41,746
well as the custom, I'm going to


645
00:17:41,746 --> 00:17:42,836
turn it over to Doug, who is


646
00:17:42,936 --> 00:17:45,666
going to do a demo and then walk


647
00:17:45,666 --> 00:17:46,426
you through the rest of the


648
00:17:46,426 --> 00:17:46,786
session.


649
00:17:47,426 --> 00:17:48,066
Over to you, Doug.


650
00:17:49,516 --> 00:17:55,836
[ Applause ]


651
00:17:56,336 --> 00:17:57,036
>> All right.


652
00:17:57,036 --> 00:17:58,196
So, let's go over to the demo


653
00:17:58,196 --> 00:18:00,066
machine here, and let's see some


654
00:18:00,066 --> 00:18:00,976
of this in action.


655
00:18:01,656 --> 00:18:02,986
So, the first thing I've done


656
00:18:02,986 --> 00:18:04,796
here is to write a very tiny


657
00:18:04,796 --> 00:18:06,496
demo application that helps us


658
00:18:06,496 --> 00:18:08,566
explore Word Embeddings.


659
00:18:08,606 --> 00:18:10,456
So, I type a word in here, and


660
00:18:10,456 --> 00:18:11,636
it shows us the nearest


661
00:18:11,636 --> 00:18:13,676
neighbor, nearest neighbors of


662
00:18:13,676 --> 00:18:15,296
that word in embedding space.


663
00:18:15,636 --> 00:18:16,826
Let's start by using the


664
00:18:16,826 --> 00:18:18,976
built-in OS Word Embeddings for


665
00:18:18,976 --> 00:18:19,456
English.


666
00:18:19,806 --> 00:18:21,466
So, I type a word like chair,


667
00:18:21,666 --> 00:18:23,076
and we see the nearest neighbors


668
00:18:23,076 --> 00:18:24,476
of chair are words that are


669
00:18:24,476 --> 00:18:25,886
similar in meaning to chair,


670
00:18:25,886 --> 00:18:28,246
sofa, couch, and so forth, or I


671
00:18:28,246 --> 00:18:29,636
could type in something like


672
00:18:29,716 --> 00:18:31,116
bicycle.


673
00:18:31,796 --> 00:18:33,466
And the nearest neighbors, bike


674
00:18:33,466 --> 00:18:34,666
and motorcycle and so forth,


675
00:18:34,666 --> 00:18:36,166
these are words that are close


676
00:18:36,166 --> 00:18:38,596
in meaning to bicycle or maybe


677
00:18:39,216 --> 00:18:39,596
book.


678
00:18:40,406 --> 00:18:41,256
And we get words that are


679
00:18:41,256 --> 00:18:42,576
similar in meaning to book.


680
00:18:43,026 --> 00:18:44,616
So, what we can see from this,


681
00:18:44,936 --> 00:18:46,746
we can understand that the


682
00:18:46,746 --> 00:18:48,316
built-in OS Word Embeddings


683
00:18:48,716 --> 00:18:50,826
represent the ordinary meanings


684
00:18:50,826 --> 00:18:52,936
of words and the language and


685
00:18:53,006 --> 00:18:54,736
recognize the similarity of


686
00:18:54,776 --> 00:18:57,876
meanings as expressed in general


687
00:18:57,876 --> 00:18:59,206
text in that language.


688
00:19:00,206 --> 00:19:02,596
But, of course, what I'm really


689
00:19:02,596 --> 00:19:04,686
interested in here is knowing


690
00:19:05,066 --> 00:19:06,216
what do these embeddings


691
00:19:06,216 --> 00:19:08,916
understand about cheese, because


692
00:19:08,916 --> 00:19:09,976
we're dealing with a cheese


693
00:19:09,976 --> 00:19:10,726
application here.


694
00:19:11,426 --> 00:19:12,936
So, let me type in a cheese


695
00:19:12,936 --> 00:19:13,246
word.


696
00:19:14,556 --> 00:19:16,156
And take a look here, and what I


697
00:19:16,156 --> 00:19:18,996
can see right away is that these


698
00:19:18,996 --> 00:19:21,446
built-in embeddings do know what


699
00:19:21,446 --> 00:19:23,846
cheese is, but I'm very


700
00:19:23,846 --> 00:19:24,506
disappointed.


701
00:19:24,966 --> 00:19:26,196
I can see these embeddings know


702
00:19:26,196 --> 00:19:27,566
nothing about the finer points


703
00:19:27,566 --> 00:19:28,206
of cheese.


704
00:19:29,406 --> 00:19:31,086
Otherwise, they would never have


705
00:19:31,086 --> 00:19:32,796
put these particular cheeses and


706
00:19:32,796 --> 00:19:34,086
cheese-related things together.


707
00:19:34,086 --> 00:19:35,436
They don't go together at all.


708
00:19:36,236 --> 00:19:37,706
What I really want here is


709
00:19:37,706 --> 00:19:39,136
something that understands the


710
00:19:39,136 --> 00:19:40,486
relationships of cheeses.


711
00:19:40,776 --> 00:19:42,046
So, I've taken the opportunity


712
00:19:42,046 --> 00:19:44,316
to train my own custom cheese


713
00:19:44,316 --> 00:19:46,446
embedding that puts cheeses


714
00:19:46,446 --> 00:19:47,316
together based on their


715
00:19:47,316 --> 00:19:48,016
similarity.


716
00:19:48,936 --> 00:19:50,116
And let's switch over to it.


717
00:19:51,436 --> 00:19:52,616
So, here are the neighbors of


718
00:19:52,616 --> 00:19:54,276
cheddar in my own custom cheese


719
00:19:54,276 --> 00:19:54,716
embedding.


720
00:19:54,966 --> 00:19:55,806
This is much better.


721
00:19:56,586 --> 00:19:57,786
We can see that it puts near


722
00:19:57,786 --> 00:19:59,646
cheddar, it puts some fine


723
00:20:00,216 --> 00:20:01,596
cheeses that are similar to


724
00:20:01,596 --> 00:20:03,446
cheddar in texture like our


725
00:20:03,446 --> 00:20:05,096
Lancashires, Double Gloucester,


726
00:20:05,096 --> 00:20:05,676
and Cheshire.


727
00:20:06,666 --> 00:20:07,826
So this is something that we can


728
00:20:07,826 --> 00:20:09,356
use in our cheese application.


729
00:20:09,946 --> 00:20:10,896
So, let's take a look at the


730
00:20:10,896 --> 00:20:12,886
cheese application now.


731
00:20:15,426 --> 00:20:16,476
So, I've been trying out some


732
00:20:16,476 --> 00:20:17,646
ideas for our cheese


733
00:20:17,646 --> 00:20:18,266
application.


734
00:20:18,266 --> 00:20:20,676
Let's see how this looks.


735
00:20:21,226 --> 00:20:22,276
So, when the user types


736
00:20:22,276 --> 00:20:23,406
something in, the first thing


737
00:20:23,406 --> 00:20:25,486
I'm going to do is get a


738
00:20:25,486 --> 00:20:27,826
sentiment score on it to see and


739
00:20:27,826 --> 00:20:30,066
check does this represent a


740
00:20:30,066 --> 00:20:31,446
sentence with a positive


741
00:20:31,446 --> 00:20:34,146
sentiment, and if it does, then


742
00:20:34,146 --> 00:20:35,436
I'm going to go through it using


743
00:20:35,436 --> 00:20:39,156
my tagger using, of course, our


744
00:20:39,156 --> 00:20:41,776
custom cheese Gazetteer to see


745
00:20:41,776 --> 00:20:43,116
whether the user mentioned any


746
00:20:43,146 --> 00:20:44,656
cheeses in it.


747
00:20:45,356 --> 00:20:47,076
And so I'll look for a cheese,


748
00:20:47,126 --> 00:20:48,826
and if the user did mention a


749
00:20:48,826 --> 00:20:50,736
cheese, then I'm going to pass


750
00:20:50,736 --> 00:20:52,296
it through my custom cheese


751
00:20:52,296 --> 00:20:55,146
embedding to find similar


752
00:20:55,146 --> 00:20:56,366
related cheeses.


753
00:20:57,426 --> 00:20:58,336
Sounds plausible?


754
00:20:58,336 --> 00:21:01,386
Let's try it out.


755
00:21:01,656 --> 00:21:02,726
Let's bring up our cheese


756
00:21:02,726 --> 00:21:08,816
application, and so I visited


757
00:21:08,816 --> 00:21:10,136
the Netherlands last year, and I


758
00:21:10,136 --> 00:21:11,796
fell in love with Dutch cheeses,


759
00:21:11,796 --> 00:21:15,826
so I'm going to tell my app


760
00:21:16,636 --> 00:21:16,986
that.


761
00:21:16,986 --> 00:21:19,616
So, this is a certainly a


762
00:21:19,616 --> 00:21:20,686
sentence with a positive


763
00:21:20,686 --> 00:21:22,716
sentiment, and it does reference


764
00:21:22,716 --> 00:21:24,006
a particular cheese.


765
00:21:24,416 --> 00:21:27,586
So, I go through, and now my app


766
00:21:27,876 --> 00:21:29,336
can make recommendations of


767
00:21:29,336 --> 00:21:31,216
cheeses that are similar to the


768
00:21:31,216 --> 00:21:32,296
one that I mentioned here.


769
00:21:33,376 --> 00:21:35,186
So, this shows of the power of


770
00:21:35,226 --> 00:21:36,946
Word Embeddings, but even more


771
00:21:36,946 --> 00:21:39,166
than that, it shows how the


772
00:21:39,166 --> 00:21:40,626
natural, various NaturalLanguage


773
00:21:40,626 --> 00:21:43,566
APIs can come together for


774
00:21:43,566 --> 00:21:44,906
application functionality.


775
00:21:46,516 --> 00:21:50,736
[ Applause ]


776
00:21:51,236 --> 00:21:52,656
So, now, let's go back to the


777
00:21:52,656 --> 00:21:54,976
slides, and I want to review


778
00:21:54,976 --> 00:21:57,496
briefly how this looks in API.


779
00:21:58,466 --> 00:22:00,546
So, if you want to use a


780
00:22:00,666 --> 00:22:02,926
built-in OS Word Embedding, it's


781
00:22:02,926 --> 00:22:03,546
very simple.


782
00:22:03,806 --> 00:22:04,996
All you do is ask for it.


783
00:22:05,206 --> 00:22:06,696
Ask for the word embedding for a


784
00:22:06,696 --> 00:22:07,876
particular language, and we'll


785
00:22:07,876 --> 00:22:08,346
give it to you.


786
00:22:08,346 --> 00:22:10,976
Once you have one of these NL


787
00:22:10,976 --> 00:22:12,766
embedding objects, there are


788
00:22:12,766 --> 00:22:13,936
various things you can do with


789
00:22:13,936 --> 00:22:14,106
it.


790
00:22:14,536 --> 00:22:15,736
You can, of course, get the


791
00:22:15,736 --> 00:22:16,886
components, the vector


792
00:22:16,886 --> 00:22:18,866
components, corresponding to any


793
00:22:18,866 --> 00:22:19,856
particular entry.


794
00:22:21,136 --> 00:22:22,476
You can find the distance


795
00:22:22,476 --> 00:22:24,326
between two words, be it short


796
00:22:24,326 --> 00:22:26,436
or far, in embedding space.


797
00:22:27,346 --> 00:22:28,936
And as we saw in our cheese


798
00:22:28,936 --> 00:22:30,676
application, you can go through


799
00:22:30,676 --> 00:22:32,166
and find the nearest neighbors


800
00:22:32,596 --> 00:22:35,296
of any particular item in this


801
00:22:35,426 --> 00:22:37,186
embedding space.


802
00:22:37,796 --> 00:22:40,436
If you want to use a custom word


803
00:22:40,436 --> 00:22:43,346
embedding, then to create it,


804
00:22:43,346 --> 00:22:46,496
you go over to Create ML, and


805
00:22:46,546 --> 00:22:48,486
you need, of course, all of the


806
00:22:48,486 --> 00:22:50,316
vectors that represent your


807
00:22:50,316 --> 00:22:50,846
embedding.


808
00:22:51,186 --> 00:22:52,596
I can't really show them all to


809
00:22:52,596 --> 00:22:53,986
you right here in the slide


810
00:22:53,986 --> 00:22:55,536
because there are 50 or 100


811
00:22:55,856 --> 00:22:57,736
components long, but here's an


812
00:22:57,736 --> 00:22:59,906
example of what they look like.


813
00:22:59,906 --> 00:23:01,146
In practice, you're probably


814
00:23:01,176 --> 00:23:02,396
going to be bringing them in


815
00:23:02,396 --> 00:23:04,486
from a file using the various


816
00:23:04,486 --> 00:23:06,656
Create ML facilities for loading


817
00:23:06,656 --> 00:23:07,746
data from files.


818
00:23:08,076 --> 00:23:12,476
And then you just create a word


819
00:23:12,476 --> 00:23:15,336
embedding object from it and


820
00:23:15,336 --> 00:23:16,376
write it out to disc.


821
00:23:16,376 --> 00:23:18,056
Now, what's going on when you do


822
00:23:18,056 --> 00:23:18,376
this?


823
00:23:19,036 --> 00:23:22,256
Well, in practice, these


824
00:23:22,256 --> 00:23:23,796
embeddings tend to be quite


825
00:23:23,796 --> 00:23:25,936
large, hundreds of dimensions


826
00:23:25,936 --> 00:23:27,206
times thousands of entries.


827
00:23:27,206 --> 00:23:30,066
It could be huge, and they could


828
00:23:30,066 --> 00:23:32,206
take a lot of space on disc,


829
00:23:32,776 --> 00:23:34,846
naively and be expensive to


830
00:23:34,846 --> 00:23:35,286
search.


831
00:23:35,856 --> 00:23:38,336
But when you compile them into


832
00:23:38,336 --> 00:23:41,416
our word embedding object, then


833
00:23:41,416 --> 00:23:43,836
under the hood what we do is we


834
00:23:43,836 --> 00:23:46,346
use a product quantization


835
00:23:46,346 --> 00:23:47,906
technique to achieve a high


836
00:23:47,906 --> 00:23:50,856
degree of compression, and we


837
00:23:50,856 --> 00:23:53,336
add indexes so you can do fast


838
00:23:53,506 --> 00:23:55,456
searching for nearest neighbors,


839
00:23:55,456 --> 00:23:56,926
as you saw in our examples.


840
00:23:57,606 --> 00:23:59,196
Just try this out.


841
00:23:59,626 --> 00:24:00,926
We took some very large


842
00:24:00,926 --> 00:24:02,766
embeddings that are readily


843
00:24:02,766 --> 00:24:04,256
available as open source.


844
00:24:04,446 --> 00:24:06,456
This is some GloVe and fasttext


845
00:24:06,456 --> 00:24:06,916
embeddings.


846
00:24:06,916 --> 00:24:08,876
These are a gigabyte or 2


847
00:24:08,876 --> 00:24:11,046
gigabytes in uncompressed form.


848
00:24:11,686 --> 00:24:13,956
When we put them into our NL


849
00:24:13,956 --> 00:24:15,606
embedding compressed format,


850
00:24:16,206 --> 00:24:17,736
they're only tens of megabytes,


851
00:24:18,136 --> 00:24:19,086
and you can search through them


852
00:24:19,086 --> 00:24:20,146
for nearest neighbors in just a


853
00:24:20,146 --> 00:24:21,176
couple of milliseconds.


854
00:24:23,056 --> 00:24:23,976
Closer to home--


855
00:24:24,516 --> 00:24:27,716
[ Applause ]


856
00:24:28,216 --> 00:24:30,146
For an example, closer to home,


857
00:24:30,266 --> 00:24:32,406
Apple does a lot with podcasts,


858
00:24:32,536 --> 00:24:34,516
so our podcast group, we talked


859
00:24:34,516 --> 00:24:36,616
to them, and they, as it


860
00:24:36,616 --> 00:24:38,226
happens, have an embedding for


861
00:24:38,226 --> 00:24:40,426
podcasts that represents the


862
00:24:40,426 --> 00:24:42,786
similarity of various podcasts,


863
00:24:42,786 --> 00:24:43,686
one to another.


864
00:24:44,346 --> 00:24:46,196
So, we thought we'd try it out


865
00:24:46,226 --> 00:24:48,186
and see what would happen if we


866
00:24:48,186 --> 00:24:49,886
took this embedding and put it


867
00:24:49,886 --> 00:24:51,826
into our NL embedding format.


868
00:24:52,456 --> 00:24:54,156
So this embedding represents


869
00:24:54,156 --> 00:24:57,466
66,000 different podcasts, and


870
00:24:57,466 --> 00:24:59,486
source form is 167 megabytes,


871
00:24:59,526 --> 00:25:00,906
but we compress it down to just


872
00:25:00,906 --> 00:25:02,976
3 megabytes on disc.


873
00:25:03,326 --> 00:25:05,716
So what NL embedding does is it


874
00:25:05,716 --> 00:25:08,246
makes it practical to include


875
00:25:08,246 --> 00:25:10,376
these embeddings and use them on


876
00:25:11,036 --> 00:25:12,616
, on the device, in your


877
00:25:12,616 --> 00:25:13,236
application.


878
00:25:16,716 --> 00:25:17,276
All right.


879
00:25:17,996 --> 00:25:19,716
So, next I want to switch and


880
00:25:19,716 --> 00:25:22,646
talk about another thing that's


881
00:25:22,646 --> 00:25:24,976
related to Word Embeddings, and


882
00:25:24,976 --> 00:25:26,886
that is Transfer Learning for


883
00:25:26,956 --> 00:25:28,036
Text Classification.


884
00:25:29,356 --> 00:25:31,886
So, I'd like to start by talking


885
00:25:31,886 --> 00:25:33,516
a little bit about what we do,


886
00:25:33,516 --> 00:25:36,806
what it is we do when we train a


887
00:25:36,806 --> 00:25:37,936
text classifier.


888
00:25:39,176 --> 00:25:40,886
So, when we're training a text


889
00:25:40,886 --> 00:25:44,076
classifier, we give it a set of


890
00:25:44,076 --> 00:25:47,096
examples for various classes.


891
00:25:47,636 --> 00:25:50,476
You can pass that in to Create


892
00:25:50,476 --> 00:25:50,826
ML.


893
00:25:50,826 --> 00:25:52,346
Create ML will call on Natural


894
00:25:52,346 --> 00:25:52,946
Language.


895
00:25:53,506 --> 00:25:55,766
We will trained a classifier and


896
00:25:55,876 --> 00:25:58,136
out will come a Core ML model.


897
00:25:58,506 --> 00:26:00,686
And what we hope is that these


898
00:26:00,686 --> 00:26:04,256
examples will give sufficient


899
00:26:04,576 --> 00:26:06,626
information about the various


900
00:26:06,686 --> 00:26:08,546
classes that the model can


901
00:26:08,546 --> 00:26:11,916
generalize to classify examples


902
00:26:11,916 --> 00:26:12,926
that it hasn't seen.


903
00:26:13,406 --> 00:26:15,126
And, of course, we have already


904
00:26:15,366 --> 00:26:17,786
shipped this last year, and we


905
00:26:17,786 --> 00:26:20,566
have algorithms for training


906
00:26:20,566 --> 00:26:23,136
these models, most notably our


907
00:26:23,136 --> 00:26:24,846
standard algorithm is what we


908
00:26:24,846 --> 00:26:26,926
call the maxEnt algorithm, based


909
00:26:26,926 --> 00:26:27,966
on logistic compression.


910
00:26:28,336 --> 00:26:30,266
It's very fast, robust, and


911
00:26:30,266 --> 00:26:30,816
effective.


912
00:26:31,666 --> 00:26:35,126
But one thing about it is it


913
00:26:35,126 --> 00:26:36,876
doesn't know anything except


914
00:26:36,876 --> 00:26:39,076
what it learns from the training


915
00:26:39,076 --> 00:26:41,846
data that you give it.


916
00:26:42,116 --> 00:26:45,566
So, you have to make sure that


917
00:26:45,566 --> 00:26:46,876
the training material you give


918
00:26:46,876 --> 00:26:50,736
it covers essentially all of the


919
00:26:50,736 --> 00:26:52,296
sort of things that you expect


920
00:26:52,296 --> 00:26:55,156
to see in examples in practice.


921
00:26:55,386 --> 00:26:57,336
So, in some sense, we've done


922
00:26:57,336 --> 00:26:58,736
the easy part of creating the


923
00:26:58,736 --> 00:27:00,136
algorithm and left you the hard


924
00:27:00,136 --> 00:27:02,276
part of producing the training


925
00:27:02,966 --> 00:27:03,096
data.


926
00:27:03,716 --> 00:27:06,916
But, wouldn't it be nice if we


927
00:27:06,916 --> 00:27:09,216
could take advantage of prior


928
00:27:09,216 --> 00:27:11,386
knowledge of the language and


929
00:27:12,316 --> 00:27:14,736
then maybe use that in


930
00:27:14,766 --> 00:27:16,966
conjunction with some smaller


931
00:27:16,966 --> 00:27:18,526
amount of training material that


932
00:27:18,526 --> 00:27:21,366
you have to provide in order to


933
00:27:21,366 --> 00:27:24,616
train a model that would combine


934
00:27:24,696 --> 00:27:26,886
these two and so hopefully


935
00:27:26,886 --> 00:27:28,736
understand more about the


936
00:27:28,736 --> 00:27:31,176
examples it's going to see with


937
00:27:31,176 --> 00:27:32,496
less in the way of training


938
00:27:32,496 --> 00:27:33,046
material.


939
00:27:34,426 --> 00:27:36,686
And so this is the promise of


940
00:27:36,856 --> 00:27:37,866
Transfer Learning.


941
00:27:38,576 --> 00:27:41,036
This is a highly active research


942
00:27:41,036 --> 00:27:43,876
area in NLP, and I'm happy to


943
00:27:43,876 --> 00:27:45,786
say we have a solution for this


944
00:27:46,136 --> 00:27:47,326
that we're delivering now.


945
00:27:48,286 --> 00:27:50,426
Again, NaturalLanguage trains a


946
00:27:50,426 --> 00:27:52,396
model, and the outcome is a Core


947
00:27:52,396 --> 00:27:52,946
ML model.


948
00:27:53,326 --> 00:27:54,916
But how are we going to


949
00:27:54,916 --> 00:27:56,966
incorporate previous knowledge


950
00:27:56,966 --> 00:27:57,696
of the language?


951
00:27:58,026 --> 00:27:58,886
Where are we going to get it?


952
00:27:59,946 --> 00:28:03,966
Well, Word Embeddings provide a


953
00:28:04,006 --> 00:28:05,806
great deal of knowledge of the


954
00:28:05,806 --> 00:28:06,376
language.


955
00:28:06,376 --> 00:28:07,656
In particular, they know quite a


956
00:28:07,656 --> 00:28:10,626
bit about the meaning of words.


957
00:28:11,296 --> 00:28:13,996
So, our solution uses Word


958
00:28:13,996 --> 00:28:16,026
Embeddings, takes the training


959
00:28:16,026 --> 00:28:18,056
material you provide, puts them


960
00:28:18,056 --> 00:28:19,466
through the Word Embeddings, and


961
00:28:19,466 --> 00:28:21,686
then on top of that we train a


962
00:28:21,686 --> 00:28:25,596
Neural Network model, and that


963
00:28:26,096 --> 00:28:27,986
is what we provide as a Transfer


964
00:28:27,986 --> 00:28:30,026
Learning Text Classification


965
00:28:30,026 --> 00:28:30,456
model.


966
00:28:31,556 --> 00:28:32,686
Now, there's a lot of work going


967
00:28:32,686 --> 00:28:34,716
on here, but if you want to use


968
00:28:34,716 --> 00:28:36,786
it, all you have to do is ask


969
00:28:36,786 --> 00:28:37,156
for it.


970
00:28:38,496 --> 00:28:42,416
You just change one parameter in


971
00:28:42,416 --> 00:28:43,566
the specification of the


972
00:28:43,566 --> 00:28:45,436
algorithm that you want when


973
00:28:45,436 --> 00:28:46,516
training a Transfer Learning


974
00:28:46,516 --> 00:28:46,876
model.


975
00:28:47,216 --> 00:28:48,566
Now, there are a few different


976
00:28:48,566 --> 00:28:49,366
options here.


977
00:28:50,056 --> 00:28:52,776
So, the first one, most obvious


978
00:28:52,776 --> 00:28:54,696
is, you can use the built-in OS


979
00:28:54,696 --> 00:28:56,806
Word Embeddings that represent


980
00:28:57,296 --> 00:29:00,486
the ordinary meaning of words,


981
00:29:00,656 --> 00:29:02,696
and if you have a custom Word


982
00:29:02,696 --> 00:29:03,936
Embeddings, you could also use


983
00:29:03,936 --> 00:29:06,106
that as well.


984
00:29:06,306 --> 00:29:10,066
We know that a given word can


985
00:29:10,066 --> 00:29:11,236
have very different meanings,


986
00:29:11,236 --> 00:29:12,456
depending on how it appears in


987
00:29:12,456 --> 00:29:13,586
the context of a sentence.


988
00:29:14,016 --> 00:29:15,316
So, for example, Apple in these


989
00:29:15,316 --> 00:29:16,526
two sentences has very different


990
00:29:16,526 --> 00:29:16,896
meanings.


991
00:29:18,206 --> 00:29:20,586
So, what we'd like is to have an


992
00:29:20,586 --> 00:29:22,356
embedding for Transfer Learning


993
00:29:22,356 --> 00:29:24,766
purposes that gives different


994
00:29:25,386 --> 00:29:28,816
values for these words depending


995
00:29:28,816 --> 00:29:31,226
on their meaning and context.


996
00:29:31,226 --> 00:29:32,366
And, of course, an ordinary word


997
00:29:32,366 --> 00:29:34,966
embedding, it just maps words to


998
00:29:34,966 --> 00:29:37,306
vectors, and it will give the


999
00:29:37,306 --> 00:29:39,036
same value for the word no


1000
00:29:39,036 --> 00:29:40,076
matter how it appears.


1001
00:29:41,466 --> 00:29:44,876
But, what we have done is


1002
00:29:44,876 --> 00:29:46,866
trained a specialized embedding


1003
00:29:46,976 --> 00:29:50,356
that gives different values for


1004
00:29:50,356 --> 00:29:51,656
the words depending on their


1005
00:29:51,656 --> 00:29:52,866
meaning and context.


1006
00:29:53,446 --> 00:29:54,886
Now, to give you some idea of


1007
00:29:54,886 --> 00:29:56,086
how fast the field is moving,


1008
00:29:56,086 --> 00:29:57,456
this is something that was just


1009
00:29:57,456 --> 00:30:00,166
researched a year ago, and we're


1010
00:30:00,166 --> 00:30:03,156
delivering it now.


1011
00:30:03,376 --> 00:30:04,796
And again, if you want to use


1012
00:30:04,796 --> 00:30:06,546
it, you just ask for it.


1013
00:30:07,076 --> 00:30:08,486
You specify the dynamic


1014
00:30:08,486 --> 00:30:08,956
embedding.


1015
00:30:09,186 --> 00:30:10,426
So, the dynamic embedding


1016
00:30:10,956 --> 00:30:13,366
changes the value of the


1017
00:30:13,366 --> 00:30:15,106
embedding for words depending on


1018
00:30:15,106 --> 00:30:17,766
their sentence context, and this


1019
00:30:17,766 --> 00:30:20,016
is a very powerful technique for


1020
00:30:20,016 --> 00:30:21,566
doing Transfer Learning for Test


1021
00:30:21,566 --> 00:30:22,296
Classification.


1022
00:30:23,546 --> 00:30:25,206
Well, let's see it.


1023
00:30:27,056 --> 00:30:27,676
All right.


1024
00:30:27,906 --> 00:30:30,716
So, here what I have is some


1025
00:30:30,716 --> 00:30:32,636
fairly standard code for


1026
00:30:32,676 --> 00:30:34,566
training a Text Classifier using


1027
00:30:34,566 --> 00:30:37,236
Create ML, and what I'm going to


1028
00:30:37,236 --> 00:30:39,056
be training, this is based on a


1029
00:30:39,056 --> 00:30:41,326
dataset using an Open Source


1030
00:30:41,766 --> 00:30:43,836
encyclopedia called DBpedia.


1031
00:30:44,676 --> 00:30:46,486
It has short entries about many


1032
00:30:46,486 --> 00:30:47,426
different topics.


1033
00:30:47,496 --> 00:30:49,456
Some of them are people,


1034
00:30:49,456 --> 00:30:51,096
artists, writers, plants,


1035
00:30:51,096 --> 00:30:52,616
animals, and so forth, and the


1036
00:30:52,616 --> 00:30:55,146
task here is to determine from


1037
00:30:55,146 --> 00:30:56,746
the entry what the


1038
00:30:56,876 --> 00:30:59,186
classification is, whether it's


1039
00:30:59,186 --> 00:31:01,396
a person or writer or artist,


1040
00:31:01,396 --> 00:31:01,886
etc.


1041
00:31:01,956 --> 00:31:04,186
And there are 14 different


1042
00:31:04,186 --> 00:31:05,546
classes here, and I'm going to


1043
00:31:05,546 --> 00:31:07,036
try and train a classifier using


1044
00:31:07,036 --> 00:31:08,406
only 200 examples.


1045
00:31:08,906 --> 00:31:11,016
So, it's a fairly difficult task


1046
00:31:11,016 --> 00:31:13,766
here, and so let's just-- let's


1047
00:31:13,766 --> 00:31:15,656
try it with our existing maxEnt


1048
00:31:15,776 --> 00:31:16,236
model.


1049
00:31:17,356 --> 00:31:19,006
So, I'll fire it off.


1050
00:31:19,436 --> 00:31:21,316
It starts, and it's done.


1051
00:31:22,776 --> 00:31:25,296
Very fast and easy, and on our


1052
00:31:25,296 --> 00:31:29,026
training-- if we take a look at


1053
00:31:29,026 --> 00:31:30,966
our performance on our test set,


1054
00:31:31,286 --> 00:31:34,116
we see it got 77% accuracy.


1055
00:31:35,116 --> 00:31:39,566
That's okay, but can we do


1056
00:31:39,676 --> 00:31:39,796
better?


1057
00:31:39,796 --> 00:31:41,756
Well, let's make one little


1058
00:31:41,756 --> 00:31:43,926
change to our code here.


1059
00:31:44,266 --> 00:31:46,856
Instead of using the maxEnt


1060
00:31:46,856 --> 00:31:47,986
model, we're going to use the


1061
00:31:47,986 --> 00:31:49,526
Transfer Learning with Dynamic


1062
00:31:49,526 --> 00:31:53,266
Embeddings, and let's start it.


1063
00:31:54,736 --> 00:31:56,186
Now, as I mentioned, this is


1064
00:31:56,186 --> 00:31:57,956
training a Neural Network model,


1065
00:31:58,136 --> 00:31:59,526
so it takes a little bit longer,


1066
00:32:00,256 --> 00:32:02,606
so while it's training, let's


1067
00:32:02,606 --> 00:32:04,286
just take a little closer look


1068
00:32:04,326 --> 00:32:05,596
at the data that we're training


1069
00:32:05,596 --> 00:32:05,916
on.


1070
00:32:06,326 --> 00:32:08,196
As it turns out, when you're


1071
00:32:08,196 --> 00:32:09,646
training Neural Network models,


1072
00:32:09,916 --> 00:32:11,556
it's important to pay close


1073
00:32:11,556 --> 00:32:13,616
attention to the data that you


1074
00:32:13,616 --> 00:32:14,216
train it on.


1075
00:32:14,596 --> 00:32:17,166
So, notice that this data is a


1076
00:32:17,276 --> 00:32:19,386
random sample across the various


1077
00:32:19,386 --> 00:32:22,646
classes, and I've arranged it so


1078
00:32:22,646 --> 00:32:23,846
that they're roughly the same


1079
00:32:23,846 --> 00:32:25,996
number of instances for each


1080
00:32:26,046 --> 00:32:26,676
class.


1081
00:32:27,186 --> 00:32:28,346
It's a balanced set.


1082
00:32:29,366 --> 00:32:30,626
This is our training set.


1083
00:32:30,626 --> 00:32:31,926
In addition, we also have a


1084
00:32:31,926 --> 00:32:34,146
separate validation set that is


1085
00:32:34,146 --> 00:32:36,226
similarly a random sampling of


1086
00:32:36,226 --> 00:32:38,546
examples across classes, maybe


1087
00:32:38,546 --> 00:32:39,756
not quite as large as the


1088
00:32:39,756 --> 00:32:41,296
training set, but balanced.


1089
00:32:41,986 --> 00:32:43,246
And the validation set is


1090
00:32:43,306 --> 00:32:44,886
particularly important in this


1091
00:32:44,886 --> 00:32:45,536
kind of training.


1092
00:32:45,996 --> 00:32:48,466
Neural Network training has a


1093
00:32:48,516 --> 00:32:50,846
tendency to over fitting, where


1094
00:32:50,846 --> 00:32:52,666
it more or less memorizes the


1095
00:32:52,666 --> 00:32:53,916
training material and doesn't


1096
00:32:54,056 --> 00:32:54,816
generalize.


1097
00:32:55,096 --> 00:32:56,616
The validation set helps keep it


1098
00:32:56,616 --> 00:32:57,976
honest and make sure it


1099
00:32:57,976 --> 00:32:59,316
continues to generalize.


1100
00:33:00,146 --> 00:33:01,376
And then, of course, we also


1101
00:33:01,376 --> 00:33:03,946
have a separate test set that's


1102
00:33:03,946 --> 00:33:05,846
similarly randomly sampled and


1103
00:33:05,846 --> 00:33:08,056
balanced, and of course there


1104
00:33:08,056 --> 00:33:10,196
can't be any overlap between the


1105
00:33:10,196 --> 00:33:12,006
training validation test sets.


1106
00:33:12,006 --> 00:33:12,796
That would be cheating.


1107
00:33:13,966 --> 00:33:16,606
And the test set we need to see


1108
00:33:16,606 --> 00:33:17,576
how well we're doing, in


1109
00:33:17,576 --> 00:33:19,586
particular in this case, we need


1110
00:33:19,586 --> 00:33:22,296
it so that we can see whether


1111
00:33:22,296 --> 00:33:24,646
the Transfer Learning model is


1112
00:33:24,646 --> 00:33:27,766
doing better than our maxEnt


1113
00:33:27,766 --> 00:33:28,126
model.


1114
00:33:28,596 --> 00:33:29,866
And it looks like it's finished


1115
00:33:29,866 --> 00:33:31,046
now, so let's take a look and


1116
00:33:31,046 --> 00:33:31,326
see.


1117
00:33:31,606 --> 00:33:36,486
And we can see here that the


1118
00:33:36,486 --> 00:33:38,576
Transfer Learning has achieved


1119
00:33:38,576 --> 00:33:41,106
an accuracy of 86.5%, much


1120
00:33:41,186 --> 00:33:45,976
better than our maxEnt model.


1121
00:33:46,516 --> 00:33:51,796
[ Applause ]


1122
00:33:52,296 --> 00:33:55,996
So, how does this apply to our


1123
00:33:55,996 --> 00:33:56,976
cheese application?


1124
00:33:57,056 --> 00:33:59,536
Well, what I've done is I've


1125
00:33:59,576 --> 00:34:01,746
taken my cheese tasting notes,


1126
00:34:03,146 --> 00:34:05,726
and I labeled them each by the


1127
00:34:05,756 --> 00:34:07,116
cheese that they referred to,


1128
00:34:07,396 --> 00:34:09,626
and I use that to train a cheese


1129
00:34:09,626 --> 00:34:10,676
classifier model.


1130
00:34:10,676 --> 00:34:13,196
And so my cheese classifier


1131
00:34:13,196 --> 00:34:16,146
model can take a sentence and


1132
00:34:16,246 --> 00:34:18,216
try to classify it and determine


1133
00:34:18,216 --> 00:34:20,156
which cheese it most closely


1134
00:34:20,156 --> 00:34:20,866
refers to.


1135
00:34:21,016 --> 00:34:24,036
And I put that into my cheese


1136
00:34:24,036 --> 00:34:27,936
application, and so, what I'm


1137
00:34:27,936 --> 00:34:28,826
going to do in the cheese


1138
00:34:28,826 --> 00:34:32,366
application is if the user


1139
00:34:32,366 --> 00:34:33,545
didn't refer to a specific


1140
00:34:33,585 --> 00:34:34,936
cheese, then I'm going to try to


1141
00:34:34,936 --> 00:34:36,136
figure out which cheese they


1142
00:34:36,136 --> 00:34:36,746
might want.


1143
00:34:37,255 --> 00:34:39,456
And all I do is ask the model


1144
00:34:39,456 --> 00:34:41,306
for the label for the text.


1145
00:34:42,076 --> 00:34:43,226
And very simple.


1146
00:34:43,226 --> 00:34:45,000
Let's try it out.


1147
00:35:01,046 --> 00:35:02,336
So, I'm going to type in


1148
00:35:02,336 --> 00:35:03,000
something here.


1149
00:35:15,486 --> 00:35:18,936
And we'll let the cheese


1150
00:35:18,936 --> 00:35:20,966
classifier work on it.


1151
00:35:21,516 --> 00:35:23,536
And so the cheese classifier


1152
00:35:23,696 --> 00:35:24,996
determined that this is most


1153
00:35:25,046 --> 00:35:26,716
closely resembling Camembert,


1154
00:35:27,066 --> 00:35:29,066
and then my cheese embedding has


1155
00:35:29,066 --> 00:35:30,516
recommended some other cheeses


1156
00:35:30,516 --> 00:35:31,936
that are very similar, Brie and


1157
00:35:31,936 --> 00:35:32,756
so on and so forth.


1158
00:35:34,156 --> 00:35:36,000
Or, maybe I say--


1159
00:35:45,386 --> 00:35:46,826
Something firm and sharp and it


1160
00:35:46,826 --> 00:35:47,946
recognizes that as resembling


1161
00:35:48,286 --> 00:35:49,826
cheddar, and it recommends some


1162
00:35:50,036 --> 00:35:50,966
similar cheeses to us.


1163
00:35:51,001 --> 00:35:53,001
[applause]


1164
00:35:53,036 --> 00:35:54,386
So, this again shows us the


1165
00:35:54,426 --> 00:35:57,596
power of Text Classification in


1166
00:35:57,596 --> 00:35:59,746
combination with the other


1167
00:35:59,956 --> 00:36:01,486
NaturalLanguage APIs.


1168
00:36:01,736 --> 00:36:03,276
So, I'd like to finish off with


1169
00:36:03,276 --> 00:36:05,366
some considerations for the use


1170
00:36:05,456 --> 00:36:07,656
of the Text Classification.


1171
00:36:07,656 --> 00:36:09,266
First of all, we need to note


1172
00:36:09,266 --> 00:36:10,756
the languages that are supported


1173
00:36:11,166 --> 00:36:12,846
for transfer learning, either


1174
00:36:12,846 --> 00:36:14,956
via Static Embeddings or the


1175
00:36:14,956 --> 00:36:17,746
special Dynamic Embeddings that


1176
00:36:17,886 --> 00:36:19,576
take context into account.


1177
00:36:20,026 --> 00:36:23,196
And then I want to talk a bit


1178
00:36:23,196 --> 00:36:25,056
about, more about data.


1179
00:36:26,326 --> 00:36:28,446
So, the first commandment when


1180
00:36:28,446 --> 00:36:29,626
dealing with data is that you


1181
00:36:29,626 --> 00:36:31,676
need to understand the domain


1182
00:36:31,676 --> 00:36:32,296
you're working with.


1183
00:36:33,506 --> 00:36:35,036
What kind of text do you expect


1184
00:36:35,036 --> 00:36:36,176
to see in practice?


1185
00:36:36,396 --> 00:36:37,626
Is it going to be sentence


1186
00:36:37,626 --> 00:36:39,086
fragments, full sentences,


1187
00:36:39,086 --> 00:36:41,556
multiple sentences, and make


1188
00:36:41,556 --> 00:36:43,576
sure that your training data is


1189
00:36:43,576 --> 00:36:45,526
as similar as possible to the


1190
00:36:45,526 --> 00:36:47,106
text that you expect to see and


1191
00:36:47,106 --> 00:36:48,576
try to classify in practice.


1192
00:36:49,646 --> 00:36:52,026
And covers as much as possible


1193
00:36:52,286 --> 00:36:53,646
of the variations that you're


1194
00:36:53,646 --> 00:36:55,866
likely to see when you encounter


1195
00:36:55,866 --> 00:36:57,776
this text in your application.


1196
00:36:58,906 --> 00:37:02,746
And, as we saw in our DBpedia


1197
00:37:02,746 --> 00:37:04,806
example, you want to make sure


1198
00:37:05,266 --> 00:37:08,806
that you have randomly sampled


1199
00:37:08,806 --> 00:37:11,316
as much as possible distinct


1200
00:37:11,316 --> 00:37:13,606
sets for training, for


1201
00:37:13,606 --> 00:37:15,266
validation, and tests.


1202
00:37:15,766 --> 00:37:17,696
This is basic data hygiene.


1203
00:37:18,096 --> 00:37:21,706
And how do you know which


1204
00:37:21,706 --> 00:37:23,306
algorithm will be best for your


1205
00:37:23,306 --> 00:37:23,916
case?


1206
00:37:24,336 --> 00:37:25,616
Well, in general, you'll have to


1207
00:37:25,616 --> 00:37:28,426
try it, but some guidelines.


1208
00:37:28,626 --> 00:37:29,886
You can start with the maxEnt


1209
00:37:29,886 --> 00:37:30,466
classifier.


1210
00:37:30,466 --> 00:37:31,456
It's very fast.


1211
00:37:31,456 --> 00:37:32,606
It will give you an answer.


1212
00:37:33,766 --> 00:37:35,206
But what does a maxEnt


1213
00:37:35,206 --> 00:37:36,356
classifier do?


1214
00:37:36,896 --> 00:37:38,926
A maxEnt classifier works by


1215
00:37:38,926 --> 00:37:41,556
noticing the words that are used


1216
00:37:42,146 --> 00:37:44,056
most often in the training


1217
00:37:44,056 --> 00:37:44,556
material.


1218
00:37:45,096 --> 00:37:46,806
So, for example, if you're


1219
00:37:46,806 --> 00:37:49,756
trying to train positive and


1220
00:37:49,756 --> 00:37:51,486
negative, it might notice words


1221
00:37:51,486 --> 00:37:52,676
like love and happy are


1222
00:37:52,736 --> 00:37:54,166
positive, hate and unhappy


1223
00:37:54,166 --> 00:37:54,666
negative.


1224
00:37:55,326 --> 00:37:57,406
And if the examples you


1225
00:37:57,406 --> 00:37:59,106
encounter in practice use these


1226
00:37:59,106 --> 00:38:00,426
same words, then the maxEnt


1227
00:38:00,426 --> 00:38:01,876
classifier is going to work very


1228
00:38:01,876 --> 00:38:02,146
well.


1229
00:38:02,676 --> 00:38:08,146
What the Transfer Learning does


1230
00:38:08,456 --> 00:38:10,076
is it notices the meaning of


1231
00:38:10,076 --> 00:38:10,546
words.


1232
00:38:11,056 --> 00:38:12,906
So if the examples you encounter


1233
00:38:12,906 --> 00:38:14,476
in practice are likely to


1234
00:38:14,476 --> 00:38:16,926
express a similar meaning with


1235
00:38:17,016 --> 00:38:20,426
different words, then that is


1236
00:38:20,426 --> 00:38:21,786
the case where Transfer Learning


1237
00:38:21,786 --> 00:38:24,476
shines and it's likely to do


1238
00:38:24,476 --> 00:38:27,156
better than the simple maxEnt


1239
00:38:27,156 --> 00:38:27,546
model.


1240
00:38:28,046 --> 00:38:33,086
So, to summarize, we have new


1241
00:38:33,086 --> 00:38:35,676
APIs available for Sentiment


1242
00:38:35,676 --> 00:38:38,706
Analysis, for Text Catalogs with


1243
00:38:38,706 --> 00:38:41,906
MLGazetteer, for Word Embeddings


1244
00:38:41,996 --> 00:38:45,376
with NL embedding, and we have a


1245
00:38:45,376 --> 00:38:47,306
new type of text classification,


1246
00:38:47,466 --> 00:38:49,046
a particularly powerful new type


1247
00:38:49,716 --> 00:38:51,736
that takes advantage of Transfer


1248
00:38:51,736 --> 00:38:52,056
Learning.


1249
00:38:53,096 --> 00:38:55,226
I hope you'll take advantage of


1250
00:38:55,226 --> 00:38:58,086
these in your applications, and


1251
00:38:58,426 --> 00:38:59,566
there's much more information


1252
00:38:59,566 --> 00:39:01,496
available online, and there are


1253
00:39:01,496 --> 00:39:04,256
other related sessions that you


1254
00:39:04,256 --> 00:39:05,256
can take a look at.


1255
00:39:06,356 --> 00:39:06,796
Thank you.


1256
00:39:07,516 --> 00:39:12,500
[ Applause ]

