1
00:00:00,506 --> 00:00:04,500
[ Music ]


2
00:00:09,516 --> 00:00:12,996
[ Applause ]


3
00:00:13,496 --> 00:00:14,336
>> Hi, everyone.


4
00:00:16,676 --> 00:00:18,306
I'm so excited that you're able


5
00:00:18,306 --> 00:00:19,136
to join us today.


6
00:00:19,546 --> 00:00:21,226
I'm Kayur and I'm here with some


7
00:00:21,286 --> 00:00:23,756
amazing designers, Rubii and


8
00:00:23,756 --> 00:00:24,166
Cas.


9
00:00:24,676 --> 00:00:25,996
And we're so excited to talk to


10
00:00:25,996 --> 00:00:27,716
you today about design and


11
00:00:27,716 --> 00:00:28,366
machine learning.


12
00:00:29,666 --> 00:00:31,686
You see, at Apple, we've been


13
00:00:31,686 --> 00:00:33,326
thinking about design and


14
00:00:33,326 --> 00:00:34,826
machine learning for some time


15
00:00:34,826 --> 00:00:35,036
now.


16
00:00:35,326 --> 00:00:36,886
And when we think about and we


17
00:00:36,886 --> 00:00:38,896
talk about machine learning, we


18
00:00:38,896 --> 00:00:40,226
talk about all the amazing


19
00:00:40,226 --> 00:00:42,056
technological advances in speech


20
00:00:42,056 --> 00:00:43,756
recognition and computer vision.


21
00:00:44,336 --> 00:00:45,896
We talk about deep neural nets.


22
00:00:45,896 --> 00:00:48,306
We talk about custom processing


23
00:00:48,356 --> 00:00:50,016
for on-device machine learning.


24
00:00:50,616 --> 00:00:52,386
We talk about all these things


25
00:00:53,036 --> 00:00:54,566
because we care about products


26
00:00:55,626 --> 00:00:57,566
and we know that many of the


27
00:00:57,606 --> 00:01:00,066
products that we build today and


28
00:01:00,066 --> 00:01:01,946
many of the products and


29
00:01:01,946 --> 00:01:03,306
experiences that we want to


30
00:01:03,306 --> 00:01:05,296
build in the future would not be


31
00:01:05,296 --> 00:01:07,076
possible without machine


32
00:01:07,076 --> 00:01:07,386
learning.


33
00:01:08,556 --> 00:01:09,816
Let's take a look at some of the


34
00:01:11,056 --> 00:01:11,366
products.


35
00:01:11,696 --> 00:01:12,226
AirPods.


36
00:01:12,676 --> 00:01:14,946
AirPods allow you to summon Siri


37
00:01:15,266 --> 00:01:16,736
to control your device with your


38
00:01:16,736 --> 00:01:17,056
voice.


39
00:01:17,766 --> 00:01:19,256
You can easily change your music


40
00:01:19,256 --> 00:01:21,106
or answer a call all when your


41
00:01:21,106 --> 00:01:22,796
hands are busy and when you


42
00:01:22,796 --> 00:01:24,206
can't really look at the screen.


43
00:01:24,996 --> 00:01:26,466
This AirPods experience would


44
00:01:26,466 --> 00:01:27,986
not be possible without machine


45
00:01:27,986 --> 00:01:29,466
learning and it would not be


46
00:01:29,466 --> 00:01:30,396
possible without Siri.


47
00:01:31,686 --> 00:01:33,106
Machine learning allows us to


48
00:01:33,106 --> 00:01:35,096
create Face ID which provides


49
00:01:35,096 --> 00:01:36,966
fast secure authentication for


50
00:01:36,966 --> 00:01:38,026
your iOS devices.


51
00:01:38,536 --> 00:01:41,256
And we use machine learning in


52
00:01:41,256 --> 00:01:43,226
ways that you may not expect,


53
00:01:43,766 --> 00:01:47,376
subtle ways that improve your


54
00:01:47,376 --> 00:01:48,846
experience with your devices.


55
00:01:49,716 --> 00:01:50,946
We use machine learning to


56
00:01:50,946 --> 00:01:52,836
invisibly improve your typing


57
00:01:52,836 --> 00:01:53,386
experience.


58
00:01:54,196 --> 00:01:56,056
We increase or decrease the


59
00:01:56,056 --> 00:01:57,626
target tap area for keyboard


60
00:01:57,656 --> 00:01:59,256
buttons based on the word you're


61
00:01:59,256 --> 00:02:00,076
most likely to type.


62
00:02:01,306 --> 00:02:02,586
Machine learning applications


63
00:02:02,586 --> 00:02:03,376
are diverse.


64
00:02:04,196 --> 00:02:05,576
They're not just about voice


65
00:02:05,576 --> 00:02:07,416
assistance or recommending


66
00:02:07,416 --> 00:02:09,246
content or self-driving cars,


67
00:02:10,316 --> 00:02:11,626
machine learning applications


68
00:02:11,676 --> 00:02:13,536
are as diverse as any


69
00:02:13,536 --> 00:02:14,576
application of software


70
00:02:14,576 --> 00:02:15,206
engineering.


71
00:02:16,036 --> 00:02:18,016
They can make existing products


72
00:02:18,166 --> 00:02:20,316
better or enable new products


73
00:02:20,316 --> 00:02:21,046
that enrich the human


74
00:02:21,046 --> 00:02:21,596
experience.


75
00:02:22,586 --> 00:02:24,786
And inside Apple, we've been


76
00:02:24,786 --> 00:02:26,566
talking about and thinking about


77
00:02:27,066 --> 00:02:28,776
what makes a great machine


78
00:02:28,776 --> 00:02:30,026
learning product for some time


79
00:02:30,026 --> 00:02:30,226
now.


80
00:02:31,216 --> 00:02:32,176
And to go into this in more


81
00:02:32,176 --> 00:02:34,376
detail, let's dive into a single


82
00:02:34,376 --> 00:02:35,626
experience, Photos.


83
00:02:36,656 --> 00:02:38,076
Photos uses machine learning in


84
00:02:38,076 --> 00:02:39,026
a variety of ways.


85
00:02:39,616 --> 00:02:40,766
Machine learning helps people


86
00:02:41,006 --> 00:02:43,086
create albums, edit photos and


87
00:02:43,086 --> 00:02:44,396
search for specific memories.


88
00:02:45,166 --> 00:02:48,796
Speaking of memories, recently I


89
00:02:48,796 --> 00:02:49,796
was looking for this memory.


90
00:02:50,506 --> 00:02:51,256
This is Angie.


91
00:02:51,626 --> 00:02:53,216
She's a friend of the family and


92
00:02:53,216 --> 00:02:54,226
this picture was taken from a


93
00:02:54,226 --> 00:02:55,316
hike a few years ago.


94
00:02:56,126 --> 00:02:58,116
I felt nostalgic and wanted to


95
00:02:58,116 --> 00:02:59,126
share the picture with some


96
00:02:59,126 --> 00:03:00,386
friends who were already there.


97
00:03:00,806 --> 00:03:03,136
Until very recently, finding a


98
00:03:03,136 --> 00:03:04,566
specific picture was painful.


99
00:03:05,396 --> 00:03:06,526
I'd have to sift through


100
00:03:06,526 --> 00:03:08,506
thousands of pictures, try and


101
00:03:08,506 --> 00:03:10,056
remember where I was or when I


102
00:03:10,056 --> 00:03:10,706
took the picture.


103
00:03:11,256 --> 00:03:12,036
I would've given up.


104
00:03:12,776 --> 00:03:14,036
Finding a picture used to be a


105
00:03:14,036 --> 00:03:16,336
barrier to me engaging with my


106
00:03:16,336 --> 00:03:17,696
memories and sharing them with


107
00:03:17,726 --> 00:03:18,326
my family.


108
00:03:19,326 --> 00:03:22,046
In iOS X, Apple introduced a new


109
00:03:22,046 --> 00:03:23,186
search experience that could


110
00:03:23,186 --> 00:03:25,006
like inside a picture and


111
00:03:25,006 --> 00:03:26,356
detect, among other things,


112
00:03:26,356 --> 00:03:26,706
dogs.


113
00:03:27,326 --> 00:03:28,686
And over the years, we've been


114
00:03:28,686 --> 00:03:29,946
making this experience better.


115
00:03:31,366 --> 00:03:32,456
Here's what the experience looks


116
00:03:32,456 --> 00:03:32,766
like now.


117
00:03:33,586 --> 00:03:35,776
I tap on the Search box.


118
00:03:35,776 --> 00:03:37,366
I type in dog.


119
00:03:37,366 --> 00:03:39,086
And I get a list of pictures


120
00:03:39,086 --> 00:03:39,496
with dogs.


121
00:03:39,496 --> 00:03:41,006
I can then select the picture I


122
00:03:41,006 --> 00:03:42,296
was looking for and share it.


123
00:03:42,556 --> 00:03:43,236
Easy peasy.


124
00:03:44,406 --> 00:03:45,976
Searching for pictures based on


125
00:03:45,976 --> 00:03:48,016
what's in a picture changes how


126
00:03:48,016 --> 00:03:49,176
we engage with our memories.


127
00:03:49,926 --> 00:03:50,746
It's something we take for


128
00:03:50,746 --> 00:03:51,166
granted.


129
00:03:51,856 --> 00:03:52,966
In fact, it's such a great


130
00:03:52,966 --> 00:03:54,556
experience it's hard to remember


131
00:03:54,836 --> 00:03:55,976
a time before we had this


132
00:03:55,976 --> 00:03:56,606
capability.


133
00:03:57,286 --> 00:03:58,096
It's well designed.


134
00:03:59,046 --> 00:04:00,736
And there's a lot of interface


135
00:04:00,736 --> 00:04:02,656
work that goes into making this


136
00:04:02,656 --> 00:04:03,236
experience.


137
00:04:03,916 --> 00:04:05,446
Photos suggest categories you


138
00:04:05,446 --> 00:04:06,776
can search for, it


139
00:04:06,776 --> 00:04:08,546
auto-completes searches and it


140
00:04:08,546 --> 00:04:09,706
connects search results to


141
00:04:09,706 --> 00:04:12,276
Moments but designing this


142
00:04:12,276 --> 00:04:13,916
experience is more than just


143
00:04:13,916 --> 00:04:15,836
designing a grid view in the


144
00:04:15,836 --> 00:04:16,456
Search field.


145
00:04:17,086 --> 00:04:18,106
If we just looked at the


146
00:04:18,106 --> 00:04:19,916
interface, we'd miss the most


147
00:04:19,916 --> 00:04:21,016
important parts of the search


148
00:04:21,016 --> 00:04:23,166
experience, the results being


149
00:04:23,166 --> 00:04:25,146
outputted into categories that


150
00:04:25,146 --> 00:04:26,006
people can search for.


151
00:04:27,086 --> 00:04:29,316
These aspects of the experience


152
00:04:29,316 --> 00:04:30,276
should be designed.


153
00:04:30,846 --> 00:04:32,216
We get to decide which


154
00:04:32,216 --> 00:04:34,076
categories are included and we


155
00:04:34,076 --> 00:04:35,756
decide the level of quality we


156
00:04:35,756 --> 00:04:38,576
want for each category.


157
00:04:38,646 --> 00:04:40,256
We've realized that to build a


158
00:04:40,256 --> 00:04:41,116
good machine learning


159
00:04:41,116 --> 00:04:42,886
experience, we have to design


160
00:04:42,886 --> 00:04:44,176
more than just the interface.


161
00:04:44,766 --> 00:04:45,276
What do we mean?


162
00:04:46,606 --> 00:04:47,996
Well, when most people think


163
00:04:47,996 --> 00:04:49,576
about design, they think about


164
00:04:49,576 --> 00:04:51,206
the interface, how the product


165
00:04:51,206 --> 00:04:53,236
looks and feels, the flow of the


166
00:04:53,236 --> 00:04:53,846
experience.


167
00:04:54,526 --> 00:04:57,446
With machine learning, we have


168
00:04:57,516 --> 00:04:59,576
to design how the product works.


169
00:05:00,596 --> 00:05:01,796
Now we know that many of you in


170
00:05:01,796 --> 00:05:02,916
the design and developer


171
00:05:02,916 --> 00:05:04,626
community have some machine


172
00:05:04,626 --> 00:05:05,456
learning experience.


173
00:05:05,906 --> 00:05:06,826
You could create a search


174
00:05:06,826 --> 00:05:08,696
experience from scratch but to


175
00:05:08,696 --> 00:05:10,066
get everyone on the same page,


176
00:05:10,436 --> 00:05:11,646
let's look at how machine


177
00:05:11,646 --> 00:05:12,946
learning for photo search works.


178
00:05:14,596 --> 00:05:16,536
Deep within the logic of Photos


179
00:05:16,916 --> 00:05:18,436
is a function that takes a


180
00:05:18,436 --> 00:05:20,346
picture and detects if that


181
00:05:20,346 --> 00:05:21,626
picture contains any of the


182
00:05:21,626 --> 00:05:22,976
categories it can recognize.


183
00:05:23,836 --> 00:05:25,206
In our case, it recognizes that


184
00:05:25,256 --> 00:05:26,626
this picture of Angie has a dog


185
00:05:26,626 --> 00:05:27,506
in it.


186
00:05:28,076 --> 00:05:30,006
In traditional programming, we


187
00:05:30,006 --> 00:05:30,986
would have to create the


188
00:05:30,986 --> 00:05:33,596
function by writing code to tell


189
00:05:33,596 --> 00:05:34,906
the computer what to do.


190
00:05:35,986 --> 00:05:37,536
Our code would have to work for


191
00:05:37,746 --> 00:05:39,286
a variety of different breeds,


192
00:05:39,766 --> 00:05:42,566
different scenarios, different


193
00:05:42,806 --> 00:05:44,626
photo resolutions because their


194
00:05:44,626 --> 00:05:46,256
customers are diverse and so are


195
00:05:46,256 --> 00:05:46,836
their dogs.


196
00:05:47,776 --> 00:05:48,956
And we wouldn't want a search


197
00:05:48,956 --> 00:05:50,196
for dogs to be littered with


198
00:05:50,196 --> 00:05:51,336
pictures of other animals.


199
00:05:51,956 --> 00:05:52,796
Our code would have to


200
00:05:52,796 --> 00:05:54,696
differentiate between dogs and


201
00:05:54,696 --> 00:05:56,576
similar animals, like this hyena


202
00:05:56,966 --> 00:05:58,416
which looks like a dog but you


203
00:05:58,416 --> 00:06:00,446
should not have as a pet.


204
00:06:01,426 --> 00:06:03,656
Writing code that generalizes


205
00:06:03,656 --> 00:06:05,196
the countless variations of dogs


206
00:06:05,196 --> 00:06:06,776
in photos would be impossible.


207
00:06:07,176 --> 00:06:08,516
And dogs are just one of


208
00:06:08,516 --> 00:06:09,776
thousands of categories that


209
00:06:09,776 --> 00:06:10,766
Photos can recognize.


210
00:06:11,846 --> 00:06:13,476
There're experiences we want to


211
00:06:13,476 --> 00:06:15,096
create where we can't just tell


212
00:06:15,096 --> 00:06:16,076
the computer what to do.


213
00:06:17,456 --> 00:06:18,306
And for many of these


214
00:06:18,306 --> 00:06:20,256
experiences, we can use machine


215
00:06:20,256 --> 00:06:22,076
learning to teach a computer


216
00:06:22,076 --> 00:06:22,606
what to do.


217
00:06:23,946 --> 00:06:25,416
We teach by providing examples.


218
00:06:25,416 --> 00:06:26,526
If we wanted to distinguish


219
00:06:26,526 --> 00:06:28,086
pictures of dogs from pictures


220
00:06:28,086 --> 00:06:29,936
that do not contain dogs, we


221
00:06:29,936 --> 00:06:31,296
have to provide pictures with


222
00:06:31,296 --> 00:06:32,706
dogs and pictures without dogs.


223
00:06:33,566 --> 00:06:35,786
Machine learning learns a


224
00:06:35,956 --> 00:06:37,856
function that we can later use


225
00:06:37,856 --> 00:06:39,186
in our app.


226
00:06:39,856 --> 00:06:41,366
This function can take this


227
00:06:41,366 --> 00:06:42,966
picture of Angie and understand


228
00:06:42,966 --> 00:06:43,916
that it's a picture of a dog.


229
00:06:44,796 --> 00:06:46,776
We call this function a model


230
00:06:47,436 --> 00:06:50,296
and a model is what makes the


231
00:06:50,296 --> 00:06:53,026
Photos Search experience work.


232
00:06:54,316 --> 00:06:56,436
This model can generalize two


233
00:06:56,636 --> 00:06:57,576
pictures that it's never seen


234
00:06:57,576 --> 00:06:57,886
before.


235
00:06:58,326 --> 00:06:59,686
It can recognize different dog


236
00:06:59,736 --> 00:07:01,766
species and differentiate dogs


237
00:07:01,766 --> 00:07:03,406
from other animals and objects.


238
00:07:04,616 --> 00:07:06,226
Models are central to the


239
00:07:06,226 --> 00:07:07,246
machine learning experience.


240
00:07:07,896 --> 00:07:09,876
Every product or experience that


241
00:07:09,876 --> 00:07:11,026
depends on machine learning


242
00:07:11,026 --> 00:07:11,896
depends on a model.


243
00:07:12,796 --> 00:07:14,736
Siri has a model that converts


244
00:07:14,736 --> 00:07:15,436
your voice to text.


245
00:07:16,176 --> 00:07:17,986
And the keyboard has a model


246
00:07:17,986 --> 00:07:19,686
that infers the key you meant to


247
00:07:19,686 --> 00:07:20,726
type based on the letters you've


248
00:07:20,726 --> 00:07:21,776
already typed and your typing


249
00:07:21,776 --> 00:07:21,976
history.


250
00:07:27,176 --> 00:07:29,506
To design a great machine


251
00:07:29,506 --> 00:07:31,776
learning experience, we have to


252
00:07:31,776 --> 00:07:35,226
design both how it works and how


253
00:07:35,226 --> 00:07:35,966
it looks and feels.


254
00:07:36,586 --> 00:07:38,606
We have to design both the model


255
00:07:38,606 --> 00:07:39,486
and the interface.


256
00:07:40,216 --> 00:07:41,696
In this talk, we'll cover both.


257
00:07:43,166 --> 00:07:44,006
Creating a model can be


258
00:07:44,006 --> 00:07:44,746
complicated.


259
00:07:44,746 --> 00:07:46,456
You have to make a lot of


260
00:07:46,456 --> 00:07:48,256
decisions about algorithms and


261
00:07:48,256 --> 00:07:49,406
parameters and frameworks.


262
00:07:49,906 --> 00:07:51,536
And all of these decisions


263
00:07:51,666 --> 00:07:53,736
affect what the model does and,


264
00:07:53,736 --> 00:07:54,696
therefore, the experience.


265
00:07:55,696 --> 00:07:57,506
Machine learning decisions are


266
00:07:57,506 --> 00:08:00,646
all design decisions but not all


267
00:08:00,646 --> 00:08:02,336
of them are effective places for


268
00:08:02,336 --> 00:08:03,026
design input.


269
00:08:03,816 --> 00:08:05,836
We choose a few places where we


270
00:08:05,836 --> 00:08:07,236
think design can have the most


271
00:08:07,856 --> 00:08:08,046
impact.


272
00:08:09,116 --> 00:08:11,236
We talk about the need to design


273
00:08:11,436 --> 00:08:12,616
what we use to teach the


274
00:08:12,616 --> 00:08:13,076
computer.


275
00:08:13,426 --> 00:08:14,056
This is the data.


276
00:08:14,966 --> 00:08:17,176
And we also talk about how we


277
00:08:17,176 --> 00:08:18,936
design what we evaluate and


278
00:08:19,756 --> 00:08:22,736
these are the metrics.


279
00:08:22,796 --> 00:08:24,756
Along with the model, we do need


280
00:08:24,756 --> 00:08:25,776
to design the interface.


281
00:08:26,726 --> 00:08:27,886
We have to design what the model


282
00:08:27,886 --> 00:08:29,566
outputs and how those model's


283
00:08:29,566 --> 00:08:31,066
outputs are presented to people.


284
00:08:31,916 --> 00:08:33,336
We also have to design how


285
00:08:33,336 --> 00:08:34,616
people interact with the model


286
00:08:34,826 --> 00:08:36,905
and, if appropriate, provide


287
00:08:36,905 --> 00:08:38,385
input to improve the model.


288
00:08:38,946 --> 00:08:40,466
Rubii and Cas will talk about


289
00:08:40,466 --> 00:08:41,000
that later.


290
00:08:42,905 --> 00:08:44,476
So let's start.


291
00:08:45,076 --> 00:08:47,926
Let's talk about the data.


292
00:08:50,476 --> 00:08:52,366
To recognize dogs in pictures,


293
00:08:52,706 --> 00:08:54,896
we used machine learning to


294
00:08:54,896 --> 00:08:56,606
create a model using examples.


295
00:08:57,926 --> 00:08:59,576
Those examples are called data.


296
00:09:00,176 --> 00:09:02,596
And to build a good search


297
00:09:02,596 --> 00:09:04,146
experience, you need a lot of


298
00:09:04,146 --> 00:09:04,686
diverse data.


299
00:09:05,356 --> 00:09:06,886
You need photos of the


300
00:09:06,886 --> 00:09:08,386
categories that you want people


301
00:09:08,386 --> 00:09:09,436
to be able to search for.


302
00:09:10,176 --> 00:09:11,516
You need to provide plenty of


303
00:09:11,516 --> 00:09:13,736
pictures of dogs and of other


304
00:09:13,736 --> 00:09:15,636
animals to ensure the search


305
00:09:15,636 --> 00:09:17,676
experience doesn't show random


306
00:09:17,676 --> 00:09:18,626
animals when you're searching


307
00:09:18,626 --> 00:09:19,086
for dogs.


308
00:09:19,686 --> 00:09:21,396
And a good search experience


309
00:09:21,486 --> 00:09:23,036
needs to support thousands of


310
00:09:23,036 --> 00:09:24,556
categories that cover the


311
00:09:24,606 --> 00:09:25,976
objects and events people want


312
00:09:25,976 --> 00:09:26,486
to search for.


313
00:09:27,246 --> 00:09:28,186
And for each of those


314
00:09:28,186 --> 00:09:29,526
categories, you'll need data.


315
00:09:29,646 --> 00:09:31,226
If you want to support a new


316
00:09:31,226 --> 00:09:32,566
category, you'll need data.


317
00:09:33,326 --> 00:09:34,166
If you want to improve an


318
00:09:34,166 --> 00:09:35,916
existing category, you will need


319
00:09:35,916 --> 00:09:36,336
data.


320
00:09:36,956 --> 00:09:39,036
Choosing data is key to


321
00:09:39,036 --> 00:09:40,186
designing the experience.


322
00:09:41,676 --> 00:09:43,696
Data determines the behavior of


323
00:09:43,696 --> 00:09:44,286
a model.


324
00:09:44,646 --> 00:09:46,246
It's easily the most important


325
00:09:46,246 --> 00:09:47,246
decision you'll make when


326
00:09:47,246 --> 00:09:48,056
creating your model.


327
00:09:48,726 --> 00:09:50,086
And if you don't have data that


328
00:09:50,596 --> 00:09:52,206
captures an important scenario,


329
00:09:52,656 --> 00:09:54,546
it's unlikely that your model's


330
00:09:54,546 --> 00:09:55,386
going to work well in that


331
00:09:55,386 --> 00:09:55,956
scenario.


332
00:09:56,496 --> 00:09:59,336
And since data determines the


333
00:09:59,336 --> 00:10:01,396
behavior of the model, and since


334
00:10:01,396 --> 00:10:02,716
the behavior of the model


335
00:10:02,936 --> 00:10:05,066
determines the experience, data


336
00:10:05,066 --> 00:10:07,546
needs to be designed to reflect


337
00:10:07,656 --> 00:10:09,276
good values in the best interest


338
00:10:09,276 --> 00:10:10,106
of your customers.


339
00:10:11,336 --> 00:10:12,846
To understand this better, let's


340
00:10:12,846 --> 00:10:13,656
look at an example.


341
00:10:14,806 --> 00:10:15,786
Let's look at Portrait mode.


342
00:10:17,326 --> 00:10:19,276
Portrait mode uses machine


343
00:10:19,276 --> 00:10:21,636
learning to detect faces and


344
00:10:21,636 --> 00:10:22,896
segment your body from the


345
00:10:22,896 --> 00:10:23,406
background.


346
00:10:24,776 --> 00:10:26,846
Historically, face recognition


347
00:10:26,846 --> 00:10:28,516
hasn't worked well for people of


348
00:10:28,516 --> 00:10:28,886
color.


349
00:10:29,546 --> 00:10:31,486
At Apple, we want to make sure


350
00:10:31,486 --> 00:10:33,406
our experiences are inclusive.


351
00:10:34,066 --> 00:10:35,556
So our design and engineering


352
00:10:35,556 --> 00:10:37,666
teams gather data from across


353
00:10:37,736 --> 00:10:39,406
different races, different


354
00:10:39,406 --> 00:10:40,656
cultures, and different


355
00:10:40,656 --> 00:10:41,196
scenarios.


356
00:10:41,916 --> 00:10:43,666
We built a dataset that matched


357
00:10:43,666 --> 00:10:45,776
the experience we wanted to


358
00:10:45,776 --> 00:10:46,646
create.


359
00:10:47,316 --> 00:10:49,366
We collected data intentionally.


360
00:10:50,186 --> 00:10:51,106
When collecting data, it's


361
00:10:51,106 --> 00:10:52,266
important to ask questions.


362
00:10:52,836 --> 00:10:54,306
Who is collecting the data?


363
00:10:54,786 --> 00:10:56,056
What data are they collecting?


364
00:10:56,316 --> 00:10:57,336
And how are they doing it?


365
00:10:58,076 --> 00:10:59,886
Data bias can seep into your


366
00:10:59,886 --> 00:11:01,416
dataset in a variety of ways.


367
00:11:01,996 --> 00:11:03,976
And data bias extends beyond


368
00:11:03,976 --> 00:11:04,336
fairness.


369
00:11:05,316 --> 00:11:07,056
You should strive to be fair and


370
00:11:07,056 --> 00:11:07,516
inclusive.


371
00:11:07,836 --> 00:11:08,966
Those are good values.


372
00:11:09,326 --> 00:11:11,576
But you should also see how data


373
00:11:11,576 --> 00:11:13,276
collection might skew away from


374
00:11:13,276 --> 00:11:14,266
other design intents.


375
00:11:15,046 --> 00:11:16,596
If you're creating a fun or


376
00:11:16,596 --> 00:11:18,396
enriching experience, you should


377
00:11:18,396 --> 00:11:20,406
sample data for fun, enriching


378
00:11:20,406 --> 00:11:21,076
experiences.


379
00:11:21,846 --> 00:11:23,036
If your product is going to be


380
00:11:23,036 --> 00:11:25,166
used outdoors, you should sample


381
00:11:25,166 --> 00:11:26,006
from scenarios that are


382
00:11:26,006 --> 00:11:26,656
outdoors.


383
00:11:27,806 --> 00:11:29,446
It's tempting to disconnect from


384
00:11:29,446 --> 00:11:31,146
this decision and make decisions


385
00:11:31,146 --> 00:11:33,566
about data collection that just


386
00:11:33,566 --> 00:11:35,146
sample the data from your


387
00:11:35,146 --> 00:11:37,126
existing customers and get a


388
00:11:37,126 --> 00:11:38,816
uniform sample of the world from


389
00:11:38,816 --> 00:11:41,776
other mechanisms but you can't


390
00:11:41,776 --> 00:11:43,256
just reflect the world.


391
00:11:43,706 --> 00:11:45,116
Reflecting the world can


392
00:11:45,116 --> 00:11:46,456
reinforce systemic biases.


393
00:11:47,336 --> 00:11:48,506
You shouldn't optimize for the


394
00:11:48,506 --> 00:11:50,076
customers you have.


395
00:11:50,526 --> 00:11:51,526
You should optimize for the


396
00:11:51,526 --> 00:11:52,736
customers you want.


397
00:11:53,696 --> 00:11:55,176
You shouldn't reflect the world


398
00:11:55,176 --> 00:11:55,646
as it is.


399
00:11:55,696 --> 00:11:57,756
You should reflect a better


400
00:11:57,756 --> 00:11:59,336
world, that world that you want


401
00:11:59,336 --> 00:11:59,636
it to be.


402
00:12:00,696 --> 00:12:02,806
Collecting data is a way to


403
00:12:02,806 --> 00:12:05,526
design experiences and great


404
00:12:05,526 --> 00:12:07,306
experiences often change the


405
00:12:07,306 --> 00:12:07,706
world.


406
00:12:08,196 --> 00:12:09,536
They don't just reflect what


407
00:12:09,536 --> 00:12:10,426
already exists.


408
00:12:11,886 --> 00:12:13,166
So how do we put this into


409
00:12:13,166 --> 00:12:14,000
practice?


410
00:12:15,676 --> 00:12:17,796
We'll start by collecting data


411
00:12:17,796 --> 00:12:18,506
intentionally.


412
00:12:19,226 --> 00:12:20,876
Understand the experience you're


413
00:12:20,876 --> 00:12:22,526
trying to create and think about


414
00:12:22,526 --> 00:12:23,646
what you'll need to make that


415
00:12:23,646 --> 00:12:24,496
experience work.


416
00:12:25,326 --> 00:12:26,426
If specific scenarios are


417
00:12:26,426 --> 00:12:28,096
important, spend more time and


418
00:12:28,096 --> 00:12:29,296
ensure you collect data for


419
00:12:29,296 --> 00:12:30,046
those scenarios.


420
00:12:31,126 --> 00:12:32,896
Spending time up front


421
00:12:33,926 --> 00:12:35,976
collecting the right data can


422
00:12:35,976 --> 00:12:37,836
save time and effort and money


423
00:12:37,836 --> 00:12:38,166
later.


424
00:12:38,726 --> 00:12:41,566
Make sure you test for biases.


425
00:12:42,266 --> 00:12:43,516
Analyze your dataset.


426
00:12:44,036 --> 00:12:45,656
Catalogue your assumptions about


427
00:12:45,856 --> 00:12:47,106
who will use your product and


428
00:12:47,106 --> 00:12:48,086
how it will be used.


429
00:12:48,796 --> 00:12:50,126
Think of ways your data might be


430
00:12:50,126 --> 00:12:51,806
biased towards or against


431
00:12:51,806 --> 00:12:53,266
certain populations or certain


432
00:12:53,266 --> 00:12:54,016
experiences.


433
00:12:54,486 --> 00:12:58,446
Update data as products change.


434
00:12:59,436 --> 00:13:01,476
Product specifications change


435
00:13:01,476 --> 00:13:02,446
the more you learn about your


436
00:13:02,446 --> 00:13:04,566
customers or the market or what


437
00:13:04,566 --> 00:13:05,896
you want to actually create.


438
00:13:06,946 --> 00:13:08,106
You need to change your data to


439
00:13:08,106 --> 00:13:08,616
match.


440
00:13:09,236 --> 00:13:10,326
You may not need to collect more


441
00:13:10,326 --> 00:13:10,596
data.


442
00:13:11,206 --> 00:13:12,926
You may get rid of concepts that


443
00:13:12,926 --> 00:13:15,066
are not important but you must


444
00:13:15,066 --> 00:13:17,476
routinely align your data with


445
00:13:17,476 --> 00:13:18,506
your product goals.


446
00:13:19,006 --> 00:13:22,926
And beware of standard datasets.


447
00:13:23,286 --> 00:13:25,006
Academic or industry benchmark


448
00:13:25,006 --> 00:13:27,386
datasets might be a great way to


449
00:13:27,386 --> 00:13:29,266
start to get some knowledge


450
00:13:29,266 --> 00:13:30,266
about how machine learning


451
00:13:30,266 --> 00:13:30,596
works.


452
00:13:30,926 --> 00:13:32,196
It might be a great way to ramp


453
00:13:32,196 --> 00:13:33,516
up your product development


454
00:13:33,516 --> 00:13:34,066
process.


455
00:13:34,706 --> 00:13:35,986
But they're not designed to


456
00:13:35,986 --> 00:13:37,736
represent real experiences,


457
00:13:38,276 --> 00:13:39,666
especially your experience.


458
00:13:40,396 --> 00:13:41,596
Before you start using an


459
00:13:41,596 --> 00:13:43,326
off-the-shelf dataset, think


460
00:13:43,326 --> 00:13:44,506
about what the data covers and


461
00:13:44,506 --> 00:13:45,116
doesn't cover.


462
00:13:45,556 --> 00:13:47,276
Spend time augmenting the data


463
00:13:47,276 --> 00:13:48,666
to match your needs.


464
00:13:49,936 --> 00:13:52,926
Spending time thinking about


465
00:13:53,516 --> 00:13:55,916
cataloguing and critically


466
00:13:56,196 --> 00:13:58,376
collecting data can help you


467
00:13:58,376 --> 00:13:59,976
align what you want your product


468
00:13:59,976 --> 00:14:02,156
to be and what machine learning


469
00:14:02,156 --> 00:14:02,726
can provide.


470
00:14:03,226 --> 00:14:06,906
So, we just talked about data,


471
00:14:06,966 --> 00:14:08,376
which is what you use to teach a


472
00:14:08,376 --> 00:14:08,756
model.


473
00:14:10,166 --> 00:14:11,576
Next, let's talk about how you


474
00:14:11,576 --> 00:14:12,396
evaluate your model.


475
00:14:13,066 --> 00:14:14,906
This is done through metrics.


476
00:14:15,456 --> 00:14:18,376
You evaluate your model by


477
00:14:18,376 --> 00:14:18,946
testing it.


478
00:14:19,276 --> 00:14:20,566
In the Photo Search example,


479
00:14:21,116 --> 00:14:22,226
you'd give it pictures of


480
00:14:22,226 --> 00:14:24,206
animals and your model would


481
00:14:24,206 --> 00:14:25,476
predict what's in the pictures.


482
00:14:25,776 --> 00:14:27,076
And once it's done, you can


483
00:14:27,076 --> 00:14:28,536
compare how many times it was


484
00:14:28,886 --> 00:14:31,006
correct and how many times it


485
00:14:31,006 --> 00:14:31,786
was incorrect.


486
00:14:32,406 --> 00:14:34,676
Here, we see that the model gave


487
00:14:34,676 --> 00:14:36,656
the correct prediction 75% of


488
00:14:36,656 --> 00:14:37,016
the time.


489
00:14:37,686 --> 00:14:39,526
This is a metric and a metric


490
00:14:39,676 --> 00:14:41,846
like this will define how


491
00:14:41,846 --> 00:14:43,686
successful your model is and,


492
00:14:43,686 --> 00:14:45,216
therefore, whether it's ready to


493
00:14:45,216 --> 00:14:46,706
use or whether you have to go


494
00:14:46,706 --> 00:14:47,786
back to the drawing board and


495
00:14:47,786 --> 00:14:48,676
improve it.


496
00:14:49,146 --> 00:14:51,366
Models can be evaluated in many


497
00:14:51,366 --> 00:14:51,776
ways.


498
00:14:52,156 --> 00:14:53,346
You could look at how fast the


499
00:14:53,346 --> 00:14:54,846
model works or how many


500
00:14:54,846 --> 00:14:55,936
categories it can support.


501
00:14:56,316 --> 00:14:57,576
You can balance all of these


502
00:14:57,576 --> 00:14:59,286
together and find the right set


503
00:14:59,286 --> 00:15:00,846
of metrics for your problem.


504
00:15:02,106 --> 00:15:04,096
Designing metrics define how the


505
00:15:04,096 --> 00:15:05,526
model will work and, therefore,


506
00:15:05,526 --> 00:15:06,956
how the experience will work but


507
00:15:07,136 --> 00:15:10,966
ultimately you get to decide.


508
00:15:11,076 --> 00:15:12,886
Metrics encode what you think a


509
00:15:12,886 --> 00:15:13,836
good experience is.


510
00:15:14,296 --> 00:15:15,776
They define what you care about


511
00:15:15,776 --> 00:15:16,816
and what you can ignore.


512
00:15:17,906 --> 00:15:19,476
If part of the experience is not


513
00:15:19,476 --> 00:15:21,246
measured, it may be sacrificed


514
00:15:21,306 --> 00:15:22,436
for something that is.


515
00:15:23,586 --> 00:15:25,326
And as a consequence, your


516
00:15:25,326 --> 00:15:28,416
metrics reflect your values.


517
00:15:28,886 --> 00:15:30,436
Let's look at an example.


518
00:15:31,806 --> 00:15:32,826
Let's look at Face ID.


519
00:15:34,256 --> 00:15:36,296
Face ID uses machine learning to


520
00:15:36,296 --> 00:15:38,376
detect your face to unlock your


521
00:15:38,376 --> 00:15:38,726
device.


522
00:15:40,236 --> 00:15:42,136
And behind Face ID are a number


523
00:15:42,136 --> 00:15:43,126
of design intents.


524
00:15:43,806 --> 00:15:45,026
The most important is Face ID


525
00:15:45,026 --> 00:15:46,426
needs to be secure.


526
00:15:46,786 --> 00:15:48,546
Our customers trust us with some


527
00:15:48,546 --> 00:15:49,676
of their most private data.


528
00:15:50,116 --> 00:15:51,856
There are many metrics that we


529
00:15:51,856 --> 00:15:53,946
use to track different aspects


530
00:15:53,946 --> 00:15:54,576
of security.


531
00:15:55,256 --> 00:15:56,776
One key metric was the chance


532
00:15:56,806 --> 00:15:58,666
that a random person could find


533
00:15:58,666 --> 00:16:00,206
your phone, pick it up and


534
00:16:00,206 --> 00:16:00,746
unlock it.


535
00:16:01,626 --> 00:16:02,816
We tracked this metric and


536
00:16:02,816 --> 00:16:05,146
worked hard to reduce this


537
00:16:05,826 --> 00:16:05,976
chance.


538
00:16:06,136 --> 00:16:07,856
At launch, we knew that there


539
00:16:07,856 --> 00:16:09,316
was a one-in-a-million chance


540
00:16:09,316 --> 00:16:10,916
that a random person could


541
00:16:10,916 --> 00:16:12,526
unlock your phone using Face ID.


542
00:16:12,976 --> 00:16:14,976
And since Face ID was a new


543
00:16:14,976 --> 00:16:16,526
experience, we needed to


544
00:16:16,526 --> 00:16:17,886
communicate this to our


545
00:16:17,886 --> 00:16:18,356
customers.


546
00:16:19,116 --> 00:16:20,586
That way they understood that we


547
00:16:20,586 --> 00:16:21,646
cared about their data and they


548
00:16:21,646 --> 00:16:23,106
could actually trust Face ID.


549
00:16:23,916 --> 00:16:25,786
But one in a million doesn't


550
00:16:25,786 --> 00:16:26,746
tell the whole story.


551
00:16:27,766 --> 00:16:30,066
Each failure is a person, a


552
00:16:30,066 --> 00:16:32,106
scenario, an experience that we


553
00:16:32,106 --> 00:16:35,286
have to think about and address.


554
00:16:35,466 --> 00:16:36,256
Say you're me.


555
00:16:36,606 --> 00:16:38,786
I'm your average run-of-the-mill


556
00:16:38,916 --> 00:16:43,296
Apple employee and recently I


557
00:16:43,296 --> 00:16:46,216
had a run-in with the new


558
00:16:46,216 --> 00:16:47,056
MacBook Pro.


559
00:16:47,366 --> 00:16:48,916
Due to a small mishap, I


560
00:16:49,066 --> 00:16:50,746
accidentally opened up a portal


561
00:16:50,746 --> 00:16:51,736
to another timeline.


562
00:16:51,736 --> 00:16:55,776
Now I have to routinely fight


563
00:16:55,776 --> 00:16:57,276
off my mirror universe nemesis.


564
00:16:57,766 --> 00:16:59,566
I obviously don't want him


565
00:16:59,566 --> 00:17:01,716
accessing secret Apple data, so


566
00:17:01,716 --> 00:17:03,766
I have to rely on a pass code.


567
00:17:04,306 --> 00:17:06,955
And people like me with similar


568
00:17:06,955 --> 00:17:08,546
looking family members or evil


569
00:17:08,546 --> 00:17:10,306
twins need to take the same


570
00:17:10,306 --> 00:17:10,846
precautions.


571
00:17:12,266 --> 00:17:14,646
As Apple, we also talked about


572
00:17:14,756 --> 00:17:15,675
this limitation.


573
00:17:16,146 --> 00:17:18,596
We dedicated time in a keynote


574
00:17:18,955 --> 00:17:20,026
because it's important that our


575
00:17:20,026 --> 00:17:23,046
customers understand and take


576
00:17:23,046 --> 00:17:24,556
steps to secure their data.


577
00:17:25,445 --> 00:17:26,656
It's important for you to


578
00:17:26,656 --> 00:17:27,886
understand and communicate


579
00:17:27,886 --> 00:17:30,386
limitations to unpack aggregate


580
00:17:30,466 --> 00:17:31,076
statistics.


581
00:17:31,566 --> 00:17:34,256
Not all mistakes are equal.


582
00:17:35,126 --> 00:17:37,266
Mistakes in machine learning are


583
00:17:37,266 --> 00:17:37,866
inevitable.


584
00:17:38,296 --> 00:17:40,126
Few models work 100% of the


585
00:17:40,126 --> 00:17:40,536
time.


586
00:17:41,326 --> 00:17:42,396
When you start, you may not


587
00:17:42,396 --> 00:17:44,296
understand all the limitations.


588
00:17:44,696 --> 00:17:45,756
That's OK.


589
00:17:46,116 --> 00:17:47,286
It's an iterative process.


590
00:17:48,036 --> 00:17:50,136
But over time, you need to build


591
00:17:50,136 --> 00:17:51,876
a better understanding of what


592
00:17:51,926 --> 00:17:53,426
is and is not possible.


593
00:17:54,446 --> 00:17:56,306
Mistakes don't mean you can't


594
00:17:56,306 --> 00:17:57,676
create an experience that people


595
00:17:57,676 --> 00:17:57,966
love.


596
00:17:58,586 --> 00:18:00,066
If you understand mistakes, you


597
00:18:00,066 --> 00:18:02,406
can account for them either by


598
00:18:02,526 --> 00:18:04,436
creating new models, improving


599
00:18:04,436 --> 00:18:06,286
the product or clearly


600
00:18:06,286 --> 00:18:07,386
communicating technical


601
00:18:07,386 --> 00:18:07,976
limitations.


602
00:18:10,366 --> 00:18:12,196
And remember that metrics are


603
00:18:12,196 --> 00:18:14,696
proxies for what we actually


604
00:18:14,696 --> 00:18:15,196
care about.


605
00:18:16,106 --> 00:18:17,656
Metrics provide numbers, a sense


606
00:18:17,656 --> 00:18:20,156
of scientific accuracy, and it's


607
00:18:20,306 --> 00:18:22,386
easy to get caught up in numbers


608
00:18:22,386 --> 00:18:24,326
and improving them but we


609
00:18:24,326 --> 00:18:26,096
ultimately care about abstract


610
00:18:26,096 --> 00:18:26,606
concepts.


611
00:18:27,446 --> 00:18:28,646
These things are hard to measure


612
00:18:28,926 --> 00:18:30,926
like good experiences, happy


613
00:18:30,926 --> 00:18:32,396
customers and strong brands.


614
00:18:33,256 --> 00:18:34,836
Let's look at an example.


615
00:18:35,976 --> 00:18:37,386
To understand metrics as


616
00:18:37,426 --> 00:18:39,486
proxies, let's talk about the


617
00:18:39,486 --> 00:18:40,876
App Store.


618
00:18:41,056 --> 00:18:42,556
The App Store uses machine


619
00:18:42,556 --> 00:18:44,346
learning to recommend new apps


620
00:18:44,866 --> 00:18:46,176
based on what you've downloaded.


621
00:18:46,666 --> 00:18:48,476
And at first approximation, the


622
00:18:48,596 --> 00:18:50,186
amount of time a person spends


623
00:18:50,186 --> 00:18:51,526
in the app might be a good


624
00:18:51,526 --> 00:18:51,896
measure.


625
00:18:52,226 --> 00:18:52,426
Right?


626
00:18:52,426 --> 00:18:54,426
Afterall, the more time you


627
00:18:54,426 --> 00:18:55,526
spend doing something, the more


628
00:18:55,526 --> 00:18:56,036
you like it.


629
00:18:56,036 --> 00:18:59,246
And if the App Store is purely


630
00:18:59,246 --> 00:19:00,756
driven by metrics and models,


631
00:19:01,416 --> 00:19:02,566
people would see apps that are


632
00:19:02,566 --> 00:19:04,016
very similar to the apps they


633
00:19:04,016 --> 00:19:04,686
currently use.


634
00:19:05,416 --> 00:19:06,426
I like playing games.


635
00:19:06,886 --> 00:19:08,786
So my top recommended apps are


636
00:19:08,786 --> 00:19:09,386
all games.


637
00:19:10,066 --> 00:19:12,176
And for a while, I might like


638
00:19:12,206 --> 00:19:14,006
those recommendations but over


639
00:19:14,006 --> 00:19:15,686
time, I'd feel boxed in because


640
00:19:15,686 --> 00:19:16,946
I care about more than just


641
00:19:16,946 --> 00:19:17,306
games.


642
00:19:18,316 --> 00:19:20,886
People have diverse interests


643
00:19:20,886 --> 00:19:21,406
and tastes.


644
00:19:22,146 --> 00:19:23,576
The amount of time I spend in an


645
00:19:23,576 --> 00:19:25,236
app may not indicate how much I


646
00:19:25,236 --> 00:19:26,366
value it.


647
00:19:27,076 --> 00:19:29,156
The App Store makes an editorial


648
00:19:29,156 --> 00:19:30,516
content with recommendations.


649
00:19:31,076 --> 00:19:32,416
This allows people to explore a


650
00:19:32,416 --> 00:19:34,016
diverse set of applications and


651
00:19:34,016 --> 00:19:35,836
experiences that they may not


652
00:19:35,836 --> 00:19:37,886
normally see if they just got


653
00:19:37,886 --> 00:19:39,116
their top recommendations.


654
00:19:40,126 --> 00:19:42,346
Editorial content is a way to


655
00:19:42,346 --> 00:19:43,866
address limitations of metrics


656
00:19:43,866 --> 00:19:44,916
and recommendations.


657
00:19:45,856 --> 00:19:47,386
But as you deploy your products


658
00:19:47,386 --> 00:19:48,696
and learn more about customer


659
00:19:48,696 --> 00:19:50,626
needs, what you care about


660
00:19:50,706 --> 00:19:51,246
evolves.


661
00:19:51,886 --> 00:19:54,666
You can evolve your metrics to


662
00:19:54,666 --> 00:19:55,156
match.


663
00:19:55,936 --> 00:19:57,376
For example, you can bake


664
00:19:57,416 --> 00:19:59,186
diversity into your metrics.


665
00:20:00,046 --> 00:20:01,246
You can measure when people


666
00:20:01,246 --> 00:20:03,406
engage with diverse content and


667
00:20:03,406 --> 00:20:05,286
actively create models that


668
00:20:05,286 --> 00:20:06,886
balance the quality and


669
00:20:06,886 --> 00:20:08,336
diversity of apps that people


670
00:20:08,336 --> 00:20:08,866
engage in.


671
00:20:10,056 --> 00:20:11,156
You should ensure that your


672
00:20:11,156 --> 00:20:12,506
metrics still track what you


673
00:20:12,506 --> 00:20:15,106
care about: a good experience,


674
00:20:15,636 --> 00:20:16,896
happy and fulfilled customers


675
00:20:16,896 --> 00:20:17,736
and strong brands.


676
00:20:18,606 --> 00:20:19,906
But to do that, you need to


677
00:20:19,906 --> 00:20:21,346
question metrics to ensure


678
00:20:21,346 --> 00:20:21,856
they're relevant.


679
00:20:21,856 --> 00:20:25,836
In your day to day, you can put


680
00:20:25,836 --> 00:20:26,546
this into practice.


681
00:20:27,196 --> 00:20:29,756
You can try to understand


682
00:20:29,986 --> 00:20:31,716
mistakes because not all


683
00:20:31,716 --> 00:20:32,616
mistakes are equal.


684
00:20:33,256 --> 00:20:34,436
Group failure cases into


685
00:20:34,436 --> 00:20:35,746
categories and scenarios.


686
00:20:36,436 --> 00:20:37,566
This will help you understand


687
00:20:37,566 --> 00:20:39,116
how important each scenario is.


688
00:20:39,776 --> 00:20:41,586
Decide if it's best handled by a


689
00:20:41,586 --> 00:20:43,636
non-ML approach like improving


690
00:20:43,636 --> 00:20:45,866
the design or if you actually


691
00:20:45,866 --> 00:20:46,796
need to build a better model.


692
00:20:47,366 --> 00:20:49,826
And design for failure


693
00:20:49,826 --> 00:20:50,396
scenarios.


694
00:20:51,146 --> 00:20:52,706
When storyboarding or sketching


695
00:20:52,706 --> 00:20:54,416
out an experience, don't just


696
00:20:54,476 --> 00:20:55,656
sketch out what happens if


697
00:20:55,656 --> 00:20:56,446
things go well.


698
00:20:57,246 --> 00:20:58,356
Sketch out what happens if


699
00:20:58,356 --> 00:20:59,286
something goes wrong.


700
00:20:59,916 --> 00:21:01,396
This will help you emphasize


701
00:21:01,396 --> 00:21:02,306
what your customers might


702
00:21:02,306 --> 00:21:02,886
experience.


703
00:21:03,466 --> 00:21:06,886
Spend time evaluating the


704
00:21:06,886 --> 00:21:07,556
experience.


705
00:21:08,536 --> 00:21:09,466
The metric will give you an


706
00:21:09,466 --> 00:21:11,056
objective value for how well


707
00:21:11,056 --> 00:21:11,926
your model is working.


708
00:21:12,496 --> 00:21:14,166
Remember, the model is not the


709
00:21:14,166 --> 00:21:14,816
experience.


710
00:21:15,516 --> 00:21:17,206
The actual experience is the


711
00:21:17,206 --> 00:21:18,236
experience.


712
00:21:18,596 --> 00:21:19,946
So try to measure that


713
00:21:19,946 --> 00:21:20,556
experience.


714
00:21:21,036 --> 00:21:22,096
Run user studies.


715
00:21:22,436 --> 00:21:23,256
Build demos.


716
00:21:23,916 --> 00:21:25,096
Talk to your customers.


717
00:21:25,216 --> 00:21:26,096
Read forums.


718
00:21:27,026 --> 00:21:28,796
If the experience is bad and the


719
00:21:28,796 --> 00:21:29,906
metric says it's good, your


720
00:21:30,346 --> 00:21:32,046
metric is probably wrong.


721
00:21:32,606 --> 00:21:34,526
If the experience seems the same


722
00:21:34,526 --> 00:21:35,546
the metric says it's getting


723
00:21:35,546 --> 00:21:37,726
better, your metric is likely


724
00:21:37,726 --> 00:21:38,216
wrong.


725
00:21:38,776 --> 00:21:42,336
And over time, evolve your


726
00:21:42,336 --> 00:21:42,806
metrics.


727
00:21:43,436 --> 00:21:44,636
Question and assess the


728
00:21:44,636 --> 00:21:45,786
effectiveness of your metrics


729
00:21:46,096 --> 00:21:46,606
constantly.


730
00:21:47,176 --> 00:21:48,546
The more you rely on something,


731
00:21:48,606 --> 00:21:51,946
the more you should question it.


732
00:21:53,456 --> 00:21:55,836
Ultimately, your metrics reflect


733
00:21:55,836 --> 00:21:56,496
your values.


734
00:21:57,016 --> 00:21:59,716
And if you want to align your


735
00:21:59,716 --> 00:22:00,656
metrics with your values, you


736
00:22:00,656 --> 00:22:01,516
have to think carefully,


737
00:22:01,626 --> 00:22:03,356
critically and continuously


738
00:22:03,646 --> 00:22:04,686
about what is and is not


739
00:22:04,686 --> 00:22:05,026
measured.


740
00:22:05,536 --> 00:22:08,366
We just talked about metrics


741
00:22:08,876 --> 00:22:10,066
which is how you understand if


742
00:22:10,066 --> 00:22:11,646
the model is good, how you


743
00:22:11,646 --> 00:22:14,446
evaluate a model.


744
00:22:14,606 --> 00:22:16,616
Next, let's talk about the


745
00:22:16,616 --> 00:22:17,226
interface.


746
00:22:17,836 --> 00:22:20,106
Designing metrics in data is key


747
00:22:20,106 --> 00:22:21,006
to designing how your model


748
00:22:21,006 --> 00:22:21,356
behaves.


749
00:22:22,226 --> 00:22:23,766
But we also have to figure out


750
00:22:23,766 --> 00:22:25,696
how do we surface the model in


751
00:22:25,696 --> 00:22:26,236
the interface.


752
00:22:26,436 --> 00:22:27,876
And to do that, I'll hand it


753
00:22:27,876 --> 00:22:30,096
over to Rubii and Cas to talk


754
00:22:30,146 --> 00:22:31,696
more about outputs/inputs.


755
00:22:31,946 --> 00:22:32,696
Thank you so much.


756
00:22:33,516 --> 00:22:37,500
[ Applause ]


757
00:22:46,126 --> 00:22:47,836
>> As Kayur has shown, there's a


758
00:22:47,836 --> 00:22:49,856
lot that goes into creating the


759
00:22:49,856 --> 00:22:51,286
underlying machine learning


760
00:22:51,286 --> 00:22:52,506
system that powers an


761
00:22:52,506 --> 00:22:53,136
experience.


762
00:22:54,036 --> 00:22:55,356
But we also need to design


763
00:22:55,356 --> 00:22:57,336
interfaces that allow people to


764
00:22:57,336 --> 00:22:58,636
interact with the experience in


765
00:22:58,636 --> 00:22:59,756
an intuitive way.


766
00:23:00,416 --> 00:23:02,926
The interface can translate


767
00:23:02,926 --> 00:23:04,586
results from a model to outputs


768
00:23:04,806 --> 00:23:05,676
that people can actually


769
00:23:05,676 --> 00:23:06,286
interact with.


770
00:23:07,286 --> 00:23:08,436
The feedback we collect from


771
00:23:08,436 --> 00:23:10,466
these interactions are inputs we


772
00:23:10,466 --> 00:23:11,916
can use to future improve the


773
00:23:11,916 --> 00:23:12,506
experience.


774
00:23:12,996 --> 00:23:16,996
We've created a set of patterns


775
00:23:17,116 --> 00:23:18,126
in the human interface


776
00:23:18,126 --> 00:23:19,786
guidelines to help you design


777
00:23:19,786 --> 00:23:21,086
output and inputs.


778
00:23:22,286 --> 00:23:23,336
Cas and I will go in-depth


779
00:23:23,336 --> 00:23:24,506
through some of them to help you


780
00:23:24,506 --> 00:23:26,316
understand how they apply to the


781
00:23:26,316 --> 00:23:27,236
experience you're building.


782
00:23:27,236 --> 00:23:31,416
First let's talk about outputs.


783
00:23:31,486 --> 00:23:34,326
Outputs can be more than just


784
00:23:34,326 --> 00:23:34,856
predictions.


785
00:23:35,106 --> 00:23:36,706
They're a design medium that can


786
00:23:36,786 --> 00:23:38,306
augment an experience into


787
00:23:38,306 --> 00:23:39,506
something that feels more


788
00:23:39,506 --> 00:23:41,326
contextual and seamlessly


789
00:23:41,326 --> 00:23:41,776
helpful.


790
00:23:42,856 --> 00:23:44,406
There are four types of outputs


791
00:23:45,226 --> 00:23:47,436
we'll discuss.


792
00:23:47,556 --> 00:23:48,986
Multiple options allow you to


793
00:23:49,026 --> 00:23:51,196
present a diverse set of outputs


794
00:23:51,746 --> 00:23:53,686
to people.


795
00:23:53,806 --> 00:23:55,626
Attributions are explanations


796
00:23:55,816 --> 00:23:57,356
that help people understand more


797
00:23:57,356 --> 00:23:58,596
about how your app makes


798
00:23:58,656 --> 00:23:59,146
decisions.


799
00:24:01,196 --> 00:24:02,876
Confidence is a measurement of


800
00:24:02,876 --> 00:24:06,556
certainty for an output.


801
00:24:06,726 --> 00:24:08,426
And limitations occurs when


802
00:24:08,426 --> 00:24:09,536
there's a mismatch between


803
00:24:09,536 --> 00:24:10,736
people's mental model of a


804
00:24:10,736 --> 00:24:12,606
feature and what the feature can


805
00:24:12,656 --> 00:24:13,426
actually do.


806
00:24:14,006 --> 00:24:16,836
Let's start with multiple


807
00:24:16,836 --> 00:24:17,256
options.


808
00:24:17,716 --> 00:24:22,586
As I had mentioned, multiple


809
00:24:22,586 --> 00:24:24,126
options allow people to choose


810
00:24:24,286 --> 00:24:25,646
from among the results a feature


811
00:24:25,646 --> 00:24:26,106
generates.


812
00:24:27,186 --> 00:24:28,296
What does this actually mean?


813
00:24:28,826 --> 00:24:31,686
Well it's often tempting to only


814
00:24:31,686 --> 00:24:33,306
reveal the best option that was


815
00:24:33,306 --> 00:24:34,546
created by your model.


816
00:24:34,686 --> 00:24:35,936
That's often not the best


817
00:24:35,936 --> 00:24:36,546
experience.


818
00:24:37,356 --> 00:24:38,586
Let me show you an example from


819
00:24:38,586 --> 00:24:39,126
the real world.


820
00:24:40,166 --> 00:24:41,786
Last weekend I wanted to take a


821
00:24:41,786 --> 00:24:43,516
short trip and I asked my


822
00:24:43,516 --> 00:24:45,306
colleagues what's the best way


823
00:24:45,366 --> 00:24:47,056
to get between San Francisco and


824
00:24:47,056 --> 00:24:47,426
Napa.


825
00:24:49,166 --> 00:24:50,516
Depending on the person and the


826
00:24:50,516 --> 00:24:52,186
time of day that I asked, the


827
00:24:52,186 --> 00:24:53,286
answers varied.


828
00:24:53,666 --> 00:24:55,136
Sometimes they would say take


829
00:24:55,136 --> 00:24:55,896
the I-80.


830
00:24:56,166 --> 00:24:57,516
Sometimes they would say take


831
00:24:57,516 --> 00:24:57,976
the 101.


832
00:24:58,826 --> 00:25:01,076
This is because route prediction


833
00:25:01,076 --> 00:25:03,186
is a complex task with a lot of


834
00:25:03,186 --> 00:25:04,366
different variables that might


835
00:25:04,366 --> 00:25:05,556
constantly be changing.


836
00:25:06,366 --> 00:25:07,636
There might be traffic or


837
00:25:07,636 --> 00:25:09,056
construction or even car


838
00:25:09,926 --> 00:25:10,196
accidents.


839
00:25:11,936 --> 00:25:13,716
Given all of that information,


840
00:25:13,926 --> 00:25:15,696
in Maps we try to predict the


841
00:25:15,696 --> 00:25:17,276
best route possible but


842
00:25:17,276 --> 00:25:19,236
sometimes a single option is not


843
00:25:19,236 --> 00:25:19,586
enough.


844
00:25:21,096 --> 00:25:22,716
We can't know everything that a


845
00:25:22,716 --> 00:25:24,176
particular person may care


846
00:25:24,176 --> 00:25:24,456
about.


847
00:25:25,336 --> 00:25:26,996
They may prefer scenic routes or


848
00:25:26,996 --> 00:25:28,856
routes without tolls or routes


849
00:25:28,856 --> 00:25:30,566
not along highways.


850
00:25:32,856 --> 00:25:34,676
Providing a set of meaningfully


851
00:25:34,676 --> 00:25:36,246
different routes can help people


852
00:25:36,246 --> 00:25:37,566
navigate the gap between their


853
00:25:37,636 --> 00:25:39,766
preferences and what a model can


854
00:25:39,766 --> 00:25:40,726
realistically predict.


855
00:25:41,526 --> 00:25:43,176
Here, Maps gives us three


856
00:25:43,176 --> 00:25:45,116
distinctly different routes: One


857
00:25:45,116 --> 00:25:46,486
that goes to the North Bay and


858
00:25:46,486 --> 00:25:47,916
two that go to the East Bay.


859
00:25:48,926 --> 00:25:50,056
This can give people a sense of


860
00:25:50,106 --> 00:25:51,766
control over how to get to their


861
00:25:51,766 --> 00:25:52,976
final destination.


862
00:25:56,336 --> 00:25:57,696
Whenever possible, you should


863
00:25:57,696 --> 00:25:59,556
prefer diverse options that


864
00:25:59,556 --> 00:26:00,806
encapsulate a meaningful


865
00:26:00,806 --> 00:26:04,256
selection of choices.


866
00:26:06,516 --> 00:26:08,246
People might also be using Maps


867
00:26:08,246 --> 00:26:09,736
while on the go and some of the


868
00:26:09,736 --> 00:26:11,056
options might appear very


869
00:26:11,056 --> 00:26:12,746
similar which makes it difficult


870
00:26:12,746 --> 00:26:14,086
for people to quickly choose the


871
00:26:14,086 --> 00:26:14,226
route.


872
00:26:15,556 --> 00:26:17,276
We can also use attributions to


873
00:26:17,276 --> 00:26:18,336
help people differentiate


874
00:26:18,336 --> 00:26:19,916
between the options and make a


875
00:26:19,916 --> 00:26:20,786
choice faster.


876
00:26:22,816 --> 00:26:24,756
Here, we show you whether a


877
00:26:24,756 --> 00:26:27,606
route requires a toll, which


878
00:26:27,606 --> 00:26:30,286
highway it goes through and we


879
00:26:30,416 --> 00:26:31,936
even highlight each path on the


880
00:26:31,936 --> 00:26:34,196
map making it easier to find


881
00:26:34,196 --> 00:26:36,376
that perfect scenic waterfront


882
00:26:37,216 --> 00:26:37,346
drive.


883
00:26:39,336 --> 00:26:41,136
These small summaries are a


884
00:26:41,136 --> 00:26:42,666
great tool to help people


885
00:26:42,666 --> 00:26:44,236
differentiate between a broad


886
00:26:44,296 --> 00:26:45,776
selection of options at a quick


887
00:26:45,776 --> 00:26:47,306
glance and easily make a


888
00:26:47,306 --> 00:26:50,766
selection while on the go.


889
00:26:51,026 --> 00:26:53,076
Now I know Maps is an obvious


890
00:26:53,076 --> 00:26:54,716
example for presenting options


891
00:26:55,246 --> 00:26:56,656
because it's reacting to very


892
00:26:56,656 --> 00:26:57,426
explicit input.


893
00:26:57,426 --> 00:26:59,576
I know where I am, where I want


894
00:26:59,576 --> 00:27:01,316
to go and I'm expecting a list


895
00:27:01,316 --> 00:27:02,596
of options that can get me


896
00:27:03,066 --> 00:27:03,166
there.


897
00:27:03,736 --> 00:27:05,796
But multiple options can also be


898
00:27:05,796 --> 00:27:07,106
useful for features that are


899
00:27:07,106 --> 00:27:08,456
proactively surfacing


900
00:27:08,456 --> 00:27:10,336
suggestions or it might be more


901
00:27:10,336 --> 00:27:12,246
ambiguous what my current intent


902
00:27:12,246 --> 00:27:13,886
and context is.


903
00:27:16,296 --> 00:27:17,376
Let's talk about the watch.


904
00:27:17,376 --> 00:27:19,476
When I start the day every


905
00:27:19,476 --> 00:27:21,686
morning, I might want to check


906
00:27:22,076 --> 00:27:23,756
the weather, see my first


907
00:27:23,756 --> 00:27:27,686
appointment and see reminders of


908
00:27:27,686 --> 00:27:29,426
what I need to do that day.


909
00:27:30,036 --> 00:27:31,536
Siri watch face allows me to


910
00:27:31,536 --> 00:27:33,736
customize up to 19 different


911
00:27:33,736 --> 00:27:35,366
data sources that I might want


912
00:27:35,366 --> 00:27:36,326
to get information from


913
00:27:36,866 --> 00:27:38,736
including weather, calendar, and


914
00:27:38,736 --> 00:27:39,186
reminders.


915
00:27:40,016 --> 00:27:40,936
You can even choose to see


916
00:27:40,936 --> 00:27:42,086
information from third-party


917
00:27:42,086 --> 00:27:42,346
apps.


918
00:27:43,166 --> 00:27:45,046
Now information from 19


919
00:27:45,046 --> 00:27:46,746
different apps is a lot to look


920
00:27:46,746 --> 00:27:48,066
at on such a small screen.


921
00:27:49,096 --> 00:27:50,446
That's why Siri chooses to


922
00:27:50,516 --> 00:27:52,056
surface a smaller selection of


923
00:27:52,056 --> 00:27:55,036
options based on time, location,


924
00:27:55,306 --> 00:27:56,356
and what I've previously


925
00:27:56,356 --> 00:27:57,036
interacted with.


926
00:27:57,546 --> 00:28:01,456
Since my watch knows it's


927
00:28:01,456 --> 00:28:03,626
morning time, I'm at home, and


928
00:28:03,626 --> 00:28:05,586
in the past I've always selected


929
00:28:05,586 --> 00:28:06,986
the option to turn on the lights


930
00:28:06,986 --> 00:28:07,976
at the certain time.


931
00:28:08,466 --> 00:28:09,836
It'll surface this as a top


932
00:28:09,876 --> 00:28:11,256
suggestion every morning.


933
00:28:11,776 --> 00:28:14,406
Siri can understand my usage


934
00:28:14,406 --> 00:28:16,056
history to help me automate this


935
00:28:16,096 --> 00:28:18,526
mundane task without having to


936
00:28:18,526 --> 00:28:20,046
scroll through this long list of


937
00:28:20,046 --> 00:28:22,146
options when I first wake up.


938
00:28:22,756 --> 00:28:24,086
This makes getting up in the


939
00:28:24,086 --> 00:28:25,626
morning so much more effortless


940
00:28:25,626 --> 00:28:26,706
for someone who's not a morning


941
00:28:26,706 --> 00:28:28,286
person, like me.


942
00:28:31,196 --> 00:28:33,176
This is important because every


943
00:28:33,176 --> 00:28:35,196
time someone selects an option,


944
00:28:35,556 --> 00:28:36,466
they're actually giving you


945
00:28:36,466 --> 00:28:38,396
valuable implicit feedback that


946
00:28:38,396 --> 00:28:39,796
you can use to make sure the


947
00:28:39,796 --> 00:28:41,706
most relevant option is always


948
00:28:41,706 --> 00:28:44,416
ranked at the top.


949
00:28:44,416 --> 00:28:45,166
If you learn from their


950
00:28:45,166 --> 00:28:46,666
selection, you'll be able to


951
00:28:46,666 --> 00:28:48,576
surface better suggestions over


952
00:28:48,576 --> 00:28:48,876
time.


953
00:28:54,786 --> 00:28:55,926
Now remember when we talked


954
00:28:55,926 --> 00:28:59,266
about Maps and how attributions


955
00:28:59,266 --> 00:29:00,676
can be used to differentiate


956
00:29:01,566 --> 00:29:01,686
routes?


957
00:29:03,276 --> 00:29:04,746
Attributions can actually be


958
00:29:04,746 --> 00:29:09,376
used for so much more than that.


959
00:29:09,656 --> 00:29:11,406
Attributions are explanations


960
00:29:11,576 --> 00:29:13,126
that help people understand more


961
00:29:13,126 --> 00:29:14,316
about how your app makes


962
00:29:14,316 --> 00:29:14,816
decisions.


963
00:29:15,346 --> 00:29:19,036
Within the App Store, we use


964
00:29:19,036 --> 00:29:20,546
attributions to explain how


965
00:29:20,546 --> 00:29:22,086
recommendations are created.


966
00:29:23,066 --> 00:29:24,646
This helps people understand why


967
00:29:24,646 --> 00:29:25,606
they might be seeing certain


968
00:29:25,606 --> 00:29:27,596
suggestions and how their data


969
00:29:27,596 --> 00:29:29,046
is being used.


970
00:29:30,716 --> 00:29:32,366
But let's say the App Store is


971
00:29:32,366 --> 00:29:33,776
showing me some recommendations


972
00:29:33,776 --> 00:29:35,006
because I downloaded a cooking


973
00:29:35,916 --> 00:29:36,046
app.


974
00:29:36,046 --> 00:29:37,486
Now I might have downloaded an


975
00:29:37,546 --> 00:29:39,316
app to cook but that doesn't


976
00:29:39,316 --> 00:29:40,856
necessarily mean I'm into


977
00:29:40,856 --> 00:29:41,186
cooking.


978
00:29:41,676 --> 00:29:44,756
Neither does it mean that I love


979
00:29:44,886 --> 00:29:46,366
that particular app.


980
00:29:48,056 --> 00:29:49,526
Therefore, when using


981
00:29:49,526 --> 00:29:50,726
attributions to explain


982
00:29:50,726 --> 00:29:52,296
suggestions, you should relate


983
00:29:52,296 --> 00:29:53,866
to objective facts rather than


984
00:29:53,866 --> 00:29:54,776
subjective taste.


985
00:29:55,646 --> 00:29:57,316
Here, we simply state that these


986
00:29:57,316 --> 00:29:58,546
suggestions are because you've


987
00:29:58,546 --> 00:29:59,626
downloaded the "New York Times"


988
00:29:59,626 --> 00:29:59,976
Cooking app.


989
00:30:04,486 --> 00:30:06,076
We can never have a complete


990
00:30:06,076 --> 00:30:07,836
picture of someone's taste and


991
00:30:07,836 --> 00:30:09,526
preferences because they might


992
00:30:09,526 --> 00:30:11,056
evolve on a daily basis.


993
00:30:11,896 --> 00:30:13,116
People might also share an


994
00:30:13,116 --> 00:30:14,416
account with their friends and


995
00:30:14,416 --> 00:30:16,766
family; therefore, profiling


996
00:30:16,766 --> 00:30:18,646
them makes them feel confused


997
00:30:18,896 --> 00:30:20,596
and boxed in.


998
00:30:20,816 --> 00:30:22,076
You should avoid profiling


999
00:30:22,076 --> 00:30:23,966
people by not using language


1000
00:30:23,966 --> 00:30:26,026
that implies understanding or


1001
00:30:26,026 --> 00:30:27,636
judgment of their emotions and


1002
00:30:27,636 --> 00:30:28,226
preferences.


1003
00:30:32,416 --> 00:30:34,226
We can also use attributions to


1004
00:30:34,226 --> 00:30:35,516
help people understand the


1005
00:30:35,516 --> 00:30:37,206
trustworthiness of a result.


1006
00:30:37,206 --> 00:30:40,026
I'm an astronomy enthusiast and


1007
00:30:40,026 --> 00:30:41,436
I wanted to see which planet was


1008
00:30:41,436 --> 00:30:42,666
visible in the sky tonight.


1009
00:30:43,296 --> 00:30:45,426
So I asked Siri, "When can you


1010
00:30:45,426 --> 00:30:46,036
see Jupiter?"


1011
00:30:48,596 --> 00:30:50,216
Siri tells me when the event


1012
00:30:50,216 --> 00:30:52,926
will happen but also gives me


1013
00:30:52,926 --> 00:30:54,846
more information from Wolfram


1014
00:30:55,356 --> 00:30:55,506
Alpha.


1015
00:30:56,156 --> 00:30:57,626
This helps me understand that


1016
00:30:57,626 --> 00:30:59,146
it's a reliable prediction


1017
00:30:59,466 --> 00:31:00,696
because Wolfram Alpha is a


1018
00:31:00,696 --> 00:31:02,206
well-known knowledge engine.


1019
00:31:03,026 --> 00:31:04,876
This is really important when it


1020
00:31:04,876 --> 00:31:06,366
comes to displaying predictions


1021
00:31:06,726 --> 00:31:08,036
where the trustworthiness of the


1022
00:31:08,036 --> 00:31:10,266
source really matters like


1023
00:31:10,396 --> 00:31:12,106
scientific information or


1024
00:31:12,106 --> 00:31:12,826
election results.


1025
00:31:13,326 --> 00:31:18,426
Cite data sources so people can


1026
00:31:18,426 --> 00:31:20,316
determine how reliable a certain


1027
00:31:20,316 --> 00:31:20,976
prediction might be.


1028
00:31:26,606 --> 00:31:28,866
Now attributions can be used for


1029
00:31:28,866 --> 00:31:30,096
more than just explaining


1030
00:31:30,096 --> 00:31:31,916
personalization or predictions.


1031
00:31:32,426 --> 00:31:33,316
We can also use it to


1032
00:31:33,316 --> 00:31:34,516
communicate confidence.


1033
00:31:34,516 --> 00:31:38,986
Let's look at the App Store


1034
00:31:38,986 --> 00:31:40,946
again and see how we really try


1035
00:31:40,946 --> 00:31:42,676
to avoid technical jargon here.


1036
00:31:44,616 --> 00:31:46,296
For example, we could've said


1037
00:31:46,866 --> 00:31:48,906
these apps are an 85% match for


1038
00:31:48,906 --> 00:31:51,086
you but it's really difficult to


1039
00:31:51,086 --> 00:31:53,006
understand what 85% mean.


1040
00:31:53,816 --> 00:31:54,936
That number might also mean


1041
00:31:54,936 --> 00:31:56,016
different things to different


1042
00:31:56,016 --> 00:31:56,366
people.


1043
00:31:56,896 --> 00:32:00,686
That's why we try to use a more


1044
00:32:00,746 --> 00:32:02,826
understandable explanation such


1045
00:32:02,826 --> 00:32:04,966
as recommendations based on apps


1046
00:32:05,266 --> 00:32:06,106
you've downloaded.


1047
00:32:06,626 --> 00:32:11,056
That 85% I mentioned is a


1048
00:32:11,056 --> 00:32:12,816
measurement of confidence or how


1049
00:32:12,916 --> 00:32:14,556
certain the model is that you'll


1050
00:32:14,556 --> 00:32:15,706
like the recommendations.


1051
00:32:16,826 --> 00:32:18,566
Confidence is what you get from


1052
00:32:18,566 --> 00:32:20,336
a machine learning model but


1053
00:32:20,336 --> 00:32:21,866
it's important to translate it


1054
00:32:21,946 --> 00:32:22,886
into something more


1055
00:32:22,886 --> 00:32:27,606
understandable for people.


1056
00:32:27,736 --> 00:32:29,626
Sometimes it's OK to directly


1057
00:32:29,626 --> 00:32:30,576
display confidence.


1058
00:32:31,556 --> 00:32:32,596
The Weather app gives you


1059
00:32:32,596 --> 00:32:33,756
information that it's going to


1060
00:32:33,756 --> 00:32:35,686
rain but it also gives you a


1061
00:32:35,686 --> 00:32:37,466
percentage for how likely it's


1062
00:32:37,466 --> 00:32:39,166
going to rain.


1063
00:32:39,386 --> 00:32:41,516
Now you might think what kind of


1064
00:32:41,516 --> 00:32:42,926
a decision should I make based


1065
00:32:42,926 --> 00:32:44,186
on this 30% chance.


1066
00:32:45,106 --> 00:32:46,156
Is it worth bringing my


1067
00:32:46,156 --> 00:32:46,596
umbrella?


1068
00:32:47,726 --> 00:32:48,836
It's unclear.


1069
00:32:49,136 --> 00:32:50,136
But we've been conditioned to


1070
00:32:50,136 --> 00:32:51,686
understand this percentage over


1071
00:32:52,646 --> 00:32:52,756
time.


1072
00:32:55,266 --> 00:32:56,386
And while numbers are


1073
00:32:56,386 --> 00:32:57,996
appropriate for statistical


1074
00:32:57,996 --> 00:32:59,426
predictions such as weather,


1075
00:33:00,116 --> 00:33:01,646
sports results or election


1076
00:33:01,646 --> 00:33:03,616
predictions, it might not work


1077
00:33:03,616 --> 00:33:04,596
in other situations.


1078
00:33:05,166 --> 00:33:08,276
This is Hopper.


1079
00:33:09,056 --> 00:33:10,666
It's an app that helps you book


1080
00:33:10,716 --> 00:33:11,346
cheaper flights.


1081
00:33:12,716 --> 00:33:14,246
It uses confidence to tell


1082
00:33:14,246 --> 00:33:15,466
people whether the fare will go


1083
00:33:15,466 --> 00:33:16,636
up or down.


1084
00:33:17,986 --> 00:33:19,416
And we don't expect people to


1085
00:33:19,416 --> 00:33:20,866
grapple with percentages here


1086
00:33:20,996 --> 00:33:22,236
because in this context,


1087
00:33:22,416 --> 00:33:23,876
percentages are difficult to


1088
00:33:23,876 --> 00:33:24,366
interpret.


1089
00:33:24,836 --> 00:33:28,146
Seeing a 65% chance the price


1090
00:33:28,146 --> 00:33:29,586
will go down is not really


1091
00:33:29,586 --> 00:33:30,216
actionable.


1092
00:33:30,886 --> 00:33:34,626
How is 65% different than 70%?


1093
00:33:35,716 --> 00:33:37,166
The way Hopper presents


1094
00:33:37,166 --> 00:33:38,676
confidence is by giving you


1095
00:33:38,676 --> 00:33:40,746
actual suggestions for actions


1096
00:33:40,746 --> 00:33:42,276
you should take, whether you


1097
00:33:42,276 --> 00:33:44,676
should wait or buy now.


1098
00:33:47,026 --> 00:33:48,666
It also provides additional


1099
00:33:48,666 --> 00:33:50,576
context such as how much money


1100
00:33:50,576 --> 00:33:51,906
you're going to save and the


1101
00:33:51,906 --> 00:33:53,386
optimal time range to book a


1102
00:33:53,386 --> 00:33:53,706
flight.


1103
00:33:55,206 --> 00:33:56,716
These additional explanations


1104
00:33:56,716 --> 00:33:58,456
help people make a more informed


1105
00:33:58,546 --> 00:33:59,736
decision.


1106
00:34:02,706 --> 00:34:03,866
When confidence is used


1107
00:34:03,866 --> 00:34:05,416
appropriately, it can make an


1108
00:34:05,416 --> 00:34:07,906
experience feel so much more


1109
00:34:07,906 --> 00:34:08,346
human.


1110
00:34:08,346 --> 00:34:11,406
Most of the time you should


1111
00:34:11,626 --> 00:34:13,126
prefer to translate confidence


1112
00:34:13,166 --> 00:34:15,295
into easy-to-understand terms to


1113
00:34:15,295 --> 00:34:16,446
help people make a decision.


1114
00:34:20,795 --> 00:34:22,376
So by this point, you probably


1115
00:34:22,376 --> 00:34:23,956
understand that confidence can


1116
00:34:23,956 --> 00:34:26,096
be a great tool to help people


1117
00:34:26,096 --> 00:34:27,696
estimate how risky a certain


1118
00:34:27,696 --> 00:34:30,516
decision might be but there are


1119
00:34:30,516 --> 00:34:31,766
cases where this doesn't work.


1120
00:34:33,106 --> 00:34:36,065
For example, if I ask you how


1121
00:34:36,065 --> 00:34:37,406
long it would take for me to get


1122
00:34:37,406 --> 00:34:39,056
between here and San Francisco


1123
00:34:40,166 --> 00:34:42,966
and you replied, "I'm 72%


1124
00:34:42,966 --> 00:34:44,585
confident you'll get there at


1125
00:34:44,585 --> 00:34:45,096
1:30."


1126
00:34:46,116 --> 00:34:47,426
That would be pretty confusing.


1127
00:34:47,426 --> 00:34:49,476
How can I be sure what time I'll


1128
00:34:49,476 --> 00:34:53,876
actually get home?


1129
00:34:54,085 --> 00:34:55,446
A better way is to provide a


1130
00:34:55,446 --> 00:34:56,676
range in the prediction.


1131
00:34:57,546 --> 00:34:59,216
With ride sharing, it's often


1132
00:34:59,216 --> 00:35:00,716
difficult to pinpoint an exact


1133
00:35:00,716 --> 00:35:02,746
arrival time since there might


1134
00:35:02,746 --> 00:35:04,246
be traffic or the driver might


1135
00:35:04,246 --> 00:35:05,196
pick up more riders.


1136
00:35:06,876 --> 00:35:08,796
Lyft help people estimate when


1137
00:35:08,796 --> 00:35:09,706
they will arrive at their


1138
00:35:09,706 --> 00:35:11,436
destination before they book a


1139
00:35:11,436 --> 00:35:13,716
ride by providing a range about


1140
00:35:13,716 --> 00:35:15,086
the time the driver will pick


1141
00:35:15,086 --> 00:35:18,066
you up and the time you will


1142
00:35:18,066 --> 00:35:19,086
arrive at the airport.


1143
00:35:20,366 --> 00:35:21,686
These ranges help me have a


1144
00:35:21,686 --> 00:35:23,106
realistic expectation of when


1145
00:35:23,106 --> 00:35:23,946
I'll actually get home.


1146
00:35:28,626 --> 00:35:30,126
Range can be a great tool to


1147
00:35:30,326 --> 00:35:32,026
help people estimate how risky a


1148
00:35:32,026 --> 00:35:33,796
certain decision might be.


1149
00:35:36,936 --> 00:35:38,866
Now these are all good examples


1150
00:35:38,866 --> 00:35:40,986
of how to display confidence but


1151
00:35:40,986 --> 00:35:42,366
what do you do when there is low


1152
00:35:42,366 --> 00:35:44,166
confidence and the model doesn't


1153
00:35:44,206 --> 00:35:45,476
have enough information to


1154
00:35:45,596 --> 00:35:46,926
actually take an action?


1155
00:35:47,476 --> 00:35:49,946
In a lot of cases, we can


1156
00:35:49,946 --> 00:35:51,826
actually ask people for help.


1157
00:35:53,616 --> 00:35:56,286
For example, the Photos app can


1158
00:35:56,366 --> 00:35:58,036
automatically recognize people


1159
00:35:58,566 --> 00:35:59,716
in order to make searching for


1160
00:35:59,716 --> 00:36:00,736
their pictures easier.


1161
00:36:02,166 --> 00:36:03,696
When Photos has low confidence


1162
00:36:03,696 --> 00:36:05,666
who is in a picture, it will ask


1163
00:36:05,756 --> 00:36:07,296
people to confirm additional


1164
00:36:07,296 --> 00:36:09,466
photos of that person before


1165
00:36:09,466 --> 00:36:10,806
automatically labeling them.


1166
00:36:12,196 --> 00:36:13,736
Asking for confirmation is


1167
00:36:13,736 --> 00:36:14,986
important because it'd be


1168
00:36:14,986 --> 00:36:16,526
annoying if I saw pictures that


1169
00:36:16,526 --> 00:36:18,306
were marked as me that weren't


1170
00:36:18,446 --> 00:36:19,416
photos of me at all.


1171
00:36:19,916 --> 00:36:23,616
With every photo I mark as me,


1172
00:36:24,426 --> 00:36:25,586
Photos become better at


1173
00:36:25,586 --> 00:36:27,506
recognizing who I am.


1174
00:36:28,736 --> 00:36:30,176
This is an example of a


1175
00:36:30,176 --> 00:36:31,956
limitation that the facial


1176
00:36:31,956 --> 00:36:33,366
recognition in Photos has,


1177
00:36:37,296 --> 00:36:39,326
which also brings me to our last


1178
00:36:39,326 --> 00:36:39,966
output pattern.


1179
00:36:40,546 --> 00:36:43,936
So what actually is a


1180
00:36:43,936 --> 00:36:44,526
limitation?


1181
00:36:45,556 --> 00:36:46,896
A limitation is that when


1182
00:36:46,896 --> 00:36:48,076
there's a mismatch between


1183
00:36:48,076 --> 00:36:49,516
people's mental model of a


1184
00:36:49,516 --> 00:36:51,306
feature and what the feature can


1185
00:36:51,306 --> 00:36:52,346
actually do.


1186
00:36:52,946 --> 00:36:55,636
I might expect Photos to always


1187
00:36:55,636 --> 00:36:57,456
know who I am even though it


1188
00:36:57,456 --> 00:36:59,206
can't do that yet because a


1189
00:36:59,206 --> 00:37:00,976
photo might be blurry or taken


1190
00:37:00,976 --> 00:37:04,896
in low light or not in focus.


1191
00:37:05,046 --> 00:37:06,606
Every feature has limitations


1192
00:37:07,126 --> 00:37:09,056
whether by design, capability,


1193
00:37:09,216 --> 00:37:09,976
or circumstance.


1194
00:37:10,556 --> 00:37:12,766
You have to strengthen people's


1195
00:37:12,766 --> 00:37:13,856
trust in your app by


1196
00:37:13,856 --> 00:37:15,546
acknowledging its limitations


1197
00:37:15,746 --> 00:37:17,676
and teaching people how to work


1198
00:37:18,326 --> 00:37:21,166
with them.


1199
00:37:21,376 --> 00:37:23,566
Now Memoji is one of my favorite


1200
00:37:23,566 --> 00:37:25,736
features but people might not


1201
00:37:25,736 --> 00:37:27,526
understand that it won't work in


1202
00:37:27,526 --> 00:37:30,436
certain scenarios, whether your


1203
00:37:30,606 --> 00:37:34,916
face is not in view, something


1204
00:37:34,916 --> 00:37:39,026
is covering the camera, or


1205
00:37:39,026 --> 00:37:40,636
you're in a dark room.


1206
00:37:41,216 --> 00:37:42,886
Every time this limitation


1207
00:37:42,886 --> 00:37:45,036
occurs, we instantly show these


1208
00:37:45,036 --> 00:37:46,956
inline coaching tips to help


1209
00:37:46,956 --> 00:37:48,736
people move past the limitation


1210
00:37:48,996 --> 00:37:50,236
and successfully use the


1211
00:37:50,286 --> 00:37:50,666
feature.


1212
00:37:51,186 --> 00:37:54,216
Explaining the limitations when


1213
00:37:54,216 --> 00:37:55,826
they happen help people learn to


1214
00:37:55,826 --> 00:37:57,446
avoid these situations in the


1215
00:37:57,446 --> 00:37:57,896
future.


1216
00:37:58,546 --> 00:38:03,066
People might lose trust in your


1217
00:38:03,066 --> 00:38:04,966
feature if limitations are not


1218
00:38:04,966 --> 00:38:06,026
appropriately addressed.


1219
00:38:07,426 --> 00:38:08,726
You should take care to manage


1220
00:38:08,726 --> 00:38:10,376
people's expectations of what a


1221
00:38:10,376 --> 00:38:13,146
feature can actually do and


1222
00:38:13,146 --> 00:38:14,766
guide people to move past


1223
00:38:14,986 --> 00:38:15,666
limitations.


1224
00:38:19,726 --> 00:38:21,036
Another way to help people move


1225
00:38:21,096 --> 00:38:22,866
past limitations is to suggest


1226
00:38:22,966 --> 00:38:25,146
alternative ways to accomplish


1227
00:38:25,786 --> 00:38:26,666
their goals.


1228
00:38:26,856 --> 00:38:28,146
In order to do this right, you


1229
00:38:28,286 --> 00:38:29,936
need to understand the goal well


1230
00:38:29,936 --> 00:38:31,996
enough to suggest alternatives


1231
00:38:31,996 --> 00:38:32,946
that actually make sense.


1232
00:38:34,596 --> 00:38:36,636
For example, if people ask Siri


1233
00:38:36,636 --> 00:38:38,656
to set a timer on a Mac, it


1234
00:38:38,656 --> 00:38:40,426
can't perform the action because


1235
00:38:40,456 --> 00:38:43,286
timers aren't available at


1236
00:38:45,176 --> 00:38:45,346
MacOS.


1237
00:38:45,486 --> 00:38:47,156
Instead of simply replying, "I


1238
00:38:47,156 --> 00:38:48,736
can't do it," which is kind of


1239
00:38:48,736 --> 00:38:50,746
frustrating, Siri suggests


1240
00:38:50,746 --> 00:38:52,076
setting a reminder instead.


1241
00:38:53,336 --> 00:38:54,506
This suggestion actually makes


1242
00:38:54,506 --> 00:38:56,456
sense because Siri understands


1243
00:38:56,726 --> 00:38:58,136
that the goal is to receive an


1244
00:38:58,136 --> 00:39:00,436
alert at a certain time and


1245
00:39:00,436 --> 00:39:02,376
setting a reminder accomplishes


1246
00:39:02,456 --> 00:39:04,136
the same goal as setting a


1247
00:39:04,816 --> 00:39:04,956
timer.


1248
00:39:07,256 --> 00:39:08,996
When possible, suggest


1249
00:39:08,996 --> 00:39:10,266
alternatives that can help


1250
00:39:10,266 --> 00:39:11,586
people accomplish their goals.


1251
00:39:11,586 --> 00:39:16,736
I hope these patterns have given


1252
00:39:16,736 --> 00:39:18,256
you some ideas on different


1253
00:39:18,256 --> 00:39:19,966
outputs that you can get from a


1254
00:39:19,966 --> 00:39:20,946
machine learning model.


1255
00:39:21,486 --> 00:39:24,066
But you have to remember that


1256
00:39:24,066 --> 00:39:25,466
outputs are a design medium.


1257
00:39:26,566 --> 00:39:27,926
By understanding the types of


1258
00:39:27,926 --> 00:39:29,676
outputs that are available, you


1259
00:39:29,676 --> 00:39:31,676
can choose outputs that align


1260
00:39:31,676 --> 00:39:32,846
with the experience you want to


1261
00:39:32,846 --> 00:39:34,706
build and not just rely on


1262
00:39:34,706 --> 00:39:36,266
standard outputs from the model.


1263
00:39:36,896 --> 00:39:39,306
We should respect people's


1264
00:39:39,306 --> 00:39:41,476
agency and time by choosing


1265
00:39:41,596 --> 00:39:42,906
outputs that are easy to


1266
00:39:42,906 --> 00:39:44,866
understand and effortlessly


1267
00:39:44,866 --> 00:39:45,286
helpful.


1268
00:39:48,586 --> 00:39:50,406
As you've seen, there are many


1269
00:39:50,406 --> 00:39:51,756
different ways to translate


1270
00:39:51,756 --> 00:39:53,206
outputs from the model to the


1271
00:39:53,206 --> 00:39:53,676
interface.


1272
00:39:54,366 --> 00:39:57,326
But of course, outputs aren't


1273
00:39:57,326 --> 00:39:57,756
static.


1274
00:39:58,526 --> 00:40:00,386
They're dynamic and constantly


1275
00:40:00,386 --> 00:40:01,646
update based on inputs.


1276
00:40:02,936 --> 00:40:04,136
People interact with the


1277
00:40:04,136 --> 00:40:05,956
experience through inputs and


1278
00:40:05,956 --> 00:40:07,446
now Cas will tell you all about


1279
00:40:07,446 --> 00:40:08,656
how to design for inputs.


1280
00:40:08,656 --> 00:40:08,896
Thank you.


1281
00:40:09,516 --> 00:40:15,500
[ Applause ]


1282
00:40:19,546 --> 00:40:21,006
>> So Rubii showed a range of


1283
00:40:21,006 --> 00:40:22,556
outputs that people can interact


1284
00:40:22,556 --> 00:40:24,726
with on the interface and these


1285
00:40:24,726 --> 00:40:26,476
interactions serve as inputs


1286
00:40:26,616 --> 00:40:27,796
that we can use to collect


1287
00:40:27,886 --> 00:40:29,576
feedback for information from


1288
00:40:29,576 --> 00:40:31,446
people so we can improve our


1289
00:40:31,446 --> 00:40:32,056
experience.


1290
00:40:33,256 --> 00:40:34,346
These are the four inputs we


1291
00:40:34,346 --> 00:40:34,946
will discuss.


1292
00:40:36,656 --> 00:40:38,136
Calibration helps you get


1293
00:40:38,136 --> 00:40:39,576
essential information for


1294
00:40:39,576 --> 00:40:40,786
someone to engage in your


1295
00:40:40,786 --> 00:40:41,426
experience.


1296
00:40:42,566 --> 00:40:43,706
Calibration allows you to


1297
00:40:43,706 --> 00:40:45,886
collect important information


1298
00:40:46,116 --> 00:40:47,466
from interactions someone has


1299
00:40:47,466 --> 00:40:48,506
with your experience.


1300
00:40:49,396 --> 00:40:51,066
Explicit feedback also allows


1301
00:40:51,066 --> 00:40:52,586
you to collect information but


1302
00:40:52,586 --> 00:40:53,976
this time by asking specific


1303
00:40:53,976 --> 00:40:55,336
questions about the results


1304
00:40:55,336 --> 00:40:55,816
you're showing.


1305
00:40:56,836 --> 00:40:58,246
And corrections allow people to


1306
00:40:58,326 --> 00:40:59,996
fix a mistake a model has made


1307
00:41:00,416 --> 00:41:02,006
by using familiar interfaces.


1308
00:41:02,826 --> 00:41:04,306
So let's start with calibration.


1309
00:41:05,696 --> 00:41:07,256
As I just said, calibrations


1310
00:41:07,256 --> 00:41:08,436
allow people to provide


1311
00:41:08,436 --> 00:41:09,906
essential information for them


1312
00:41:09,906 --> 00:41:11,396
to engage in your experience.


1313
00:41:12,126 --> 00:41:13,326
We can use calibration for


1314
00:41:13,326 --> 00:41:14,836
example to collect biometric


1315
00:41:14,836 --> 00:41:16,586
data or data about your


1316
00:41:16,586 --> 00:41:17,146
surroundings.


1317
00:41:17,966 --> 00:41:18,866
Let me give an example.


1318
00:41:19,836 --> 00:41:20,936
Let's look at HomeCourt.


1319
00:41:21,556 --> 00:41:22,896
HomeCourt is an app that helps


1320
00:41:22,896 --> 00:41:24,236
you become a better basketball


1321
00:41:24,296 --> 00:41:24,576
player.


1322
00:41:25,316 --> 00:41:26,536
It uses machine learning to


1323
00:41:26,536 --> 00:41:28,016
analyze images from the camera


1324
00:41:28,326 --> 00:41:29,696
and detect for example how


1325
00:41:29,696 --> 00:41:31,526
accurately you take shots at the


1326
00:41:31,526 --> 00:41:31,816
hoop.


1327
00:41:32,716 --> 00:41:34,246
In order to do so, the camera


1328
00:41:34,246 --> 00:41:35,706
needs to be calibrated so it can


1329
00:41:35,706 --> 00:41:37,636
detect you, the hoop and the


1330
00:41:37,636 --> 00:41:37,876
court.


1331
00:41:38,436 --> 00:41:40,446
And HomeCourt has done an


1332
00:41:40,446 --> 00:41:42,046
amazing job at doing this fast


1333
00:41:42,046 --> 00:41:42,736
and intuitively.


1334
00:41:43,516 --> 00:41:44,286
You simply point the


1335
00:41:44,336 --> 00:41:45,936
front-facing camera to the hoop


1336
00:41:46,046 --> 00:41:47,656
and it immediately detects it by


1337
00:41:47,656 --> 00:41:49,006
putting a wide square around it.


1338
00:41:49,696 --> 00:41:50,916
It then asks you to make one


1339
00:41:50,916 --> 00:41:52,136
shot and from then on, you're


1340
00:41:52,136 --> 00:41:53,996
good to go and it will start


1341
00:41:53,996 --> 00:41:55,006
counting your shots.


1342
00:41:55,546 --> 00:41:58,206
What's remarkable here is what


1343
00:41:58,206 --> 00:41:59,516
HomeCourt is not asking you to


1344
00:41:59,516 --> 00:41:59,706
do.


1345
00:42:00,396 --> 00:42:01,296
For example, you don't have to


1346
00:42:01,296 --> 00:42:02,646
draw lines around the hoop or


1347
00:42:02,646 --> 00:42:03,046
the court.


1348
00:42:04,026 --> 00:42:05,536
It doesn't ask for confirmation


1349
00:42:05,536 --> 00:42:06,706
on whether it got the hoop right


1350
00:42:06,706 --> 00:42:07,086
or wrong.


1351
00:42:07,876 --> 00:42:08,926
And you don't need to take shots


1352
00:42:08,926 --> 00:42:10,506
from multiple angles.


1353
00:42:12,076 --> 00:42:13,816
Calibration also happens in some


1354
00:42:13,816 --> 00:42:15,256
of Apple's products, for example


1355
00:42:15,576 --> 00:42:16,566
when you set up Face ID.


1356
00:42:17,636 --> 00:42:19,406
Face ID uses calibration to only


1357
00:42:19,406 --> 00:42:21,036
collect essential information.


1358
00:42:21,986 --> 00:42:23,406
It asks you to scan your face


1359
00:42:23,406 --> 00:42:24,806
twice and from then on, it is


1360
00:42:24,806 --> 00:42:26,246
set up and it will always keep


1361
00:42:26,246 --> 00:42:27,646
working regardless of whether


1362
00:42:27,646 --> 00:42:28,866
you might start to wear glasses


1363
00:42:29,146 --> 00:42:30,316
or change your hairstyle.


1364
00:42:30,906 --> 00:42:33,196
So when you're using


1365
00:42:33,196 --> 00:42:35,106
calibration, try to be quick and


1366
00:42:35,106 --> 00:42:36,746
effortless and only ask for


1367
00:42:36,746 --> 00:42:39,036
essential information and, when


1368
00:42:39,036 --> 00:42:40,916
possible, try to avoid the need


1369
00:42:41,186 --> 00:42:42,556
for multiple calibrations.


1370
00:42:43,136 --> 00:42:46,456
Once you're setting up Face ID,


1371
00:42:46,596 --> 00:42:47,796
we help you along the way.


1372
00:42:48,226 --> 00:42:49,446
We start with an introduction


1373
00:42:49,446 --> 00:42:50,916
that clearly states why your


1374
00:42:50,916 --> 00:42:52,466
phone needs to scan your face.


1375
00:42:53,106 --> 00:42:54,256
And we do this by explaining


1376
00:42:54,256 --> 00:42:55,856
both how it works and what it


1377
00:42:55,856 --> 00:42:56,966
will allow you to do.


1378
00:42:57,456 --> 00:42:59,746
Throughout the process, we


1379
00:42:59,746 --> 00:43:00,736
always give you a sense of


1380
00:43:00,816 --> 00:43:01,296
progress.


1381
00:43:01,736 --> 00:43:03,036
Here, we fill out the lines


1382
00:43:03,036 --> 00:43:03,766
around your face.


1383
00:43:04,286 --> 00:43:07,906
And if this progress might


1384
00:43:07,906 --> 00:43:09,456
stall, we make sure you never


1385
00:43:09,456 --> 00:43:10,696
get stuck and we provide


1386
00:43:10,696 --> 00:43:11,826
guidance to help you move


1387
00:43:11,946 --> 00:43:12,466
forward.


1388
00:43:12,976 --> 00:43:14,626
Here, we point arrows that point


1389
00:43:14,626 --> 00:43:15,466
in which way to look.


1390
00:43:15,466 --> 00:43:19,126
And at the end, we give the


1391
00:43:19,126 --> 00:43:20,006
notion of success.


1392
00:43:20,396 --> 00:43:21,706
We tell you the work is done and


1393
00:43:21,706 --> 00:43:23,636
the feature can be used now.


1394
00:43:24,336 --> 00:43:26,096
So always provide help by


1395
00:43:26,096 --> 00:43:27,496
introducing, guiding and


1396
00:43:27,496 --> 00:43:29,136
confirming the calibration.


1397
00:43:29,696 --> 00:43:32,696
Of course, Face ID collects a


1398
00:43:32,696 --> 00:43:34,136
lot of sensitive information.


1399
00:43:34,376 --> 00:43:35,796
And so to respect your privacy,


1400
00:43:36,076 --> 00:43:37,546
we give you a way to edit or


1401
00:43:37,546 --> 00:43:39,046
remove this information in


1402
00:43:39,046 --> 00:43:39,456
Settings.


1403
00:43:41,066 --> 00:43:42,776
So when possible, allow people


1404
00:43:42,776 --> 00:43:44,106
to update their information.


1405
00:43:44,686 --> 00:43:48,636
Now as I said before, Face ID


1406
00:43:48,636 --> 00:43:50,406
asks for just one calibration


1407
00:43:50,636 --> 00:43:51,896
and from then on, it will keep


1408
00:43:51,896 --> 00:43:53,226
working regardless of whether


1409
00:43:53,226 --> 00:43:54,556
you might start to wear glasses,


1410
00:43:54,906 --> 00:43:56,376
change your hairstyle, maybe


1411
00:43:56,376 --> 00:43:58,156
wear a hat or a scarf sometimes


1412
00:43:58,566 --> 00:44:00,046
or even as your face changes as


1413
00:44:00,046 --> 00:44:00,736
you become older.


1414
00:44:01,656 --> 00:44:02,886
This was a big challenge when we


1415
00:44:02,886 --> 00:44:03,736
designed Face ID.


1416
00:44:04,296 --> 00:44:05,756
It would've been a lot easier to


1417
00:44:05,756 --> 00:44:07,446
occasionally ask to recalibrate


1418
00:44:07,446 --> 00:44:09,396
your face so your iPhone or iPad


1419
00:44:09,486 --> 00:44:10,506
could keep recognizing you.


1420
00:44:11,336 --> 00:44:12,326
But who would like to rescan


1421
00:44:12,326 --> 00:44:13,656
their face each time they change


1422
00:44:13,656 --> 00:44:14,236
their hairstyle?


1423
00:44:15,356 --> 00:44:16,456
So instead of asking for


1424
00:44:16,456 --> 00:44:18,436
multiple calibrations, Face ID


1425
00:44:18,436 --> 00:44:20,196
collects implicit feedback to


1426
00:44:20,196 --> 00:44:21,566
update the information about


1427
00:44:21,566 --> 00:44:23,906
your face each time you use Face


1428
00:44:23,906 --> 00:44:24,046
ID.


1429
00:44:24,046 --> 00:44:26,046
And that brings us to our next


1430
00:44:26,046 --> 00:44:28,536
pattern which is implicit


1431
00:44:29,536 --> 00:44:29,746
feedback.


1432
00:44:30,636 --> 00:44:32,566
Implicit feedback is information


1433
00:44:32,566 --> 00:44:33,346
that arises from the


1434
00:44:33,346 --> 00:44:34,886
interactions people have with


1435
00:44:34,886 --> 00:44:36,906
your app and that information


1436
00:44:36,906 --> 00:44:38,326
can be used to improve the model


1437
00:44:38,636 --> 00:44:39,346
and your feature.


1438
00:44:40,446 --> 00:44:42,006
A very common example of using


1439
00:44:42,006 --> 00:44:43,196
implicit feedback is


1440
00:44:43,266 --> 00:44:44,126
personalization.


1441
00:44:44,886 --> 00:44:46,616
For example, Siri personalizes


1442
00:44:46,736 --> 00:44:48,796
the search experiences on iOS


1443
00:44:49,166 --> 00:44:50,336
based on how you use your


1444
00:44:50,336 --> 00:44:50,836
device.


1445
00:44:51,366 --> 00:44:53,716
When you trigger the Search bar


1446
00:44:53,716 --> 00:44:55,046
on your Home screen, Siri


1447
00:44:55,046 --> 00:44:56,536
presents a range of apps you


1448
00:44:56,536 --> 00:44:57,436
might want to use.


1449
00:44:58,366 --> 00:45:00,206
Which apps appear here depends


1450
00:45:00,206 --> 00:45:01,756
on the implicit feedback you


1451
00:45:01,756 --> 00:45:02,476
give to Siri.


1452
00:45:03,186 --> 00:45:04,096
These might be apps you


1453
00:45:04,096 --> 00:45:05,686
frequently used, maybe ones


1454
00:45:05,686 --> 00:45:07,466
you've just used or ones you use


1455
00:45:07,466 --> 00:45:08,846
typically at this time of day.


1456
00:45:09,826 --> 00:45:11,196
For example in the car, I might


1457
00:45:11,196 --> 00:45:13,086
get Maps so I can get directions


1458
00:45:13,496 --> 00:45:14,896
or music and podcasts so I have


1459
00:45:14,896 --> 00:45:15,816
something to listen to.


1460
00:45:16,786 --> 00:45:18,306
At work, I might get apps that


1461
00:45:18,306 --> 00:45:19,706
help me at a meeting like Notes


1462
00:45:19,706 --> 00:45:21,756
or Reminders and at home, I


1463
00:45:21,756 --> 00:45:22,926
might get Messages to text


1464
00:45:22,926 --> 00:45:25,116
friends or family or suggestions


1465
00:45:25,116 --> 00:45:26,956
to check my activity or news.


1466
00:45:27,446 --> 00:45:30,206
Based on how I use these apps,


1467
00:45:30,356 --> 00:45:32,306
Siri tries to identify my intent


1468
00:45:32,826 --> 00:45:34,286
so it can surface apps to help


1469
00:45:34,286 --> 00:45:35,686
me achieve that intent.


1470
00:45:36,626 --> 00:45:37,626
So when you're using implicit


1471
00:45:37,626 --> 00:45:39,396
feedback, strive to identify


1472
00:45:39,396 --> 00:45:41,116
people's intent by looking at


1473
00:45:41,196 --> 00:45:42,466
how they interact with your


1474
00:45:42,466 --> 00:45:42,856
feature.


1475
00:45:43,386 --> 00:45:47,466
Over time, Siri will get better


1476
00:45:47,466 --> 00:45:49,296
at understanding my intent and,


1477
00:45:49,296 --> 00:45:50,666
apart from just showing apps as


1478
00:45:50,666 --> 00:45:52,106
a suggestion, it might also


1479
00:45:52,106 --> 00:45:53,846
start suggesting shortcuts of


1480
00:45:53,896 --> 00:45:55,356
actions I frequently perform.


1481
00:45:56,436 --> 00:45:57,976
For example in the car, I might


1482
00:45:57,976 --> 00:45:59,176
get directions to places I


1483
00:45:59,246 --> 00:46:01,236
frequently visit or the location


1484
00:46:01,236 --> 00:46:02,086
of my next meeting.


1485
00:46:03,356 --> 00:46:04,856
At work, I might get shortcuts


1486
00:46:04,886 --> 00:46:06,536
to my meeting notes or my work


1487
00:46:06,536 --> 00:46:07,146
reminders.


1488
00:46:07,986 --> 00:46:09,236
And at home, I might get


1489
00:46:09,236 --> 00:46:10,456
shortcuts to turn on the lights


1490
00:46:10,796 --> 00:46:12,256
or message or FaceTime my


1491
00:46:12,256 --> 00:46:13,616
closest friends and family.


1492
00:46:15,076 --> 00:46:16,776
These shortcuts appear after a


1493
00:46:16,776 --> 00:46:17,686
few days or weeks.


1494
00:46:18,206 --> 00:46:19,666
The more specific they are, the


1495
00:46:19,666 --> 00:46:21,256
more certain Siri needs to be


1496
00:46:21,346 --> 00:46:22,176
about my intent.


1497
00:46:23,196 --> 00:46:24,506
As I said, these shortcuts are


1498
00:46:24,506 --> 00:46:26,696
based on implicit feedback, so


1499
00:46:26,696 --> 00:46:27,976
it might take a while for Siri


1500
00:46:27,976 --> 00:46:29,366
to be certain enough about a


1501
00:46:29,366 --> 00:46:31,136
suggestion and that's OK.


1502
00:46:32,206 --> 00:46:33,496
It's better to be patient and


1503
00:46:33,496 --> 00:46:34,896
become certain of a suggestion


1504
00:46:35,406 --> 00:46:36,636
than to be quick and show an


1505
00:46:36,666 --> 00:46:37,616
unhelpful suggestion.


1506
00:46:38,206 --> 00:46:40,566
So bear in mind that implicit


1507
00:46:40,606 --> 00:46:42,946
feedback can be slow but it also


1508
00:46:42,946 --> 00:46:44,666
can be more accurate over time.


1509
00:46:45,266 --> 00:46:48,966
Now these suggestions can appear


1510
00:46:48,966 --> 00:46:50,596
on the Lock screen and it might


1511
00:46:50,646 --> 00:46:51,676
be that they contain some


1512
00:46:51,676 --> 00:46:52,726
sensitive information.


1513
00:46:53,246 --> 00:46:54,956
For example, it might show an


1514
00:46:54,956 --> 00:46:55,996
event you want to keep as a


1515
00:46:55,996 --> 00:46:58,356
surprise or notes you might want


1516
00:46:58,496 --> 00:46:59,426
to keep secret.


1517
00:47:00,096 --> 00:47:02,196
To respect people's privacy, we


1518
00:47:02,196 --> 00:47:03,316
added settings for you to


1519
00:47:03,316 --> 00:47:05,286
control which app and which app


1520
00:47:05,286 --> 00:47:07,306
shortcuts can appear in Search.


1521
00:47:07,866 --> 00:47:11,326
So respect people's privacy and


1522
00:47:11,326 --> 00:47:12,706
give them full control over


1523
00:47:12,706 --> 00:47:13,406
their information.


1524
00:47:13,866 --> 00:47:15,756
Treat it privately and securely.


1525
00:47:16,346 --> 00:47:19,246
So implicit feedback is a great


1526
00:47:19,246 --> 00:47:21,116
tool for personalization but you


1527
00:47:21,116 --> 00:47:22,486
can also use it for some maybe


1528
00:47:22,486 --> 00:47:24,476
less obvious purposes, for


1529
00:47:24,476 --> 00:47:25,586
example simply making a


1530
00:47:25,586 --> 00:47:27,586
direction faster or more


1531
00:47:27,586 --> 00:47:27,976
accurate.


1532
00:47:29,126 --> 00:47:30,386
One good example has been with


1533
00:47:30,386 --> 00:47:31,986
us since the beginning of iOS


1534
00:47:31,986 --> 00:47:32,716
and that's the keyboard.


1535
00:47:33,326 --> 00:47:36,456
Each key on the keyboard has a


1536
00:47:36,456 --> 00:47:38,466
touch area and the keyboard uses


1537
00:47:38,466 --> 00:47:39,996
machine learning to optimize


1538
00:47:39,996 --> 00:47:41,576
these touch areas based on what


1539
00:47:41,576 --> 00:47:41,936
you type.


1540
00:47:43,526 --> 00:47:44,936
Each touch area might become


1541
00:47:44,936 --> 00:47:46,516
bigger or smaller depending on


1542
00:47:46,516 --> 00:47:47,996
the word you're typing or the


1543
00:47:47,996 --> 00:47:49,616
way your fingers are positioned


1544
00:47:49,616 --> 00:47:51,976
on the keyboard.


1545
00:47:52,086 --> 00:47:52,986
Now notice that we're not


1546
00:47:53,076 --> 00:47:54,586
visibly making these buttons any


1547
00:47:54,586 --> 00:47:55,466
bigger or smaller.


1548
00:47:55,536 --> 00:47:57,356
The keyboard always appears in


1549
00:47:57,356 --> 00:47:57,966
the same way.


1550
00:47:58,636 --> 00:48:00,046
But over time, the keyboard


1551
00:48:00,046 --> 00:48:01,106
might start to feel more


1552
00:48:01,106 --> 00:48:02,806
accurate and more personalized


1553
00:48:02,966 --> 00:48:03,956
to you.


1554
00:48:04,996 --> 00:48:06,926
So use implicit feedback to make


1555
00:48:06,926 --> 00:48:08,376
your interactions more accurate


1556
00:48:08,706 --> 00:48:09,306
and delightful.


1557
00:48:12,856 --> 00:48:15,196
One last example are the Siri


1558
00:48:15,196 --> 00:48:16,556
suggestions in Safari.


1559
00:48:17,256 --> 00:48:18,916
Safari uses machine learning to


1560
00:48:18,916 --> 00:48:20,196
collect links from messages,


1561
00:48:20,416 --> 00:48:22,176
mail, your reading lists, your


1562
00:48:22,176 --> 00:48:23,446
iCloud tabs, and other places.


1563
00:48:24,216 --> 00:48:25,376
And hopefully these suggestions


1564
00:48:25,376 --> 00:48:26,716
are good and they help you


1565
00:48:26,716 --> 00:48:28,106
discover interesting content


1566
00:48:28,106 --> 00:48:29,866
from your friends and family or


1567
00:48:29,866 --> 00:48:31,156
ones you've saved yourself.


1568
00:48:31,806 --> 00:48:33,196
Occasionally, though, you might


1569
00:48:33,196 --> 00:48:34,496
get suggestions you'd rather not


1570
00:48:34,496 --> 00:48:36,536
see, maybe an article you're not


1571
00:48:36,536 --> 00:48:38,016
interested in or a source you


1572
00:48:38,016 --> 00:48:38,846
don't really trust.


1573
00:48:39,816 --> 00:48:41,216
If all of these suggestions turn


1574
00:48:41,216 --> 00:48:42,786
out to be unhelpful, you might


1575
00:48:42,786 --> 00:48:44,646
start losing trust in the


1576
00:48:44,646 --> 00:48:46,906
suggestions or even worse, start


1577
00:48:46,906 --> 00:48:48,406
to lose trust in Safari.


1578
00:48:48,906 --> 00:48:50,206
And that is obviously something


1579
00:48:50,206 --> 00:48:51,146
we would like to avoid.


1580
00:48:52,306 --> 00:48:53,766
Rubii talked about attribution


1581
00:48:53,766 --> 00:48:54,936
that can really help here in


1582
00:48:54,936 --> 00:48:56,226
explaining why we're showing


1583
00:48:56,226 --> 00:48:58,206
these suggestions but we also


1584
00:48:58,206 --> 00:48:59,176
want to make sure you can


1585
00:48:59,176 --> 00:49:01,086
control these suggestions so you


1586
00:49:01,086 --> 00:49:02,016
can get rid of the ones you


1587
00:49:02,016 --> 00:49:03,426
don't want to see and make sure


1588
00:49:03,426 --> 00:49:04,696
they don't appear again.


1589
00:49:05,646 --> 00:49:06,796
And that brings us to our next


1590
00:49:06,796 --> 00:49:08,716
pattern which is explicit


1591
00:49:09,276 --> 00:49:09,466
feedback.


1592
00:49:11,176 --> 00:49:12,976
Explicit feedback allows your


1593
00:49:12,976 --> 00:49:14,646
app to collect information by


1594
00:49:14,646 --> 00:49:16,596
asking specific questions about


1595
00:49:16,596 --> 00:49:17,206
your results.


1596
00:49:17,756 --> 00:49:20,096
In the previous example, it


1597
00:49:20,096 --> 00:49:21,236
would be great if I could get


1598
00:49:21,236 --> 00:49:22,486
feedback on these suggestions


1599
00:49:22,536 --> 00:49:24,276
that I don't want to see and


1600
00:49:24,276 --> 00:49:26,036
that way the model can learn and


1601
00:49:26,036 --> 00:49:27,166
can avoid showing similar


1602
00:49:27,166 --> 00:49:28,696
suggestions in the future.


1603
00:49:30,056 --> 00:49:31,166
So how do I design these


1604
00:49:31,206 --> 00:49:31,976
feedback actions?


1605
00:49:32,556 --> 00:49:35,276
Here are two actions that


1606
00:49:35,356 --> 00:49:36,726
frequently appear when we're


1607
00:49:36,726 --> 00:49:38,186
using explicit feedback: the


1608
00:49:38,186 --> 00:49:39,216
heart and the heart with a


1609
00:49:39,216 --> 00:49:39,736
strikethrough.


1610
00:49:40,486 --> 00:49:41,746
Now seeing these as buttons


1611
00:49:41,746 --> 00:49:42,656
leaves a lot of room for


1612
00:49:42,656 --> 00:49:43,426
interpretation.


1613
00:49:44,126 --> 00:49:45,536
It's unclear what will happen


1614
00:49:45,536 --> 00:49:47,386
when I press one of these even


1615
00:49:47,386 --> 00:49:48,856
if I add labels like Love or


1616
00:49:48,856 --> 00:49:49,336
Dislike.


1617
00:49:50,566 --> 00:49:52,946
Let's say I want to get feedback


1618
00:49:52,946 --> 00:49:54,046
on the third article here.


1619
00:49:54,616 --> 00:49:55,866
I can bring up the Action menu


1620
00:49:55,866 --> 00:49:57,256
and I can see the action Love.


1621
00:49:58,866 --> 00:49:59,806
That leaves a lot of room for


1622
00:49:59,806 --> 00:50:00,516
interpretation.


1623
00:50:00,956 --> 00:50:02,136
Does this mean I have to love


1624
00:50:02,186 --> 00:50:03,306
every article that I like?


1625
00:50:04,706 --> 00:50:06,056
Positive explicit feedback


1626
00:50:06,166 --> 00:50:07,526
implies additional work.


1627
00:50:08,236 --> 00:50:09,416
People might think they have to


1628
00:50:09,416 --> 00:50:10,996
give positive explicit feedback


1629
00:50:11,266 --> 00:50:13,196
to every article they like just


1630
00:50:13,196 --> 00:50:14,736
to get more good suggestions.


1631
00:50:15,626 --> 00:50:17,166
So we actually recommend to


1632
00:50:17,166 --> 00:50:18,536
prioritize negative feedback


1633
00:50:18,806 --> 00:50:19,546
over positive.


1634
00:50:20,346 --> 00:50:21,946
Positive feedback can better be


1635
00:50:21,946 --> 00:50:23,136
inferred through implicit


1636
00:50:23,136 --> 00:50:25,526
signals, for example me reading


1637
00:50:25,526 --> 00:50:27,426
the article, bookmarking it or


1638
00:50:27,426 --> 00:50:28,506
sharing it.


1639
00:50:29,716 --> 00:50:31,606
So instead of showing both Love


1640
00:50:31,606 --> 00:50:33,036
and Dislike, we can actually


1641
00:50:33,036 --> 00:50:34,606
only show Dislike.


1642
00:50:35,516 --> 00:50:36,746
But still, that leaves a lot of


1643
00:50:36,746 --> 00:50:37,666
room for interpretation.


1644
00:50:38,426 --> 00:50:39,816
If I dislike an article, am I


1645
00:50:39,816 --> 00:50:41,286
disliking the article, the


1646
00:50:41,286 --> 00:50:43,396
author, the source, the person


1647
00:50:43,396 --> 00:50:45,016
who sent it to me, or maybe even


1648
00:50:45,016 --> 00:50:46,216
the app in which I received it?


1649
00:50:46,986 --> 00:50:47,826
It's still difficult to


1650
00:50:47,826 --> 00:50:50,426
understand what will happen when


1651
00:50:50,426 --> 00:50:52,366
I tap Dislike.


1652
00:50:52,496 --> 00:50:53,906
Words like "suggest less" or


1653
00:50:53,906 --> 00:50:55,476
"hide the suggestion" make it


1654
00:50:55,506 --> 00:50:57,036
much easier to understand what


1655
00:50:57,036 --> 00:50:58,216
will happen when I tap such a


1656
00:50:58,216 --> 00:50:59,196
button.


1657
00:51:00,196 --> 00:51:01,216
To give people even more


1658
00:51:01,216 --> 00:51:02,676
control, we can allow them to


1659
00:51:02,676 --> 00:51:04,396
select exactly what they like to


1660
00:51:04,396 --> 00:51:06,356
see less, for example less of


1661
00:51:06,356 --> 00:51:08,086
the source, the person who sent


1662
00:51:08,086 --> 00:51:09,726
it to me or the app in which I


1663
00:51:09,726 --> 00:51:10,846
received it.


1664
00:51:12,336 --> 00:51:14,126
So when using explicit feedback,


1665
00:51:14,526 --> 00:51:16,146
clearly describe the option and


1666
00:51:16,146 --> 00:51:17,006
its consequences.


1667
00:51:17,666 --> 00:51:19,246
Use words that describe what


1668
00:51:19,246 --> 00:51:19,716
will happen.


1669
00:51:19,936 --> 00:51:21,456
And when possible, provide


1670
00:51:21,576 --> 00:51:22,716
different options to better


1671
00:51:22,716 --> 00:51:23,926
understand the user's


1672
00:51:23,926 --> 00:51:24,426
preference.


1673
00:51:25,076 --> 00:51:28,446
And of course, when I select one


1674
00:51:28,446 --> 00:51:29,956
of these options, the interface


1675
00:51:29,956 --> 00:51:31,126
should immediately reflect my


1676
00:51:31,126 --> 00:51:33,066
choice and hide the suggestions


1677
00:51:33,236 --> 00:51:34,536
that match my preference.


1678
00:51:37,076 --> 00:51:38,796
So always act immediately and


1679
00:51:38,796 --> 00:51:40,496
persistently when the user gives


1680
00:51:40,746 --> 00:51:42,066
explicit feedback.


1681
00:51:43,936 --> 00:51:45,226
So you've seen that explicit


1682
00:51:45,226 --> 00:51:46,636
feedback allows us to correct


1683
00:51:46,636 --> 00:51:48,196
suggestions that might be wrong,


1684
00:51:48,196 --> 00:51:49,646
unwanted or inappropriate.


1685
00:51:50,616 --> 00:51:51,546
But for some machine learning


1686
00:51:51,546 --> 00:51:53,106
features, using explicit


1687
00:51:53,106 --> 00:51:55,216
feedback might not be the right


1688
00:51:55,216 --> 00:51:56,766
choice or might not even be


1689
00:51:56,766 --> 00:51:57,296
possible.


1690
00:51:58,386 --> 00:52:00,346
Here's Angie again, the dog from


1691
00:52:00,346 --> 00:52:00,726
our friends.


1692
00:52:01,006 --> 00:52:02,366
She's often the main topic in


1693
00:52:02,366 --> 00:52:03,276
our group conversation.


1694
00:52:04,716 --> 00:52:05,996
Now the keyboard uses machine


1695
00:52:05,996 --> 00:52:07,876
learning to suggest corrections


1696
00:52:07,876 --> 00:52:08,746
of what I'm typing.


1697
00:52:09,526 --> 00:52:10,816
And when I initially type the


1698
00:52:10,816 --> 00:52:12,366
word "Angie," it wanted to


1699
00:52:12,366 --> 00:52:14,036
correct it to the word "angle."


1700
00:52:14,856 --> 00:52:16,266
Now that's obviously wrong but


1701
00:52:16,266 --> 00:52:17,796
using explicit feedback here


1702
00:52:18,046 --> 00:52:19,196
seems a little bit off.


1703
00:52:19,736 --> 00:52:20,696
Let's say I can bring up a


1704
00:52:20,696 --> 00:52:21,696
contextual menu here.


1705
00:52:22,936 --> 00:52:24,346
This doesn't feel very intuitive


1706
00:52:24,686 --> 00:52:25,896
and it doesn't really allow me


1707
00:52:25,896 --> 00:52:27,386
to say what I actually meant.


1708
00:52:28,746 --> 00:52:30,716
Instead, I can simply select the


1709
00:52:30,716 --> 00:52:33,436
words and correct the suggestion


1710
00:52:33,436 --> 00:52:34,516
the keyboard has made by


1711
00:52:34,516 --> 00:52:36,626
retyping it and this time the


1712
00:52:36,626 --> 00:52:38,066
keyboard will not autocorrect


1713
00:52:38,066 --> 00:52:38,166
it.


1714
00:52:38,826 --> 00:52:39,976
The keyboard learned from my


1715
00:52:39,976 --> 00:52:41,706
correction and the next time I


1716
00:52:41,706 --> 00:52:43,636
type in Angie, it knows I'm


1717
00:52:43,636 --> 00:52:45,386
referring to a name and not the


1718
00:52:45,386 --> 00:52:46,176
word "angle."


1719
00:52:47,186 --> 00:52:48,696
This is the most obvious example


1720
00:52:48,906 --> 00:52:50,436
of our last pattern which is


1721
00:52:50,556 --> 00:52:51,106
corrections.


1722
00:52:53,256 --> 00:52:55,596
Corrections allow people to fix


1723
00:52:55,596 --> 00:52:57,316
a mistake a model has made by


1724
00:52:57,316 --> 00:52:58,336
using known tasks.


1725
00:52:58,796 --> 00:52:59,986
And with known tasks, I'll


1726
00:52:59,986 --> 00:53:00,766
explain what that means.


1727
00:53:01,806 --> 00:53:03,106
In the previous example, you've


1728
00:53:03,106 --> 00:53:04,346
seen that we corrected this


1729
00:53:04,676 --> 00:53:08,966
using standard text controls.


1730
00:53:09,486 --> 00:53:10,816
There was no new interface that


1731
00:53:10,816 --> 00:53:11,476
we showed here.


1732
00:53:11,946 --> 00:53:13,436
Everybody knows how to do this


1733
00:53:13,506 --> 00:53:14,686
since this is how the keyboard's


1734
00:53:14,906 --> 00:53:15,536
always worked.


1735
00:53:16,736 --> 00:53:17,986
Corrections are, therefore, an


1736
00:53:17,986 --> 00:53:19,536
amazing pattern to optimize your


1737
00:53:19,536 --> 00:53:21,436
results without feeling like


1738
00:53:21,436 --> 00:53:22,076
extra work.


1739
00:53:22,626 --> 00:53:24,916
Let me give another example.


1740
00:53:25,976 --> 00:53:27,526
Photos uses machine learning to


1741
00:53:27,526 --> 00:53:28,556
optimize your pictures.


1742
00:53:29,216 --> 00:53:30,496
It can help find to the right


1743
00:53:30,496 --> 00:53:32,096
rotation or cropping your


1744
00:53:32,096 --> 00:53:32,976
pictures could take.


1745
00:53:34,276 --> 00:53:35,536
The way Photos suggest these


1746
00:53:35,536 --> 00:53:38,406
croppings or rotations is quite


1747
00:53:38,406 --> 00:53:38,746
subtle.


1748
00:53:39,576 --> 00:53:40,806
When you go into Edit mode and


1749
00:53:40,806 --> 00:53:42,056
select Rotation or Cropping


1750
00:53:42,056 --> 00:53:44,456
tool, photos will crop or rotate


1751
00:53:44,456 --> 00:53:45,336
the picture for you.


1752
00:53:46,096 --> 00:53:47,386
Now it doesn't apply the


1753
00:53:47,476 --> 00:53:49,346
rotation or cropping, it simply


1754
00:53:49,346 --> 00:53:50,866
suggests it as a starting point.


1755
00:53:51,936 --> 00:53:53,036
If you like what Photos has


1756
00:53:53,096 --> 00:53:54,596
done, you can simply tap Done


1757
00:53:54,976 --> 00:53:56,966
and the rotation or cropping is


1758
00:53:56,966 --> 00:53:57,346
applied.


1759
00:53:57,346 --> 00:53:59,276
But if you'd like to change what


1760
00:53:59,346 --> 00:54:01,066
Photos has suggested, you can


1761
00:54:01,066 --> 00:54:02,566
simply use the slider at the


1762
00:54:02,606 --> 00:54:04,256
bottom to rotate or drag the


1763
00:54:04,256 --> 00:54:05,346
corners to crop.


1764
00:54:05,346 --> 00:54:07,386
So these are great examples of


1765
00:54:07,416 --> 00:54:07,886
corrections.


1766
00:54:08,426 --> 00:54:10,046
We show you familiar controls


1767
00:54:10,516 --> 00:54:11,196
and we learn from the


1768
00:54:11,196 --> 00:54:12,356
corrections you make.


1769
00:54:13,046 --> 00:54:15,936
So that concludes the last


1770
00:54:15,936 --> 00:54:16,236
pattern.


1771
00:54:17,276 --> 00:54:18,236
Allow corrections through


1772
00:54:18,236 --> 00:54:18,906
familiar ways.


1773
00:54:19,416 --> 00:54:20,866
This makes it easy and fast for


1774
00:54:20,866 --> 00:54:21,696
somebody to correct.


1775
00:54:22,666 --> 00:54:24,136
Provide immediate value when


1776
00:54:24,136 --> 00:54:25,256
somebody makes a correction.


1777
00:54:25,466 --> 00:54:26,406
As we saw with the text


1778
00:54:26,406 --> 00:54:28,396
correction, the keyboard won't


1779
00:54:28,396 --> 00:54:29,616
autocorrect things that we


1780
00:54:29,616 --> 00:54:29,926
typed.


1781
00:54:30,856 --> 00:54:32,436
And use corrections as implicit


1782
00:54:32,436 --> 00:54:32,886
feedback.


1783
00:54:33,276 --> 00:54:34,446
Corrections work great as


1784
00:54:34,446 --> 00:54:36,076
implicit feedback to improve


1785
00:54:36,396 --> 00:54:37,766
your machine learning results.


1786
00:54:38,346 --> 00:54:41,566
So those are all the interface


1787
00:54:41,566 --> 00:54:42,676
patterns we wanted to show you


1788
00:54:42,676 --> 00:54:42,996
today.


1789
00:54:43,766 --> 00:54:45,026
As you can see, many of these


1790
00:54:45,026 --> 00:54:46,536
patterns leverage existing


1791
00:54:46,536 --> 00:54:48,216
interface elements we've had for


1792
00:54:48,216 --> 00:54:48,816
a long time.


1793
00:54:49,586 --> 00:54:51,436
Machine learning, therefore, is


1794
00:54:51,436 --> 00:54:52,916
an elevation of what we've been


1795
00:54:52,916 --> 00:54:53,756
doing all along.


1796
00:54:54,436 --> 00:54:55,236
These patterns are not


1797
00:54:55,236 --> 00:54:56,886
necessarily new but they are


1798
00:54:56,966 --> 00:54:57,976
applied in a new context.


1799
00:54:58,096 --> 00:55:00,536
And whenever we choose our


1800
00:55:00,536 --> 00:55:02,046
patterns, we have to make sure


1801
00:55:02,046 --> 00:55:03,446
we respect people's work.


1802
00:55:04,456 --> 00:55:06,266
Adding additional attribution or


1803
00:55:06,266 --> 00:55:08,246
additional feedback actions asks


1804
00:55:08,246 --> 00:55:09,496
even more information for


1805
00:55:09,496 --> 00:55:11,246
someone to parse and that


1806
00:55:11,246 --> 00:55:12,406
invades their attention and


1807
00:55:12,406 --> 00:55:13,996
might distract them from their


1808
00:55:13,996 --> 00:55:14,786
task at hand.


1809
00:55:15,536 --> 00:55:16,816
So choose your patterns with


1810
00:55:16,866 --> 00:55:18,466
people in mind first.


1811
00:55:18,946 --> 00:55:22,416
So designing a machine learning


1812
00:55:22,416 --> 00:55:23,786
experience is not just


1813
00:55:23,786 --> 00:55:24,946
outputting your results in an


1814
00:55:24,946 --> 00:55:25,446
interface.


1815
00:55:26,376 --> 00:55:27,626
The way we select our data,


1816
00:55:27,806 --> 00:55:29,526
metrics, inputs and outputs


1817
00:55:29,836 --> 00:55:31,546
plays a very important role in


1818
00:55:31,546 --> 00:55:32,746
making these experiences


1819
00:55:32,816 --> 00:55:34,856
understandable, intuitive and


1820
00:55:34,856 --> 00:55:35,256
delightful.


1821
00:55:35,906 --> 00:55:39,716
Now to end our talk, I want to


1822
00:55:39,716 --> 00:55:40,916
go back to something that Kayur


1823
00:55:40,916 --> 00:55:41,786
said in the beginning.


1824
00:55:42,796 --> 00:55:44,156
Apple uses machine learning to


1825
00:55:44,156 --> 00:55:45,906
create products and experiences


1826
00:55:46,186 --> 00:55:47,416
we could never create before,


1827
00:55:47,876 --> 00:55:49,136
products and experiences we


1828
00:55:49,186 --> 00:55:49,956
really care about.


1829
00:55:51,156 --> 00:55:52,236
You've seen examples of how


1830
00:55:52,236 --> 00:55:53,826
machine learning helps us manage


1831
00:55:53,826 --> 00:55:55,986
our attention, on how it allows


1832
00:55:55,986 --> 00:55:56,676
us to give you better


1833
00:55:56,676 --> 00:55:58,656
recommendations, on how it can


1834
00:55:58,656 --> 00:56:00,276
present contextual information


1835
00:56:00,276 --> 00:56:01,896
at the right time, and how we


1836
00:56:01,896 --> 00:56:03,946
can automate mundane tasks so


1837
00:56:04,156 --> 00:56:05,646
you can focus on what matters.


1838
00:56:06,446 --> 00:56:07,716
But machine learning can help us


1839
00:56:07,716 --> 00:56:09,086
achieve much more than that.


1840
00:56:10,356 --> 00:56:11,846
Apple has always used technology


1841
00:56:11,846 --> 00:56:13,886
to empower everyone and machine


1842
00:56:13,886 --> 00:56:15,486
learning only elevates that


1843
00:56:15,486 --> 00:56:16,116
capability.


1844
00:56:16,716 --> 00:56:19,416
It can empower us to be healthy


1845
00:56:19,736 --> 00:56:22,186
by measuring our activity and


1846
00:56:23,016 --> 00:56:25,746
our steps.


1847
00:56:25,936 --> 00:56:27,336
Machine learning allows us to be


1848
00:56:27,336 --> 00:56:29,206
more inclusive by leveraging our


1849
00:56:29,476 --> 00:56:31,426
communication, for example by


1850
00:56:31,426 --> 00:56:32,776
adding voice control to the


1851
00:56:32,776 --> 00:56:34,456
camera so a blind person can see


1852
00:56:34,456 --> 00:56:35,886
what they're holding or it can


1853
00:56:35,886 --> 00:56:37,336
know when their loved ones are


1854
00:56:38,116 --> 00:56:40,216
in frame.


1855
00:56:40,396 --> 00:56:41,566
Machine learning helps us to be


1856
00:56:41,566 --> 00:56:43,416
safe by detecting problems with


1857
00:56:43,416 --> 00:56:46,016
our heart by measuring our heart


1858
00:56:46,016 --> 00:56:48,126
beats or an ECG.


1859
00:56:48,346 --> 00:56:49,976
And lastly, it can allow us to


1860
00:56:49,976 --> 00:56:51,656
be creative by seeing the world


1861
00:56:51,656 --> 00:56:53,606
in a whole new way, for example


1862
00:56:53,606 --> 00:56:54,856
by letting a known tool like a


1863
00:56:54,856 --> 00:56:56,946
pencil do magic things on


1864
00:56:56,946 --> 00:56:57,286
screen.


1865
00:56:58,896 --> 00:57:00,926
So you can see when we align the


1866
00:57:00,926 --> 00:57:02,836
we create with the values we


1867
00:57:02,836 --> 00:57:04,246
uphold, we can create


1868
00:57:04,246 --> 00:57:05,786
experiences that really elevate


1869
00:57:05,846 --> 00:57:06,766
the best of humanity.


1870
00:57:07,316 --> 00:57:09,186
That's everything we had in


1871
00:57:09,186 --> 00:57:10,516
store for you and we hope we've


1872
00:57:10,566 --> 00:57:11,986
given you plenty of inspiration,


1873
00:57:11,986 --> 00:57:13,576
insight into designing great


1874
00:57:13,576 --> 00:57:14,716
machine learning experiences.


1875
00:57:15,806 --> 00:57:17,086
All the patterns we talked about


1876
00:57:17,086 --> 00:57:18,646
and more are available on the


1877
00:57:18,646 --> 00:57:20,456
Human Interface Guidelines as a


1878
00:57:21,066 --> 00:57:21,196
beta.


1879
00:57:21,876 --> 00:57:23,416
There are still a few more talks


1880
00:57:23,416 --> 00:57:24,556
this afternoon about machine


1881
00:57:24,556 --> 00:57:26,026
learning and all of us will be


1882
00:57:26,026 --> 00:57:28,196
available in the coming hour at


1883
00:57:28,196 --> 00:57:29,546
the User Interface Design Lab to


1884
00:57:29,546 --> 00:57:30,706
answer any questions you might


1885
00:57:30,706 --> 00:57:30,946
have.


1886
00:57:31,226 --> 00:57:32,916
So make sure to come by and say


1887
00:57:32,916 --> 00:57:33,146
hi.


1888
00:57:33,866 --> 00:57:34,936
Thank you all for attending and


1889
00:57:34,936 --> 00:57:35,966
enjoy the last day of WWDC.


1890
00:57:36,016 --> 00:57:38,000
[ Applause ]

